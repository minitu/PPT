//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-24330188
// Cuda compilation tools, release 9.2, V9.2.148
// Based on LLVM 3.4svn
//

.version 6.2
.target sm_70
.address_size 64

	// .weak	cudaMalloc
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
;
.const .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.weak .func  (.param .b32 func_retval0) cudaMalloc(
	.param .b64 cudaMalloc_param_0,
	.param .b64 cudaMalloc_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaFuncGetAttributes
.weak .func  (.param .b32 func_retval0) cudaFuncGetAttributes(
	.param .b64 cudaFuncGetAttributes_param_0,
	.param .b64 cudaFuncGetAttributes_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaDeviceGetAttribute
.weak .func  (.param .b32 func_retval0) cudaDeviceGetAttribute(
	.param .b64 cudaDeviceGetAttribute_param_0,
	.param .b32 cudaDeviceGetAttribute_param_1,
	.param .b32 cudaDeviceGetAttribute_param_2
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaGetDevice
.weak .func  (.param .b32 func_retval0) cudaGetDevice(
	.param .b64 cudaGetDevice_param_0
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessor
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessor(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_3
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_3,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_4
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_Z14VerySmoothBumpddPdiPii
.visible .func  (.param .b64 func_retval0) _Z14VerySmoothBumpddPdiPii(
	.param .b64 _Z14VerySmoothBumpddPdiPii_param_0,
	.param .b64 _Z14VerySmoothBumpddPdiPii_param_1,
	.param .b64 _Z14VerySmoothBumpddPdiPii_param_2,
	.param .b32 _Z14VerySmoothBumpddPdiPii_param_3,
	.param .b64 _Z14VerySmoothBumpddPdiPii_param_4,
	.param .b32 _Z14VerySmoothBumpddPdiPii_param_5
)
{
	.reg .pred 	%p<111>;
	.reg .b32 	%r<164>;
	.reg .f64 	%fd<127>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd70, [_Z14VerySmoothBumpddPdiPii_param_0];
	ld.param.f64 	%fd71, [_Z14VerySmoothBumpddPdiPii_param_1];
	mul.f64 	%fd1, %fd70, %fd71;
	setp.lt.f64	%p7, %fd1, 0d0000000000000000;
	setp.gt.f64	%p8, %fd1, 0d3FF0000000000000;
	or.pred  	%p9, %p7, %p8;
	mov.f64 	%fd126, 0d0000000000000000;
	@%p9 bra 	BB6_98;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd72, 0d4024000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd72;
	}
	bfe.u32 	%r8, %r2, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd7, 4621819117588971520;
	shl.b64 	%rd1, %rd7, %r9;
	setp.eq.s64	%p10, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd109, [retval0+0];
	
	//{
	}// Callseq End 0
	setp.lt.s32	%p11, %r1, 0;
	and.pred  	%p1, %p11, %p10;
	@!%p1 bra 	BB6_3;
	bra.uni 	BB6_2;

BB6_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd109;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd109;
	}
	mov.b64 	%fd109, {%r12, %r11};

BB6_3:
	setp.eq.f64	%p12, %fd1, 0d0000000000000000;
	@%p12 bra 	BB6_6;
	bra.uni 	BB6_4;

BB6_6:
	selp.b32	%r13, %r1, 0, %p10;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r15, %r14, %r13, %p16;
	mov.u32 	%r16, 0;
	mov.b64 	%fd109, {%r16, %r15};
	bra.uni 	BB6_7;

BB6_4:
	setp.gt.s32	%p13, %r1, -1;
	@%p13 bra 	BB6_7;

	cvt.rzi.f64.f64	%fd74, %fd72;
	setp.neu.f64	%p14, %fd74, 0d4024000000000000;
	selp.f64	%fd109, 0dFFF8000000000000, %fd109, %p14;

BB6_7:
	add.f64 	%fd110, %fd1, 0d4024000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd110;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p17, %r18, 2146435072;
	@%p17 bra 	BB6_8;

	setp.gtu.f64	%p18, %fd2, 0d7FF0000000000000;
	@%p18 bra 	BB6_17;

	and.b32  	%r19, %r2, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB6_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd72;
	}
	setp.eq.s32	%p20, %r20, 0;
	@%p20 bra 	BB6_16;

BB6_12:
	and.b32  	%r21, %r1, 2147483647;
	setp.ne.s32	%p21, %r21, 2146435072;
	@%p21 bra 	BB6_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd1;
	}
	setp.ne.s32	%p22, %r22, 0;
	mov.f64 	%fd110, %fd109;
	@%p22 bra 	BB6_17;

	shr.s32 	%r23, %r2, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd110, {%r28, %r27};
	bra.uni 	BB6_17;

BB6_8:
	mov.f64 	%fd110, %fd109;
	bra.uni 	BB6_17;

BB6_13:
	mov.f64 	%fd110, %fd109;
	bra.uni 	BB6_17;

BB6_16:
	setp.gt.f64	%p23, %fd2, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p23;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p24, %r2, 0;
	selp.b32	%r31, %r30, %r29, %p24;
	setp.eq.f64	%p25, %fd1, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p25;
	mov.u32 	%r33, 0;
	mov.b64 	%fd110, {%r33, %r32};

BB6_17:
	mov.f64 	%fd76, 0d4022000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd8, 4621256167635550208;
	shl.b64 	%rd2, %rd8, %r35;
	setp.eq.s64	%p26, %rd2, -9223372036854775808;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd112, [retval0+0];
	
	//{
	}// Callseq End 1
	and.pred  	%p2, %p11, %p26;
	@!%p2 bra 	BB6_19;
	bra.uni 	BB6_18;

BB6_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd112;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd112;
	}
	mov.b64 	%fd112, {%r38, %r37};

BB6_19:
	@%p12 bra 	BB6_22;
	bra.uni 	BB6_20;

BB6_22:
	selp.b32	%r39, %r1, 0, %p26;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p32, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p32;
	mov.u32 	%r42, 0;
	mov.b64 	%fd112, {%r42, %r41};
	bra.uni 	BB6_23;

BB6_20:
	setp.gt.s32	%p29, %r1, -1;
	@%p29 bra 	BB6_23;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p30, %fd78, 0d4022000000000000;
	selp.f64	%fd112, 0dFFF8000000000000, %fd112, %p30;

BB6_23:
	add.f64 	%fd113, %fd1, 0d4022000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd113;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB6_24;

	setp.gtu.f64	%p34, %fd2, 0d7FF0000000000000;
	@%p34 bra 	BB6_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB6_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd76;
	}
	setp.eq.s32	%p36, %r46, 0;
	@%p36 bra 	BB6_32;

BB6_28:
	and.b32  	%r47, %r1, 2147483647;
	setp.ne.s32	%p37, %r47, 2146435072;
	@%p37 bra 	BB6_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p38, %r48, 0;
	mov.f64 	%fd113, %fd112;
	@%p38 bra 	BB6_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd113, {%r54, %r53};
	bra.uni 	BB6_33;

BB6_24:
	mov.f64 	%fd113, %fd112;
	bra.uni 	BB6_33;

BB6_29:
	mov.f64 	%fd113, %fd112;
	bra.uni 	BB6_33;

BB6_32:
	setp.gt.f64	%p39, %fd2, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p39;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p40, %r3, 0;
	selp.b32	%r57, %r56, %r55, %p40;
	setp.eq.f64	%p41, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p41;
	mov.u32 	%r59, 0;
	mov.b64 	%fd113, {%r59, %r58};

BB6_33:
	mul.f64 	%fd80, %fd113, 0d40B4000000000000;
	setp.eq.f64	%p42, %fd1, 0d3FF0000000000000;
	selp.f64	%fd81, 0d40B4000000000000, %fd80, %p42;
	mul.f64 	%fd82, %fd110, 0dC090000000000000;
	selp.f64	%fd83, 0dC090000000000000, %fd82, %p42;
	add.f64 	%fd23, %fd83, %fd81;
	mov.f64 	%fd84, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd84;
	}
	bfe.u32 	%r60, %r4, 20, 11;
	add.s32 	%r61, %r60, -1012;
	mov.u64 	%rd9, 4620693217682128896;
	shl.b64 	%rd3, %rd9, %r61;
	setp.eq.s64	%p43, %rd3, -9223372036854775808;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd115, [retval0+0];
	
	//{
	}// Callseq End 2
	and.pred  	%p3, %p11, %p43;
	@!%p3 bra 	BB6_35;
	bra.uni 	BB6_34;

BB6_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd115;
	}
	xor.b32  	%r63, %r62, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd115;
	}
	mov.b64 	%fd115, {%r64, %r63};

BB6_35:
	@%p12 bra 	BB6_38;
	bra.uni 	BB6_36;

BB6_38:
	selp.b32	%r65, %r1, 0, %p43;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p49, %r4, 0;
	selp.b32	%r67, %r66, %r65, %p49;
	mov.u32 	%r68, 0;
	mov.b64 	%fd115, {%r68, %r67};
	bra.uni 	BB6_39;

BB6_36:
	setp.gt.s32	%p46, %r1, -1;
	@%p46 bra 	BB6_39;

	cvt.rzi.f64.f64	%fd86, %fd84;
	setp.neu.f64	%p47, %fd86, 0d4020000000000000;
	selp.f64	%fd115, 0dFFF8000000000000, %fd115, %p47;

BB6_39:
	add.f64 	%fd116, %fd1, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd116;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p50, %r70, 2146435072;
	@%p50 bra 	BB6_40;

	setp.gtu.f64	%p51, %fd2, 0d7FF0000000000000;
	@%p51 bra 	BB6_49;

	and.b32  	%r71, %r4, 2147483647;
	setp.ne.s32	%p52, %r71, 2146435072;
	@%p52 bra 	BB6_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd84;
	}
	setp.eq.s32	%p53, %r72, 0;
	@%p53 bra 	BB6_48;

BB6_44:
	and.b32  	%r73, %r1, 2147483647;
	setp.ne.s32	%p54, %r73, 2146435072;
	@%p54 bra 	BB6_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd1;
	}
	setp.ne.s32	%p55, %r74, 0;
	mov.f64 	%fd116, %fd115;
	@%p55 bra 	BB6_49;

	shr.s32 	%r75, %r4, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd116, {%r80, %r79};
	bra.uni 	BB6_49;

BB6_40:
	mov.f64 	%fd116, %fd115;
	bra.uni 	BB6_49;

BB6_45:
	mov.f64 	%fd116, %fd115;
	bra.uni 	BB6_49;

BB6_48:
	setp.gt.f64	%p56, %fd2, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p56;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p57, %r4, 0;
	selp.b32	%r83, %r82, %r81, %p57;
	setp.eq.f64	%p58, %fd1, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p58;
	mov.u32 	%r85, 0;
	mov.b64 	%fd116, {%r85, %r84};

BB6_49:
	mul.f64 	%fd88, %fd116, 0d40C4000000000000;
	selp.f64	%fd89, 0d40C4000000000000, %fd88, %p42;
	sub.f64 	%fd34, %fd23, %fd89;
	mov.f64 	%fd90, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd90;
	}
	bfe.u32 	%r86, %r5, 20, 11;
	add.s32 	%r87, %r86, -1012;
	mov.u64 	%rd10, 4619567317775286272;
	shl.b64 	%rd4, %rd10, %r87;
	setp.eq.s64	%p60, %rd4, -9223372036854775808;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd118, [retval0+0];
	
	//{
	}// Callseq End 3
	and.pred  	%p4, %p11, %p60;
	@!%p4 bra 	BB6_51;
	bra.uni 	BB6_50;

BB6_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd118;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd118;
	}
	mov.b64 	%fd118, {%r90, %r89};

BB6_51:
	@%p12 bra 	BB6_54;
	bra.uni 	BB6_52;

BB6_54:
	selp.b32	%r91, %r1, 0, %p60;
	or.b32  	%r92, %r91, 2146435072;
	setp.lt.s32	%p66, %r5, 0;
	selp.b32	%r93, %r92, %r91, %p66;
	mov.u32 	%r94, 0;
	mov.b64 	%fd118, {%r94, %r93};
	bra.uni 	BB6_55;

BB6_52:
	setp.gt.s32	%p63, %r1, -1;
	@%p63 bra 	BB6_55;

	cvt.rzi.f64.f64	%fd92, %fd90;
	setp.neu.f64	%p64, %fd92, 0d401C000000000000;
	selp.f64	%fd118, 0dFFF8000000000000, %fd118, %p64;

BB6_55:
	add.f64 	%fd119, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd119;
	}
	and.b32  	%r96, %r95, 2146435072;
	setp.ne.s32	%p67, %r96, 2146435072;
	@%p67 bra 	BB6_56;

	setp.gtu.f64	%p68, %fd2, 0d7FF0000000000000;
	@%p68 bra 	BB6_65;

	and.b32  	%r97, %r5, 2147483647;
	setp.ne.s32	%p69, %r97, 2146435072;
	@%p69 bra 	BB6_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd90;
	}
	setp.eq.s32	%p70, %r98, 0;
	@%p70 bra 	BB6_64;

BB6_60:
	and.b32  	%r99, %r1, 2147483647;
	setp.ne.s32	%p71, %r99, 2146435072;
	@%p71 bra 	BB6_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd1;
	}
	setp.ne.s32	%p72, %r100, 0;
	mov.f64 	%fd119, %fd118;
	@%p72 bra 	BB6_65;

	shr.s32 	%r101, %r5, 31;
	and.b32  	%r102, %r101, -2146435072;
	add.s32 	%r103, %r102, 2146435072;
	or.b32  	%r104, %r103, -2147483648;
	selp.b32	%r105, %r104, %r103, %p4;
	mov.u32 	%r106, 0;
	mov.b64 	%fd119, {%r106, %r105};
	bra.uni 	BB6_65;

BB6_56:
	mov.f64 	%fd119, %fd118;
	bra.uni 	BB6_65;

BB6_61:
	mov.f64 	%fd119, %fd118;
	bra.uni 	BB6_65;

BB6_64:
	setp.gt.f64	%p73, %fd2, 0d3FF0000000000000;
	selp.b32	%r107, 2146435072, 0, %p73;
	xor.b32  	%r108, %r107, 2146435072;
	setp.lt.s32	%p74, %r5, 0;
	selp.b32	%r109, %r108, %r107, %p74;
	setp.eq.f64	%p75, %fd1, 0dBFF0000000000000;
	selp.b32	%r110, 1072693248, %r109, %p75;
	mov.u32 	%r111, 0;
	mov.b64 	%fd119, {%r111, %r110};

BB6_65:
	mul.f64 	%fd94, %fd119, 0d40C4000000000000;
	selp.f64	%fd95, 0d40C4000000000000, %fd94, %p42;
	add.f64 	%fd45, %fd34, %fd95;
	mov.f64 	%fd96, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd96;
	}
	bfe.u32 	%r112, %r6, 20, 11;
	add.s32 	%r113, %r112, -1012;
	mov.u64 	%rd11, 4618441417868443648;
	shl.b64 	%rd5, %rd11, %r113;
	setp.eq.s64	%p77, %rd5, -9223372036854775808;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd121, [retval0+0];
	
	//{
	}// Callseq End 4
	and.pred  	%p5, %p11, %p77;
	@!%p5 bra 	BB6_67;
	bra.uni 	BB6_66;

BB6_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd121;
	}
	xor.b32  	%r115, %r114, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd121;
	}
	mov.b64 	%fd121, {%r116, %r115};

BB6_67:
	@%p12 bra 	BB6_70;
	bra.uni 	BB6_68;

BB6_70:
	selp.b32	%r117, %r1, 0, %p77;
	or.b32  	%r118, %r117, 2146435072;
	setp.lt.s32	%p83, %r6, 0;
	selp.b32	%r119, %r118, %r117, %p83;
	mov.u32 	%r120, 0;
	mov.b64 	%fd121, {%r120, %r119};
	bra.uni 	BB6_71;

BB6_68:
	setp.gt.s32	%p80, %r1, -1;
	@%p80 bra 	BB6_71;

	cvt.rzi.f64.f64	%fd98, %fd96;
	setp.neu.f64	%p81, %fd98, 0d4018000000000000;
	selp.f64	%fd121, 0dFFF8000000000000, %fd121, %p81;

BB6_71:
	add.f64 	%fd122, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd122;
	}
	and.b32  	%r122, %r121, 2146435072;
	setp.ne.s32	%p84, %r122, 2146435072;
	@%p84 bra 	BB6_72;

	setp.gtu.f64	%p85, %fd2, 0d7FF0000000000000;
	@%p85 bra 	BB6_81;

	and.b32  	%r123, %r6, 2147483647;
	setp.ne.s32	%p86, %r123, 2146435072;
	@%p86 bra 	BB6_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd96;
	}
	setp.eq.s32	%p87, %r124, 0;
	@%p87 bra 	BB6_80;

BB6_76:
	and.b32  	%r125, %r1, 2147483647;
	setp.ne.s32	%p88, %r125, 2146435072;
	@%p88 bra 	BB6_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd1;
	}
	setp.ne.s32	%p89, %r126, 0;
	mov.f64 	%fd122, %fd121;
	@%p89 bra 	BB6_81;

	shr.s32 	%r127, %r6, 31;
	and.b32  	%r128, %r127, -2146435072;
	add.s32 	%r129, %r128, 2146435072;
	or.b32  	%r130, %r129, -2147483648;
	selp.b32	%r131, %r130, %r129, %p5;
	mov.u32 	%r132, 0;
	mov.b64 	%fd122, {%r132, %r131};
	bra.uni 	BB6_81;

BB6_72:
	mov.f64 	%fd122, %fd121;
	bra.uni 	BB6_81;

BB6_77:
	mov.f64 	%fd122, %fd121;
	bra.uni 	BB6_81;

BB6_80:
	setp.gt.f64	%p90, %fd2, 0d3FF0000000000000;
	selp.b32	%r133, 2146435072, 0, %p90;
	xor.b32  	%r134, %r133, 2146435072;
	setp.lt.s32	%p91, %r6, 0;
	selp.b32	%r135, %r134, %r133, %p91;
	setp.eq.f64	%p92, %fd1, 0dBFF0000000000000;
	selp.b32	%r136, 1072693248, %r135, %p92;
	mov.u32 	%r137, 0;
	mov.b64 	%fd122, {%r137, %r136};

BB6_81:
	mul.f64 	%fd100, %fd122, 0d40B4000000000000;
	selp.f64	%fd101, 0d40B4000000000000, %fd100, %p42;
	sub.f64 	%fd56, %fd45, %fd101;
	mov.f64 	%fd102, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd102;
	}
	bfe.u32 	%r138, %r7, 20, 11;
	add.s32 	%r139, %r138, -1012;
	mov.u64 	%rd12, 4617315517961601024;
	shl.b64 	%rd6, %rd12, %r139;
	setp.eq.s64	%p94, %rd6, -9223372036854775808;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd124, [retval0+0];
	
	//{
	}// Callseq End 5
	and.pred  	%p6, %p11, %p94;
	@!%p6 bra 	BB6_83;
	bra.uni 	BB6_82;

BB6_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd124;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd124;
	}
	mov.b64 	%fd124, {%r142, %r141};

BB6_83:
	@%p12 bra 	BB6_86;
	bra.uni 	BB6_84;

BB6_86:
	selp.b32	%r143, %r1, 0, %p94;
	or.b32  	%r144, %r143, 2146435072;
	setp.lt.s32	%p100, %r7, 0;
	selp.b32	%r145, %r144, %r143, %p100;
	mov.u32 	%r146, 0;
	mov.b64 	%fd124, {%r146, %r145};
	bra.uni 	BB6_87;

BB6_84:
	setp.gt.s32	%p97, %r1, -1;
	@%p97 bra 	BB6_87;

	cvt.rzi.f64.f64	%fd104, %fd102;
	setp.neu.f64	%p98, %fd104, 0d4014000000000000;
	selp.f64	%fd124, 0dFFF8000000000000, %fd124, %p98;

BB6_87:
	add.f64 	%fd125, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd125;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32	%p101, %r148, 2146435072;
	@%p101 bra 	BB6_88;

	setp.gtu.f64	%p102, %fd2, 0d7FF0000000000000;
	@%p102 bra 	BB6_97;

	and.b32  	%r149, %r7, 2147483647;
	setp.ne.s32	%p103, %r149, 2146435072;
	@%p103 bra 	BB6_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd102;
	}
	setp.eq.s32	%p104, %r150, 0;
	@%p104 bra 	BB6_96;

BB6_92:
	and.b32  	%r151, %r1, 2147483647;
	setp.ne.s32	%p105, %r151, 2146435072;
	@%p105 bra 	BB6_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd1;
	}
	setp.ne.s32	%p106, %r152, 0;
	mov.f64 	%fd125, %fd124;
	@%p106 bra 	BB6_97;

	shr.s32 	%r153, %r7, 31;
	and.b32  	%r154, %r153, -2146435072;
	add.s32 	%r155, %r154, 2146435072;
	or.b32  	%r156, %r155, -2147483648;
	selp.b32	%r157, %r156, %r155, %p6;
	mov.u32 	%r158, 0;
	mov.b64 	%fd125, {%r158, %r157};
	bra.uni 	BB6_97;

BB6_88:
	mov.f64 	%fd125, %fd124;
	bra.uni 	BB6_97;

BB6_93:
	mov.f64 	%fd125, %fd124;
	bra.uni 	BB6_97;

BB6_96:
	setp.gt.f64	%p107, %fd2, 0d3FF0000000000000;
	selp.b32	%r159, 2146435072, 0, %p107;
	xor.b32  	%r160, %r159, 2146435072;
	setp.lt.s32	%p108, %r7, 0;
	selp.b32	%r161, %r160, %r159, %p108;
	setp.eq.f64	%p109, %fd1, 0dBFF0000000000000;
	selp.b32	%r162, 1072693248, %r161, %p109;
	mov.u32 	%r163, 0;
	mov.b64 	%fd125, {%r163, %r162};

BB6_97:
	mul.f64 	%fd106, %fd125, 0d4090000000000000;
	selp.f64	%fd107, 0d4090000000000000, %fd106, %p42;
	add.f64 	%fd126, %fd56, %fd107;

BB6_98:
	st.param.f64	[func_retval0+0], %fd126;
	ret;
}

	// .globl	_Z16VerySmoothBump_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16VerySmoothBump_tddPdiPii(
	.param .b64 _Z16VerySmoothBump_tddPdiPii_param_0,
	.param .b64 _Z16VerySmoothBump_tddPdiPii_param_1,
	.param .b64 _Z16VerySmoothBump_tddPdiPii_param_2,
	.param .b32 _Z16VerySmoothBump_tddPdiPii_param_3,
	.param .b64 _Z16VerySmoothBump_tddPdiPii_param_4,
	.param .b32 _Z16VerySmoothBump_tddPdiPii_param_5
)
{
	.reg .pred 	%p<111>;
	.reg .b32 	%r<164>;
	.reg .f64 	%fd<128>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd69, [_Z16VerySmoothBump_tddPdiPii_param_0];
	ld.param.f64 	%fd71, [_Z16VerySmoothBump_tddPdiPii_param_1];
	mul.f64 	%fd1, %fd69, %fd71;
	setp.lt.f64	%p7, %fd1, 0d0000000000000000;
	setp.gt.f64	%p8, %fd1, 0d3FF0000000000000;
	or.pred  	%p9, %p7, %p8;
	mov.f64 	%fd127, 0d0000000000000000;
	@%p9 bra 	BB7_98;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd72, 0d4022000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd72;
	}
	bfe.u32 	%r8, %r2, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd7, 4621256167635550208;
	shl.b64 	%rd1, %rd7, %r9;
	setp.eq.s64	%p10, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd110, [retval0+0];
	
	//{
	}// Callseq End 6
	setp.lt.s32	%p11, %r1, 0;
	and.pred  	%p1, %p11, %p10;
	@!%p1 bra 	BB7_3;
	bra.uni 	BB7_2;

BB7_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd110;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd110;
	}
	mov.b64 	%fd110, {%r12, %r11};

BB7_3:
	setp.eq.f64	%p12, %fd1, 0d0000000000000000;
	@%p12 bra 	BB7_6;
	bra.uni 	BB7_4;

BB7_6:
	selp.b32	%r13, %r1, 0, %p10;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r15, %r14, %r13, %p16;
	mov.u32 	%r16, 0;
	mov.b64 	%fd110, {%r16, %r15};
	bra.uni 	BB7_7;

BB7_4:
	setp.gt.s32	%p13, %r1, -1;
	@%p13 bra 	BB7_7;

	cvt.rzi.f64.f64	%fd74, %fd72;
	setp.neu.f64	%p14, %fd74, 0d4022000000000000;
	selp.f64	%fd110, 0dFFF8000000000000, %fd110, %p14;

BB7_7:
	add.f64 	%fd111, %fd1, 0d4022000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd111;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p17, %r18, 2146435072;
	@%p17 bra 	BB7_8;

	setp.gtu.f64	%p18, %fd2, 0d7FF0000000000000;
	@%p18 bra 	BB7_17;

	and.b32  	%r19, %r2, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB7_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd72;
	}
	setp.eq.s32	%p20, %r20, 0;
	@%p20 bra 	BB7_16;

BB7_12:
	and.b32  	%r21, %r1, 2147483647;
	setp.ne.s32	%p21, %r21, 2146435072;
	@%p21 bra 	BB7_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd1;
	}
	setp.ne.s32	%p22, %r22, 0;
	mov.f64 	%fd111, %fd110;
	@%p22 bra 	BB7_17;

	shr.s32 	%r23, %r2, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd111, {%r28, %r27};
	bra.uni 	BB7_17;

BB7_8:
	mov.f64 	%fd111, %fd110;
	bra.uni 	BB7_17;

BB7_13:
	mov.f64 	%fd111, %fd110;
	bra.uni 	BB7_17;

BB7_16:
	setp.gt.f64	%p23, %fd2, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p23;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p24, %r2, 0;
	selp.b32	%r31, %r30, %r29, %p24;
	setp.eq.f64	%p25, %fd1, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p25;
	mov.u32 	%r33, 0;
	mov.b64 	%fd111, {%r33, %r32};

BB7_17:
	mov.f64 	%fd76, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd8, 4620693217682128896;
	shl.b64 	%rd2, %rd8, %r35;
	setp.eq.s64	%p26, %rd2, -9223372036854775808;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd113, [retval0+0];
	
	//{
	}// Callseq End 7
	and.pred  	%p2, %p11, %p26;
	@!%p2 bra 	BB7_19;
	bra.uni 	BB7_18;

BB7_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd113;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd113;
	}
	mov.b64 	%fd113, {%r38, %r37};

BB7_19:
	@%p12 bra 	BB7_22;
	bra.uni 	BB7_20;

BB7_22:
	selp.b32	%r39, %r1, 0, %p26;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p32, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p32;
	mov.u32 	%r42, 0;
	mov.b64 	%fd113, {%r42, %r41};
	bra.uni 	BB7_23;

BB7_20:
	setp.gt.s32	%p29, %r1, -1;
	@%p29 bra 	BB7_23;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p30, %fd78, 0d4020000000000000;
	selp.f64	%fd113, 0dFFF8000000000000, %fd113, %p30;

BB7_23:
	add.f64 	%fd114, %fd1, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd114;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB7_24;

	setp.gtu.f64	%p34, %fd2, 0d7FF0000000000000;
	@%p34 bra 	BB7_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB7_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd76;
	}
	setp.eq.s32	%p36, %r46, 0;
	@%p36 bra 	BB7_32;

BB7_28:
	and.b32  	%r47, %r1, 2147483647;
	setp.ne.s32	%p37, %r47, 2146435072;
	@%p37 bra 	BB7_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p38, %r48, 0;
	mov.f64 	%fd114, %fd113;
	@%p38 bra 	BB7_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd114, {%r54, %r53};
	bra.uni 	BB7_33;

BB7_24:
	mov.f64 	%fd114, %fd113;
	bra.uni 	BB7_33;

BB7_29:
	mov.f64 	%fd114, %fd113;
	bra.uni 	BB7_33;

BB7_32:
	setp.gt.f64	%p39, %fd2, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p39;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p40, %r3, 0;
	selp.b32	%r57, %r56, %r55, %p40;
	setp.eq.f64	%p41, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p41;
	mov.u32 	%r59, 0;
	mov.b64 	%fd114, {%r59, %r58};

BB7_33:
	mul.f64 	%fd80, %fd114, 0d40E6800000000000;
	setp.eq.f64	%p42, %fd1, 0d3FF0000000000000;
	selp.f64	%fd81, 0d40E6800000000000, %fd80, %p42;
	mul.f64 	%fd82, %fd111, 0dC0C4000000000000;
	selp.f64	%fd83, 0dC0C4000000000000, %fd82, %p42;
	add.f64 	%fd23, %fd83, %fd81;
	mov.f64 	%fd84, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd84;
	}
	bfe.u32 	%r60, %r4, 20, 11;
	add.s32 	%r61, %r60, -1012;
	mov.u64 	%rd9, 4619567317775286272;
	shl.b64 	%rd3, %rd9, %r61;
	setp.eq.s64	%p43, %rd3, -9223372036854775808;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd116, [retval0+0];
	
	//{
	}// Callseq End 8
	and.pred  	%p3, %p11, %p43;
	@!%p3 bra 	BB7_35;
	bra.uni 	BB7_34;

BB7_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd116;
	}
	xor.b32  	%r63, %r62, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd116;
	}
	mov.b64 	%fd116, {%r64, %r63};

BB7_35:
	@%p12 bra 	BB7_38;
	bra.uni 	BB7_36;

BB7_38:
	selp.b32	%r65, %r1, 0, %p43;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p49, %r4, 0;
	selp.b32	%r67, %r66, %r65, %p49;
	mov.u32 	%r68, 0;
	mov.b64 	%fd116, {%r68, %r67};
	bra.uni 	BB7_39;

BB7_36:
	setp.gt.s32	%p46, %r1, -1;
	@%p46 bra 	BB7_39;

	cvt.rzi.f64.f64	%fd86, %fd84;
	setp.neu.f64	%p47, %fd86, 0d401C000000000000;
	selp.f64	%fd116, 0dFFF8000000000000, %fd116, %p47;

BB7_39:
	add.f64 	%fd117, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd117;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p50, %r70, 2146435072;
	@%p50 bra 	BB7_40;

	setp.gtu.f64	%p51, %fd2, 0d7FF0000000000000;
	@%p51 bra 	BB7_49;

	and.b32  	%r71, %r4, 2147483647;
	setp.ne.s32	%p52, %r71, 2146435072;
	@%p52 bra 	BB7_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd84;
	}
	setp.eq.s32	%p53, %r72, 0;
	@%p53 bra 	BB7_48;

BB7_44:
	and.b32  	%r73, %r1, 2147483647;
	setp.ne.s32	%p54, %r73, 2146435072;
	@%p54 bra 	BB7_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd1;
	}
	setp.ne.s32	%p55, %r74, 0;
	mov.f64 	%fd117, %fd116;
	@%p55 bra 	BB7_49;

	shr.s32 	%r75, %r4, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd117, {%r80, %r79};
	bra.uni 	BB7_49;

BB7_40:
	mov.f64 	%fd117, %fd116;
	bra.uni 	BB7_49;

BB7_45:
	mov.f64 	%fd117, %fd116;
	bra.uni 	BB7_49;

BB7_48:
	setp.gt.f64	%p56, %fd2, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p56;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p57, %r4, 0;
	selp.b32	%r83, %r82, %r81, %p57;
	setp.eq.f64	%p58, %fd1, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p58;
	mov.u32 	%r85, 0;
	mov.b64 	%fd117, {%r85, %r84};

BB7_49:
	mul.f64 	%fd88, %fd117, 0d40F4000000000000;
	selp.f64	%fd89, 0d40F4000000000000, %fd88, %p42;
	sub.f64 	%fd34, %fd23, %fd89;
	mov.f64 	%fd90, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd90;
	}
	bfe.u32 	%r86, %r5, 20, 11;
	add.s32 	%r87, %r86, -1012;
	mov.u64 	%rd10, 4618441417868443648;
	shl.b64 	%rd4, %rd10, %r87;
	setp.eq.s64	%p60, %rd4, -9223372036854775808;
	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd119, [retval0+0];
	
	//{
	}// Callseq End 9
	and.pred  	%p4, %p11, %p60;
	@!%p4 bra 	BB7_51;
	bra.uni 	BB7_50;

BB7_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd119;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd119;
	}
	mov.b64 	%fd119, {%r90, %r89};

BB7_51:
	@%p12 bra 	BB7_54;
	bra.uni 	BB7_52;

BB7_54:
	selp.b32	%r91, %r1, 0, %p60;
	or.b32  	%r92, %r91, 2146435072;
	setp.lt.s32	%p66, %r5, 0;
	selp.b32	%r93, %r92, %r91, %p66;
	mov.u32 	%r94, 0;
	mov.b64 	%fd119, {%r94, %r93};
	bra.uni 	BB7_55;

BB7_52:
	setp.gt.s32	%p63, %r1, -1;
	@%p63 bra 	BB7_55;

	cvt.rzi.f64.f64	%fd92, %fd90;
	setp.neu.f64	%p64, %fd92, 0d4018000000000000;
	selp.f64	%fd119, 0dFFF8000000000000, %fd119, %p64;

BB7_55:
	add.f64 	%fd120, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd120;
	}
	and.b32  	%r96, %r95, 2146435072;
	setp.ne.s32	%p67, %r96, 2146435072;
	@%p67 bra 	BB7_56;

	setp.gtu.f64	%p68, %fd2, 0d7FF0000000000000;
	@%p68 bra 	BB7_65;

	and.b32  	%r97, %r5, 2147483647;
	setp.ne.s32	%p69, %r97, 2146435072;
	@%p69 bra 	BB7_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd90;
	}
	setp.eq.s32	%p70, %r98, 0;
	@%p70 bra 	BB7_64;

BB7_60:
	and.b32  	%r99, %r1, 2147483647;
	setp.ne.s32	%p71, %r99, 2146435072;
	@%p71 bra 	BB7_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd1;
	}
	setp.ne.s32	%p72, %r100, 0;
	mov.f64 	%fd120, %fd119;
	@%p72 bra 	BB7_65;

	shr.s32 	%r101, %r5, 31;
	and.b32  	%r102, %r101, -2146435072;
	add.s32 	%r103, %r102, 2146435072;
	or.b32  	%r104, %r103, -2147483648;
	selp.b32	%r105, %r104, %r103, %p4;
	mov.u32 	%r106, 0;
	mov.b64 	%fd120, {%r106, %r105};
	bra.uni 	BB7_65;

BB7_56:
	mov.f64 	%fd120, %fd119;
	bra.uni 	BB7_65;

BB7_61:
	mov.f64 	%fd120, %fd119;
	bra.uni 	BB7_65;

BB7_64:
	setp.gt.f64	%p73, %fd2, 0d3FF0000000000000;
	selp.b32	%r107, 2146435072, 0, %p73;
	xor.b32  	%r108, %r107, 2146435072;
	setp.lt.s32	%p74, %r5, 0;
	selp.b32	%r109, %r108, %r107, %p74;
	setp.eq.f64	%p75, %fd1, 0dBFF0000000000000;
	selp.b32	%r110, 1072693248, %r109, %p75;
	mov.u32 	%r111, 0;
	mov.b64 	%fd120, {%r111, %r110};

BB7_65:
	mul.f64 	%fd94, %fd120, 0d40F1800000000000;
	selp.f64	%fd95, 0d40F1800000000000, %fd94, %p42;
	add.f64 	%fd45, %fd34, %fd95;
	mov.f64 	%fd96, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd96;
	}
	bfe.u32 	%r112, %r6, 20, 11;
	add.s32 	%r113, %r112, -1012;
	mov.u64 	%rd11, 4617315517961601024;
	shl.b64 	%rd5, %rd11, %r113;
	setp.eq.s64	%p77, %rd5, -9223372036854775808;
	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd122, [retval0+0];
	
	//{
	}// Callseq End 10
	and.pred  	%p5, %p11, %p77;
	@!%p5 bra 	BB7_67;
	bra.uni 	BB7_66;

BB7_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd122;
	}
	xor.b32  	%r115, %r114, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd122;
	}
	mov.b64 	%fd122, {%r116, %r115};

BB7_67:
	@%p12 bra 	BB7_70;
	bra.uni 	BB7_68;

BB7_70:
	selp.b32	%r117, %r1, 0, %p77;
	or.b32  	%r118, %r117, 2146435072;
	setp.lt.s32	%p83, %r6, 0;
	selp.b32	%r119, %r118, %r117, %p83;
	mov.u32 	%r120, 0;
	mov.b64 	%fd122, {%r120, %r119};
	bra.uni 	BB7_71;

BB7_68:
	setp.gt.s32	%p80, %r1, -1;
	@%p80 bra 	BB7_71;

	cvt.rzi.f64.f64	%fd98, %fd96;
	setp.neu.f64	%p81, %fd98, 0d4014000000000000;
	selp.f64	%fd122, 0dFFF8000000000000, %fd122, %p81;

BB7_71:
	add.f64 	%fd123, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd123;
	}
	and.b32  	%r122, %r121, 2146435072;
	setp.ne.s32	%p84, %r122, 2146435072;
	@%p84 bra 	BB7_72;

	setp.gtu.f64	%p85, %fd2, 0d7FF0000000000000;
	@%p85 bra 	BB7_81;

	and.b32  	%r123, %r6, 2147483647;
	setp.ne.s32	%p86, %r123, 2146435072;
	@%p86 bra 	BB7_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd96;
	}
	setp.eq.s32	%p87, %r124, 0;
	@%p87 bra 	BB7_80;

BB7_76:
	and.b32  	%r125, %r1, 2147483647;
	setp.ne.s32	%p88, %r125, 2146435072;
	@%p88 bra 	BB7_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd1;
	}
	setp.ne.s32	%p89, %r126, 0;
	mov.f64 	%fd123, %fd122;
	@%p89 bra 	BB7_81;

	shr.s32 	%r127, %r6, 31;
	and.b32  	%r128, %r127, -2146435072;
	add.s32 	%r129, %r128, 2146435072;
	or.b32  	%r130, %r129, -2147483648;
	selp.b32	%r131, %r130, %r129, %p5;
	mov.u32 	%r132, 0;
	mov.b64 	%fd123, {%r132, %r131};
	bra.uni 	BB7_81;

BB7_72:
	mov.f64 	%fd123, %fd122;
	bra.uni 	BB7_81;

BB7_77:
	mov.f64 	%fd123, %fd122;
	bra.uni 	BB7_81;

BB7_80:
	setp.gt.f64	%p90, %fd2, 0d3FF0000000000000;
	selp.b32	%r133, 2146435072, 0, %p90;
	xor.b32  	%r134, %r133, 2146435072;
	setp.lt.s32	%p91, %r6, 0;
	selp.b32	%r135, %r134, %r133, %p91;
	setp.eq.f64	%p92, %fd1, 0dBFF0000000000000;
	selp.b32	%r136, 1072693248, %r135, %p92;
	mov.u32 	%r137, 0;
	mov.b64 	%fd123, {%r137, %r136};

BB7_81:
	mul.f64 	%fd100, %fd123, 0d40DE000000000000;
	selp.f64	%fd101, 0d40DE000000000000, %fd100, %p42;
	sub.f64 	%fd56, %fd45, %fd101;
	mov.f64 	%fd102, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd102;
	}
	bfe.u32 	%r138, %r7, 20, 11;
	add.s32 	%r139, %r138, -1012;
	mov.u64 	%rd12, 4616189618054758400;
	shl.b64 	%rd6, %rd12, %r139;
	setp.eq.s64	%p94, %rd6, -9223372036854775808;
	// Callseq Start 11
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd125, [retval0+0];
	
	//{
	}// Callseq End 11
	and.pred  	%p6, %p11, %p94;
	@!%p6 bra 	BB7_83;
	bra.uni 	BB7_82;

BB7_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd125;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd125;
	}
	mov.b64 	%fd125, {%r142, %r141};

BB7_83:
	@%p12 bra 	BB7_86;
	bra.uni 	BB7_84;

BB7_86:
	selp.b32	%r143, %r1, 0, %p94;
	or.b32  	%r144, %r143, 2146435072;
	setp.lt.s32	%p100, %r7, 0;
	selp.b32	%r145, %r144, %r143, %p100;
	mov.u32 	%r146, 0;
	mov.b64 	%fd125, {%r146, %r145};
	bra.uni 	BB7_87;

BB7_84:
	setp.gt.s32	%p97, %r1, -1;
	@%p97 bra 	BB7_87;

	cvt.rzi.f64.f64	%fd104, %fd102;
	setp.neu.f64	%p98, %fd104, 0d4010000000000000;
	selp.f64	%fd125, 0dFFF8000000000000, %fd125, %p98;

BB7_87:
	add.f64 	%fd126, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd126;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32	%p101, %r148, 2146435072;
	@%p101 bra 	BB7_88;

	setp.gtu.f64	%p102, %fd2, 0d7FF0000000000000;
	@%p102 bra 	BB7_97;

	and.b32  	%r149, %r7, 2147483647;
	setp.ne.s32	%p103, %r149, 2146435072;
	@%p103 bra 	BB7_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd102;
	}
	setp.eq.s32	%p104, %r150, 0;
	@%p104 bra 	BB7_96;

BB7_92:
	and.b32  	%r151, %r1, 2147483647;
	setp.ne.s32	%p105, %r151, 2146435072;
	@%p105 bra 	BB7_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd1;
	}
	setp.ne.s32	%p106, %r152, 0;
	mov.f64 	%fd126, %fd125;
	@%p106 bra 	BB7_97;

	shr.s32 	%r153, %r7, 31;
	and.b32  	%r154, %r153, -2146435072;
	add.s32 	%r155, %r154, 2146435072;
	or.b32  	%r156, %r155, -2147483648;
	selp.b32	%r157, %r156, %r155, %p6;
	mov.u32 	%r158, 0;
	mov.b64 	%fd126, {%r158, %r157};
	bra.uni 	BB7_97;

BB7_88:
	mov.f64 	%fd126, %fd125;
	bra.uni 	BB7_97;

BB7_93:
	mov.f64 	%fd126, %fd125;
	bra.uni 	BB7_97;

BB7_96:
	setp.gt.f64	%p107, %fd2, 0d3FF0000000000000;
	selp.b32	%r159, 2146435072, 0, %p107;
	xor.b32  	%r160, %r159, 2146435072;
	setp.lt.s32	%p108, %r7, 0;
	selp.b32	%r161, %r160, %r159, %p108;
	setp.eq.f64	%p109, %fd1, 0dBFF0000000000000;
	selp.b32	%r162, 1072693248, %r161, %p109;
	mov.u32 	%r163, 0;
	mov.b64 	%fd126, {%r163, %r162};

BB7_97:
	mul.f64 	%fd106, %fd126, 0d40B4000000000000;
	selp.f64	%fd107, 0d40B4000000000000, %fd106, %p42;
	add.f64 	%fd108, %fd56, %fd107;
	mul.f64 	%fd127, %fd108, %fd69;

BB7_98:
	st.param.f64	[func_retval0+0], %fd127;
	ret;
}

	// .globl	_Z17VerySmoothBump_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17VerySmoothBump_omddPdiPii(
	.param .b64 _Z17VerySmoothBump_omddPdiPii_param_0,
	.param .b64 _Z17VerySmoothBump_omddPdiPii_param_1,
	.param .b64 _Z17VerySmoothBump_omddPdiPii_param_2,
	.param .b32 _Z17VerySmoothBump_omddPdiPii_param_3,
	.param .b64 _Z17VerySmoothBump_omddPdiPii_param_4,
	.param .b32 _Z17VerySmoothBump_omddPdiPii_param_5
)
{
	.reg .pred 	%p<111>;
	.reg .b32 	%r<164>;
	.reg .f64 	%fd<128>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd71, [_Z17VerySmoothBump_omddPdiPii_param_0];
	ld.param.f64 	%fd69, [_Z17VerySmoothBump_omddPdiPii_param_1];
	mul.f64 	%fd1, %fd71, %fd69;
	setp.lt.f64	%p7, %fd1, 0d0000000000000000;
	setp.gt.f64	%p8, %fd1, 0d3FF0000000000000;
	or.pred  	%p9, %p7, %p8;
	mov.f64 	%fd127, 0d0000000000000000;
	@%p9 bra 	BB8_98;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd72, 0d4022000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd72;
	}
	bfe.u32 	%r8, %r2, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd7, 4621256167635550208;
	shl.b64 	%rd1, %rd7, %r9;
	setp.eq.s64	%p10, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 12
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd110, [retval0+0];
	
	//{
	}// Callseq End 12
	setp.lt.s32	%p11, %r1, 0;
	and.pred  	%p1, %p11, %p10;
	@!%p1 bra 	BB8_3;
	bra.uni 	BB8_2;

BB8_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd110;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd110;
	}
	mov.b64 	%fd110, {%r12, %r11};

BB8_3:
	setp.eq.f64	%p12, %fd1, 0d0000000000000000;
	@%p12 bra 	BB8_6;
	bra.uni 	BB8_4;

BB8_6:
	selp.b32	%r13, %r1, 0, %p10;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r15, %r14, %r13, %p16;
	mov.u32 	%r16, 0;
	mov.b64 	%fd110, {%r16, %r15};
	bra.uni 	BB8_7;

BB8_4:
	setp.gt.s32	%p13, %r1, -1;
	@%p13 bra 	BB8_7;

	cvt.rzi.f64.f64	%fd74, %fd72;
	setp.neu.f64	%p14, %fd74, 0d4022000000000000;
	selp.f64	%fd110, 0dFFF8000000000000, %fd110, %p14;

BB8_7:
	add.f64 	%fd111, %fd1, 0d4022000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd111;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p17, %r18, 2146435072;
	@%p17 bra 	BB8_8;

	setp.gtu.f64	%p18, %fd2, 0d7FF0000000000000;
	@%p18 bra 	BB8_17;

	and.b32  	%r19, %r2, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB8_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd72;
	}
	setp.eq.s32	%p20, %r20, 0;
	@%p20 bra 	BB8_16;

BB8_12:
	and.b32  	%r21, %r1, 2147483647;
	setp.ne.s32	%p21, %r21, 2146435072;
	@%p21 bra 	BB8_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd1;
	}
	setp.ne.s32	%p22, %r22, 0;
	mov.f64 	%fd111, %fd110;
	@%p22 bra 	BB8_17;

	shr.s32 	%r23, %r2, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd111, {%r28, %r27};
	bra.uni 	BB8_17;

BB8_8:
	mov.f64 	%fd111, %fd110;
	bra.uni 	BB8_17;

BB8_13:
	mov.f64 	%fd111, %fd110;
	bra.uni 	BB8_17;

BB8_16:
	setp.gt.f64	%p23, %fd2, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p23;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p24, %r2, 0;
	selp.b32	%r31, %r30, %r29, %p24;
	setp.eq.f64	%p25, %fd1, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p25;
	mov.u32 	%r33, 0;
	mov.b64 	%fd111, {%r33, %r32};

BB8_17:
	mov.f64 	%fd76, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd8, 4620693217682128896;
	shl.b64 	%rd2, %rd8, %r35;
	setp.eq.s64	%p26, %rd2, -9223372036854775808;
	// Callseq Start 13
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd113, [retval0+0];
	
	//{
	}// Callseq End 13
	and.pred  	%p2, %p11, %p26;
	@!%p2 bra 	BB8_19;
	bra.uni 	BB8_18;

BB8_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd113;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd113;
	}
	mov.b64 	%fd113, {%r38, %r37};

BB8_19:
	@%p12 bra 	BB8_22;
	bra.uni 	BB8_20;

BB8_22:
	selp.b32	%r39, %r1, 0, %p26;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p32, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p32;
	mov.u32 	%r42, 0;
	mov.b64 	%fd113, {%r42, %r41};
	bra.uni 	BB8_23;

BB8_20:
	setp.gt.s32	%p29, %r1, -1;
	@%p29 bra 	BB8_23;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p30, %fd78, 0d4020000000000000;
	selp.f64	%fd113, 0dFFF8000000000000, %fd113, %p30;

BB8_23:
	add.f64 	%fd114, %fd1, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd114;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB8_24;

	setp.gtu.f64	%p34, %fd2, 0d7FF0000000000000;
	@%p34 bra 	BB8_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB8_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd76;
	}
	setp.eq.s32	%p36, %r46, 0;
	@%p36 bra 	BB8_32;

BB8_28:
	and.b32  	%r47, %r1, 2147483647;
	setp.ne.s32	%p37, %r47, 2146435072;
	@%p37 bra 	BB8_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p38, %r48, 0;
	mov.f64 	%fd114, %fd113;
	@%p38 bra 	BB8_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd114, {%r54, %r53};
	bra.uni 	BB8_33;

BB8_24:
	mov.f64 	%fd114, %fd113;
	bra.uni 	BB8_33;

BB8_29:
	mov.f64 	%fd114, %fd113;
	bra.uni 	BB8_33;

BB8_32:
	setp.gt.f64	%p39, %fd2, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p39;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p40, %r3, 0;
	selp.b32	%r57, %r56, %r55, %p40;
	setp.eq.f64	%p41, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p41;
	mov.u32 	%r59, 0;
	mov.b64 	%fd114, {%r59, %r58};

BB8_33:
	mul.f64 	%fd80, %fd114, 0d40E6800000000000;
	setp.eq.f64	%p42, %fd1, 0d3FF0000000000000;
	selp.f64	%fd81, 0d40E6800000000000, %fd80, %p42;
	mul.f64 	%fd82, %fd111, 0dC0C4000000000000;
	selp.f64	%fd83, 0dC0C4000000000000, %fd82, %p42;
	add.f64 	%fd23, %fd83, %fd81;
	mov.f64 	%fd84, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd84;
	}
	bfe.u32 	%r60, %r4, 20, 11;
	add.s32 	%r61, %r60, -1012;
	mov.u64 	%rd9, 4619567317775286272;
	shl.b64 	%rd3, %rd9, %r61;
	setp.eq.s64	%p43, %rd3, -9223372036854775808;
	// Callseq Start 14
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd116, [retval0+0];
	
	//{
	}// Callseq End 14
	and.pred  	%p3, %p11, %p43;
	@!%p3 bra 	BB8_35;
	bra.uni 	BB8_34;

BB8_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd116;
	}
	xor.b32  	%r63, %r62, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd116;
	}
	mov.b64 	%fd116, {%r64, %r63};

BB8_35:
	@%p12 bra 	BB8_38;
	bra.uni 	BB8_36;

BB8_38:
	selp.b32	%r65, %r1, 0, %p43;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p49, %r4, 0;
	selp.b32	%r67, %r66, %r65, %p49;
	mov.u32 	%r68, 0;
	mov.b64 	%fd116, {%r68, %r67};
	bra.uni 	BB8_39;

BB8_36:
	setp.gt.s32	%p46, %r1, -1;
	@%p46 bra 	BB8_39;

	cvt.rzi.f64.f64	%fd86, %fd84;
	setp.neu.f64	%p47, %fd86, 0d401C000000000000;
	selp.f64	%fd116, 0dFFF8000000000000, %fd116, %p47;

BB8_39:
	add.f64 	%fd117, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd117;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p50, %r70, 2146435072;
	@%p50 bra 	BB8_40;

	setp.gtu.f64	%p51, %fd2, 0d7FF0000000000000;
	@%p51 bra 	BB8_49;

	and.b32  	%r71, %r4, 2147483647;
	setp.ne.s32	%p52, %r71, 2146435072;
	@%p52 bra 	BB8_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd84;
	}
	setp.eq.s32	%p53, %r72, 0;
	@%p53 bra 	BB8_48;

BB8_44:
	and.b32  	%r73, %r1, 2147483647;
	setp.ne.s32	%p54, %r73, 2146435072;
	@%p54 bra 	BB8_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd1;
	}
	setp.ne.s32	%p55, %r74, 0;
	mov.f64 	%fd117, %fd116;
	@%p55 bra 	BB8_49;

	shr.s32 	%r75, %r4, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd117, {%r80, %r79};
	bra.uni 	BB8_49;

BB8_40:
	mov.f64 	%fd117, %fd116;
	bra.uni 	BB8_49;

BB8_45:
	mov.f64 	%fd117, %fd116;
	bra.uni 	BB8_49;

BB8_48:
	setp.gt.f64	%p56, %fd2, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p56;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p57, %r4, 0;
	selp.b32	%r83, %r82, %r81, %p57;
	setp.eq.f64	%p58, %fd1, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p58;
	mov.u32 	%r85, 0;
	mov.b64 	%fd117, {%r85, %r84};

BB8_49:
	mul.f64 	%fd88, %fd117, 0d40F4000000000000;
	selp.f64	%fd89, 0d40F4000000000000, %fd88, %p42;
	sub.f64 	%fd34, %fd23, %fd89;
	mov.f64 	%fd90, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd90;
	}
	bfe.u32 	%r86, %r5, 20, 11;
	add.s32 	%r87, %r86, -1012;
	mov.u64 	%rd10, 4618441417868443648;
	shl.b64 	%rd4, %rd10, %r87;
	setp.eq.s64	%p60, %rd4, -9223372036854775808;
	// Callseq Start 15
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd119, [retval0+0];
	
	//{
	}// Callseq End 15
	and.pred  	%p4, %p11, %p60;
	@!%p4 bra 	BB8_51;
	bra.uni 	BB8_50;

BB8_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd119;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd119;
	}
	mov.b64 	%fd119, {%r90, %r89};

BB8_51:
	@%p12 bra 	BB8_54;
	bra.uni 	BB8_52;

BB8_54:
	selp.b32	%r91, %r1, 0, %p60;
	or.b32  	%r92, %r91, 2146435072;
	setp.lt.s32	%p66, %r5, 0;
	selp.b32	%r93, %r92, %r91, %p66;
	mov.u32 	%r94, 0;
	mov.b64 	%fd119, {%r94, %r93};
	bra.uni 	BB8_55;

BB8_52:
	setp.gt.s32	%p63, %r1, -1;
	@%p63 bra 	BB8_55;

	cvt.rzi.f64.f64	%fd92, %fd90;
	setp.neu.f64	%p64, %fd92, 0d4018000000000000;
	selp.f64	%fd119, 0dFFF8000000000000, %fd119, %p64;

BB8_55:
	add.f64 	%fd120, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd120;
	}
	and.b32  	%r96, %r95, 2146435072;
	setp.ne.s32	%p67, %r96, 2146435072;
	@%p67 bra 	BB8_56;

	setp.gtu.f64	%p68, %fd2, 0d7FF0000000000000;
	@%p68 bra 	BB8_65;

	and.b32  	%r97, %r5, 2147483647;
	setp.ne.s32	%p69, %r97, 2146435072;
	@%p69 bra 	BB8_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd90;
	}
	setp.eq.s32	%p70, %r98, 0;
	@%p70 bra 	BB8_64;

BB8_60:
	and.b32  	%r99, %r1, 2147483647;
	setp.ne.s32	%p71, %r99, 2146435072;
	@%p71 bra 	BB8_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd1;
	}
	setp.ne.s32	%p72, %r100, 0;
	mov.f64 	%fd120, %fd119;
	@%p72 bra 	BB8_65;

	shr.s32 	%r101, %r5, 31;
	and.b32  	%r102, %r101, -2146435072;
	add.s32 	%r103, %r102, 2146435072;
	or.b32  	%r104, %r103, -2147483648;
	selp.b32	%r105, %r104, %r103, %p4;
	mov.u32 	%r106, 0;
	mov.b64 	%fd120, {%r106, %r105};
	bra.uni 	BB8_65;

BB8_56:
	mov.f64 	%fd120, %fd119;
	bra.uni 	BB8_65;

BB8_61:
	mov.f64 	%fd120, %fd119;
	bra.uni 	BB8_65;

BB8_64:
	setp.gt.f64	%p73, %fd2, 0d3FF0000000000000;
	selp.b32	%r107, 2146435072, 0, %p73;
	xor.b32  	%r108, %r107, 2146435072;
	setp.lt.s32	%p74, %r5, 0;
	selp.b32	%r109, %r108, %r107, %p74;
	setp.eq.f64	%p75, %fd1, 0dBFF0000000000000;
	selp.b32	%r110, 1072693248, %r109, %p75;
	mov.u32 	%r111, 0;
	mov.b64 	%fd120, {%r111, %r110};

BB8_65:
	mul.f64 	%fd94, %fd120, 0d40F1800000000000;
	selp.f64	%fd95, 0d40F1800000000000, %fd94, %p42;
	add.f64 	%fd45, %fd34, %fd95;
	mov.f64 	%fd96, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd96;
	}
	bfe.u32 	%r112, %r6, 20, 11;
	add.s32 	%r113, %r112, -1012;
	mov.u64 	%rd11, 4617315517961601024;
	shl.b64 	%rd5, %rd11, %r113;
	setp.eq.s64	%p77, %rd5, -9223372036854775808;
	// Callseq Start 16
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd122, [retval0+0];
	
	//{
	}// Callseq End 16
	and.pred  	%p5, %p11, %p77;
	@!%p5 bra 	BB8_67;
	bra.uni 	BB8_66;

BB8_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd122;
	}
	xor.b32  	%r115, %r114, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd122;
	}
	mov.b64 	%fd122, {%r116, %r115};

BB8_67:
	@%p12 bra 	BB8_70;
	bra.uni 	BB8_68;

BB8_70:
	selp.b32	%r117, %r1, 0, %p77;
	or.b32  	%r118, %r117, 2146435072;
	setp.lt.s32	%p83, %r6, 0;
	selp.b32	%r119, %r118, %r117, %p83;
	mov.u32 	%r120, 0;
	mov.b64 	%fd122, {%r120, %r119};
	bra.uni 	BB8_71;

BB8_68:
	setp.gt.s32	%p80, %r1, -1;
	@%p80 bra 	BB8_71;

	cvt.rzi.f64.f64	%fd98, %fd96;
	setp.neu.f64	%p81, %fd98, 0d4014000000000000;
	selp.f64	%fd122, 0dFFF8000000000000, %fd122, %p81;

BB8_71:
	add.f64 	%fd123, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd123;
	}
	and.b32  	%r122, %r121, 2146435072;
	setp.ne.s32	%p84, %r122, 2146435072;
	@%p84 bra 	BB8_72;

	setp.gtu.f64	%p85, %fd2, 0d7FF0000000000000;
	@%p85 bra 	BB8_81;

	and.b32  	%r123, %r6, 2147483647;
	setp.ne.s32	%p86, %r123, 2146435072;
	@%p86 bra 	BB8_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd96;
	}
	setp.eq.s32	%p87, %r124, 0;
	@%p87 bra 	BB8_80;

BB8_76:
	and.b32  	%r125, %r1, 2147483647;
	setp.ne.s32	%p88, %r125, 2146435072;
	@%p88 bra 	BB8_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd1;
	}
	setp.ne.s32	%p89, %r126, 0;
	mov.f64 	%fd123, %fd122;
	@%p89 bra 	BB8_81;

	shr.s32 	%r127, %r6, 31;
	and.b32  	%r128, %r127, -2146435072;
	add.s32 	%r129, %r128, 2146435072;
	or.b32  	%r130, %r129, -2147483648;
	selp.b32	%r131, %r130, %r129, %p5;
	mov.u32 	%r132, 0;
	mov.b64 	%fd123, {%r132, %r131};
	bra.uni 	BB8_81;

BB8_72:
	mov.f64 	%fd123, %fd122;
	bra.uni 	BB8_81;

BB8_77:
	mov.f64 	%fd123, %fd122;
	bra.uni 	BB8_81;

BB8_80:
	setp.gt.f64	%p90, %fd2, 0d3FF0000000000000;
	selp.b32	%r133, 2146435072, 0, %p90;
	xor.b32  	%r134, %r133, 2146435072;
	setp.lt.s32	%p91, %r6, 0;
	selp.b32	%r135, %r134, %r133, %p91;
	setp.eq.f64	%p92, %fd1, 0dBFF0000000000000;
	selp.b32	%r136, 1072693248, %r135, %p92;
	mov.u32 	%r137, 0;
	mov.b64 	%fd123, {%r137, %r136};

BB8_81:
	mul.f64 	%fd100, %fd123, 0d40DE000000000000;
	selp.f64	%fd101, 0d40DE000000000000, %fd100, %p42;
	sub.f64 	%fd56, %fd45, %fd101;
	mov.f64 	%fd102, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd102;
	}
	bfe.u32 	%r138, %r7, 20, 11;
	add.s32 	%r139, %r138, -1012;
	mov.u64 	%rd12, 4616189618054758400;
	shl.b64 	%rd6, %rd12, %r139;
	setp.eq.s64	%p94, %rd6, -9223372036854775808;
	// Callseq Start 17
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd125, [retval0+0];
	
	//{
	}// Callseq End 17
	and.pred  	%p6, %p11, %p94;
	@!%p6 bra 	BB8_83;
	bra.uni 	BB8_82;

BB8_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd125;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd125;
	}
	mov.b64 	%fd125, {%r142, %r141};

BB8_83:
	@%p12 bra 	BB8_86;
	bra.uni 	BB8_84;

BB8_86:
	selp.b32	%r143, %r1, 0, %p94;
	or.b32  	%r144, %r143, 2146435072;
	setp.lt.s32	%p100, %r7, 0;
	selp.b32	%r145, %r144, %r143, %p100;
	mov.u32 	%r146, 0;
	mov.b64 	%fd125, {%r146, %r145};
	bra.uni 	BB8_87;

BB8_84:
	setp.gt.s32	%p97, %r1, -1;
	@%p97 bra 	BB8_87;

	cvt.rzi.f64.f64	%fd104, %fd102;
	setp.neu.f64	%p98, %fd104, 0d4010000000000000;
	selp.f64	%fd125, 0dFFF8000000000000, %fd125, %p98;

BB8_87:
	add.f64 	%fd126, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd126;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32	%p101, %r148, 2146435072;
	@%p101 bra 	BB8_88;

	setp.gtu.f64	%p102, %fd2, 0d7FF0000000000000;
	@%p102 bra 	BB8_97;

	and.b32  	%r149, %r7, 2147483647;
	setp.ne.s32	%p103, %r149, 2146435072;
	@%p103 bra 	BB8_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd102;
	}
	setp.eq.s32	%p104, %r150, 0;
	@%p104 bra 	BB8_96;

BB8_92:
	and.b32  	%r151, %r1, 2147483647;
	setp.ne.s32	%p105, %r151, 2146435072;
	@%p105 bra 	BB8_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd1;
	}
	setp.ne.s32	%p106, %r152, 0;
	mov.f64 	%fd126, %fd125;
	@%p106 bra 	BB8_97;

	shr.s32 	%r153, %r7, 31;
	and.b32  	%r154, %r153, -2146435072;
	add.s32 	%r155, %r154, 2146435072;
	or.b32  	%r156, %r155, -2147483648;
	selp.b32	%r157, %r156, %r155, %p6;
	mov.u32 	%r158, 0;
	mov.b64 	%fd126, {%r158, %r157};
	bra.uni 	BB8_97;

BB8_88:
	mov.f64 	%fd126, %fd125;
	bra.uni 	BB8_97;

BB8_93:
	mov.f64 	%fd126, %fd125;
	bra.uni 	BB8_97;

BB8_96:
	setp.gt.f64	%p107, %fd2, 0d3FF0000000000000;
	selp.b32	%r159, 2146435072, 0, %p107;
	xor.b32  	%r160, %r159, 2146435072;
	setp.lt.s32	%p108, %r7, 0;
	selp.b32	%r161, %r160, %r159, %p108;
	setp.eq.f64	%p109, %fd1, 0dBFF0000000000000;
	selp.b32	%r162, 1072693248, %r161, %p109;
	mov.u32 	%r163, 0;
	mov.b64 	%fd126, {%r163, %r162};

BB8_97:
	mul.f64 	%fd106, %fd126, 0d40B4000000000000;
	selp.f64	%fd107, 0d40B4000000000000, %fd106, %p42;
	add.f64 	%fd108, %fd56, %fd107;
	mul.f64 	%fd127, %fd108, %fd69;

BB8_98:
	st.param.f64	[func_retval0+0], %fd127;
	ret;
}

	// .globl	_Z17VerySmoothBump_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17VerySmoothBump_ttddPdiPii(
	.param .b64 _Z17VerySmoothBump_ttddPdiPii_param_0,
	.param .b64 _Z17VerySmoothBump_ttddPdiPii_param_1,
	.param .b64 _Z17VerySmoothBump_ttddPdiPii_param_2,
	.param .b32 _Z17VerySmoothBump_ttddPdiPii_param_3,
	.param .b64 _Z17VerySmoothBump_ttddPdiPii_param_4,
	.param .b32 _Z17VerySmoothBump_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<111>;
	.reg .b32 	%r<164>;
	.reg .f64 	%fd<129>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd69, [_Z17VerySmoothBump_ttddPdiPii_param_0];
	ld.param.f64 	%fd71, [_Z17VerySmoothBump_ttddPdiPii_param_1];
	mul.f64 	%fd1, %fd69, %fd71;
	setp.lt.f64	%p7, %fd1, 0d0000000000000000;
	setp.gt.f64	%p8, %fd1, 0d3FF0000000000000;
	or.pred  	%p9, %p7, %p8;
	mov.f64 	%fd128, 0d0000000000000000;
	@%p9 bra 	BB9_98;

	mov.f64 	%fd72, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd72;
	}
	bfe.u32 	%r8, %r1, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd7, 4620693217682128896;
	shl.b64 	%rd1, %rd7, %r9;
	setp.eq.s64	%p10, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 18
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd111, [retval0+0];
	
	//{
	}// Callseq End 18
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p11, %r2, 0;
	and.pred  	%p1, %p11, %p10;
	@!%p1 bra 	BB9_3;
	bra.uni 	BB9_2;

BB9_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd111;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd111;
	}
	mov.b64 	%fd111, {%r12, %r11};

BB9_3:
	setp.eq.f64	%p12, %fd1, 0d0000000000000000;
	@%p12 bra 	BB9_6;
	bra.uni 	BB9_4;

BB9_6:
	selp.b32	%r13, %r2, 0, %p10;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p16, %r1, 0;
	selp.b32	%r15, %r14, %r13, %p16;
	mov.u32 	%r16, 0;
	mov.b64 	%fd111, {%r16, %r15};
	bra.uni 	BB9_7;

BB9_4:
	setp.gt.s32	%p13, %r2, -1;
	@%p13 bra 	BB9_7;

	cvt.rzi.f64.f64	%fd74, %fd72;
	setp.neu.f64	%p14, %fd74, 0d4020000000000000;
	selp.f64	%fd111, 0dFFF8000000000000, %fd111, %p14;

BB9_7:
	add.f64 	%fd112, %fd1, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd112;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p17, %r18, 2146435072;
	@%p17 bra 	BB9_8;

	setp.gtu.f64	%p18, %fd2, 0d7FF0000000000000;
	@%p18 bra 	BB9_17;

	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB9_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd72;
	}
	setp.eq.s32	%p20, %r20, 0;
	@%p20 bra 	BB9_16;

BB9_12:
	and.b32  	%r21, %r2, 2147483647;
	setp.ne.s32	%p21, %r21, 2146435072;
	@%p21 bra 	BB9_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd1;
	}
	setp.ne.s32	%p22, %r22, 0;
	mov.f64 	%fd112, %fd111;
	@%p22 bra 	BB9_17;

	shr.s32 	%r23, %r1, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd112, {%r28, %r27};
	bra.uni 	BB9_17;

BB9_8:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB9_17;

BB9_13:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB9_17;

BB9_16:
	setp.gt.f64	%p23, %fd2, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p23;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p24, %r1, 0;
	selp.b32	%r31, %r30, %r29, %p24;
	setp.eq.f64	%p25, %fd1, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p25;
	mov.u32 	%r33, 0;
	mov.b64 	%fd112, {%r33, %r32};

BB9_17:
	mov.f64 	%fd76, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd8, 4619567317775286272;
	shl.b64 	%rd2, %rd8, %r35;
	setp.eq.s64	%p26, %rd2, -9223372036854775808;
	// Callseq Start 19
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd114, [retval0+0];
	
	//{
	}// Callseq End 19
	and.pred  	%p2, %p11, %p26;
	@!%p2 bra 	BB9_19;
	bra.uni 	BB9_18;

BB9_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd114;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd114;
	}
	mov.b64 	%fd114, {%r38, %r37};

BB9_19:
	@%p12 bra 	BB9_22;
	bra.uni 	BB9_20;

BB9_22:
	selp.b32	%r39, %r2, 0, %p26;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p32, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p32;
	mov.u32 	%r42, 0;
	mov.b64 	%fd114, {%r42, %r41};
	bra.uni 	BB9_23;

BB9_20:
	setp.gt.s32	%p29, %r2, -1;
	@%p29 bra 	BB9_23;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p30, %fd78, 0d401C000000000000;
	selp.f64	%fd114, 0dFFF8000000000000, %fd114, %p30;

BB9_23:
	add.f64 	%fd115, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd115;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB9_24;

	setp.gtu.f64	%p34, %fd2, 0d7FF0000000000000;
	@%p34 bra 	BB9_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB9_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd76;
	}
	setp.eq.s32	%p36, %r46, 0;
	@%p36 bra 	BB9_32;

BB9_28:
	and.b32  	%r47, %r2, 2147483647;
	setp.ne.s32	%p37, %r47, 2146435072;
	@%p37 bra 	BB9_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p38, %r48, 0;
	mov.f64 	%fd115, %fd114;
	@%p38 bra 	BB9_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd115, {%r54, %r53};
	bra.uni 	BB9_33;

BB9_24:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB9_33;

BB9_29:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB9_33;

BB9_32:
	setp.gt.f64	%p39, %fd2, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p39;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p40, %r3, 0;
	selp.b32	%r57, %r56, %r55, %p40;
	setp.eq.f64	%p41, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p41;
	mov.u32 	%r59, 0;
	mov.b64 	%fd115, {%r59, %r58};

BB9_33:
	mul.f64 	%fd80, %fd115, 0d4116800000000000;
	setp.eq.f64	%p42, %fd1, 0d3FF0000000000000;
	selp.f64	%fd81, 0d4116800000000000, %fd80, %p42;
	mul.f64 	%fd82, %fd112, 0dC0F6800000000000;
	selp.f64	%fd83, 0dC0F6800000000000, %fd82, %p42;
	add.f64 	%fd23, %fd83, %fd81;
	mov.f64 	%fd84, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd84;
	}
	bfe.u32 	%r60, %r4, 20, 11;
	add.s32 	%r61, %r60, -1012;
	mov.u64 	%rd9, 4618441417868443648;
	shl.b64 	%rd3, %rd9, %r61;
	setp.eq.s64	%p43, %rd3, -9223372036854775808;
	// Callseq Start 20
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd117, [retval0+0];
	
	//{
	}// Callseq End 20
	and.pred  	%p3, %p11, %p43;
	@!%p3 bra 	BB9_35;
	bra.uni 	BB9_34;

BB9_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd117;
	}
	xor.b32  	%r63, %r62, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd117;
	}
	mov.b64 	%fd117, {%r64, %r63};

BB9_35:
	@%p12 bra 	BB9_38;
	bra.uni 	BB9_36;

BB9_38:
	selp.b32	%r65, %r2, 0, %p43;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p49, %r4, 0;
	selp.b32	%r67, %r66, %r65, %p49;
	mov.u32 	%r68, 0;
	mov.b64 	%fd117, {%r68, %r67};
	bra.uni 	BB9_39;

BB9_36:
	setp.gt.s32	%p46, %r2, -1;
	@%p46 bra 	BB9_39;

	cvt.rzi.f64.f64	%fd86, %fd84;
	setp.neu.f64	%p47, %fd86, 0d4018000000000000;
	selp.f64	%fd117, 0dFFF8000000000000, %fd117, %p47;

BB9_39:
	add.f64 	%fd118, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd118;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p50, %r70, 2146435072;
	@%p50 bra 	BB9_40;

	setp.gtu.f64	%p51, %fd2, 0d7FF0000000000000;
	@%p51 bra 	BB9_49;

	and.b32  	%r71, %r4, 2147483647;
	setp.ne.s32	%p52, %r71, 2146435072;
	@%p52 bra 	BB9_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd84;
	}
	setp.eq.s32	%p53, %r72, 0;
	@%p53 bra 	BB9_48;

BB9_44:
	and.b32  	%r73, %r2, 2147483647;
	setp.ne.s32	%p54, %r73, 2146435072;
	@%p54 bra 	BB9_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd1;
	}
	setp.ne.s32	%p55, %r74, 0;
	mov.f64 	%fd118, %fd117;
	@%p55 bra 	BB9_49;

	shr.s32 	%r75, %r4, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd118, {%r80, %r79};
	bra.uni 	BB9_49;

BB9_40:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB9_49;

BB9_45:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB9_49;

BB9_48:
	setp.gt.f64	%p56, %fd2, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p56;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p57, %r4, 0;
	selp.b32	%r83, %r82, %r81, %p57;
	setp.eq.f64	%p58, %fd1, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p58;
	mov.u32 	%r85, 0;
	mov.b64 	%fd118, {%r85, %r84};

BB9_49:
	mul.f64 	%fd88, %fd118, 0d4121800000000000;
	selp.f64	%fd89, 0d4121800000000000, %fd88, %p42;
	sub.f64 	%fd34, %fd23, %fd89;
	mov.f64 	%fd90, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd90;
	}
	bfe.u32 	%r86, %r5, 20, 11;
	add.s32 	%r87, %r86, -1012;
	mov.u64 	%rd10, 4617315517961601024;
	shl.b64 	%rd4, %rd10, %r87;
	setp.eq.s64	%p60, %rd4, -9223372036854775808;
	// Callseq Start 21
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd120, [retval0+0];
	
	//{
	}// Callseq End 21
	and.pred  	%p4, %p11, %p60;
	@!%p4 bra 	BB9_51;
	bra.uni 	BB9_50;

BB9_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd120;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd120;
	}
	mov.b64 	%fd120, {%r90, %r89};

BB9_51:
	@%p12 bra 	BB9_54;
	bra.uni 	BB9_52;

BB9_54:
	selp.b32	%r91, %r2, 0, %p60;
	or.b32  	%r92, %r91, 2146435072;
	setp.lt.s32	%p66, %r5, 0;
	selp.b32	%r93, %r92, %r91, %p66;
	mov.u32 	%r94, 0;
	mov.b64 	%fd120, {%r94, %r93};
	bra.uni 	BB9_55;

BB9_52:
	setp.gt.s32	%p63, %r2, -1;
	@%p63 bra 	BB9_55;

	cvt.rzi.f64.f64	%fd92, %fd90;
	setp.neu.f64	%p64, %fd92, 0d4014000000000000;
	selp.f64	%fd120, 0dFFF8000000000000, %fd120, %p64;

BB9_55:
	add.f64 	%fd121, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd121;
	}
	and.b32  	%r96, %r95, 2146435072;
	setp.ne.s32	%p67, %r96, 2146435072;
	@%p67 bra 	BB9_56;

	setp.gtu.f64	%p68, %fd2, 0d7FF0000000000000;
	@%p68 bra 	BB9_65;

	and.b32  	%r97, %r5, 2147483647;
	setp.ne.s32	%p69, %r97, 2146435072;
	@%p69 bra 	BB9_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd90;
	}
	setp.eq.s32	%p70, %r98, 0;
	@%p70 bra 	BB9_64;

BB9_60:
	and.b32  	%r99, %r2, 2147483647;
	setp.ne.s32	%p71, %r99, 2146435072;
	@%p71 bra 	BB9_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd1;
	}
	setp.ne.s32	%p72, %r100, 0;
	mov.f64 	%fd121, %fd120;
	@%p72 bra 	BB9_65;

	shr.s32 	%r101, %r5, 31;
	and.b32  	%r102, %r101, -2146435072;
	add.s32 	%r103, %r102, 2146435072;
	or.b32  	%r104, %r103, -2147483648;
	selp.b32	%r105, %r104, %r103, %p4;
	mov.u32 	%r106, 0;
	mov.b64 	%fd121, {%r106, %r105};
	bra.uni 	BB9_65;

BB9_56:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB9_65;

BB9_61:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB9_65;

BB9_64:
	setp.gt.f64	%p73, %fd2, 0d3FF0000000000000;
	selp.b32	%r107, 2146435072, 0, %p73;
	xor.b32  	%r108, %r107, 2146435072;
	setp.lt.s32	%p74, %r5, 0;
	selp.b32	%r109, %r108, %r107, %p74;
	setp.eq.f64	%p75, %fd1, 0dBFF0000000000000;
	selp.b32	%r110, 1072693248, %r109, %p75;
	mov.u32 	%r111, 0;
	mov.b64 	%fd121, {%r111, %r110};

BB9_65:
	mul.f64 	%fd94, %fd121, 0d411A400000000000;
	selp.f64	%fd95, 0d411A400000000000, %fd94, %p42;
	add.f64 	%fd45, %fd34, %fd95;
	mov.f64 	%fd96, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd96;
	}
	bfe.u32 	%r112, %r6, 20, 11;
	add.s32 	%r113, %r112, -1012;
	mov.u64 	%rd11, 4616189618054758400;
	shl.b64 	%rd5, %rd11, %r113;
	setp.eq.s64	%p77, %rd5, -9223372036854775808;
	// Callseq Start 22
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd123, [retval0+0];
	
	//{
	}// Callseq End 22
	and.pred  	%p5, %p11, %p77;
	@!%p5 bra 	BB9_67;
	bra.uni 	BB9_66;

BB9_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd123;
	}
	xor.b32  	%r115, %r114, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd123;
	}
	mov.b64 	%fd123, {%r116, %r115};

BB9_67:
	@%p12 bra 	BB9_70;
	bra.uni 	BB9_68;

BB9_70:
	selp.b32	%r117, %r2, 0, %p77;
	or.b32  	%r118, %r117, 2146435072;
	setp.lt.s32	%p83, %r6, 0;
	selp.b32	%r119, %r118, %r117, %p83;
	mov.u32 	%r120, 0;
	mov.b64 	%fd123, {%r120, %r119};
	bra.uni 	BB9_71;

BB9_68:
	setp.gt.s32	%p80, %r2, -1;
	@%p80 bra 	BB9_71;

	cvt.rzi.f64.f64	%fd98, %fd96;
	setp.neu.f64	%p81, %fd98, 0d4010000000000000;
	selp.f64	%fd123, 0dFFF8000000000000, %fd123, %p81;

BB9_71:
	add.f64 	%fd124, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd124;
	}
	and.b32  	%r122, %r121, 2146435072;
	setp.ne.s32	%p84, %r122, 2146435072;
	@%p84 bra 	BB9_72;

	setp.gtu.f64	%p85, %fd2, 0d7FF0000000000000;
	@%p85 bra 	BB9_81;

	and.b32  	%r123, %r6, 2147483647;
	setp.ne.s32	%p86, %r123, 2146435072;
	@%p86 bra 	BB9_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd96;
	}
	setp.eq.s32	%p87, %r124, 0;
	@%p87 bra 	BB9_80;

BB9_76:
	and.b32  	%r125, %r2, 2147483647;
	setp.ne.s32	%p88, %r125, 2146435072;
	@%p88 bra 	BB9_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd1;
	}
	setp.ne.s32	%p89, %r126, 0;
	mov.f64 	%fd124, %fd123;
	@%p89 bra 	BB9_81;

	shr.s32 	%r127, %r6, 31;
	and.b32  	%r128, %r127, -2146435072;
	add.s32 	%r129, %r128, 2146435072;
	or.b32  	%r130, %r129, -2147483648;
	selp.b32	%r131, %r130, %r129, %p5;
	mov.u32 	%r132, 0;
	mov.b64 	%fd124, {%r132, %r131};
	bra.uni 	BB9_81;

BB9_72:
	mov.f64 	%fd124, %fd123;
	bra.uni 	BB9_81;

BB9_77:
	mov.f64 	%fd124, %fd123;
	bra.uni 	BB9_81;

BB9_80:
	setp.gt.f64	%p90, %fd2, 0d3FF0000000000000;
	selp.b32	%r133, 2146435072, 0, %p90;
	xor.b32  	%r134, %r133, 2146435072;
	setp.lt.s32	%p91, %r6, 0;
	selp.b32	%r135, %r134, %r133, %p91;
	setp.eq.f64	%p92, %fd1, 0dBFF0000000000000;
	selp.b32	%r136, 1072693248, %r135, %p92;
	mov.u32 	%r137, 0;
	mov.b64 	%fd124, {%r137, %r136};

BB9_81:
	mul.f64 	%fd100, %fd124, 0d4102C00000000000;
	selp.f64	%fd101, 0d4102C00000000000, %fd100, %p42;
	sub.f64 	%fd56, %fd45, %fd101;
	mov.f64 	%fd102, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd102;
	}
	bfe.u32 	%r138, %r7, 20, 11;
	add.s32 	%r139, %r138, -1012;
	mov.u64 	%rd12, 4613937818241073152;
	shl.b64 	%rd6, %rd12, %r139;
	setp.eq.s64	%p94, %rd6, -9223372036854775808;
	// Callseq Start 23
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd126, [retval0+0];
	
	//{
	}// Callseq End 23
	and.pred  	%p6, %p11, %p94;
	@!%p6 bra 	BB9_83;
	bra.uni 	BB9_82;

BB9_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd126;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd126;
	}
	mov.b64 	%fd126, {%r142, %r141};

BB9_83:
	@%p12 bra 	BB9_86;
	bra.uni 	BB9_84;

BB9_86:
	selp.b32	%r143, %r2, 0, %p94;
	or.b32  	%r144, %r143, 2146435072;
	setp.lt.s32	%p100, %r7, 0;
	selp.b32	%r145, %r144, %r143, %p100;
	mov.u32 	%r146, 0;
	mov.b64 	%fd126, {%r146, %r145};
	bra.uni 	BB9_87;

BB9_84:
	setp.gt.s32	%p97, %r2, -1;
	@%p97 bra 	BB9_87;

	cvt.rzi.f64.f64	%fd104, %fd102;
	setp.neu.f64	%p98, %fd104, 0d4008000000000000;
	selp.f64	%fd126, 0dFFF8000000000000, %fd126, %p98;

BB9_87:
	add.f64 	%fd127, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd127;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32	%p101, %r148, 2146435072;
	@%p101 bra 	BB9_88;

	setp.gtu.f64	%p102, %fd2, 0d7FF0000000000000;
	@%p102 bra 	BB9_97;

	and.b32  	%r149, %r7, 2147483647;
	setp.ne.s32	%p103, %r149, 2146435072;
	@%p103 bra 	BB9_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd102;
	}
	setp.eq.s32	%p104, %r150, 0;
	@%p104 bra 	BB9_96;

BB9_92:
	and.b32  	%r151, %r2, 2147483647;
	setp.ne.s32	%p105, %r151, 2146435072;
	@%p105 bra 	BB9_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd1;
	}
	setp.ne.s32	%p106, %r152, 0;
	mov.f64 	%fd127, %fd126;
	@%p106 bra 	BB9_97;

	shr.s32 	%r153, %r7, 31;
	and.b32  	%r154, %r153, -2146435072;
	add.s32 	%r155, %r154, 2146435072;
	or.b32  	%r156, %r155, -2147483648;
	selp.b32	%r157, %r156, %r155, %p6;
	mov.u32 	%r158, 0;
	mov.b64 	%fd127, {%r158, %r157};
	bra.uni 	BB9_97;

BB9_88:
	mov.f64 	%fd127, %fd126;
	bra.uni 	BB9_97;

BB9_93:
	mov.f64 	%fd127, %fd126;
	bra.uni 	BB9_97;

BB9_96:
	setp.gt.f64	%p107, %fd2, 0d3FF0000000000000;
	selp.b32	%r159, 2146435072, 0, %p107;
	xor.b32  	%r160, %r159, 2146435072;
	setp.lt.s32	%p108, %r7, 0;
	selp.b32	%r161, %r160, %r159, %p108;
	setp.eq.f64	%p109, %fd1, 0dBFF0000000000000;
	selp.b32	%r162, 1072693248, %r161, %p109;
	mov.u32 	%r163, 0;
	mov.b64 	%fd127, {%r163, %r162};

BB9_97:
	mul.f64 	%fd106, %fd127, 0d40D4000000000000;
	selp.f64	%fd107, 0d40D4000000000000, %fd106, %p42;
	add.f64 	%fd108, %fd56, %fd107;
	mul.f64 	%fd109, %fd69, %fd69;
	mul.f64 	%fd128, %fd109, %fd108;

BB9_98:
	st.param.f64	[func_retval0+0], %fd128;
	ret;
}

	// .globl	_Z18VerySmoothBump_tomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z18VerySmoothBump_tomddPdiPii(
	.param .b64 _Z18VerySmoothBump_tomddPdiPii_param_0,
	.param .b64 _Z18VerySmoothBump_tomddPdiPii_param_1,
	.param .b64 _Z18VerySmoothBump_tomddPdiPii_param_2,
	.param .b32 _Z18VerySmoothBump_tomddPdiPii_param_3,
	.param .b64 _Z18VerySmoothBump_tomddPdiPii_param_4,
	.param .b32 _Z18VerySmoothBump_tomddPdiPii_param_5
)
{
	.reg .pred 	%p<79>;
	.reg .b32 	%r<114>;
	.reg .f64 	%fd<91>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd48, [_Z18VerySmoothBump_tomddPdiPii_param_0];
	ld.param.f64 	%fd49, [_Z18VerySmoothBump_tomddPdiPii_param_1];
	mul.f64 	%fd1, %fd48, %fd49;
	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	setp.gt.f64	%p5, %fd1, 0d3FF0000000000000;
	or.pred  	%p6, %p4, %p5;
	mov.f64 	%fd90, 0d0000000000000000;
	@%p6 bra 	BB10_66;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd51, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd51;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd4, 4616189618054758400;
	shl.b64 	%rd1, %rd4, %r7;
	setp.eq.s64	%p7, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 24
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd51;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd79, [retval0+0];
	
	//{
	}// Callseq End 24
	setp.lt.s32	%p8, %r1, 0;
	and.pred  	%p1, %p8, %p7;
	@!%p1 bra 	BB10_3;
	bra.uni 	BB10_2;

BB10_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd79;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd79;
	}
	mov.b64 	%fd79, {%r10, %r9};

BB10_3:
	setp.eq.f64	%p9, %fd1, 0d0000000000000000;
	@%p9 bra 	BB10_6;
	bra.uni 	BB10_4;

BB10_6:
	selp.b32	%r11, %r1, 0, %p7;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p13, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p13;
	mov.u32 	%r14, 0;
	mov.b64 	%fd79, {%r14, %r13};
	bra.uni 	BB10_7;

BB10_4:
	setp.gt.s32	%p10, %r1, -1;
	@%p10 bra 	BB10_7;

	cvt.rzi.f64.f64	%fd53, %fd51;
	setp.neu.f64	%p11, %fd53, 0d4010000000000000;
	selp.f64	%fd79, 0dFFF8000000000000, %fd79, %p11;

BB10_7:
	add.f64 	%fd80, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd80;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p14, %r16, 2146435072;
	@%p14 bra 	BB10_8;

	setp.gtu.f64	%p15, %fd2, 0d7FF0000000000000;
	@%p15 bra 	BB10_17;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p16, %r17, 2146435072;
	@%p16 bra 	BB10_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd51;
	}
	setp.eq.s32	%p17, %r18, 0;
	@%p17 bra 	BB10_16;

BB10_12:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p18, %r19, 2146435072;
	@%p18 bra 	BB10_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p19, %r20, 0;
	mov.f64 	%fd80, %fd79;
	@%p19 bra 	BB10_17;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd80, {%r26, %r25};
	bra.uni 	BB10_17;

BB10_8:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB10_17;

BB10_13:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB10_17;

BB10_16:
	setp.gt.f64	%p20, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p20;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p21, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p21;
	setp.eq.f64	%p22, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p22;
	mov.u32 	%r31, 0;
	mov.b64 	%fd80, {%r31, %r30};

BB10_17:
	setp.eq.f64	%p23, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd80, %p23;
	mov.f64 	%fd55, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd55;
	}
	bfe.u32 	%r32, %r3, 20, 11;
	add.s32 	%r33, %r32, -1012;
	mov.u64 	%rd5, 4617315517961601024;
	shl.b64 	%rd6, %rd5, %r33;
	setp.eq.s64	%p24, %rd6, -9223372036854775808;
	// Callseq Start 25
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd55;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd82, [retval0+0];
	
	//{
	}// Callseq End 25
	and.pred  	%p26, %p8, %p24;
	@!%p26 bra 	BB10_19;
	bra.uni 	BB10_18;

BB10_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd82;
	}
	xor.b32  	%r35, %r34, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd82;
	}
	mov.b64 	%fd82, {%r36, %r35};

BB10_19:
	@%p9 bra 	BB10_22;
	bra.uni 	BB10_20;

BB10_22:
	bfe.u32 	%r37, %r3, 20, 11;
	add.s32 	%r38, %r37, -1012;
	shl.b64 	%rd8, %rd5, %r38;
	setp.eq.s64	%p30, %rd8, -9223372036854775808;
	selp.b32	%r39, %r1, 0, %p30;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p31;
	mov.u32 	%r42, 0;
	mov.b64 	%fd82, {%r42, %r41};
	bra.uni 	BB10_23;

BB10_20:
	setp.gt.s32	%p28, %r1, -1;
	@%p28 bra 	BB10_23;

	cvt.rzi.f64.f64	%fd57, %fd55;
	setp.neu.f64	%p29, %fd57, 0d4014000000000000;
	selp.f64	%fd82, 0dFFF8000000000000, %fd82, %p29;

BB10_23:
	add.f64 	%fd83, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd83;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p32, %r44, 2146435072;
	@%p32 bra 	BB10_24;

	setp.gtu.f64	%p33, %fd2, 0d7FF0000000000000;
	@%p33 bra 	BB10_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p34, %r45, 2146435072;
	@%p34 bra 	BB10_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd55;
	}
	setp.eq.s32	%p35, %r46, 0;
	@%p35 bra 	BB10_32;

BB10_28:
	and.b32  	%r47, %r1, 2147483647;
	setp.ne.s32	%p36, %r47, 2146435072;
	@%p36 bra 	BB10_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p37, %r48, 0;
	mov.f64 	%fd83, %fd82;
	@%p37 bra 	BB10_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	bfe.u32 	%r53, %r3, 20, 11;
	add.s32 	%r54, %r53, -1012;
	shl.b64 	%rd10, %rd5, %r54;
	setp.eq.s64	%p38, %rd10, -9223372036854775808;
	and.pred  	%p40, %p8, %p38;
	selp.b32	%r55, %r52, %r51, %p40;
	mov.u32 	%r56, 0;
	mov.b64 	%fd83, {%r56, %r55};
	bra.uni 	BB10_33;

BB10_24:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB10_33;

BB10_29:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB10_33;

BB10_32:
	setp.gt.f64	%p41, %fd2, 0d3FF0000000000000;
	selp.b32	%r57, 2146435072, 0, %p41;
	xor.b32  	%r58, %r57, 2146435072;
	setp.lt.s32	%p42, %r3, 0;
	selp.b32	%r59, %r58, %r57, %p42;
	setp.eq.f64	%p43, %fd1, 0dBFF0000000000000;
	selp.b32	%r60, 1072693248, %r59, %p43;
	mov.u32 	%r61, 0;
	mov.b64 	%fd83, {%r61, %r60};

BB10_33:
	mul.f64 	%fd59, %fd83, 0dC034000000000000;
	selp.f64	%fd60, 0dC034000000000000, %fd59, %p23;
	fma.rn.f64 	%fd24, %fd13, 0d4054400000000000, %fd60;
	mov.f64 	%fd61, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd61;
	}
	bfe.u32 	%r62, %r4, 20, 11;
	add.s32 	%r63, %r62, -1012;
	mov.u64 	%rd11, 4613937818241073152;
	shl.b64 	%rd2, %rd11, %r63;
	setp.eq.s64	%p45, %rd2, -9223372036854775808;
	// Callseq Start 26
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd85, [retval0+0];
	
	//{
	}// Callseq End 26
	and.pred  	%p2, %p8, %p45;
	@!%p2 bra 	BB10_35;
	bra.uni 	BB10_34;

BB10_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd85;
	}
	xor.b32  	%r65, %r64, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r66, %temp}, %fd85;
	}
	mov.b64 	%fd85, {%r66, %r65};

BB10_35:
	@%p9 bra 	BB10_38;
	bra.uni 	BB10_36;

BB10_38:
	selp.b32	%r67, %r1, 0, %p45;
	or.b32  	%r68, %r67, 2146435072;
	setp.lt.s32	%p51, %r4, 0;
	selp.b32	%r69, %r68, %r67, %p51;
	mov.u32 	%r70, 0;
	mov.b64 	%fd85, {%r70, %r69};
	bra.uni 	BB10_39;

BB10_36:
	setp.gt.s32	%p48, %r1, -1;
	@%p48 bra 	BB10_39;

	cvt.rzi.f64.f64	%fd63, %fd61;
	setp.neu.f64	%p49, %fd63, 0d4008000000000000;
	selp.f64	%fd85, 0dFFF8000000000000, %fd85, %p49;

BB10_39:
	add.f64 	%fd86, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd86;
	}
	and.b32  	%r72, %r71, 2146435072;
	setp.ne.s32	%p52, %r72, 2146435072;
	@%p52 bra 	BB10_40;

	setp.gtu.f64	%p53, %fd2, 0d7FF0000000000000;
	@%p53 bra 	BB10_49;

	and.b32  	%r73, %r4, 2147483647;
	setp.ne.s32	%p54, %r73, 2146435072;
	@%p54 bra 	BB10_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd61;
	}
	setp.eq.s32	%p55, %r74, 0;
	@%p55 bra 	BB10_48;

BB10_44:
	and.b32  	%r75, %r1, 2147483647;
	setp.ne.s32	%p56, %r75, 2146435072;
	@%p56 bra 	BB10_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r76, %temp}, %fd1;
	}
	setp.ne.s32	%p57, %r76, 0;
	mov.f64 	%fd86, %fd85;
	@%p57 bra 	BB10_49;

	shr.s32 	%r77, %r4, 31;
	and.b32  	%r78, %r77, -2146435072;
	add.s32 	%r79, %r78, 2146435072;
	or.b32  	%r80, %r79, -2147483648;
	selp.b32	%r81, %r80, %r79, %p2;
	mov.u32 	%r82, 0;
	mov.b64 	%fd86, {%r82, %r81};
	bra.uni 	BB10_49;

BB10_40:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB10_49;

BB10_45:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB10_49;

BB10_48:
	setp.gt.f64	%p58, %fd2, 0d3FF0000000000000;
	selp.b32	%r83, 2146435072, 0, %p58;
	xor.b32  	%r84, %r83, 2146435072;
	setp.lt.s32	%p59, %r4, 0;
	selp.b32	%r85, %r84, %r83, %p59;
	setp.eq.f64	%p60, %fd1, 0dBFF0000000000000;
	selp.b32	%r86, 1072693248, %r85, %p60;
	mov.u32 	%r87, 0;
	mov.b64 	%fd86, {%r87, %r86};

BB10_49:
	mul.f64 	%fd65, %fd86, 0d4060000000000000;
	selp.f64	%fd66, 0d4060000000000000, %fd65, %p23;
	sub.f64 	%fd35, %fd24, %fd66;
	mov.f64 	%fd67, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd67;
	}
	bfe.u32 	%r88, %r5, 20, 11;
	add.s32 	%r89, %r88, -1012;
	mov.u64 	%rd12, 4611686018427387904;
	shl.b64 	%rd3, %rd12, %r89;
	setp.eq.s64	%p62, %rd3, -9223372036854775808;
	// Callseq Start 27
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd67;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd88, [retval0+0];
	
	//{
	}// Callseq End 27
	and.pred  	%p3, %p8, %p62;
	@!%p3 bra 	BB10_51;
	bra.uni 	BB10_50;

BB10_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd88;
	}
	xor.b32  	%r91, %r90, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r92, %temp}, %fd88;
	}
	mov.b64 	%fd88, {%r92, %r91};

BB10_51:
	@%p9 bra 	BB10_54;
	bra.uni 	BB10_52;

BB10_54:
	selp.b32	%r93, %r1, 0, %p62;
	or.b32  	%r94, %r93, 2146435072;
	setp.lt.s32	%p68, %r5, 0;
	selp.b32	%r95, %r94, %r93, %p68;
	mov.u32 	%r96, 0;
	mov.b64 	%fd88, {%r96, %r95};
	bra.uni 	BB10_55;

BB10_52:
	setp.gt.s32	%p65, %r1, -1;
	@%p65 bra 	BB10_55;

	cvt.rzi.f64.f64	%fd69, %fd67;
	setp.neu.f64	%p66, %fd69, 0d4000000000000000;
	selp.f64	%fd88, 0dFFF8000000000000, %fd88, %p66;

BB10_55:
	add.f64 	%fd89, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd89;
	}
	and.b32  	%r98, %r97, 2146435072;
	setp.ne.s32	%p69, %r98, 2146435072;
	@%p69 bra 	BB10_56;

	setp.gtu.f64	%p70, %fd2, 0d7FF0000000000000;
	@%p70 bra 	BB10_65;

	and.b32  	%r99, %r5, 2147483647;
	setp.ne.s32	%p71, %r99, 2146435072;
	@%p71 bra 	BB10_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd67;
	}
	setp.eq.s32	%p72, %r100, 0;
	@%p72 bra 	BB10_64;

BB10_60:
	and.b32  	%r101, %r1, 2147483647;
	setp.ne.s32	%p73, %r101, 2146435072;
	@%p73 bra 	BB10_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r102, %temp}, %fd1;
	}
	setp.ne.s32	%p74, %r102, 0;
	mov.f64 	%fd89, %fd88;
	@%p74 bra 	BB10_65;

	shr.s32 	%r103, %r5, 31;
	and.b32  	%r104, %r103, -2146435072;
	add.s32 	%r105, %r104, 2146435072;
	or.b32  	%r106, %r105, -2147483648;
	selp.b32	%r107, %r106, %r105, %p3;
	mov.u32 	%r108, 0;
	mov.b64 	%fd89, {%r108, %r107};
	bra.uni 	BB10_65;

BB10_56:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB10_65;

BB10_61:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB10_65;

BB10_64:
	setp.gt.f64	%p75, %fd2, 0d3FF0000000000000;
	selp.b32	%r109, 2146435072, 0, %p75;
	xor.b32  	%r110, %r109, 2146435072;
	setp.lt.s32	%p76, %r5, 0;
	selp.b32	%r111, %r110, %r109, %p76;
	setp.eq.f64	%p77, %fd1, 0dBFF0000000000000;
	selp.b32	%r112, 1072693248, %r111, %p77;
	mov.u32 	%r113, 0;
	mov.b64 	%fd89, {%r113, %r112};

BB10_65:
	mul.f64 	%fd71, %fd89, 0d4058800000000000;
	selp.f64	%fd72, 0d4058800000000000, %fd71, %p23;
	add.f64 	%fd73, %fd35, %fd72;
	mul.f64 	%fd74, %fd49, 0dC042000000000000;
	fma.rn.f64 	%fd75, %fd74, %fd48, %fd73;
	add.f64 	%fd76, %fd75, 0d4014000000000000;
	mul.f64 	%fd77, %fd13, 0d40B4000000000000;
	mul.f64 	%fd90, %fd77, %fd76;

BB10_66:
	st.param.f64	[func_retval0+0], %fd90;
	ret;
}

	// .globl	_Z19VerySmoothBump_omomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z19VerySmoothBump_omomddPdiPii(
	.param .b64 _Z19VerySmoothBump_omomddPdiPii_param_0,
	.param .b64 _Z19VerySmoothBump_omomddPdiPii_param_1,
	.param .b64 _Z19VerySmoothBump_omomddPdiPii_param_2,
	.param .b32 _Z19VerySmoothBump_omomddPdiPii_param_3,
	.param .b64 _Z19VerySmoothBump_omomddPdiPii_param_4,
	.param .b32 _Z19VerySmoothBump_omomddPdiPii_param_5
)
{
	.reg .pred 	%p<111>;
	.reg .b32 	%r<164>;
	.reg .f64 	%fd<129>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd71, [_Z19VerySmoothBump_omomddPdiPii_param_0];
	ld.param.f64 	%fd69, [_Z19VerySmoothBump_omomddPdiPii_param_1];
	mul.f64 	%fd1, %fd71, %fd69;
	setp.lt.f64	%p7, %fd1, 0d0000000000000000;
	setp.gt.f64	%p8, %fd1, 0d3FF0000000000000;
	or.pred  	%p9, %p7, %p8;
	mov.f64 	%fd128, 0d0000000000000000;
	@%p9 bra 	BB11_98;

	mov.f64 	%fd72, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd72;
	}
	bfe.u32 	%r8, %r1, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd7, 4620693217682128896;
	shl.b64 	%rd1, %rd7, %r9;
	setp.eq.s64	%p10, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 28
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd111, [retval0+0];
	
	//{
	}// Callseq End 28
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p11, %r2, 0;
	and.pred  	%p1, %p11, %p10;
	@!%p1 bra 	BB11_3;
	bra.uni 	BB11_2;

BB11_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd111;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd111;
	}
	mov.b64 	%fd111, {%r12, %r11};

BB11_3:
	setp.eq.f64	%p12, %fd1, 0d0000000000000000;
	@%p12 bra 	BB11_6;
	bra.uni 	BB11_4;

BB11_6:
	selp.b32	%r13, %r2, 0, %p10;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p16, %r1, 0;
	selp.b32	%r15, %r14, %r13, %p16;
	mov.u32 	%r16, 0;
	mov.b64 	%fd111, {%r16, %r15};
	bra.uni 	BB11_7;

BB11_4:
	setp.gt.s32	%p13, %r2, -1;
	@%p13 bra 	BB11_7;

	cvt.rzi.f64.f64	%fd74, %fd72;
	setp.neu.f64	%p14, %fd74, 0d4020000000000000;
	selp.f64	%fd111, 0dFFF8000000000000, %fd111, %p14;

BB11_7:
	add.f64 	%fd112, %fd1, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd112;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p17, %r18, 2146435072;
	@%p17 bra 	BB11_8;

	setp.gtu.f64	%p18, %fd2, 0d7FF0000000000000;
	@%p18 bra 	BB11_17;

	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB11_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd72;
	}
	setp.eq.s32	%p20, %r20, 0;
	@%p20 bra 	BB11_16;

BB11_12:
	and.b32  	%r21, %r2, 2147483647;
	setp.ne.s32	%p21, %r21, 2146435072;
	@%p21 bra 	BB11_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd1;
	}
	setp.ne.s32	%p22, %r22, 0;
	mov.f64 	%fd112, %fd111;
	@%p22 bra 	BB11_17;

	shr.s32 	%r23, %r1, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd112, {%r28, %r27};
	bra.uni 	BB11_17;

BB11_8:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB11_17;

BB11_13:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB11_17;

BB11_16:
	setp.gt.f64	%p23, %fd2, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p23;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p24, %r1, 0;
	selp.b32	%r31, %r30, %r29, %p24;
	setp.eq.f64	%p25, %fd1, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p25;
	mov.u32 	%r33, 0;
	mov.b64 	%fd112, {%r33, %r32};

BB11_17:
	mov.f64 	%fd76, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd8, 4619567317775286272;
	shl.b64 	%rd2, %rd8, %r35;
	setp.eq.s64	%p26, %rd2, -9223372036854775808;
	// Callseq Start 29
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd114, [retval0+0];
	
	//{
	}// Callseq End 29
	and.pred  	%p2, %p11, %p26;
	@!%p2 bra 	BB11_19;
	bra.uni 	BB11_18;

BB11_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd114;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd114;
	}
	mov.b64 	%fd114, {%r38, %r37};

BB11_19:
	@%p12 bra 	BB11_22;
	bra.uni 	BB11_20;

BB11_22:
	selp.b32	%r39, %r2, 0, %p26;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p32, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p32;
	mov.u32 	%r42, 0;
	mov.b64 	%fd114, {%r42, %r41};
	bra.uni 	BB11_23;

BB11_20:
	setp.gt.s32	%p29, %r2, -1;
	@%p29 bra 	BB11_23;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p30, %fd78, 0d401C000000000000;
	selp.f64	%fd114, 0dFFF8000000000000, %fd114, %p30;

BB11_23:
	add.f64 	%fd115, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd115;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB11_24;

	setp.gtu.f64	%p34, %fd2, 0d7FF0000000000000;
	@%p34 bra 	BB11_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB11_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd76;
	}
	setp.eq.s32	%p36, %r46, 0;
	@%p36 bra 	BB11_32;

BB11_28:
	and.b32  	%r47, %r2, 2147483647;
	setp.ne.s32	%p37, %r47, 2146435072;
	@%p37 bra 	BB11_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p38, %r48, 0;
	mov.f64 	%fd115, %fd114;
	@%p38 bra 	BB11_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd115, {%r54, %r53};
	bra.uni 	BB11_33;

BB11_24:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB11_33;

BB11_29:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB11_33;

BB11_32:
	setp.gt.f64	%p39, %fd2, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p39;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p40, %r3, 0;
	selp.b32	%r57, %r56, %r55, %p40;
	setp.eq.f64	%p41, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p41;
	mov.u32 	%r59, 0;
	mov.b64 	%fd115, {%r59, %r58};

BB11_33:
	mul.f64 	%fd80, %fd115, 0d4116800000000000;
	setp.eq.f64	%p42, %fd1, 0d3FF0000000000000;
	selp.f64	%fd81, 0d4116800000000000, %fd80, %p42;
	mul.f64 	%fd82, %fd112, 0dC0F6800000000000;
	selp.f64	%fd83, 0dC0F6800000000000, %fd82, %p42;
	add.f64 	%fd23, %fd83, %fd81;
	mov.f64 	%fd84, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd84;
	}
	bfe.u32 	%r60, %r4, 20, 11;
	add.s32 	%r61, %r60, -1012;
	mov.u64 	%rd9, 4618441417868443648;
	shl.b64 	%rd3, %rd9, %r61;
	setp.eq.s64	%p43, %rd3, -9223372036854775808;
	// Callseq Start 30
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd117, [retval0+0];
	
	//{
	}// Callseq End 30
	and.pred  	%p3, %p11, %p43;
	@!%p3 bra 	BB11_35;
	bra.uni 	BB11_34;

BB11_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd117;
	}
	xor.b32  	%r63, %r62, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd117;
	}
	mov.b64 	%fd117, {%r64, %r63};

BB11_35:
	@%p12 bra 	BB11_38;
	bra.uni 	BB11_36;

BB11_38:
	selp.b32	%r65, %r2, 0, %p43;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p49, %r4, 0;
	selp.b32	%r67, %r66, %r65, %p49;
	mov.u32 	%r68, 0;
	mov.b64 	%fd117, {%r68, %r67};
	bra.uni 	BB11_39;

BB11_36:
	setp.gt.s32	%p46, %r2, -1;
	@%p46 bra 	BB11_39;

	cvt.rzi.f64.f64	%fd86, %fd84;
	setp.neu.f64	%p47, %fd86, 0d4018000000000000;
	selp.f64	%fd117, 0dFFF8000000000000, %fd117, %p47;

BB11_39:
	add.f64 	%fd118, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd118;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p50, %r70, 2146435072;
	@%p50 bra 	BB11_40;

	setp.gtu.f64	%p51, %fd2, 0d7FF0000000000000;
	@%p51 bra 	BB11_49;

	and.b32  	%r71, %r4, 2147483647;
	setp.ne.s32	%p52, %r71, 2146435072;
	@%p52 bra 	BB11_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd84;
	}
	setp.eq.s32	%p53, %r72, 0;
	@%p53 bra 	BB11_48;

BB11_44:
	and.b32  	%r73, %r2, 2147483647;
	setp.ne.s32	%p54, %r73, 2146435072;
	@%p54 bra 	BB11_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd1;
	}
	setp.ne.s32	%p55, %r74, 0;
	mov.f64 	%fd118, %fd117;
	@%p55 bra 	BB11_49;

	shr.s32 	%r75, %r4, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd118, {%r80, %r79};
	bra.uni 	BB11_49;

BB11_40:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB11_49;

BB11_45:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB11_49;

BB11_48:
	setp.gt.f64	%p56, %fd2, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p56;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p57, %r4, 0;
	selp.b32	%r83, %r82, %r81, %p57;
	setp.eq.f64	%p58, %fd1, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p58;
	mov.u32 	%r85, 0;
	mov.b64 	%fd118, {%r85, %r84};

BB11_49:
	mul.f64 	%fd88, %fd118, 0d4121800000000000;
	selp.f64	%fd89, 0d4121800000000000, %fd88, %p42;
	sub.f64 	%fd34, %fd23, %fd89;
	mov.f64 	%fd90, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd90;
	}
	bfe.u32 	%r86, %r5, 20, 11;
	add.s32 	%r87, %r86, -1012;
	mov.u64 	%rd10, 4617315517961601024;
	shl.b64 	%rd4, %rd10, %r87;
	setp.eq.s64	%p60, %rd4, -9223372036854775808;
	// Callseq Start 31
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd120, [retval0+0];
	
	//{
	}// Callseq End 31
	and.pred  	%p4, %p11, %p60;
	@!%p4 bra 	BB11_51;
	bra.uni 	BB11_50;

BB11_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd120;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd120;
	}
	mov.b64 	%fd120, {%r90, %r89};

BB11_51:
	@%p12 bra 	BB11_54;
	bra.uni 	BB11_52;

BB11_54:
	selp.b32	%r91, %r2, 0, %p60;
	or.b32  	%r92, %r91, 2146435072;
	setp.lt.s32	%p66, %r5, 0;
	selp.b32	%r93, %r92, %r91, %p66;
	mov.u32 	%r94, 0;
	mov.b64 	%fd120, {%r94, %r93};
	bra.uni 	BB11_55;

BB11_52:
	setp.gt.s32	%p63, %r2, -1;
	@%p63 bra 	BB11_55;

	cvt.rzi.f64.f64	%fd92, %fd90;
	setp.neu.f64	%p64, %fd92, 0d4014000000000000;
	selp.f64	%fd120, 0dFFF8000000000000, %fd120, %p64;

BB11_55:
	add.f64 	%fd121, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd121;
	}
	and.b32  	%r96, %r95, 2146435072;
	setp.ne.s32	%p67, %r96, 2146435072;
	@%p67 bra 	BB11_56;

	setp.gtu.f64	%p68, %fd2, 0d7FF0000000000000;
	@%p68 bra 	BB11_65;

	and.b32  	%r97, %r5, 2147483647;
	setp.ne.s32	%p69, %r97, 2146435072;
	@%p69 bra 	BB11_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd90;
	}
	setp.eq.s32	%p70, %r98, 0;
	@%p70 bra 	BB11_64;

BB11_60:
	and.b32  	%r99, %r2, 2147483647;
	setp.ne.s32	%p71, %r99, 2146435072;
	@%p71 bra 	BB11_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd1;
	}
	setp.ne.s32	%p72, %r100, 0;
	mov.f64 	%fd121, %fd120;
	@%p72 bra 	BB11_65;

	shr.s32 	%r101, %r5, 31;
	and.b32  	%r102, %r101, -2146435072;
	add.s32 	%r103, %r102, 2146435072;
	or.b32  	%r104, %r103, -2147483648;
	selp.b32	%r105, %r104, %r103, %p4;
	mov.u32 	%r106, 0;
	mov.b64 	%fd121, {%r106, %r105};
	bra.uni 	BB11_65;

BB11_56:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB11_65;

BB11_61:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB11_65;

BB11_64:
	setp.gt.f64	%p73, %fd2, 0d3FF0000000000000;
	selp.b32	%r107, 2146435072, 0, %p73;
	xor.b32  	%r108, %r107, 2146435072;
	setp.lt.s32	%p74, %r5, 0;
	selp.b32	%r109, %r108, %r107, %p74;
	setp.eq.f64	%p75, %fd1, 0dBFF0000000000000;
	selp.b32	%r110, 1072693248, %r109, %p75;
	mov.u32 	%r111, 0;
	mov.b64 	%fd121, {%r111, %r110};

BB11_65:
	mul.f64 	%fd94, %fd121, 0d411A400000000000;
	selp.f64	%fd95, 0d411A400000000000, %fd94, %p42;
	add.f64 	%fd45, %fd34, %fd95;
	mov.f64 	%fd96, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd96;
	}
	bfe.u32 	%r112, %r6, 20, 11;
	add.s32 	%r113, %r112, -1012;
	mov.u64 	%rd11, 4616189618054758400;
	shl.b64 	%rd5, %rd11, %r113;
	setp.eq.s64	%p77, %rd5, -9223372036854775808;
	// Callseq Start 32
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd123, [retval0+0];
	
	//{
	}// Callseq End 32
	and.pred  	%p5, %p11, %p77;
	@!%p5 bra 	BB11_67;
	bra.uni 	BB11_66;

BB11_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd123;
	}
	xor.b32  	%r115, %r114, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd123;
	}
	mov.b64 	%fd123, {%r116, %r115};

BB11_67:
	@%p12 bra 	BB11_70;
	bra.uni 	BB11_68;

BB11_70:
	selp.b32	%r117, %r2, 0, %p77;
	or.b32  	%r118, %r117, 2146435072;
	setp.lt.s32	%p83, %r6, 0;
	selp.b32	%r119, %r118, %r117, %p83;
	mov.u32 	%r120, 0;
	mov.b64 	%fd123, {%r120, %r119};
	bra.uni 	BB11_71;

BB11_68:
	setp.gt.s32	%p80, %r2, -1;
	@%p80 bra 	BB11_71;

	cvt.rzi.f64.f64	%fd98, %fd96;
	setp.neu.f64	%p81, %fd98, 0d4010000000000000;
	selp.f64	%fd123, 0dFFF8000000000000, %fd123, %p81;

BB11_71:
	add.f64 	%fd124, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd124;
	}
	and.b32  	%r122, %r121, 2146435072;
	setp.ne.s32	%p84, %r122, 2146435072;
	@%p84 bra 	BB11_72;

	setp.gtu.f64	%p85, %fd2, 0d7FF0000000000000;
	@%p85 bra 	BB11_81;

	and.b32  	%r123, %r6, 2147483647;
	setp.ne.s32	%p86, %r123, 2146435072;
	@%p86 bra 	BB11_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd96;
	}
	setp.eq.s32	%p87, %r124, 0;
	@%p87 bra 	BB11_80;

BB11_76:
	and.b32  	%r125, %r2, 2147483647;
	setp.ne.s32	%p88, %r125, 2146435072;
	@%p88 bra 	BB11_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd1;
	}
	setp.ne.s32	%p89, %r126, 0;
	mov.f64 	%fd124, %fd123;
	@%p89 bra 	BB11_81;

	shr.s32 	%r127, %r6, 31;
	and.b32  	%r128, %r127, -2146435072;
	add.s32 	%r129, %r128, 2146435072;
	or.b32  	%r130, %r129, -2147483648;
	selp.b32	%r131, %r130, %r129, %p5;
	mov.u32 	%r132, 0;
	mov.b64 	%fd124, {%r132, %r131};
	bra.uni 	BB11_81;

BB11_72:
	mov.f64 	%fd124, %fd123;
	bra.uni 	BB11_81;

BB11_77:
	mov.f64 	%fd124, %fd123;
	bra.uni 	BB11_81;

BB11_80:
	setp.gt.f64	%p90, %fd2, 0d3FF0000000000000;
	selp.b32	%r133, 2146435072, 0, %p90;
	xor.b32  	%r134, %r133, 2146435072;
	setp.lt.s32	%p91, %r6, 0;
	selp.b32	%r135, %r134, %r133, %p91;
	setp.eq.f64	%p92, %fd1, 0dBFF0000000000000;
	selp.b32	%r136, 1072693248, %r135, %p92;
	mov.u32 	%r137, 0;
	mov.b64 	%fd124, {%r137, %r136};

BB11_81:
	mul.f64 	%fd100, %fd124, 0d4102C00000000000;
	selp.f64	%fd101, 0d4102C00000000000, %fd100, %p42;
	sub.f64 	%fd56, %fd45, %fd101;
	mov.f64 	%fd102, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd102;
	}
	bfe.u32 	%r138, %r7, 20, 11;
	add.s32 	%r139, %r138, -1012;
	mov.u64 	%rd12, 4613937818241073152;
	shl.b64 	%rd6, %rd12, %r139;
	setp.eq.s64	%p94, %rd6, -9223372036854775808;
	// Callseq Start 33
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd126, [retval0+0];
	
	//{
	}// Callseq End 33
	and.pred  	%p6, %p11, %p94;
	@!%p6 bra 	BB11_83;
	bra.uni 	BB11_82;

BB11_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd126;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd126;
	}
	mov.b64 	%fd126, {%r142, %r141};

BB11_83:
	@%p12 bra 	BB11_86;
	bra.uni 	BB11_84;

BB11_86:
	selp.b32	%r143, %r2, 0, %p94;
	or.b32  	%r144, %r143, 2146435072;
	setp.lt.s32	%p100, %r7, 0;
	selp.b32	%r145, %r144, %r143, %p100;
	mov.u32 	%r146, 0;
	mov.b64 	%fd126, {%r146, %r145};
	bra.uni 	BB11_87;

BB11_84:
	setp.gt.s32	%p97, %r2, -1;
	@%p97 bra 	BB11_87;

	cvt.rzi.f64.f64	%fd104, %fd102;
	setp.neu.f64	%p98, %fd104, 0d4008000000000000;
	selp.f64	%fd126, 0dFFF8000000000000, %fd126, %p98;

BB11_87:
	add.f64 	%fd127, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd127;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32	%p101, %r148, 2146435072;
	@%p101 bra 	BB11_88;

	setp.gtu.f64	%p102, %fd2, 0d7FF0000000000000;
	@%p102 bra 	BB11_97;

	and.b32  	%r149, %r7, 2147483647;
	setp.ne.s32	%p103, %r149, 2146435072;
	@%p103 bra 	BB11_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd102;
	}
	setp.eq.s32	%p104, %r150, 0;
	@%p104 bra 	BB11_96;

BB11_92:
	and.b32  	%r151, %r2, 2147483647;
	setp.ne.s32	%p105, %r151, 2146435072;
	@%p105 bra 	BB11_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd1;
	}
	setp.ne.s32	%p106, %r152, 0;
	mov.f64 	%fd127, %fd126;
	@%p106 bra 	BB11_97;

	shr.s32 	%r153, %r7, 31;
	and.b32  	%r154, %r153, -2146435072;
	add.s32 	%r155, %r154, 2146435072;
	or.b32  	%r156, %r155, -2147483648;
	selp.b32	%r157, %r156, %r155, %p6;
	mov.u32 	%r158, 0;
	mov.b64 	%fd127, {%r158, %r157};
	bra.uni 	BB11_97;

BB11_88:
	mov.f64 	%fd127, %fd126;
	bra.uni 	BB11_97;

BB11_93:
	mov.f64 	%fd127, %fd126;
	bra.uni 	BB11_97;

BB11_96:
	setp.gt.f64	%p107, %fd2, 0d3FF0000000000000;
	selp.b32	%r159, 2146435072, 0, %p107;
	xor.b32  	%r160, %r159, 2146435072;
	setp.lt.s32	%p108, %r7, 0;
	selp.b32	%r161, %r160, %r159, %p108;
	setp.eq.f64	%p109, %fd1, 0dBFF0000000000000;
	selp.b32	%r162, 1072693248, %r161, %p109;
	mov.u32 	%r163, 0;
	mov.b64 	%fd127, {%r163, %r162};

BB11_97:
	mul.f64 	%fd106, %fd127, 0d40D4000000000000;
	selp.f64	%fd107, 0d40D4000000000000, %fd106, %p42;
	add.f64 	%fd108, %fd56, %fd107;
	mul.f64 	%fd109, %fd69, %fd69;
	mul.f64 	%fd128, %fd109, %fd108;

BB11_98:
	st.param.f64	[func_retval0+0], %fd128;
	ret;
}

	// .globl	_Z18VerySmoothBump_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z18VerySmoothBump_tttddPdiPii(
	.param .b64 _Z18VerySmoothBump_tttddPdiPii_param_0,
	.param .b64 _Z18VerySmoothBump_tttddPdiPii_param_1,
	.param .b64 _Z18VerySmoothBump_tttddPdiPii_param_2,
	.param .b32 _Z18VerySmoothBump_tttddPdiPii_param_3,
	.param .b64 _Z18VerySmoothBump_tttddPdiPii_param_4,
	.param .b32 _Z18VerySmoothBump_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<111>;
	.reg .b32 	%r<164>;
	.reg .f64 	%fd<130>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd69, [_Z18VerySmoothBump_tttddPdiPii_param_0];
	ld.param.f64 	%fd71, [_Z18VerySmoothBump_tttddPdiPii_param_1];
	mul.f64 	%fd1, %fd69, %fd71;
	setp.lt.f64	%p7, %fd1, 0d0000000000000000;
	setp.gt.f64	%p8, %fd1, 0d3FF0000000000000;
	or.pred  	%p9, %p7, %p8;
	mov.f64 	%fd129, 0d0000000000000000;
	@%p9 bra 	BB12_98;

	mov.f64 	%fd72, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd72;
	}
	bfe.u32 	%r8, %r1, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd7, 4619567317775286272;
	shl.b64 	%rd1, %rd7, %r9;
	setp.eq.s64	%p10, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 34
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd112, [retval0+0];
	
	//{
	}// Callseq End 34
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p11, %r2, 0;
	and.pred  	%p1, %p11, %p10;
	@!%p1 bra 	BB12_3;
	bra.uni 	BB12_2;

BB12_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd112;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd112;
	}
	mov.b64 	%fd112, {%r12, %r11};

BB12_3:
	setp.eq.f64	%p12, %fd1, 0d0000000000000000;
	@%p12 bra 	BB12_6;
	bra.uni 	BB12_4;

BB12_6:
	selp.b32	%r13, %r2, 0, %p10;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p16, %r1, 0;
	selp.b32	%r15, %r14, %r13, %p16;
	mov.u32 	%r16, 0;
	mov.b64 	%fd112, {%r16, %r15};
	bra.uni 	BB12_7;

BB12_4:
	setp.gt.s32	%p13, %r2, -1;
	@%p13 bra 	BB12_7;

	cvt.rzi.f64.f64	%fd74, %fd72;
	setp.neu.f64	%p14, %fd74, 0d401C000000000000;
	selp.f64	%fd112, 0dFFF8000000000000, %fd112, %p14;

BB12_7:
	add.f64 	%fd113, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd113;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p17, %r18, 2146435072;
	@%p17 bra 	BB12_8;

	setp.gtu.f64	%p18, %fd2, 0d7FF0000000000000;
	@%p18 bra 	BB12_17;

	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB12_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd72;
	}
	setp.eq.s32	%p20, %r20, 0;
	@%p20 bra 	BB12_16;

BB12_12:
	and.b32  	%r21, %r2, 2147483647;
	setp.ne.s32	%p21, %r21, 2146435072;
	@%p21 bra 	BB12_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd1;
	}
	setp.ne.s32	%p22, %r22, 0;
	mov.f64 	%fd113, %fd112;
	@%p22 bra 	BB12_17;

	shr.s32 	%r23, %r1, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd113, {%r28, %r27};
	bra.uni 	BB12_17;

BB12_8:
	mov.f64 	%fd113, %fd112;
	bra.uni 	BB12_17;

BB12_13:
	mov.f64 	%fd113, %fd112;
	bra.uni 	BB12_17;

BB12_16:
	setp.gt.f64	%p23, %fd2, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p23;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p24, %r1, 0;
	selp.b32	%r31, %r30, %r29, %p24;
	setp.eq.f64	%p25, %fd1, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p25;
	mov.u32 	%r33, 0;
	mov.b64 	%fd113, {%r33, %r32};

BB12_17:
	mov.f64 	%fd76, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd8, 4618441417868443648;
	shl.b64 	%rd2, %rd8, %r35;
	setp.eq.s64	%p26, %rd2, -9223372036854775808;
	// Callseq Start 35
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd115, [retval0+0];
	
	//{
	}// Callseq End 35
	and.pred  	%p2, %p11, %p26;
	@!%p2 bra 	BB12_19;
	bra.uni 	BB12_18;

BB12_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd115;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd115;
	}
	mov.b64 	%fd115, {%r38, %r37};

BB12_19:
	@%p12 bra 	BB12_22;
	bra.uni 	BB12_20;

BB12_22:
	selp.b32	%r39, %r2, 0, %p26;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p32, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p32;
	mov.u32 	%r42, 0;
	mov.b64 	%fd115, {%r42, %r41};
	bra.uni 	BB12_23;

BB12_20:
	setp.gt.s32	%p29, %r2, -1;
	@%p29 bra 	BB12_23;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p30, %fd78, 0d4018000000000000;
	selp.f64	%fd115, 0dFFF8000000000000, %fd115, %p30;

BB12_23:
	add.f64 	%fd116, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd116;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB12_24;

	setp.gtu.f64	%p34, %fd2, 0d7FF0000000000000;
	@%p34 bra 	BB12_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB12_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd76;
	}
	setp.eq.s32	%p36, %r46, 0;
	@%p36 bra 	BB12_32;

BB12_28:
	and.b32  	%r47, %r2, 2147483647;
	setp.ne.s32	%p37, %r47, 2146435072;
	@%p37 bra 	BB12_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p38, %r48, 0;
	mov.f64 	%fd116, %fd115;
	@%p38 bra 	BB12_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd116, {%r54, %r53};
	bra.uni 	BB12_33;

BB12_24:
	mov.f64 	%fd116, %fd115;
	bra.uni 	BB12_33;

BB12_29:
	mov.f64 	%fd116, %fd115;
	bra.uni 	BB12_33;

BB12_32:
	setp.gt.f64	%p39, %fd2, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p39;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p40, %r3, 0;
	selp.b32	%r57, %r56, %r55, %p40;
	setp.eq.f64	%p41, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p41;
	mov.u32 	%r59, 0;
	mov.b64 	%fd116, {%r59, %r58};

BB12_33:
	mul.f64 	%fd80, %fd116, 0d4143B00000000000;
	setp.eq.f64	%p42, %fd1, 0d3FF0000000000000;
	selp.f64	%fd81, 0d4143B00000000000, %fd80, %p42;
	mul.f64 	%fd82, %fd113, 0dC126800000000000;
	selp.f64	%fd83, 0dC126800000000000, %fd82, %p42;
	add.f64 	%fd23, %fd83, %fd81;
	mov.f64 	%fd84, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd84;
	}
	bfe.u32 	%r60, %r4, 20, 11;
	add.s32 	%r61, %r60, -1012;
	mov.u64 	%rd9, 4617315517961601024;
	shl.b64 	%rd3, %rd9, %r61;
	setp.eq.s64	%p43, %rd3, -9223372036854775808;
	// Callseq Start 36
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd118, [retval0+0];
	
	//{
	}// Callseq End 36
	and.pred  	%p3, %p11, %p43;
	@!%p3 bra 	BB12_35;
	bra.uni 	BB12_34;

BB12_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd118;
	}
	xor.b32  	%r63, %r62, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd118;
	}
	mov.b64 	%fd118, {%r64, %r63};

BB12_35:
	@%p12 bra 	BB12_38;
	bra.uni 	BB12_36;

BB12_38:
	selp.b32	%r65, %r2, 0, %p43;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p49, %r4, 0;
	selp.b32	%r67, %r66, %r65, %p49;
	mov.u32 	%r68, 0;
	mov.b64 	%fd118, {%r68, %r67};
	bra.uni 	BB12_39;

BB12_36:
	setp.gt.s32	%p46, %r2, -1;
	@%p46 bra 	BB12_39;

	cvt.rzi.f64.f64	%fd86, %fd84;
	setp.neu.f64	%p47, %fd86, 0d4014000000000000;
	selp.f64	%fd118, 0dFFF8000000000000, %fd118, %p47;

BB12_39:
	add.f64 	%fd119, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd119;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p50, %r70, 2146435072;
	@%p50 bra 	BB12_40;

	setp.gtu.f64	%p51, %fd2, 0d7FF0000000000000;
	@%p51 bra 	BB12_49;

	and.b32  	%r71, %r4, 2147483647;
	setp.ne.s32	%p52, %r71, 2146435072;
	@%p52 bra 	BB12_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd84;
	}
	setp.eq.s32	%p53, %r72, 0;
	@%p53 bra 	BB12_48;

BB12_44:
	and.b32  	%r73, %r2, 2147483647;
	setp.ne.s32	%p54, %r73, 2146435072;
	@%p54 bra 	BB12_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd1;
	}
	setp.ne.s32	%p55, %r74, 0;
	mov.f64 	%fd119, %fd118;
	@%p55 bra 	BB12_49;

	shr.s32 	%r75, %r4, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd119, {%r80, %r79};
	bra.uni 	BB12_49;

BB12_40:
	mov.f64 	%fd119, %fd118;
	bra.uni 	BB12_49;

BB12_45:
	mov.f64 	%fd119, %fd118;
	bra.uni 	BB12_49;

BB12_48:
	setp.gt.f64	%p56, %fd2, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p56;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p57, %r4, 0;
	selp.b32	%r83, %r82, %r81, %p57;
	setp.eq.f64	%p58, %fd1, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p58;
	mov.u32 	%r85, 0;
	mov.b64 	%fd119, {%r85, %r84};

BB12_49:
	mul.f64 	%fd88, %fd119, 0d414A400000000000;
	selp.f64	%fd89, 0d414A400000000000, %fd88, %p42;
	sub.f64 	%fd34, %fd23, %fd89;
	mov.f64 	%fd90, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd90;
	}
	bfe.u32 	%r86, %r5, 20, 11;
	add.s32 	%r87, %r86, -1012;
	mov.u64 	%rd10, 4616189618054758400;
	shl.b64 	%rd4, %rd10, %r87;
	setp.eq.s64	%p60, %rd4, -9223372036854775808;
	// Callseq Start 37
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd121, [retval0+0];
	
	//{
	}// Callseq End 37
	and.pred  	%p4, %p11, %p60;
	@!%p4 bra 	BB12_51;
	bra.uni 	BB12_50;

BB12_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd121;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd121;
	}
	mov.b64 	%fd121, {%r90, %r89};

BB12_51:
	@%p12 bra 	BB12_54;
	bra.uni 	BB12_52;

BB12_54:
	selp.b32	%r91, %r2, 0, %p60;
	or.b32  	%r92, %r91, 2146435072;
	setp.lt.s32	%p66, %r5, 0;
	selp.b32	%r93, %r92, %r91, %p66;
	mov.u32 	%r94, 0;
	mov.b64 	%fd121, {%r94, %r93};
	bra.uni 	BB12_55;

BB12_52:
	setp.gt.s32	%p63, %r2, -1;
	@%p63 bra 	BB12_55;

	cvt.rzi.f64.f64	%fd92, %fd90;
	setp.neu.f64	%p64, %fd92, 0d4010000000000000;
	selp.f64	%fd121, 0dFFF8000000000000, %fd121, %p64;

BB12_55:
	add.f64 	%fd122, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd122;
	}
	and.b32  	%r96, %r95, 2146435072;
	setp.ne.s32	%p67, %r96, 2146435072;
	@%p67 bra 	BB12_56;

	setp.gtu.f64	%p68, %fd2, 0d7FF0000000000000;
	@%p68 bra 	BB12_65;

	and.b32  	%r97, %r5, 2147483647;
	setp.ne.s32	%p69, %r97, 2146435072;
	@%p69 bra 	BB12_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd90;
	}
	setp.eq.s32	%p70, %r98, 0;
	@%p70 bra 	BB12_64;

BB12_60:
	and.b32  	%r99, %r2, 2147483647;
	setp.ne.s32	%p71, %r99, 2146435072;
	@%p71 bra 	BB12_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd1;
	}
	setp.ne.s32	%p72, %r100, 0;
	mov.f64 	%fd122, %fd121;
	@%p72 bra 	BB12_65;

	shr.s32 	%r101, %r5, 31;
	and.b32  	%r102, %r101, -2146435072;
	add.s32 	%r103, %r102, 2146435072;
	or.b32  	%r104, %r103, -2147483648;
	selp.b32	%r105, %r104, %r103, %p4;
	mov.u32 	%r106, 0;
	mov.b64 	%fd122, {%r106, %r105};
	bra.uni 	BB12_65;

BB12_56:
	mov.f64 	%fd122, %fd121;
	bra.uni 	BB12_65;

BB12_61:
	mov.f64 	%fd122, %fd121;
	bra.uni 	BB12_65;

BB12_64:
	setp.gt.f64	%p73, %fd2, 0d3FF0000000000000;
	selp.b32	%r107, 2146435072, 0, %p73;
	xor.b32  	%r108, %r107, 2146435072;
	setp.lt.s32	%p74, %r5, 0;
	selp.b32	%r109, %r108, %r107, %p74;
	setp.eq.f64	%p75, %fd1, 0dBFF0000000000000;
	selp.b32	%r110, 1072693248, %r109, %p75;
	mov.u32 	%r111, 0;
	mov.b64 	%fd122, {%r111, %r110};

BB12_65:
	mul.f64 	%fd94, %fd122, 0d4140680000000000;
	selp.f64	%fd95, 0d4140680000000000, %fd94, %p42;
	add.f64 	%fd45, %fd34, %fd95;
	mov.f64 	%fd96, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd96;
	}
	bfe.u32 	%r112, %r6, 20, 11;
	add.s32 	%r113, %r112, -1012;
	mov.u64 	%rd11, 4613937818241073152;
	shl.b64 	%rd5, %rd11, %r113;
	setp.eq.s64	%p77, %rd5, -9223372036854775808;
	// Callseq Start 38
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd124, [retval0+0];
	
	//{
	}// Callseq End 38
	and.pred  	%p5, %p11, %p77;
	@!%p5 bra 	BB12_67;
	bra.uni 	BB12_66;

BB12_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd124;
	}
	xor.b32  	%r115, %r114, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd124;
	}
	mov.b64 	%fd124, {%r116, %r115};

BB12_67:
	@%p12 bra 	BB12_70;
	bra.uni 	BB12_68;

BB12_70:
	selp.b32	%r117, %r2, 0, %p77;
	or.b32  	%r118, %r117, 2146435072;
	setp.lt.s32	%p83, %r6, 0;
	selp.b32	%r119, %r118, %r117, %p83;
	mov.u32 	%r120, 0;
	mov.b64 	%fd124, {%r120, %r119};
	bra.uni 	BB12_71;

BB12_68:
	setp.gt.s32	%p80, %r2, -1;
	@%p80 bra 	BB12_71;

	cvt.rzi.f64.f64	%fd98, %fd96;
	setp.neu.f64	%p81, %fd98, 0d4008000000000000;
	selp.f64	%fd124, 0dFFF8000000000000, %fd124, %p81;

BB12_71:
	add.f64 	%fd125, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd125;
	}
	and.b32  	%r122, %r121, 2146435072;
	setp.ne.s32	%p84, %r122, 2146435072;
	@%p84 bra 	BB12_72;

	setp.gtu.f64	%p85, %fd2, 0d7FF0000000000000;
	@%p85 bra 	BB12_81;

	and.b32  	%r123, %r6, 2147483647;
	setp.ne.s32	%p86, %r123, 2146435072;
	@%p86 bra 	BB12_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd96;
	}
	setp.eq.s32	%p87, %r124, 0;
	@%p87 bra 	BB12_80;

BB12_76:
	and.b32  	%r125, %r2, 2147483647;
	setp.ne.s32	%p88, %r125, 2146435072;
	@%p88 bra 	BB12_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd1;
	}
	setp.ne.s32	%p89, %r126, 0;
	mov.f64 	%fd125, %fd124;
	@%p89 bra 	BB12_81;

	shr.s32 	%r127, %r6, 31;
	and.b32  	%r128, %r127, -2146435072;
	add.s32 	%r129, %r128, 2146435072;
	or.b32  	%r130, %r129, -2147483648;
	selp.b32	%r131, %r130, %r129, %p5;
	mov.u32 	%r132, 0;
	mov.b64 	%fd125, {%r132, %r131};
	bra.uni 	BB12_81;

BB12_72:
	mov.f64 	%fd125, %fd124;
	bra.uni 	BB12_81;

BB12_77:
	mov.f64 	%fd125, %fd124;
	bra.uni 	BB12_81;

BB12_80:
	setp.gt.f64	%p90, %fd2, 0d3FF0000000000000;
	selp.b32	%r133, 2146435072, 0, %p90;
	xor.b32  	%r134, %r133, 2146435072;
	setp.lt.s32	%p91, %r6, 0;
	selp.b32	%r135, %r134, %r133, %p91;
	setp.eq.f64	%p92, %fd1, 0dBFF0000000000000;
	selp.b32	%r136, 1072693248, %r135, %p92;
	mov.u32 	%r137, 0;
	mov.b64 	%fd125, {%r137, %r136};

BB12_81:
	mul.f64 	%fd100, %fd125, 0d4122C00000000000;
	selp.f64	%fd101, 0d4122C00000000000, %fd100, %p42;
	sub.f64 	%fd56, %fd45, %fd101;
	mov.f64 	%fd102, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd102;
	}
	bfe.u32 	%r138, %r7, 20, 11;
	add.s32 	%r139, %r138, -1012;
	mov.u64 	%rd12, 4611686018427387904;
	shl.b64 	%rd6, %rd12, %r139;
	setp.eq.s64	%p94, %rd6, -9223372036854775808;
	// Callseq Start 39
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd127, [retval0+0];
	
	//{
	}// Callseq End 39
	and.pred  	%p6, %p11, %p94;
	@!%p6 bra 	BB12_83;
	bra.uni 	BB12_82;

BB12_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd127;
	}
	xor.b32  	%r141, %r140, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd127;
	}
	mov.b64 	%fd127, {%r142, %r141};

BB12_83:
	@%p12 bra 	BB12_86;
	bra.uni 	BB12_84;

BB12_86:
	selp.b32	%r143, %r2, 0, %p94;
	or.b32  	%r144, %r143, 2146435072;
	setp.lt.s32	%p100, %r7, 0;
	selp.b32	%r145, %r144, %r143, %p100;
	mov.u32 	%r146, 0;
	mov.b64 	%fd127, {%r146, %r145};
	bra.uni 	BB12_87;

BB12_84:
	setp.gt.s32	%p97, %r2, -1;
	@%p97 bra 	BB12_87;

	cvt.rzi.f64.f64	%fd104, %fd102;
	setp.neu.f64	%p98, %fd104, 0d4000000000000000;
	selp.f64	%fd127, 0dFFF8000000000000, %fd127, %p98;

BB12_87:
	add.f64 	%fd128, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd128;
	}
	and.b32  	%r148, %r147, 2146435072;
	setp.ne.s32	%p101, %r148, 2146435072;
	@%p101 bra 	BB12_88;

	setp.gtu.f64	%p102, %fd2, 0d7FF0000000000000;
	@%p102 bra 	BB12_97;

	and.b32  	%r149, %r7, 2147483647;
	setp.ne.s32	%p103, %r149, 2146435072;
	@%p103 bra 	BB12_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd102;
	}
	setp.eq.s32	%p104, %r150, 0;
	@%p104 bra 	BB12_96;

BB12_92:
	and.b32  	%r151, %r2, 2147483647;
	setp.ne.s32	%p105, %r151, 2146435072;
	@%p105 bra 	BB12_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd1;
	}
	setp.ne.s32	%p106, %r152, 0;
	mov.f64 	%fd128, %fd127;
	@%p106 bra 	BB12_97;

	shr.s32 	%r153, %r7, 31;
	and.b32  	%r154, %r153, -2146435072;
	add.s32 	%r155, %r154, 2146435072;
	or.b32  	%r156, %r155, -2147483648;
	selp.b32	%r157, %r156, %r155, %p6;
	mov.u32 	%r158, 0;
	mov.b64 	%fd128, {%r158, %r157};
	bra.uni 	BB12_97;

BB12_88:
	mov.f64 	%fd128, %fd127;
	bra.uni 	BB12_97;

BB12_93:
	mov.f64 	%fd128, %fd127;
	bra.uni 	BB12_97;

BB12_96:
	setp.gt.f64	%p107, %fd2, 0d3FF0000000000000;
	selp.b32	%r159, 2146435072, 0, %p107;
	xor.b32  	%r160, %r159, 2146435072;
	setp.lt.s32	%p108, %r7, 0;
	selp.b32	%r161, %r160, %r159, %p108;
	setp.eq.f64	%p109, %fd1, 0dBFF0000000000000;
	selp.b32	%r162, 1072693248, %r161, %p109;
	mov.u32 	%r163, 0;
	mov.b64 	%fd128, {%r163, %r162};

BB12_97:
	mul.f64 	%fd106, %fd128, 0d40EE000000000000;
	selp.f64	%fd107, 0d40EE000000000000, %fd106, %p42;
	add.f64 	%fd108, %fd56, %fd107;
	mul.f64 	%fd109, %fd69, %fd69;
	mul.f64 	%fd110, %fd109, %fd69;
	mul.f64 	%fd129, %fd110, %fd108;

BB12_98:
	st.param.f64	[func_retval0+0], %fd129;
	ret;
}

	// .globl	_Z19VerySmoothBump_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z19VerySmoothBump_omttddPdiPii(
	.param .b64 _Z19VerySmoothBump_omttddPdiPii_param_0,
	.param .b64 _Z19VerySmoothBump_omttddPdiPii_param_1,
	.param .b64 _Z19VerySmoothBump_omttddPdiPii_param_2,
	.param .b32 _Z19VerySmoothBump_omttddPdiPii_param_3,
	.param .b64 _Z19VerySmoothBump_omttddPdiPii_param_4,
	.param .b32 _Z19VerySmoothBump_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<130>;
	.reg .b32 	%r<191>;
	.reg .f64 	%fd<152>;
	.reg .b64 	%rd<15>;


	ld.param.f64 	%fd83, [_Z19VerySmoothBump_omttddPdiPii_param_0];
	ld.param.f64 	%fd84, [_Z19VerySmoothBump_omttddPdiPii_param_1];
	mul.f64 	%fd1, %fd83, %fd84;
	setp.lt.f64	%p8, %fd1, 0d0000000000000000;
	setp.gt.f64	%p9, %fd1, 0d3FF0000000000000;
	or.pred  	%p10, %p8, %p9;
	mov.f64 	%fd151, 0d0000000000000000;
	@%p10 bra 	BB13_114;

	mov.f64 	%fd86, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd86;
	}
	bfe.u32 	%r9, %r1, 20, 11;
	add.s32 	%r10, %r9, -1012;
	mov.u64 	%rd8, 4619567317775286272;
	shl.b64 	%rd1, %rd8, %r10;
	setp.eq.s64	%p11, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 40
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd86;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd131, [retval0+0];
	
	//{
	}// Callseq End 40
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p12, %r2, 0;
	and.pred  	%p1, %p12, %p11;
	@!%p1 bra 	BB13_3;
	bra.uni 	BB13_2;

BB13_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd131;
	}
	xor.b32  	%r12, %r11, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd131;
	}
	mov.b64 	%fd131, {%r13, %r12};

BB13_3:
	setp.eq.f64	%p13, %fd1, 0d0000000000000000;
	@%p13 bra 	BB13_6;
	bra.uni 	BB13_4;

BB13_6:
	selp.b32	%r14, %r2, 0, %p11;
	or.b32  	%r15, %r14, 2146435072;
	setp.lt.s32	%p17, %r1, 0;
	selp.b32	%r16, %r15, %r14, %p17;
	mov.u32 	%r17, 0;
	mov.b64 	%fd131, {%r17, %r16};
	bra.uni 	BB13_7;

BB13_4:
	setp.gt.s32	%p14, %r2, -1;
	@%p14 bra 	BB13_7;

	cvt.rzi.f64.f64	%fd88, %fd86;
	setp.neu.f64	%p15, %fd88, 0d401C000000000000;
	selp.f64	%fd131, 0dFFF8000000000000, %fd131, %p15;

BB13_7:
	add.f64 	%fd132, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r18}, %fd132;
	}
	and.b32  	%r19, %r18, 2146435072;
	setp.ne.s32	%p18, %r19, 2146435072;
	@%p18 bra 	BB13_8;

	setp.gtu.f64	%p19, %fd2, 0d7FF0000000000000;
	@%p19 bra 	BB13_17;

	and.b32  	%r20, %r1, 2147483647;
	setp.ne.s32	%p20, %r20, 2146435072;
	@%p20 bra 	BB13_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd86;
	}
	setp.eq.s32	%p21, %r21, 0;
	@%p21 bra 	BB13_16;

BB13_12:
	and.b32  	%r22, %r2, 2147483647;
	setp.ne.s32	%p22, %r22, 2146435072;
	@%p22 bra 	BB13_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r23, %temp}, %fd1;
	}
	setp.ne.s32	%p23, %r23, 0;
	mov.f64 	%fd132, %fd131;
	@%p23 bra 	BB13_17;

	shr.s32 	%r24, %r1, 31;
	and.b32  	%r25, %r24, -2146435072;
	add.s32 	%r26, %r25, 2146435072;
	or.b32  	%r27, %r26, -2147483648;
	selp.b32	%r28, %r27, %r26, %p1;
	mov.u32 	%r29, 0;
	mov.b64 	%fd132, {%r29, %r28};
	bra.uni 	BB13_17;

BB13_8:
	mov.f64 	%fd132, %fd131;
	bra.uni 	BB13_17;

BB13_13:
	mov.f64 	%fd132, %fd131;
	bra.uni 	BB13_17;

BB13_16:
	setp.gt.f64	%p24, %fd2, 0d3FF0000000000000;
	selp.b32	%r30, 2146435072, 0, %p24;
	xor.b32  	%r31, %r30, 2146435072;
	setp.lt.s32	%p25, %r1, 0;
	selp.b32	%r32, %r31, %r30, %p25;
	setp.eq.f64	%p26, %fd1, 0dBFF0000000000000;
	selp.b32	%r33, 1072693248, %r32, %p26;
	mov.u32 	%r34, 0;
	mov.b64 	%fd132, {%r34, %r33};

BB13_17:
	setp.eq.f64	%p27, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd132, %p27;
	mov.f64 	%fd90, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd90;
	}
	bfe.u32 	%r35, %r3, 20, 11;
	add.s32 	%r36, %r35, -1012;
	mov.u64 	%rd9, 4618441417868443648;
	shl.b64 	%rd2, %rd9, %r36;
	setp.eq.s64	%p28, %rd2, -9223372036854775808;
	// Callseq Start 41
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd134, [retval0+0];
	
	//{
	}// Callseq End 41
	and.pred  	%p2, %p12, %p28;
	@!%p2 bra 	BB13_19;
	bra.uni 	BB13_18;

BB13_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd134;
	}
	xor.b32  	%r38, %r37, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd134;
	}
	mov.b64 	%fd134, {%r39, %r38};

BB13_19:
	@%p13 bra 	BB13_22;
	bra.uni 	BB13_20;

BB13_22:
	selp.b32	%r40, %r2, 0, %p28;
	or.b32  	%r41, %r40, 2146435072;
	setp.lt.s32	%p34, %r3, 0;
	selp.b32	%r42, %r41, %r40, %p34;
	mov.u32 	%r43, 0;
	mov.b64 	%fd134, {%r43, %r42};
	bra.uni 	BB13_23;

BB13_20:
	setp.gt.s32	%p31, %r2, -1;
	@%p31 bra 	BB13_23;

	cvt.rzi.f64.f64	%fd92, %fd90;
	setp.neu.f64	%p32, %fd92, 0d4018000000000000;
	selp.f64	%fd134, 0dFFF8000000000000, %fd134, %p32;

BB13_23:
	add.f64 	%fd135, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd135;
	}
	and.b32  	%r45, %r44, 2146435072;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB13_24;

	setp.gtu.f64	%p36, %fd2, 0d7FF0000000000000;
	@%p36 bra 	BB13_33;

	and.b32  	%r46, %r3, 2147483647;
	setp.ne.s32	%p37, %r46, 2146435072;
	@%p37 bra 	BB13_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd90;
	}
	setp.eq.s32	%p38, %r47, 0;
	@%p38 bra 	BB13_32;

BB13_28:
	and.b32  	%r48, %r2, 2147483647;
	setp.ne.s32	%p39, %r48, 2146435072;
	@%p39 bra 	BB13_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd1;
	}
	setp.ne.s32	%p40, %r49, 0;
	mov.f64 	%fd135, %fd134;
	@%p40 bra 	BB13_33;

	shr.s32 	%r50, %r3, 31;
	and.b32  	%r51, %r50, -2146435072;
	add.s32 	%r52, %r51, 2146435072;
	or.b32  	%r53, %r52, -2147483648;
	selp.b32	%r54, %r53, %r52, %p2;
	mov.u32 	%r55, 0;
	mov.b64 	%fd135, {%r55, %r54};
	bra.uni 	BB13_33;

BB13_24:
	mov.f64 	%fd135, %fd134;
	bra.uni 	BB13_33;

BB13_29:
	mov.f64 	%fd135, %fd134;
	bra.uni 	BB13_33;

BB13_32:
	setp.gt.f64	%p41, %fd2, 0d3FF0000000000000;
	selp.b32	%r56, 2146435072, 0, %p41;
	xor.b32  	%r57, %r56, 2146435072;
	setp.lt.s32	%p42, %r3, 0;
	selp.b32	%r58, %r57, %r56, %p42;
	setp.eq.f64	%p43, %fd1, 0dBFF0000000000000;
	selp.b32	%r59, 1072693248, %r58, %p43;
	mov.u32 	%r60, 0;
	mov.b64 	%fd135, {%r60, %r59};

BB13_33:
	selp.f64	%fd24, 0d3FF0000000000000, %fd135, %p27;
	mul.f64 	%fd94, %fd24, 0d4143B00000000000;
	fma.rn.f64 	%fd25, %fd13, 0dC126800000000000, %fd94;
	mov.f64 	%fd95, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd95;
	}
	bfe.u32 	%r61, %r4, 20, 11;
	add.s32 	%r62, %r61, -1012;
	mov.u64 	%rd10, 4617315517961601024;
	shl.b64 	%rd3, %rd10, %r62;
	setp.eq.s64	%p45, %rd3, -9223372036854775808;
	// Callseq Start 42
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd95;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd137, [retval0+0];
	
	//{
	}// Callseq End 42
	and.pred  	%p3, %p12, %p45;
	@!%p3 bra 	BB13_35;
	bra.uni 	BB13_34;

BB13_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r63}, %fd137;
	}
	xor.b32  	%r64, %r63, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r65, %temp}, %fd137;
	}
	mov.b64 	%fd137, {%r65, %r64};

BB13_35:
	@%p13 bra 	BB13_38;
	bra.uni 	BB13_36;

BB13_38:
	selp.b32	%r66, %r2, 0, %p45;
	or.b32  	%r67, %r66, 2146435072;
	setp.lt.s32	%p51, %r4, 0;
	selp.b32	%r68, %r67, %r66, %p51;
	mov.u32 	%r69, 0;
	mov.b64 	%fd137, {%r69, %r68};
	bra.uni 	BB13_39;

BB13_36:
	setp.gt.s32	%p48, %r2, -1;
	@%p48 bra 	BB13_39;

	cvt.rzi.f64.f64	%fd97, %fd95;
	setp.neu.f64	%p49, %fd97, 0d4014000000000000;
	selp.f64	%fd137, 0dFFF8000000000000, %fd137, %p49;

BB13_39:
	add.f64 	%fd138, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd138;
	}
	and.b32  	%r71, %r70, 2146435072;
	setp.ne.s32	%p52, %r71, 2146435072;
	@%p52 bra 	BB13_40;

	setp.gtu.f64	%p53, %fd2, 0d7FF0000000000000;
	@%p53 bra 	BB13_49;

	and.b32  	%r72, %r4, 2147483647;
	setp.ne.s32	%p54, %r72, 2146435072;
	@%p54 bra 	BB13_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd95;
	}
	setp.eq.s32	%p55, %r73, 0;
	@%p55 bra 	BB13_48;

BB13_44:
	and.b32  	%r74, %r2, 2147483647;
	setp.ne.s32	%p56, %r74, 2146435072;
	@%p56 bra 	BB13_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd1;
	}
	setp.ne.s32	%p57, %r75, 0;
	mov.f64 	%fd138, %fd137;
	@%p57 bra 	BB13_49;

	shr.s32 	%r76, %r4, 31;
	and.b32  	%r77, %r76, -2146435072;
	add.s32 	%r78, %r77, 2146435072;
	or.b32  	%r79, %r78, -2147483648;
	selp.b32	%r80, %r79, %r78, %p3;
	mov.u32 	%r81, 0;
	mov.b64 	%fd138, {%r81, %r80};
	bra.uni 	BB13_49;

BB13_40:
	mov.f64 	%fd138, %fd137;
	bra.uni 	BB13_49;

BB13_45:
	mov.f64 	%fd138, %fd137;
	bra.uni 	BB13_49;

BB13_48:
	setp.gt.f64	%p58, %fd2, 0d3FF0000000000000;
	selp.b32	%r82, 2146435072, 0, %p58;
	xor.b32  	%r83, %r82, 2146435072;
	setp.lt.s32	%p59, %r4, 0;
	selp.b32	%r84, %r83, %r82, %p59;
	setp.eq.f64	%p60, %fd1, 0dBFF0000000000000;
	selp.b32	%r85, 1072693248, %r84, %p60;
	mov.u32 	%r86, 0;
	mov.b64 	%fd138, {%r86, %r85};

BB13_49:
	selp.f64	%fd36, 0d3FF0000000000000, %fd138, %p27;
	mov.f64 	%fd99, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd99;
	}
	bfe.u32 	%r87, %r5, 20, 11;
	add.s32 	%r88, %r87, -1012;
	mov.u64 	%rd11, 4616189618054758400;
	shl.b64 	%rd4, %rd11, %r88;
	setp.eq.s64	%p62, %rd4, -9223372036854775808;
	// Callseq Start 43
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd99;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd140, [retval0+0];
	
	//{
	}// Callseq End 43
	and.pred  	%p4, %p12, %p62;
	@!%p4 bra 	BB13_51;
	bra.uni 	BB13_50;

BB13_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r89}, %fd140;
	}
	xor.b32  	%r90, %r89, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r91, %temp}, %fd140;
	}
	mov.b64 	%fd140, {%r91, %r90};

BB13_51:
	@%p13 bra 	BB13_54;
	bra.uni 	BB13_52;

BB13_54:
	selp.b32	%r92, %r2, 0, %p62;
	or.b32  	%r93, %r92, 2146435072;
	setp.lt.s32	%p68, %r5, 0;
	selp.b32	%r94, %r93, %r92, %p68;
	mov.u32 	%r95, 0;
	mov.b64 	%fd140, {%r95, %r94};
	bra.uni 	BB13_55;

BB13_52:
	setp.gt.s32	%p65, %r2, -1;
	@%p65 bra 	BB13_55;

	cvt.rzi.f64.f64	%fd101, %fd99;
	setp.neu.f64	%p66, %fd101, 0d4010000000000000;
	selp.f64	%fd140, 0dFFF8000000000000, %fd140, %p66;

BB13_55:
	add.f64 	%fd141, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r96}, %fd141;
	}
	and.b32  	%r97, %r96, 2146435072;
	setp.ne.s32	%p69, %r97, 2146435072;
	@%p69 bra 	BB13_56;

	setp.gtu.f64	%p70, %fd2, 0d7FF0000000000000;
	@%p70 bra 	BB13_65;

	and.b32  	%r98, %r5, 2147483647;
	setp.ne.s32	%p71, %r98, 2146435072;
	@%p71 bra 	BB13_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd99;
	}
	setp.eq.s32	%p72, %r99, 0;
	@%p72 bra 	BB13_64;

BB13_60:
	and.b32  	%r100, %r2, 2147483647;
	setp.ne.s32	%p73, %r100, 2146435072;
	@%p73 bra 	BB13_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r101, %temp}, %fd1;
	}
	setp.ne.s32	%p74, %r101, 0;
	mov.f64 	%fd141, %fd140;
	@%p74 bra 	BB13_65;

	shr.s32 	%r102, %r5, 31;
	and.b32  	%r103, %r102, -2146435072;
	add.s32 	%r104, %r103, 2146435072;
	or.b32  	%r105, %r104, -2147483648;
	selp.b32	%r106, %r105, %r104, %p4;
	mov.u32 	%r107, 0;
	mov.b64 	%fd141, {%r107, %r106};
	bra.uni 	BB13_65;

BB13_56:
	mov.f64 	%fd141, %fd140;
	bra.uni 	BB13_65;

BB13_61:
	mov.f64 	%fd141, %fd140;
	bra.uni 	BB13_65;

BB13_64:
	setp.gt.f64	%p75, %fd2, 0d3FF0000000000000;
	selp.b32	%r108, 2146435072, 0, %p75;
	xor.b32  	%r109, %r108, 2146435072;
	setp.lt.s32	%p76, %r5, 0;
	selp.b32	%r110, %r109, %r108, %p76;
	setp.eq.f64	%p77, %fd1, 0dBFF0000000000000;
	selp.b32	%r111, 1072693248, %r110, %p77;
	mov.u32 	%r112, 0;
	mov.b64 	%fd141, {%r112, %r111};

BB13_65:
	selp.f64	%fd47, 0d3FF0000000000000, %fd141, %p27;
	fma.rn.f64 	%fd103, %fd36, 0dC14A400000000000, %fd25;
	fma.rn.f64 	%fd48, %fd47, 0d4140680000000000, %fd103;
	mov.f64 	%fd104, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd104;
	}
	bfe.u32 	%r113, %r6, 20, 11;
	add.s32 	%r114, %r113, -1012;
	mov.u64 	%rd12, 4613937818241073152;
	shl.b64 	%rd5, %rd12, %r114;
	setp.eq.s64	%p79, %rd5, -9223372036854775808;
	// Callseq Start 44
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd104;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd143, [retval0+0];
	
	//{
	}// Callseq End 44
	and.pred  	%p5, %p12, %p79;
	@!%p5 bra 	BB13_67;
	bra.uni 	BB13_66;

BB13_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r115}, %fd143;
	}
	xor.b32  	%r116, %r115, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r117, %temp}, %fd143;
	}
	mov.b64 	%fd143, {%r117, %r116};

BB13_67:
	@%p13 bra 	BB13_70;
	bra.uni 	BB13_68;

BB13_70:
	selp.b32	%r118, %r2, 0, %p79;
	or.b32  	%r119, %r118, 2146435072;
	setp.lt.s32	%p85, %r6, 0;
	selp.b32	%r120, %r119, %r118, %p85;
	mov.u32 	%r121, 0;
	mov.b64 	%fd143, {%r121, %r120};
	bra.uni 	BB13_71;

BB13_68:
	setp.gt.s32	%p82, %r2, -1;
	@%p82 bra 	BB13_71;

	cvt.rzi.f64.f64	%fd106, %fd104;
	setp.neu.f64	%p83, %fd106, 0d4008000000000000;
	selp.f64	%fd143, 0dFFF8000000000000, %fd143, %p83;

BB13_71:
	add.f64 	%fd144, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd144;
	}
	and.b32  	%r123, %r122, 2146435072;
	setp.ne.s32	%p86, %r123, 2146435072;
	@%p86 bra 	BB13_72;

	setp.gtu.f64	%p87, %fd2, 0d7FF0000000000000;
	@%p87 bra 	BB13_81;

	and.b32  	%r124, %r6, 2147483647;
	setp.ne.s32	%p88, %r124, 2146435072;
	@%p88 bra 	BB13_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd104;
	}
	setp.eq.s32	%p89, %r125, 0;
	@%p89 bra 	BB13_80;

BB13_76:
	and.b32  	%r126, %r2, 2147483647;
	setp.ne.s32	%p90, %r126, 2146435072;
	@%p90 bra 	BB13_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %fd1;
	}
	setp.ne.s32	%p91, %r127, 0;
	mov.f64 	%fd144, %fd143;
	@%p91 bra 	BB13_81;

	shr.s32 	%r128, %r6, 31;
	and.b32  	%r129, %r128, -2146435072;
	add.s32 	%r130, %r129, 2146435072;
	or.b32  	%r131, %r130, -2147483648;
	selp.b32	%r132, %r131, %r130, %p5;
	mov.u32 	%r133, 0;
	mov.b64 	%fd144, {%r133, %r132};
	bra.uni 	BB13_81;

BB13_72:
	mov.f64 	%fd144, %fd143;
	bra.uni 	BB13_81;

BB13_77:
	mov.f64 	%fd144, %fd143;
	bra.uni 	BB13_81;

BB13_80:
	setp.gt.f64	%p92, %fd2, 0d3FF0000000000000;
	selp.b32	%r134, 2146435072, 0, %p92;
	xor.b32  	%r135, %r134, 2146435072;
	setp.lt.s32	%p93, %r6, 0;
	selp.b32	%r136, %r135, %r134, %p93;
	setp.eq.f64	%p94, %fd1, 0dBFF0000000000000;
	selp.b32	%r137, 1072693248, %r136, %p94;
	mov.u32 	%r138, 0;
	mov.b64 	%fd144, {%r138, %r137};

BB13_81:
	selp.f64	%fd59, 0d3FF0000000000000, %fd144, %p27;
	mov.f64 	%fd108, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd108;
	}
	bfe.u32 	%r139, %r7, 20, 11;
	add.s32 	%r140, %r139, -1012;
	mov.u64 	%rd13, 4611686018427387904;
	shl.b64 	%rd6, %rd13, %r140;
	setp.eq.s64	%p96, %rd6, -9223372036854775808;
	// Callseq Start 45
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd108;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd146, [retval0+0];
	
	//{
	}// Callseq End 45
	and.pred  	%p6, %p12, %p96;
	@!%p6 bra 	BB13_83;
	bra.uni 	BB13_82;

BB13_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd146;
	}
	xor.b32  	%r142, %r141, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r143, %temp}, %fd146;
	}
	mov.b64 	%fd146, {%r143, %r142};

BB13_83:
	@%p13 bra 	BB13_86;
	bra.uni 	BB13_84;

BB13_86:
	selp.b32	%r144, %r2, 0, %p96;
	or.b32  	%r145, %r144, 2146435072;
	setp.lt.s32	%p102, %r7, 0;
	selp.b32	%r146, %r145, %r144, %p102;
	mov.u32 	%r147, 0;
	mov.b64 	%fd146, {%r147, %r146};
	bra.uni 	BB13_87;

BB13_84:
	setp.gt.s32	%p99, %r2, -1;
	@%p99 bra 	BB13_87;

	cvt.rzi.f64.f64	%fd110, %fd108;
	setp.neu.f64	%p100, %fd110, 0d4000000000000000;
	selp.f64	%fd146, 0dFFF8000000000000, %fd146, %p100;

BB13_87:
	add.f64 	%fd147, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r148}, %fd147;
	}
	and.b32  	%r149, %r148, 2146435072;
	setp.ne.s32	%p103, %r149, 2146435072;
	@%p103 bra 	BB13_88;

	setp.gtu.f64	%p104, %fd2, 0d7FF0000000000000;
	@%p104 bra 	BB13_97;

	and.b32  	%r150, %r7, 2147483647;
	setp.ne.s32	%p105, %r150, 2146435072;
	@%p105 bra 	BB13_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r151, %temp}, %fd108;
	}
	setp.eq.s32	%p106, %r151, 0;
	@%p106 bra 	BB13_96;

BB13_92:
	and.b32  	%r152, %r2, 2147483647;
	setp.ne.s32	%p107, %r152, 2146435072;
	@%p107 bra 	BB13_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd1;
	}
	setp.ne.s32	%p108, %r153, 0;
	mov.f64 	%fd147, %fd146;
	@%p108 bra 	BB13_97;

	shr.s32 	%r154, %r7, 31;
	and.b32  	%r155, %r154, -2146435072;
	add.s32 	%r156, %r155, 2146435072;
	or.b32  	%r157, %r156, -2147483648;
	selp.b32	%r158, %r157, %r156, %p6;
	mov.u32 	%r159, 0;
	mov.b64 	%fd147, {%r159, %r158};
	bra.uni 	BB13_97;

BB13_88:
	mov.f64 	%fd147, %fd146;
	bra.uni 	BB13_97;

BB13_93:
	mov.f64 	%fd147, %fd146;
	bra.uni 	BB13_97;

BB13_96:
	setp.gt.f64	%p109, %fd2, 0d3FF0000000000000;
	selp.b32	%r160, 2146435072, 0, %p109;
	xor.b32  	%r161, %r160, 2146435072;
	setp.lt.s32	%p110, %r7, 0;
	selp.b32	%r162, %r161, %r160, %p110;
	setp.eq.f64	%p111, %fd1, 0dBFF0000000000000;
	selp.b32	%r163, 1072693248, %r162, %p111;
	mov.u32 	%r164, 0;
	mov.b64 	%fd147, {%r164, %r163};

BB13_97:
	mul.f64 	%fd112, %fd147, 0d40EE000000000000;
	selp.f64	%fd113, 0d40EE000000000000, %fd112, %p27;
	fma.rn.f64 	%fd114, %fd59, 0dC122C00000000000, %fd48;
	add.f64 	%fd70, %fd114, %fd113;
	mov.f64 	%fd115, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd115;
	}
	bfe.u32 	%r165, %r8, 20, 11;
	add.s32 	%r166, %r165, -1012;
	mov.u64 	%rd14, 4620693217682128896;
	shl.b64 	%rd7, %rd14, %r166;
	setp.eq.s64	%p113, %rd7, -9223372036854775808;
	// Callseq Start 46
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd149, [retval0+0];
	
	//{
	}// Callseq End 46
	and.pred  	%p7, %p12, %p113;
	@!%p7 bra 	BB13_99;
	bra.uni 	BB13_98;

BB13_98:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r167}, %fd149;
	}
	xor.b32  	%r168, %r167, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r169, %temp}, %fd149;
	}
	mov.b64 	%fd149, {%r169, %r168};

BB13_99:
	@%p13 bra 	BB13_102;
	bra.uni 	BB13_100;

BB13_102:
	selp.b32	%r170, %r2, 0, %p113;
	or.b32  	%r171, %r170, 2146435072;
	setp.lt.s32	%p119, %r8, 0;
	selp.b32	%r172, %r171, %r170, %p119;
	mov.u32 	%r173, 0;
	mov.b64 	%fd149, {%r173, %r172};
	bra.uni 	BB13_103;

BB13_100:
	setp.gt.s32	%p116, %r2, -1;
	@%p116 bra 	BB13_103;

	cvt.rzi.f64.f64	%fd117, %fd115;
	setp.neu.f64	%p117, %fd117, 0d4020000000000000;
	selp.f64	%fd149, 0dFFF8000000000000, %fd149, %p117;

BB13_103:
	add.f64 	%fd150, %fd1, 0d4020000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r174}, %fd150;
	}
	and.b32  	%r175, %r174, 2146435072;
	setp.ne.s32	%p120, %r175, 2146435072;
	@%p120 bra 	BB13_104;

	setp.gtu.f64	%p121, %fd2, 0d7FF0000000000000;
	@%p121 bra 	BB13_113;

	and.b32  	%r176, %r8, 2147483647;
	setp.ne.s32	%p122, %r176, 2146435072;
	@%p122 bra 	BB13_108;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r177, %temp}, %fd115;
	}
	setp.eq.s32	%p123, %r177, 0;
	@%p123 bra 	BB13_112;

BB13_108:
	and.b32  	%r178, %r2, 2147483647;
	setp.ne.s32	%p124, %r178, 2146435072;
	@%p124 bra 	BB13_109;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r179, %temp}, %fd1;
	}
	setp.ne.s32	%p125, %r179, 0;
	mov.f64 	%fd150, %fd149;
	@%p125 bra 	BB13_113;

	shr.s32 	%r180, %r8, 31;
	and.b32  	%r181, %r180, -2146435072;
	add.s32 	%r182, %r181, 2146435072;
	or.b32  	%r183, %r182, -2147483648;
	selp.b32	%r184, %r183, %r182, %p7;
	mov.u32 	%r185, 0;
	mov.b64 	%fd150, {%r185, %r184};
	bra.uni 	BB13_113;

BB13_104:
	mov.f64 	%fd150, %fd149;
	bra.uni 	BB13_113;

BB13_109:
	mov.f64 	%fd150, %fd149;
	bra.uni 	BB13_113;

BB13_112:
	setp.gt.f64	%p126, %fd2, 0d3FF0000000000000;
	selp.b32	%r186, 2146435072, 0, %p126;
	xor.b32  	%r187, %r186, 2146435072;
	setp.lt.s32	%p127, %r8, 0;
	selp.b32	%r188, %r187, %r186, %p127;
	setp.eq.f64	%p128, %fd1, 0dBFF0000000000000;
	selp.b32	%r189, 1072693248, %r188, %p128;
	mov.u32 	%r190, 0;
	mov.b64 	%fd150, {%r190, %r189};

BB13_113:
	mul.f64 	%fd119, %fd150, 0dC0F6800000000000;
	selp.f64	%fd120, 0dC0F6800000000000, %fd119, %p27;
	fma.rn.f64 	%fd121, %fd13, 0d4116800000000000, %fd120;
	fma.rn.f64 	%fd122, %fd24, 0dC121800000000000, %fd121;
	fma.rn.f64 	%fd123, %fd36, 0d411A400000000000, %fd122;
	fma.rn.f64 	%fd124, %fd47, 0dC102C00000000000, %fd123;
	fma.rn.f64 	%fd125, %fd59, 0d40D4000000000000, %fd124;
	add.f64 	%fd126, %fd83, %fd83;
	mul.f64 	%fd127, %fd126, %fd125;
	mul.f64 	%fd128, %fd83, %fd83;
	mul.f64 	%fd129, %fd128, %fd84;
	fma.rn.f64 	%fd151, %fd129, %fd70, %fd127;

BB13_114:
	st.param.f64	[func_retval0+0], %fd151;
	ret;
}

	// .globl	_Z19VerySmoothBump_ttttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z19VerySmoothBump_ttttddPdiPii(
	.param .b64 _Z19VerySmoothBump_ttttddPdiPii_param_0,
	.param .b64 _Z19VerySmoothBump_ttttddPdiPii_param_1,
	.param .b64 _Z19VerySmoothBump_ttttddPdiPii_param_2,
	.param .b32 _Z19VerySmoothBump_ttttddPdiPii_param_3,
	.param .b64 _Z19VerySmoothBump_ttttddPdiPii_param_4,
	.param .b32 _Z19VerySmoothBump_ttttddPdiPii_param_5
)
{
	.reg .pred 	%p<111>;
	.reg .b32 	%r<166>;
	.reg .f64 	%fd<129>;
	.reg .b64 	%rd<15>;


	ld.param.f64 	%fd69, [_Z19VerySmoothBump_ttttddPdiPii_param_0];
	ld.param.f64 	%fd71, [_Z19VerySmoothBump_ttttddPdiPii_param_1];
	mul.f64 	%fd1, %fd69, %fd71;
	setp.lt.f64	%p7, %fd1, 0d0000000000000000;
	setp.gt.f64	%p8, %fd1, 0d3FF0000000000000;
	or.pred  	%p9, %p7, %p8;
	mov.f64 	%fd128, 0d0000000000000000;
	@%p9 bra 	BB14_98;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd69;
	}
	mov.f64 	%fd72, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd72;
	}
	bfe.u32 	%r8, %r2, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd6, 4616189618054758400;
	shl.b64 	%rd1, %rd6, %r9;
	setp.eq.s64	%p10, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd69;
	// Callseq Start 47
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd111, [retval0+0];
	
	//{
	}// Callseq End 47
	setp.lt.s32	%p11, %r1, 0;
	and.pred  	%p1, %p11, %p10;
	@!%p1 bra 	BB14_3;
	bra.uni 	BB14_2;

BB14_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd111;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd111;
	}
	mov.b64 	%fd111, {%r12, %r11};

BB14_3:
	setp.eq.f64	%p12, %fd69, 0d0000000000000000;
	@%p12 bra 	BB14_6;
	bra.uni 	BB14_4;

BB14_6:
	selp.b32	%r13, %r1, 0, %p10;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r15, %r14, %r13, %p16;
	mov.u32 	%r16, 0;
	mov.b64 	%fd111, {%r16, %r15};
	bra.uni 	BB14_7;

BB14_4:
	setp.gt.s32	%p13, %r1, -1;
	@%p13 bra 	BB14_7;

	cvt.rzi.f64.f64	%fd74, %fd72;
	setp.neu.f64	%p14, %fd74, 0d4010000000000000;
	selp.f64	%fd111, 0dFFF8000000000000, %fd111, %p14;

BB14_7:
	add.f64 	%fd112, %fd69, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd112;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p17, %r18, 2146435072;
	@%p17 bra 	BB14_8;

	setp.gtu.f64	%p18, %fd2, 0d7FF0000000000000;
	@%p18 bra 	BB14_17;

	and.b32  	%r19, %r2, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB14_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd72;
	}
	setp.eq.s32	%p20, %r20, 0;
	@%p20 bra 	BB14_16;

BB14_12:
	and.b32  	%r21, %r1, 2147483647;
	setp.ne.s32	%p21, %r21, 2146435072;
	@%p21 bra 	BB14_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd69;
	}
	setp.ne.s32	%p22, %r22, 0;
	mov.f64 	%fd112, %fd111;
	@%p22 bra 	BB14_17;

	shr.s32 	%r23, %r2, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd112, {%r28, %r27};
	bra.uni 	BB14_17;

BB14_8:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB14_17;

BB14_13:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB14_17;

BB14_16:
	setp.gt.f64	%p23, %fd2, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p23;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p24, %r2, 0;
	selp.b32	%r31, %r30, %r29, %p24;
	setp.eq.f64	%p25, %fd69, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p25;
	mov.u32 	%r33, 0;
	mov.b64 	%fd112, {%r33, %r32};

BB14_17:
	mov.f64 	%fd76, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd76;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd7, 4618441417868443648;
	shl.b64 	%rd2, %rd7, %r35;
	setp.eq.s64	%p26, %rd2, -9223372036854775808;
	abs.f64 	%fd13, %fd1;
	// Callseq Start 48
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd13;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd114, [retval0+0];
	
	//{
	}// Callseq End 48
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd1;
	}
	setp.lt.s32	%p27, %r4, 0;
	and.pred  	%p2, %p27, %p26;
	@!%p2 bra 	BB14_19;
	bra.uni 	BB14_18;

BB14_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd114;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd114;
	}
	mov.b64 	%fd114, {%r38, %r37};

BB14_19:
	setp.eq.f64	%p28, %fd1, 0d0000000000000000;
	@%p28 bra 	BB14_22;
	bra.uni 	BB14_20;

BB14_22:
	selp.b32	%r39, %r4, 0, %p26;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p32, %r3, 0;
	selp.b32	%r41, %r40, %r39, %p32;
	mov.u32 	%r42, 0;
	mov.b64 	%fd114, {%r42, %r41};
	bra.uni 	BB14_23;

BB14_20:
	setp.gt.s32	%p29, %r4, -1;
	@%p29 bra 	BB14_23;

	cvt.rzi.f64.f64	%fd78, %fd76;
	setp.neu.f64	%p30, %fd78, 0d4018000000000000;
	selp.f64	%fd114, 0dFFF8000000000000, %fd114, %p30;

BB14_23:
	add.f64 	%fd115, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd115;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB14_24;

	setp.gtu.f64	%p34, %fd13, 0d7FF0000000000000;
	@%p34 bra 	BB14_33;

	and.b32  	%r45, %r3, 2147483647;
	setp.ne.s32	%p35, %r45, 2146435072;
	@%p35 bra 	BB14_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd76;
	}
	setp.eq.s32	%p36, %r46, 0;
	@%p36 bra 	BB14_32;

BB14_28:
	and.b32  	%r47, %r4, 2147483647;
	setp.ne.s32	%p37, %r47, 2146435072;
	@%p37 bra 	BB14_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p38, %r48, 0;
	mov.f64 	%fd115, %fd114;
	@%p38 bra 	BB14_33;

	shr.s32 	%r49, %r3, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd115, {%r54, %r53};
	bra.uni 	BB14_33;

BB14_24:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB14_33;

BB14_29:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB14_33;

BB14_32:
	setp.gt.f64	%p39, %fd13, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p39;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p40, %r3, 0;
	selp.b32	%r57, %r56, %r55, %p40;
	setp.eq.f64	%p41, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p41;
	mov.u32 	%r59, 0;
	mov.b64 	%fd115, {%r59, %r58};

BB14_33:
	mov.f64 	%fd80, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd80;
	}
	bfe.u32 	%r60, %r5, 20, 11;
	add.s32 	%r61, %r60, -1012;
	mov.u64 	%rd8, 4617315517961601024;
	shl.b64 	%rd3, %rd8, %r61;
	setp.eq.s64	%p42, %rd3, -9223372036854775808;
	// Callseq Start 49
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd13;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd80;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd117, [retval0+0];
	
	//{
	}// Callseq End 49
	and.pred  	%p3, %p27, %p42;
	@!%p3 bra 	BB14_35;
	bra.uni 	BB14_34;

BB14_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd117;
	}
	xor.b32  	%r63, %r62, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd117;
	}
	mov.b64 	%fd117, {%r64, %r63};

BB14_35:
	@%p28 bra 	BB14_38;
	bra.uni 	BB14_36;

BB14_38:
	selp.b32	%r65, %r4, 0, %p42;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p48, %r5, 0;
	selp.b32	%r67, %r66, %r65, %p48;
	mov.u32 	%r68, 0;
	mov.b64 	%fd117, {%r68, %r67};
	bra.uni 	BB14_39;

BB14_36:
	setp.gt.s32	%p45, %r4, -1;
	@%p45 bra 	BB14_39;

	cvt.rzi.f64.f64	%fd82, %fd80;
	setp.neu.f64	%p46, %fd82, 0d4014000000000000;
	selp.f64	%fd117, 0dFFF8000000000000, %fd117, %p46;

BB14_39:
	add.f64 	%fd118, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd118;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p49, %r70, 2146435072;
	@%p49 bra 	BB14_40;

	setp.gtu.f64	%p50, %fd13, 0d7FF0000000000000;
	@%p50 bra 	BB14_49;

	and.b32  	%r71, %r5, 2147483647;
	setp.ne.s32	%p51, %r71, 2146435072;
	@%p51 bra 	BB14_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd80;
	}
	setp.eq.s32	%p52, %r72, 0;
	@%p52 bra 	BB14_48;

BB14_44:
	and.b32  	%r73, %r4, 2147483647;
	setp.ne.s32	%p53, %r73, 2146435072;
	@%p53 bra 	BB14_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r74, 0;
	mov.f64 	%fd118, %fd117;
	@%p54 bra 	BB14_49;

	shr.s32 	%r75, %r5, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd118, {%r80, %r79};
	bra.uni 	BB14_49;

BB14_40:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB14_49;

BB14_45:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB14_49;

BB14_48:
	setp.gt.f64	%p55, %fd13, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p55;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p56, %r5, 0;
	selp.b32	%r83, %r82, %r81, %p56;
	setp.eq.f64	%p57, %fd1, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p57;
	mov.u32 	%r85, 0;
	mov.b64 	%fd118, {%r85, %r84};

BB14_49:
	bfe.u32 	%r86, %r2, 20, 11;
	add.s32 	%r87, %r86, -1012;
	shl.b64 	%rd10, %rd6, %r87;
	setp.eq.s64	%p58, %rd10, -9223372036854775808;
	mul.f64 	%fd84, %fd118, 0d405F800000000000;
	setp.eq.f64	%p59, %fd1, 0d3FF0000000000000;
	selp.f64	%fd85, 0d405F800000000000, %fd84, %p59;
	mul.f64 	%fd86, %fd115, 0dC045000000000000;
	selp.f64	%fd87, 0dC045000000000000, %fd86, %p59;
	add.f64 	%fd34, %fd87, %fd85;
	// Callseq Start 50
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd13;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd120, [retval0+0];
	
	//{
	}// Callseq End 50
	and.pred  	%p4, %p27, %p58;
	@!%p4 bra 	BB14_51;
	bra.uni 	BB14_50;

BB14_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd120;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd120;
	}
	mov.b64 	%fd120, {%r90, %r89};

BB14_51:
	@%p28 bra 	BB14_54;
	bra.uni 	BB14_52;

BB14_54:
	bfe.u32 	%r91, %r2, 20, 11;
	add.s32 	%r92, %r91, -1012;
	shl.b64 	%rd12, %rd6, %r92;
	setp.eq.s64	%p64, %rd12, -9223372036854775808;
	selp.b32	%r93, %r4, 0, %p64;
	or.b32  	%r94, %r93, 2146435072;
	setp.lt.s32	%p65, %r2, 0;
	selp.b32	%r95, %r94, %r93, %p65;
	mov.u32 	%r96, 0;
	mov.b64 	%fd120, {%r96, %r95};
	bra.uni 	BB14_55;

BB14_52:
	setp.gt.s32	%p62, %r4, -1;
	@%p62 bra 	BB14_55;

	cvt.rzi.f64.f64	%fd90, %fd72;
	setp.neu.f64	%p63, %fd90, 0d4010000000000000;
	selp.f64	%fd120, 0dFFF8000000000000, %fd120, %p63;

BB14_55:
	add.f64 	%fd121, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd121;
	}
	and.b32  	%r98, %r97, 2146435072;
	setp.ne.s32	%p66, %r98, 2146435072;
	@%p66 bra 	BB14_56;

	setp.gtu.f64	%p67, %fd13, 0d7FF0000000000000;
	@%p67 bra 	BB14_65;

	and.b32  	%r99, %r2, 2147483647;
	setp.ne.s32	%p68, %r99, 2146435072;
	@%p68 bra 	BB14_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd72;
	}
	setp.eq.s32	%p69, %r100, 0;
	@%p69 bra 	BB14_64;

BB14_60:
	and.b32  	%r101, %r4, 2147483647;
	setp.ne.s32	%p70, %r101, 2146435072;
	@%p70 bra 	BB14_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r102, %temp}, %fd1;
	}
	setp.ne.s32	%p71, %r102, 0;
	mov.f64 	%fd121, %fd120;
	@%p71 bra 	BB14_65;

	shr.s32 	%r103, %r2, 31;
	and.b32  	%r104, %r103, -2146435072;
	add.s32 	%r105, %r104, 2146435072;
	or.b32  	%r106, %r105, -2147483648;
	selp.b32	%r107, %r106, %r105, %p4;
	mov.u32 	%r108, 0;
	mov.b64 	%fd121, {%r108, %r107};
	bra.uni 	BB14_65;

BB14_56:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB14_65;

BB14_61:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB14_65;

BB14_64:
	setp.gt.f64	%p72, %fd13, 0d3FF0000000000000;
	selp.b32	%r109, 2146435072, 0, %p72;
	xor.b32  	%r110, %r109, 2146435072;
	setp.lt.s32	%p73, %r2, 0;
	selp.b32	%r111, %r110, %r109, %p73;
	setp.eq.f64	%p74, %fd1, 0dBFF0000000000000;
	selp.b32	%r112, 1072693248, %r111, %p74;
	mov.u32 	%r113, 0;
	mov.b64 	%fd121, {%r113, %r112};

BB14_65:
	mul.f64 	%fd92, %fd121, 0d4061800000000000;
	selp.f64	%fd93, 0d4061800000000000, %fd92, %p59;
	sub.f64 	%fd45, %fd34, %fd93;
	mov.f64 	%fd94, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd94;
	}
	bfe.u32 	%r114, %r6, 20, 11;
	add.s32 	%r115, %r114, -1012;
	mov.u64 	%rd13, 4613937818241073152;
	shl.b64 	%rd4, %rd13, %r115;
	setp.eq.s64	%p76, %rd4, -9223372036854775808;
	// Callseq Start 51
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd13;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd94;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd123, [retval0+0];
	
	//{
	}// Callseq End 51
	and.pred  	%p5, %p27, %p76;
	@!%p5 bra 	BB14_67;
	bra.uni 	BB14_66;

BB14_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r116}, %fd123;
	}
	xor.b32  	%r117, %r116, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r118, %temp}, %fd123;
	}
	mov.b64 	%fd123, {%r118, %r117};

BB14_67:
	@%p28 bra 	BB14_70;
	bra.uni 	BB14_68;

BB14_70:
	selp.b32	%r119, %r4, 0, %p76;
	or.b32  	%r120, %r119, 2146435072;
	setp.lt.s32	%p82, %r6, 0;
	selp.b32	%r121, %r120, %r119, %p82;
	mov.u32 	%r122, 0;
	mov.b64 	%fd123, {%r122, %r121};
	bra.uni 	BB14_71;

BB14_68:
	setp.gt.s32	%p79, %r4, -1;
	@%p79 bra 	BB14_71;

	cvt.rzi.f64.f64	%fd96, %fd94;
	setp.neu.f64	%p80, %fd96, 0d4008000000000000;
	selp.f64	%fd123, 0dFFF8000000000000, %fd123, %p80;

BB14_71:
	add.f64 	%fd124, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd124;
	}
	and.b32  	%r124, %r123, 2146435072;
	setp.ne.s32	%p83, %r124, 2146435072;
	@%p83 bra 	BB14_72;

	setp.gtu.f64	%p84, %fd13, 0d7FF0000000000000;
	@%p84 bra 	BB14_81;

	and.b32  	%r125, %r6, 2147483647;
	setp.ne.s32	%p85, %r125, 2146435072;
	@%p85 bra 	BB14_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd94;
	}
	setp.eq.s32	%p86, %r126, 0;
	@%p86 bra 	BB14_80;

BB14_76:
	and.b32  	%r127, %r4, 2147483647;
	setp.ne.s32	%p87, %r127, 2146435072;
	@%p87 bra 	BB14_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r128, %temp}, %fd1;
	}
	setp.ne.s32	%p88, %r128, 0;
	mov.f64 	%fd124, %fd123;
	@%p88 bra 	BB14_81;

	shr.s32 	%r129, %r6, 31;
	and.b32  	%r130, %r129, -2146435072;
	add.s32 	%r131, %r130, 2146435072;
	or.b32  	%r132, %r131, -2147483648;
	selp.b32	%r133, %r132, %r131, %p5;
	mov.u32 	%r134, 0;
	mov.b64 	%fd124, {%r134, %r133};
	bra.uni 	BB14_81;

BB14_72:
	mov.f64 	%fd124, %fd123;
	bra.uni 	BB14_81;

BB14_77:
	mov.f64 	%fd124, %fd123;
	bra.uni 	BB14_81;

BB14_80:
	setp.gt.f64	%p89, %fd13, 0d3FF0000000000000;
	selp.b32	%r135, 2146435072, 0, %p89;
	xor.b32  	%r136, %r135, 2146435072;
	setp.lt.s32	%p90, %r6, 0;
	selp.b32	%r137, %r136, %r135, %p90;
	setp.eq.f64	%p91, %fd1, 0dBFF0000000000000;
	selp.b32	%r138, 1072693248, %r137, %p91;
	mov.u32 	%r139, 0;
	mov.b64 	%fd124, {%r139, %r138};

BB14_81:
	mul.f64 	%fd98, %fd124, 0d4051800000000000;
	selp.f64	%fd99, 0d4051800000000000, %fd98, %p59;
	add.f64 	%fd56, %fd45, %fd99;
	mov.f64 	%fd100, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd100;
	}
	bfe.u32 	%r140, %r7, 20, 11;
	add.s32 	%r141, %r140, -1012;
	mov.u64 	%rd14, 4611686018427387904;
	shl.b64 	%rd5, %rd14, %r141;
	setp.eq.s64	%p93, %rd5, -9223372036854775808;
	// Callseq Start 52
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd13;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd100;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd126, [retval0+0];
	
	//{
	}// Callseq End 52
	and.pred  	%p6, %p27, %p93;
	@!%p6 bra 	BB14_83;
	bra.uni 	BB14_82;

BB14_82:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %fd126;
	}
	xor.b32  	%r143, %r142, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r144, %temp}, %fd126;
	}
	mov.b64 	%fd126, {%r144, %r143};

BB14_83:
	@%p28 bra 	BB14_86;
	bra.uni 	BB14_84;

BB14_86:
	selp.b32	%r145, %r4, 0, %p93;
	or.b32  	%r146, %r145, 2146435072;
	setp.lt.s32	%p99, %r7, 0;
	selp.b32	%r147, %r146, %r145, %p99;
	mov.u32 	%r148, 0;
	mov.b64 	%fd126, {%r148, %r147};
	bra.uni 	BB14_87;

BB14_84:
	setp.gt.s32	%p96, %r4, -1;
	@%p96 bra 	BB14_87;

	cvt.rzi.f64.f64	%fd102, %fd100;
	setp.neu.f64	%p97, %fd102, 0d4000000000000000;
	selp.f64	%fd126, 0dFFF8000000000000, %fd126, %p97;

BB14_87:
	add.f64 	%fd127, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r149}, %fd127;
	}
	and.b32  	%r150, %r149, 2146435072;
	setp.ne.s32	%p100, %r150, 2146435072;
	@%p100 bra 	BB14_88;

	setp.gtu.f64	%p101, %fd13, 0d7FF0000000000000;
	@%p101 bra 	BB14_97;

	and.b32  	%r151, %r7, 2147483647;
	setp.ne.s32	%p102, %r151, 2146435072;
	@%p102 bra 	BB14_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd100;
	}
	setp.eq.s32	%p103, %r152, 0;
	@%p103 bra 	BB14_96;

BB14_92:
	and.b32  	%r153, %r4, 2147483647;
	setp.ne.s32	%p104, %r153, 2146435072;
	@%p104 bra 	BB14_93;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r154, %temp}, %fd1;
	}
	setp.ne.s32	%p105, %r154, 0;
	mov.f64 	%fd127, %fd126;
	@%p105 bra 	BB14_97;

	shr.s32 	%r155, %r7, 31;
	and.b32  	%r156, %r155, -2146435072;
	add.s32 	%r157, %r156, 2146435072;
	or.b32  	%r158, %r157, -2147483648;
	selp.b32	%r159, %r158, %r157, %p6;
	mov.u32 	%r160, 0;
	mov.b64 	%fd127, {%r160, %r159};
	bra.uni 	BB14_97;

BB14_88:
	mov.f64 	%fd127, %fd126;
	bra.uni 	BB14_97;

BB14_93:
	mov.f64 	%fd127, %fd126;
	bra.uni 	BB14_97;

BB14_96:
	setp.gt.f64	%p106, %fd13, 0d3FF0000000000000;
	selp.b32	%r161, 2146435072, 0, %p106;
	xor.b32  	%r162, %r161, 2146435072;
	setp.lt.s32	%p107, %r7, 0;
	selp.b32	%r163, %r162, %r161, %p107;
	setp.eq.f64	%p108, %fd1, 0dBFF0000000000000;
	selp.b32	%r164, 1072693248, %r163, %p108;
	mov.u32 	%r165, 0;
	mov.b64 	%fd127, {%r165, %r164};

BB14_97:
	mul.f64 	%fd104, %fd127, 0d402E000000000000;
	selp.f64	%fd105, 0d402E000000000000, %fd104, %p59;
	sub.f64 	%fd106, %fd56, %fd105;
	add.f64 	%fd107, %fd1, %fd106;
	setp.eq.f64	%p110, %fd69, 0d3FF0000000000000;
	mul.f64 	%fd108, %fd112, 0d40FE000000000000;
	selp.f64	%fd109, 0d40FE000000000000, %fd108, %p110;
	mul.f64 	%fd128, %fd109, %fd107;

BB14_98:
	st.param.f64	[func_retval0+0], %fd128;
	ret;
}

	// .globl	_Z20VerySmoothBump_tttomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z20VerySmoothBump_tttomddPdiPii(
	.param .b64 _Z20VerySmoothBump_tttomddPdiPii_param_0,
	.param .b64 _Z20VerySmoothBump_tttomddPdiPii_param_1,
	.param .b64 _Z20VerySmoothBump_tttomddPdiPii_param_2,
	.param .b32 _Z20VerySmoothBump_tttomddPdiPii_param_3,
	.param .b64 _Z20VerySmoothBump_tttomddPdiPii_param_4,
	.param .b32 _Z20VerySmoothBump_tttomddPdiPii_param_5
)
{
	.reg .pred 	%p<93>;
	.reg .b32 	%r<137>;
	.reg .f64 	%fd<114>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd58, [_Z20VerySmoothBump_tttomddPdiPii_param_0];
	ld.param.f64 	%fd59, [_Z20VerySmoothBump_tttomddPdiPii_param_1];
	mul.f64 	%fd1, %fd58, %fd59;
	setp.lt.f64	%p6, %fd1, 0d0000000000000000;
	setp.gt.f64	%p7, %fd1, 0d3FF0000000000000;
	or.pred  	%p8, %p6, %p7;
	mov.f64 	%fd113, 0d0000000000000000;
	@%p8 bra 	BB15_82;

	mov.f64 	%fd61, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd61;
	}
	bfe.u32 	%r7, %r1, 20, 11;
	add.s32 	%r8, %r7, -1012;
	mov.u64 	%rd6, 4619567317775286272;
	shl.b64 	%rd1, %rd6, %r8;
	setp.eq.s64	%p9, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 53
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd99, [retval0+0];
	
	//{
	}// Callseq End 53
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p10, %r2, 0;
	and.pred  	%p1, %p10, %p9;
	@!%p1 bra 	BB15_3;
	bra.uni 	BB15_2;

BB15_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd99;
	}
	xor.b32  	%r10, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r11, %temp}, %fd99;
	}
	mov.b64 	%fd99, {%r11, %r10};

BB15_3:
	setp.eq.f64	%p11, %fd1, 0d0000000000000000;
	@%p11 bra 	BB15_6;
	bra.uni 	BB15_4;

BB15_6:
	selp.b32	%r12, %r2, 0, %p9;
	or.b32  	%r13, %r12, 2146435072;
	setp.lt.s32	%p15, %r1, 0;
	selp.b32	%r14, %r13, %r12, %p15;
	mov.u32 	%r15, 0;
	mov.b64 	%fd99, {%r15, %r14};
	bra.uni 	BB15_7;

BB15_4:
	setp.gt.s32	%p12, %r2, -1;
	@%p12 bra 	BB15_7;

	cvt.rzi.f64.f64	%fd63, %fd61;
	setp.neu.f64	%p13, %fd63, 0d401C000000000000;
	selp.f64	%fd99, 0dFFF8000000000000, %fd99, %p13;

BB15_7:
	add.f64 	%fd100, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd100;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.ne.s32	%p16, %r17, 2146435072;
	@%p16 bra 	BB15_8;

	setp.gtu.f64	%p17, %fd2, 0d7FF0000000000000;
	@%p17 bra 	BB15_17;

	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB15_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd61;
	}
	setp.eq.s32	%p19, %r19, 0;
	@%p19 bra 	BB15_16;

BB15_12:
	and.b32  	%r20, %r2, 2147483647;
	setp.ne.s32	%p20, %r20, 2146435072;
	@%p20 bra 	BB15_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd1;
	}
	setp.ne.s32	%p21, %r21, 0;
	mov.f64 	%fd100, %fd99;
	@%p21 bra 	BB15_17;

	shr.s32 	%r22, %r1, 31;
	and.b32  	%r23, %r22, -2146435072;
	add.s32 	%r24, %r23, 2146435072;
	or.b32  	%r25, %r24, -2147483648;
	selp.b32	%r26, %r25, %r24, %p1;
	mov.u32 	%r27, 0;
	mov.b64 	%fd100, {%r27, %r26};
	bra.uni 	BB15_17;

BB15_8:
	mov.f64 	%fd100, %fd99;
	bra.uni 	BB15_17;

BB15_13:
	mov.f64 	%fd100, %fd99;
	bra.uni 	BB15_17;

BB15_16:
	setp.gt.f64	%p22, %fd2, 0d3FF0000000000000;
	selp.b32	%r28, 2146435072, 0, %p22;
	xor.b32  	%r29, %r28, 2146435072;
	setp.lt.s32	%p23, %r1, 0;
	selp.b32	%r30, %r29, %r28, %p23;
	setp.eq.f64	%p24, %fd1, 0dBFF0000000000000;
	selp.b32	%r31, 1072693248, %r30, %p24;
	mov.u32 	%r32, 0;
	mov.b64 	%fd100, {%r32, %r31};

BB15_17:
	mov.f64 	%fd65, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd65;
	}
	bfe.u32 	%r33, %r3, 20, 11;
	add.s32 	%r34, %r33, -1012;
	mov.u64 	%rd7, 4618441417868443648;
	shl.b64 	%rd2, %rd7, %r34;
	setp.eq.s64	%p25, %rd2, -9223372036854775808;
	// Callseq Start 54
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd65;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd102, [retval0+0];
	
	//{
	}// Callseq End 54
	and.pred  	%p2, %p10, %p25;
	@!%p2 bra 	BB15_19;
	bra.uni 	BB15_18;

BB15_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd102;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd102;
	}
	mov.b64 	%fd102, {%r37, %r36};

BB15_19:
	@%p11 bra 	BB15_22;
	bra.uni 	BB15_20;

BB15_22:
	selp.b32	%r38, %r2, 0, %p25;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p31;
	mov.u32 	%r41, 0;
	mov.b64 	%fd102, {%r41, %r40};
	bra.uni 	BB15_23;

BB15_20:
	setp.gt.s32	%p28, %r2, -1;
	@%p28 bra 	BB15_23;

	cvt.rzi.f64.f64	%fd67, %fd65;
	setp.neu.f64	%p29, %fd67, 0d4018000000000000;
	selp.f64	%fd102, 0dFFF8000000000000, %fd102, %p29;

BB15_23:
	add.f64 	%fd103, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd103;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p32, %r43, 2146435072;
	@%p32 bra 	BB15_24;

	setp.gtu.f64	%p33, %fd2, 0d7FF0000000000000;
	@%p33 bra 	BB15_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p34, %r44, 2146435072;
	@%p34 bra 	BB15_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd65;
	}
	setp.eq.s32	%p35, %r45, 0;
	@%p35 bra 	BB15_32;

BB15_28:
	and.b32  	%r46, %r2, 2147483647;
	setp.ne.s32	%p36, %r46, 2146435072;
	@%p36 bra 	BB15_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd1;
	}
	setp.ne.s32	%p37, %r47, 0;
	mov.f64 	%fd103, %fd102;
	@%p37 bra 	BB15_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd103, {%r53, %r52};
	bra.uni 	BB15_33;

BB15_24:
	mov.f64 	%fd103, %fd102;
	bra.uni 	BB15_33;

BB15_29:
	mov.f64 	%fd103, %fd102;
	bra.uni 	BB15_33;

BB15_32:
	setp.gt.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p38;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p39;
	setp.eq.f64	%p40, %fd1, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p40;
	mov.u32 	%r58, 0;
	mov.b64 	%fd103, {%r58, %r57};

BB15_33:
	mul.f64 	%fd69, %fd103, 0d4077A00000000000;
	setp.eq.f64	%p41, %fd1, 0d3FF0000000000000;
	selp.f64	%fd70, 0d4077A00000000000, %fd69, %p41;
	mul.f64 	%fd71, %fd100, 0dC05E000000000000;
	selp.f64	%fd72, 0dC05E000000000000, %fd71, %p41;
	add.f64 	%fd23, %fd72, %fd70;
	mov.f64 	%fd73, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd73;
	}
	bfe.u32 	%r59, %r4, 20, 11;
	add.s32 	%r60, %r59, -1012;
	mov.u64 	%rd8, 4617315517961601024;
	shl.b64 	%rd3, %rd8, %r60;
	setp.eq.s64	%p42, %rd3, -9223372036854775808;
	// Callseq Start 55
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd73;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd105, [retval0+0];
	
	//{
	}// Callseq End 55
	and.pred  	%p3, %p10, %p42;
	@!%p3 bra 	BB15_35;
	bra.uni 	BB15_34;

BB15_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd105;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd105;
	}
	mov.b64 	%fd105, {%r63, %r62};

BB15_35:
	@%p11 bra 	BB15_38;
	bra.uni 	BB15_36;

BB15_38:
	selp.b32	%r64, %r2, 0, %p42;
	or.b32  	%r65, %r64, 2146435072;
	setp.lt.s32	%p48, %r4, 0;
	selp.b32	%r66, %r65, %r64, %p48;
	mov.u32 	%r67, 0;
	mov.b64 	%fd105, {%r67, %r66};
	bra.uni 	BB15_39;

BB15_36:
	setp.gt.s32	%p45, %r2, -1;
	@%p45 bra 	BB15_39;

	cvt.rzi.f64.f64	%fd75, %fd73;
	setp.neu.f64	%p46, %fd75, 0d4014000000000000;
	selp.f64	%fd105, 0dFFF8000000000000, %fd105, %p46;

BB15_39:
	add.f64 	%fd106, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd106;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.ne.s32	%p49, %r69, 2146435072;
	@%p49 bra 	BB15_40;

	setp.gtu.f64	%p50, %fd2, 0d7FF0000000000000;
	@%p50 bra 	BB15_49;

	and.b32  	%r70, %r4, 2147483647;
	setp.ne.s32	%p51, %r70, 2146435072;
	@%p51 bra 	BB15_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd73;
	}
	setp.eq.s32	%p52, %r71, 0;
	@%p52 bra 	BB15_48;

BB15_44:
	and.b32  	%r72, %r2, 2147483647;
	setp.ne.s32	%p53, %r72, 2146435072;
	@%p53 bra 	BB15_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r73, 0;
	mov.f64 	%fd106, %fd105;
	@%p54 bra 	BB15_49;

	shr.s32 	%r74, %r4, 31;
	and.b32  	%r75, %r74, -2146435072;
	add.s32 	%r76, %r75, 2146435072;
	or.b32  	%r77, %r76, -2147483648;
	selp.b32	%r78, %r77, %r76, %p3;
	mov.u32 	%r79, 0;
	mov.b64 	%fd106, {%r79, %r78};
	bra.uni 	BB15_49;

BB15_40:
	mov.f64 	%fd106, %fd105;
	bra.uni 	BB15_49;

BB15_45:
	mov.f64 	%fd106, %fd105;
	bra.uni 	BB15_49;

BB15_48:
	setp.gt.f64	%p55, %fd2, 0d3FF0000000000000;
	selp.b32	%r80, 2146435072, 0, %p55;
	xor.b32  	%r81, %r80, 2146435072;
	setp.lt.s32	%p56, %r4, 0;
	selp.b32	%r82, %r81, %r80, %p56;
	setp.eq.f64	%p57, %fd1, 0dBFF0000000000000;
	selp.b32	%r83, 1072693248, %r82, %p57;
	mov.u32 	%r84, 0;
	mov.b64 	%fd106, {%r84, %r83};

BB15_49:
	mul.f64 	%fd77, %fd106, 0d407C000000000000;
	selp.f64	%fd78, 0d407C000000000000, %fd77, %p41;
	sub.f64 	%fd34, %fd23, %fd78;
	mov.f64 	%fd79, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd79;
	}
	bfe.u32 	%r85, %r5, 20, 11;
	add.s32 	%r86, %r85, -1012;
	mov.u64 	%rd9, 4616189618054758400;
	shl.b64 	%rd4, %rd9, %r86;
	setp.eq.s64	%p59, %rd4, -9223372036854775808;
	// Callseq Start 56
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd79;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd108, [retval0+0];
	
	//{
	}// Callseq End 56
	and.pred  	%p4, %p10, %p59;
	@!%p4 bra 	BB15_51;
	bra.uni 	BB15_50;

BB15_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd108;
	}
	xor.b32  	%r88, %r87, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd108;
	}
	mov.b64 	%fd108, {%r89, %r88};

BB15_51:
	@%p11 bra 	BB15_54;
	bra.uni 	BB15_52;

BB15_54:
	selp.b32	%r90, %r2, 0, %p59;
	or.b32  	%r91, %r90, 2146435072;
	setp.lt.s32	%p65, %r5, 0;
	selp.b32	%r92, %r91, %r90, %p65;
	mov.u32 	%r93, 0;
	mov.b64 	%fd108, {%r93, %r92};
	bra.uni 	BB15_55;

BB15_52:
	setp.gt.s32	%p62, %r2, -1;
	@%p62 bra 	BB15_55;

	cvt.rzi.f64.f64	%fd81, %fd79;
	setp.neu.f64	%p63, %fd81, 0d4010000000000000;
	selp.f64	%fd108, 0dFFF8000000000000, %fd108, %p63;

BB15_55:
	add.f64 	%fd109, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd109;
	}
	and.b32  	%r95, %r94, 2146435072;
	setp.ne.s32	%p66, %r95, 2146435072;
	@%p66 bra 	BB15_56;

	setp.gtu.f64	%p67, %fd2, 0d7FF0000000000000;
	@%p67 bra 	BB15_65;

	and.b32  	%r96, %r5, 2147483647;
	setp.ne.s32	%p68, %r96, 2146435072;
	@%p68 bra 	BB15_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd79;
	}
	setp.eq.s32	%p69, %r97, 0;
	@%p69 bra 	BB15_64;

BB15_60:
	and.b32  	%r98, %r2, 2147483647;
	setp.ne.s32	%p70, %r98, 2146435072;
	@%p70 bra 	BB15_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd1;
	}
	setp.ne.s32	%p71, %r99, 0;
	mov.f64 	%fd109, %fd108;
	@%p71 bra 	BB15_65;

	shr.s32 	%r100, %r5, 31;
	and.b32  	%r101, %r100, -2146435072;
	add.s32 	%r102, %r101, 2146435072;
	or.b32  	%r103, %r102, -2147483648;
	selp.b32	%r104, %r103, %r102, %p4;
	mov.u32 	%r105, 0;
	mov.b64 	%fd109, {%r105, %r104};
	bra.uni 	BB15_65;

BB15_56:
	mov.f64 	%fd109, %fd108;
	bra.uni 	BB15_65;

BB15_61:
	mov.f64 	%fd109, %fd108;
	bra.uni 	BB15_65;

BB15_64:
	setp.gt.f64	%p72, %fd2, 0d3FF0000000000000;
	selp.b32	%r106, 2146435072, 0, %p72;
	xor.b32  	%r107, %r106, 2146435072;
	setp.lt.s32	%p73, %r5, 0;
	selp.b32	%r108, %r107, %r106, %p73;
	setp.eq.f64	%p74, %fd1, 0dBFF0000000000000;
	selp.b32	%r109, 1072693248, %r108, %p74;
	mov.u32 	%r110, 0;
	mov.b64 	%fd109, {%r110, %r109};

BB15_65:
	mul.f64 	%fd83, %fd109, 0d406EA00000000000;
	selp.f64	%fd84, 0d406EA00000000000, %fd83, %p41;
	add.f64 	%fd45, %fd34, %fd84;
	mov.f64 	%fd85, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd85;
	}
	bfe.u32 	%r111, %r6, 20, 11;
	add.s32 	%r112, %r111, -1012;
	mov.u64 	%rd10, 4613937818241073152;
	shl.b64 	%rd5, %rd10, %r112;
	setp.eq.s64	%p76, %rd5, -9223372036854775808;
	// Callseq Start 57
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd111, [retval0+0];
	
	//{
	}// Callseq End 57
	and.pred  	%p5, %p10, %p76;
	@!%p5 bra 	BB15_67;
	bra.uni 	BB15_66;

BB15_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd111;
	}
	xor.b32  	%r114, %r113, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd111;
	}
	mov.b64 	%fd111, {%r115, %r114};

BB15_67:
	@%p11 bra 	BB15_70;
	bra.uni 	BB15_68;

BB15_70:
	selp.b32	%r116, %r2, 0, %p76;
	or.b32  	%r117, %r116, 2146435072;
	setp.lt.s32	%p82, %r6, 0;
	selp.b32	%r118, %r117, %r116, %p82;
	mov.u32 	%r119, 0;
	mov.b64 	%fd111, {%r119, %r118};
	bra.uni 	BB15_71;

BB15_68:
	setp.gt.s32	%p79, %r2, -1;
	@%p79 bra 	BB15_71;

	cvt.rzi.f64.f64	%fd87, %fd85;
	setp.neu.f64	%p80, %fd87, 0d4008000000000000;
	selp.f64	%fd111, 0dFFF8000000000000, %fd111, %p80;

BB15_71:
	add.f64 	%fd112, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd112;
	}
	and.b32  	%r121, %r120, 2146435072;
	setp.ne.s32	%p83, %r121, 2146435072;
	@%p83 bra 	BB15_72;

	setp.gtu.f64	%p84, %fd2, 0d7FF0000000000000;
	@%p84 bra 	BB15_81;

	and.b32  	%r122, %r6, 2147483647;
	setp.ne.s32	%p85, %r122, 2146435072;
	@%p85 bra 	BB15_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd85;
	}
	setp.eq.s32	%p86, %r123, 0;
	@%p86 bra 	BB15_80;

BB15_76:
	and.b32  	%r124, %r2, 2147483647;
	setp.ne.s32	%p87, %r124, 2146435072;
	@%p87 bra 	BB15_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd1;
	}
	setp.ne.s32	%p88, %r125, 0;
	mov.f64 	%fd112, %fd111;
	@%p88 bra 	BB15_81;

	shr.s32 	%r126, %r6, 31;
	and.b32  	%r127, %r126, -2146435072;
	add.s32 	%r128, %r127, 2146435072;
	or.b32  	%r129, %r128, -2147483648;
	selp.b32	%r130, %r129, %r128, %p5;
	mov.u32 	%r131, 0;
	mov.b64 	%fd112, {%r131, %r130};
	bra.uni 	BB15_81;

BB15_72:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB15_81;

BB15_77:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB15_81;

BB15_80:
	setp.gt.f64	%p89, %fd2, 0d3FF0000000000000;
	selp.b32	%r132, 2146435072, 0, %p89;
	xor.b32  	%r133, %r132, 2146435072;
	setp.lt.s32	%p90, %r6, 0;
	selp.b32	%r134, %r133, %r132, %p90;
	setp.eq.f64	%p91, %fd1, 0dBFF0000000000000;
	selp.b32	%r135, 1072693248, %r134, %p91;
	mov.u32 	%r136, 0;
	mov.b64 	%fd112, {%r136, %r135};

BB15_81:
	mul.f64 	%fd89, %fd112, 0d404E000000000000;
	selp.f64	%fd90, 0d404E000000000000, %fd89, %p41;
	sub.f64 	%fd91, %fd45, %fd90;
	mul.f64 	%fd92, %fd59, 0d4014000000000000;
	mul.f64 	%fd93, %fd92, %fd58;
	mul.f64 	%fd94, %fd93, %fd59;
	fma.rn.f64 	%fd95, %fd94, %fd58, %fd91;
	mul.f64 	%fd96, %fd58, %fd58;
	mul.f64 	%fd97, %fd96, 0d40EE000000000000;
	mul.f64 	%fd113, %fd97, %fd95;

BB15_82:
	st.param.f64	[func_retval0+0], %fd113;
	ret;
}

	// .globl	_Z21VerySmoothBump_ttomomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z21VerySmoothBump_ttomomddPdiPii(
	.param .b64 _Z21VerySmoothBump_ttomomddPdiPii_param_0,
	.param .b64 _Z21VerySmoothBump_ttomomddPdiPii_param_1,
	.param .b64 _Z21VerySmoothBump_ttomomddPdiPii_param_2,
	.param .b32 _Z21VerySmoothBump_ttomomddPdiPii_param_3,
	.param .b64 _Z21VerySmoothBump_ttomomddPdiPii_param_4,
	.param .b32 _Z21VerySmoothBump_ttomomddPdiPii_param_5
)
{
	.reg .pred 	%p<93>;
	.reg .b32 	%r<137>;
	.reg .f64 	%fd<123>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd60, [_Z21VerySmoothBump_ttomomddPdiPii_param_0];
	ld.param.f64 	%fd61, [_Z21VerySmoothBump_ttomomddPdiPii_param_1];
	mul.f64 	%fd1, %fd60, %fd61;
	setp.lt.f64	%p6, %fd1, 0d0000000000000000;
	setp.gt.f64	%p7, %fd1, 0d3FF0000000000000;
	or.pred  	%p8, %p6, %p7;
	mov.f64 	%fd122, 0d0000000000000000;
	@%p8 bra 	BB16_82;

	mov.f64 	%fd63, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd63;
	}
	bfe.u32 	%r7, %r1, 20, 11;
	add.s32 	%r8, %r7, -1012;
	mov.u64 	%rd6, 4618441417868443648;
	shl.b64 	%rd1, %rd6, %r8;
	setp.eq.s64	%p9, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 58
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd108, [retval0+0];
	
	//{
	}// Callseq End 58
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p10, %r2, 0;
	and.pred  	%p1, %p10, %p9;
	@!%p1 bra 	BB16_3;
	bra.uni 	BB16_2;

BB16_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd108;
	}
	xor.b32  	%r10, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r11, %temp}, %fd108;
	}
	mov.b64 	%fd108, {%r11, %r10};

BB16_3:
	setp.eq.f64	%p11, %fd1, 0d0000000000000000;
	@%p11 bra 	BB16_6;
	bra.uni 	BB16_4;

BB16_6:
	selp.b32	%r12, %r2, 0, %p9;
	or.b32  	%r13, %r12, 2146435072;
	setp.lt.s32	%p15, %r1, 0;
	selp.b32	%r14, %r13, %r12, %p15;
	mov.u32 	%r15, 0;
	mov.b64 	%fd108, {%r15, %r14};
	bra.uni 	BB16_7;

BB16_4:
	setp.gt.s32	%p12, %r2, -1;
	@%p12 bra 	BB16_7;

	cvt.rzi.f64.f64	%fd65, %fd63;
	setp.neu.f64	%p13, %fd65, 0d4018000000000000;
	selp.f64	%fd108, 0dFFF8000000000000, %fd108, %p13;

BB16_7:
	add.f64 	%fd109, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd109;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.ne.s32	%p16, %r17, 2146435072;
	@%p16 bra 	BB16_8;

	setp.gtu.f64	%p17, %fd2, 0d7FF0000000000000;
	@%p17 bra 	BB16_17;

	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB16_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd63;
	}
	setp.eq.s32	%p19, %r19, 0;
	@%p19 bra 	BB16_16;

BB16_12:
	and.b32  	%r20, %r2, 2147483647;
	setp.ne.s32	%p20, %r20, 2146435072;
	@%p20 bra 	BB16_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd1;
	}
	setp.ne.s32	%p21, %r21, 0;
	mov.f64 	%fd109, %fd108;
	@%p21 bra 	BB16_17;

	shr.s32 	%r22, %r1, 31;
	and.b32  	%r23, %r22, -2146435072;
	add.s32 	%r24, %r23, 2146435072;
	or.b32  	%r25, %r24, -2147483648;
	selp.b32	%r26, %r25, %r24, %p1;
	mov.u32 	%r27, 0;
	mov.b64 	%fd109, {%r27, %r26};
	bra.uni 	BB16_17;

BB16_8:
	mov.f64 	%fd109, %fd108;
	bra.uni 	BB16_17;

BB16_13:
	mov.f64 	%fd109, %fd108;
	bra.uni 	BB16_17;

BB16_16:
	setp.gt.f64	%p22, %fd2, 0d3FF0000000000000;
	selp.b32	%r28, 2146435072, 0, %p22;
	xor.b32  	%r29, %r28, 2146435072;
	setp.lt.s32	%p23, %r1, 0;
	selp.b32	%r30, %r29, %r28, %p23;
	setp.eq.f64	%p24, %fd1, 0dBFF0000000000000;
	selp.b32	%r31, 1072693248, %r30, %p24;
	mov.u32 	%r32, 0;
	mov.b64 	%fd109, {%r32, %r31};

BB16_17:
	mov.f64 	%fd67, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd67;
	}
	bfe.u32 	%r33, %r3, 20, 11;
	add.s32 	%r34, %r33, -1012;
	mov.u64 	%rd7, 4617315517961601024;
	shl.b64 	%rd2, %rd7, %r34;
	setp.eq.s64	%p25, %rd2, -9223372036854775808;
	// Callseq Start 59
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd67;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd111, [retval0+0];
	
	//{
	}// Callseq End 59
	and.pred  	%p2, %p10, %p25;
	@!%p2 bra 	BB16_19;
	bra.uni 	BB16_18;

BB16_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd111;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd111;
	}
	mov.b64 	%fd111, {%r37, %r36};

BB16_19:
	@%p11 bra 	BB16_22;
	bra.uni 	BB16_20;

BB16_22:
	selp.b32	%r38, %r2, 0, %p25;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p31;
	mov.u32 	%r41, 0;
	mov.b64 	%fd111, {%r41, %r40};
	bra.uni 	BB16_23;

BB16_20:
	setp.gt.s32	%p28, %r2, -1;
	@%p28 bra 	BB16_23;

	cvt.rzi.f64.f64	%fd69, %fd67;
	setp.neu.f64	%p29, %fd69, 0d4014000000000000;
	selp.f64	%fd111, 0dFFF8000000000000, %fd111, %p29;

BB16_23:
	add.f64 	%fd112, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd112;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p32, %r43, 2146435072;
	@%p32 bra 	BB16_24;

	setp.gtu.f64	%p33, %fd2, 0d7FF0000000000000;
	@%p33 bra 	BB16_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p34, %r44, 2146435072;
	@%p34 bra 	BB16_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd67;
	}
	setp.eq.s32	%p35, %r45, 0;
	@%p35 bra 	BB16_32;

BB16_28:
	and.b32  	%r46, %r2, 2147483647;
	setp.ne.s32	%p36, %r46, 2146435072;
	@%p36 bra 	BB16_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd1;
	}
	setp.ne.s32	%p37, %r47, 0;
	mov.f64 	%fd112, %fd111;
	@%p37 bra 	BB16_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd112, {%r53, %r52};
	bra.uni 	BB16_33;

BB16_24:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB16_33;

BB16_29:
	mov.f64 	%fd112, %fd111;
	bra.uni 	BB16_33;

BB16_32:
	setp.gt.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p38;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p39;
	setp.eq.f64	%p40, %fd1, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p40;
	mov.u32 	%r58, 0;
	mov.b64 	%fd112, {%r58, %r57};

BB16_33:
	setp.eq.f64	%p41, %fd1, 0d3FF0000000000000;
	selp.f64	%fd23, 0d3FF0000000000000, %fd112, %p41;
	mul.f64 	%fd71, %fd109, 0dC045000000000000;
	selp.f64	%fd72, 0dC045000000000000, %fd71, %p41;
	fma.rn.f64 	%fd24, %fd23, 0d405F800000000000, %fd72;
	mov.f64 	%fd73, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd73;
	}
	bfe.u32 	%r59, %r4, 20, 11;
	add.s32 	%r60, %r59, -1012;
	mov.u64 	%rd8, 4616189618054758400;
	shl.b64 	%rd3, %rd8, %r60;
	setp.eq.s64	%p42, %rd3, -9223372036854775808;
	// Callseq Start 60
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd73;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd114, [retval0+0];
	
	//{
	}// Callseq End 60
	and.pred  	%p3, %p10, %p42;
	@!%p3 bra 	BB16_35;
	bra.uni 	BB16_34;

BB16_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd114;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd114;
	}
	mov.b64 	%fd114, {%r63, %r62};

BB16_35:
	@%p11 bra 	BB16_38;
	bra.uni 	BB16_36;

BB16_38:
	selp.b32	%r64, %r2, 0, %p42;
	or.b32  	%r65, %r64, 2146435072;
	setp.lt.s32	%p48, %r4, 0;
	selp.b32	%r66, %r65, %r64, %p48;
	mov.u32 	%r67, 0;
	mov.b64 	%fd114, {%r67, %r66};
	bra.uni 	BB16_39;

BB16_36:
	setp.gt.s32	%p45, %r2, -1;
	@%p45 bra 	BB16_39;

	cvt.rzi.f64.f64	%fd75, %fd73;
	setp.neu.f64	%p46, %fd75, 0d4010000000000000;
	selp.f64	%fd114, 0dFFF8000000000000, %fd114, %p46;

BB16_39:
	add.f64 	%fd115, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd115;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.ne.s32	%p49, %r69, 2146435072;
	@%p49 bra 	BB16_40;

	setp.gtu.f64	%p50, %fd2, 0d7FF0000000000000;
	@%p50 bra 	BB16_49;

	and.b32  	%r70, %r4, 2147483647;
	setp.ne.s32	%p51, %r70, 2146435072;
	@%p51 bra 	BB16_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd73;
	}
	setp.eq.s32	%p52, %r71, 0;
	@%p52 bra 	BB16_48;

BB16_44:
	and.b32  	%r72, %r2, 2147483647;
	setp.ne.s32	%p53, %r72, 2146435072;
	@%p53 bra 	BB16_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r73, 0;
	mov.f64 	%fd115, %fd114;
	@%p54 bra 	BB16_49;

	shr.s32 	%r74, %r4, 31;
	and.b32  	%r75, %r74, -2146435072;
	add.s32 	%r76, %r75, 2146435072;
	or.b32  	%r77, %r76, -2147483648;
	selp.b32	%r78, %r77, %r76, %p3;
	mov.u32 	%r79, 0;
	mov.b64 	%fd115, {%r79, %r78};
	bra.uni 	BB16_49;

BB16_40:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB16_49;

BB16_45:
	mov.f64 	%fd115, %fd114;
	bra.uni 	BB16_49;

BB16_48:
	setp.gt.f64	%p55, %fd2, 0d3FF0000000000000;
	selp.b32	%r80, 2146435072, 0, %p55;
	xor.b32  	%r81, %r80, 2146435072;
	setp.lt.s32	%p56, %r4, 0;
	selp.b32	%r82, %r81, %r80, %p56;
	setp.eq.f64	%p57, %fd1, 0dBFF0000000000000;
	selp.b32	%r83, 1072693248, %r82, %p57;
	mov.u32 	%r84, 0;
	mov.b64 	%fd115, {%r84, %r83};

BB16_49:
	selp.f64	%fd35, 0d3FF0000000000000, %fd115, %p41;
	mov.f64 	%fd77, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd77;
	}
	bfe.u32 	%r85, %r5, 20, 11;
	add.s32 	%r86, %r85, -1012;
	mov.u64 	%rd9, 4613937818241073152;
	shl.b64 	%rd4, %rd9, %r86;
	setp.eq.s64	%p59, %rd4, -9223372036854775808;
	// Callseq Start 61
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd117, [retval0+0];
	
	//{
	}// Callseq End 61
	and.pred  	%p4, %p10, %p59;
	@!%p4 bra 	BB16_51;
	bra.uni 	BB16_50;

BB16_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd117;
	}
	xor.b32  	%r88, %r87, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd117;
	}
	mov.b64 	%fd117, {%r89, %r88};

BB16_51:
	@%p11 bra 	BB16_54;
	bra.uni 	BB16_52;

BB16_54:
	selp.b32	%r90, %r2, 0, %p59;
	or.b32  	%r91, %r90, 2146435072;
	setp.lt.s32	%p65, %r5, 0;
	selp.b32	%r92, %r91, %r90, %p65;
	mov.u32 	%r93, 0;
	mov.b64 	%fd117, {%r93, %r92};
	bra.uni 	BB16_55;

BB16_52:
	setp.gt.s32	%p62, %r2, -1;
	@%p62 bra 	BB16_55;

	cvt.rzi.f64.f64	%fd79, %fd77;
	setp.neu.f64	%p63, %fd79, 0d4008000000000000;
	selp.f64	%fd117, 0dFFF8000000000000, %fd117, %p63;

BB16_55:
	add.f64 	%fd118, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd118;
	}
	and.b32  	%r95, %r94, 2146435072;
	setp.ne.s32	%p66, %r95, 2146435072;
	@%p66 bra 	BB16_56;

	setp.gtu.f64	%p67, %fd2, 0d7FF0000000000000;
	@%p67 bra 	BB16_65;

	and.b32  	%r96, %r5, 2147483647;
	setp.ne.s32	%p68, %r96, 2146435072;
	@%p68 bra 	BB16_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd77;
	}
	setp.eq.s32	%p69, %r97, 0;
	@%p69 bra 	BB16_64;

BB16_60:
	and.b32  	%r98, %r2, 2147483647;
	setp.ne.s32	%p70, %r98, 2146435072;
	@%p70 bra 	BB16_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd1;
	}
	setp.ne.s32	%p71, %r99, 0;
	mov.f64 	%fd118, %fd117;
	@%p71 bra 	BB16_65;

	shr.s32 	%r100, %r5, 31;
	and.b32  	%r101, %r100, -2146435072;
	add.s32 	%r102, %r101, 2146435072;
	or.b32  	%r103, %r102, -2147483648;
	selp.b32	%r104, %r103, %r102, %p4;
	mov.u32 	%r105, 0;
	mov.b64 	%fd118, {%r105, %r104};
	bra.uni 	BB16_65;

BB16_56:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB16_65;

BB16_61:
	mov.f64 	%fd118, %fd117;
	bra.uni 	BB16_65;

BB16_64:
	setp.gt.f64	%p72, %fd2, 0d3FF0000000000000;
	selp.b32	%r106, 2146435072, 0, %p72;
	xor.b32  	%r107, %r106, 2146435072;
	setp.lt.s32	%p73, %r5, 0;
	selp.b32	%r108, %r107, %r106, %p73;
	setp.eq.f64	%p74, %fd1, 0dBFF0000000000000;
	selp.b32	%r109, 1072693248, %r108, %p74;
	mov.u32 	%r110, 0;
	mov.b64 	%fd118, {%r110, %r109};

BB16_65:
	selp.f64	%fd46, 0d3FF0000000000000, %fd118, %p41;
	fma.rn.f64 	%fd81, %fd35, 0dC061800000000000, %fd24;
	fma.rn.f64 	%fd47, %fd46, 0d4051800000000000, %fd81;
	mov.f64 	%fd82, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd82;
	}
	bfe.u32 	%r111, %r6, 20, 11;
	add.s32 	%r112, %r111, -1012;
	mov.u64 	%rd10, 4611686018427387904;
	shl.b64 	%rd5, %rd10, %r112;
	setp.eq.s64	%p76, %rd5, -9223372036854775808;
	// Callseq Start 62
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd120, [retval0+0];
	
	//{
	}// Callseq End 62
	and.pred  	%p5, %p10, %p76;
	@!%p5 bra 	BB16_67;
	bra.uni 	BB16_66;

BB16_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd120;
	}
	xor.b32  	%r114, %r113, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd120;
	}
	mov.b64 	%fd120, {%r115, %r114};

BB16_67:
	@%p11 bra 	BB16_70;
	bra.uni 	BB16_68;

BB16_70:
	selp.b32	%r116, %r2, 0, %p76;
	or.b32  	%r117, %r116, 2146435072;
	setp.lt.s32	%p82, %r6, 0;
	selp.b32	%r118, %r117, %r116, %p82;
	mov.u32 	%r119, 0;
	mov.b64 	%fd120, {%r119, %r118};
	bra.uni 	BB16_71;

BB16_68:
	setp.gt.s32	%p79, %r2, -1;
	@%p79 bra 	BB16_71;

	cvt.rzi.f64.f64	%fd84, %fd82;
	setp.neu.f64	%p80, %fd84, 0d4000000000000000;
	selp.f64	%fd120, 0dFFF8000000000000, %fd120, %p80;

BB16_71:
	add.f64 	%fd121, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd121;
	}
	and.b32  	%r121, %r120, 2146435072;
	setp.ne.s32	%p83, %r121, 2146435072;
	@%p83 bra 	BB16_72;

	setp.gtu.f64	%p84, %fd2, 0d7FF0000000000000;
	@%p84 bra 	BB16_81;

	and.b32  	%r122, %r6, 2147483647;
	setp.ne.s32	%p85, %r122, 2146435072;
	@%p85 bra 	BB16_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd82;
	}
	setp.eq.s32	%p86, %r123, 0;
	@%p86 bra 	BB16_80;

BB16_76:
	and.b32  	%r124, %r2, 2147483647;
	setp.ne.s32	%p87, %r124, 2146435072;
	@%p87 bra 	BB16_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd1;
	}
	setp.ne.s32	%p88, %r125, 0;
	mov.f64 	%fd121, %fd120;
	@%p88 bra 	BB16_81;

	shr.s32 	%r126, %r6, 31;
	and.b32  	%r127, %r126, -2146435072;
	add.s32 	%r128, %r127, 2146435072;
	or.b32  	%r129, %r128, -2147483648;
	selp.b32	%r130, %r129, %r128, %p5;
	mov.u32 	%r131, 0;
	mov.b64 	%fd121, {%r131, %r130};
	bra.uni 	BB16_81;

BB16_72:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB16_81;

BB16_77:
	mov.f64 	%fd121, %fd120;
	bra.uni 	BB16_81;

BB16_80:
	setp.gt.f64	%p89, %fd2, 0d3FF0000000000000;
	selp.b32	%r132, 2146435072, 0, %p89;
	xor.b32  	%r133, %r132, 2146435072;
	setp.lt.s32	%p90, %r6, 0;
	selp.b32	%r134, %r133, %r132, %p90;
	setp.eq.f64	%p91, %fd1, 0dBFF0000000000000;
	selp.b32	%r135, 1072693248, %r134, %p91;
	mov.u32 	%r136, 0;
	mov.b64 	%fd121, {%r136, %r135};

BB16_81:
	selp.f64	%fd86, 0d3FF0000000000000, %fd121, %p41;
	fma.rn.f64 	%fd87, %fd86, 0dC02E000000000000, %fd47;
	add.f64 	%fd88, %fd1, %fd87;
	mul.f64 	%fd89, %fd60, %fd60;
	mul.f64 	%fd90, %fd89, %fd61;
	mul.f64 	%fd91, %fd90, %fd61;
	mul.f64 	%fd92, %fd91, 0d40FE000000000000;
	mul.f64 	%fd93, %fd60, 0d40D4000000000000;
	mul.f64 	%fd94, %fd93, %fd60;
	mul.f64 	%fd95, %fd94, %fd60;
	mul.f64 	%fd96, %fd95, %fd61;
	mul.f64 	%fd97, %fd96, %fd61;
	mul.f64 	%fd98, %fd97, %fd61;
	mul.f64 	%fd99, %fd35, 0d4080E00000000000;
	fma.rn.f64 	%fd100, %fd23, 0dC063200000000000, %fd99;
	fma.rn.f64 	%fd101, %fd46, 0dC086C00000000000, %fd100;
	fma.rn.f64 	%fd102, %fd86, 0d407CE00000000000, %fd101;
	mul.f64 	%fd103, %fd61, 0dC060E00000000000;
	fma.rn.f64 	%fd104, %fd103, %fd60, %fd102;
	add.f64 	%fd105, %fd104, 0d402C000000000000;
	mul.f64 	%fd106, %fd98, %fd105;
	fma.rn.f64 	%fd122, %fd92, %fd88, %fd106;

BB16_82:
	st.param.f64	[func_retval0+0], %fd122;
	ret;
}

	// .globl	_Z13RickerWaveletddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13RickerWaveletddPdiPii(
	.param .b64 _Z13RickerWaveletddPdiPii_param_0,
	.param .b64 _Z13RickerWaveletddPdiPii_param_1,
	.param .b64 _Z13RickerWaveletddPdiPii_param_2,
	.param .b32 _Z13RickerWaveletddPdiPii_param_3,
	.param .b64 _Z13RickerWaveletddPdiPii_param_4,
	.param .b32 _Z13RickerWaveletddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<71>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z13RickerWaveletddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z13RickerWaveletddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z13RickerWaveletddPdiPii_param_2];
	mul.f64 	%fd24, %fd22, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd24, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd25;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 63
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd67, [retval0+0];
	
	//{
	}// Callseq End 63
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB17_2;
	bra.uni 	BB17_1;

BB17_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd67;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd67;
	}
	mov.b64 	%fd67, {%r10, %r9};

BB17_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB17_5;
	bra.uni 	BB17_3;

BB17_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd67, {%r14, %r13};
	bra.uni 	BB17_6;

BB17_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB17_6;

	cvt.rzi.f64.f64	%fd27, %fd25;
	setp.neu.f64	%p6, %fd27, 0d4000000000000000;
	selp.f64	%fd67, 0dFFF8000000000000, %fd67, %p6;

BB17_6:
	add.f64 	%fd68, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd68;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB17_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB17_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB17_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd25;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB17_15;

BB17_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB17_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd68, %fd67;
	@%p14 bra 	BB17_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd68, {%r26, %r25};
	bra.uni 	BB17_16;

BB17_7:
	mov.f64 	%fd68, %fd67;
	bra.uni 	BB17_16;

BB17_12:
	mov.f64 	%fd68, %fd67;
	bra.uni 	BB17_16;

BB17_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd68, {%r31, %r30};

BB17_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd68, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd70, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB17_21;

	fma.rn.f64 	%fd15, %fd13, 0d4000000000000000, 0dBFF0000000000000;
	mov.f64 	%fd31, 0d4338000000000000;
	mov.f64 	%fd32, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd33, %fd14, %fd32, %fd31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd33;
	}
	mov.f64 	%fd34, 0dC338000000000000;
	add.rn.f64 	%fd35, %fd33, %fd34;
	mov.f64 	%fd36, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd37, %fd35, %fd36, %fd14;
	mov.f64 	%fd38, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd39, %fd35, %fd38, %fd37;
	mov.f64 	%fd40, 0d3E928AF3FCA213EA;
	mov.f64 	%fd41, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F81111111122322;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FA55555555502A1;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	mov.f64 	%fd55, 0d3FC5555555555511;
	fma.rn.f64 	%fd56, %fd54, %fd39, %fd55;
	mov.f64 	%fd57, 0d3FE000000000000B;
	fma.rn.f64 	%fd58, %fd56, %fd39, %fd57;
	mov.f64 	%fd59, 0d3FF0000000000000;
	fma.rn.f64 	%fd60, %fd58, %fd39, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd61;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd61;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd69, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB17_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd62, 0d7FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd13;
	selp.f64	%fd69, 0d0000000000000000, %fd63, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB17_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd64, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd65, {%r43, %r42};
	mul.f64 	%fd69, %fd64, %fd65;

BB17_20:
	mul.f64 	%fd70, %fd15, %fd69;

BB17_21:
	st.param.f64	[func_retval0+0], %fd70;
	ret;
}

	// .globl	_Z15RickerWavelet_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z15RickerWavelet_tddPdiPii(
	.param .b64 _Z15RickerWavelet_tddPdiPii_param_0,
	.param .b64 _Z15RickerWavelet_tddPdiPii_param_1,
	.param .b64 _Z15RickerWavelet_tddPdiPii_param_2,
	.param .b32 _Z15RickerWavelet_tddPdiPii_param_3,
	.param .b64 _Z15RickerWavelet_tddPdiPii_param_4,
	.param .b32 _Z15RickerWavelet_tddPdiPii_param_5
)
{
	.reg .pred 	%p<41>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<69>;
	.reg .f64 	%fd<92>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd35, [_Z15RickerWavelet_tddPdiPii_param_0];
	ld.param.f64 	%fd34, [_Z15RickerWavelet_tddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z15RickerWavelet_tddPdiPii_param_2];
	mul.f64 	%fd1, %fd35, 0d400921FB54442D18;
	mul.f64 	%fd2, %fd1, %fd34;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd36, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd36;
	}
	bfe.u32 	%r7, %r2, 20, 11;
	add.s32 	%r8, %r7, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r8;
	setp.eq.s64	%p3, %rd1, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 64
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd36;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd85, [retval0+0];
	
	//{
	}// Callseq End 64
	setp.lt.s32	%p4, %r1, 0;
	and.pred  	%p1, %p4, %p3;
	@!%p1 bra 	BB18_2;
	bra.uni 	BB18_1;

BB18_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd85;
	}
	xor.b32  	%r10, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r11, %temp}, %fd85;
	}
	mov.b64 	%fd85, {%r11, %r10};

BB18_2:
	setp.eq.f64	%p5, %fd2, 0d0000000000000000;
	@%p5 bra 	BB18_5;
	bra.uni 	BB18_3;

BB18_5:
	selp.b32	%r12, %r1, 0, %p3;
	or.b32  	%r13, %r12, 2146435072;
	setp.lt.s32	%p9, %r2, 0;
	selp.b32	%r14, %r13, %r12, %p9;
	mov.u32 	%r15, 0;
	mov.b64 	%fd85, {%r15, %r14};
	bra.uni 	BB18_6;

BB18_3:
	setp.gt.s32	%p6, %r1, -1;
	@%p6 bra 	BB18_6;

	cvt.rzi.f64.f64	%fd38, %fd36;
	setp.neu.f64	%p7, %fd38, 0d4000000000000000;
	selp.f64	%fd85, 0dFFF8000000000000, %fd85, %p7;

BB18_6:
	add.f64 	%fd86, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd86;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.ne.s32	%p10, %r17, 2146435072;
	@%p10 bra 	BB18_7;

	setp.gtu.f64	%p11, %fd3, 0d7FF0000000000000;
	@%p11 bra 	BB18_16;

	and.b32  	%r18, %r2, 2147483647;
	setp.ne.s32	%p12, %r18, 2146435072;
	@%p12 bra 	BB18_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd36;
	}
	setp.eq.s32	%p13, %r19, 0;
	@%p13 bra 	BB18_15;

BB18_11:
	and.b32  	%r20, %r1, 2147483647;
	setp.ne.s32	%p14, %r20, 2146435072;
	@%p14 bra 	BB18_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd2;
	}
	setp.ne.s32	%p15, %r21, 0;
	mov.f64 	%fd86, %fd85;
	@%p15 bra 	BB18_16;

	shr.s32 	%r22, %r2, 31;
	and.b32  	%r23, %r22, -2146435072;
	add.s32 	%r24, %r23, 2146435072;
	or.b32  	%r25, %r24, -2147483648;
	selp.b32	%r26, %r25, %r24, %p1;
	mov.u32 	%r27, 0;
	mov.b64 	%fd86, {%r27, %r26};
	bra.uni 	BB18_16;

BB18_7:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB18_16;

BB18_12:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB18_16;

BB18_15:
	setp.gt.f64	%p16, %fd3, 0d3FF0000000000000;
	selp.b32	%r28, 2146435072, 0, %p16;
	xor.b32  	%r29, %r28, 2146435072;
	setp.lt.s32	%p17, %r2, 0;
	selp.b32	%r30, %r29, %r28, %p17;
	setp.eq.f64	%p18, %fd2, 0dBFF0000000000000;
	selp.b32	%r31, 1072693248, %r30, %p18;
	mov.u32 	%r32, 0;
	mov.b64 	%fd86, {%r32, %r31};

BB18_16:
	setp.eq.f64	%p19, %fd2, 0d3FF0000000000000;
	selp.f64	%fd14, 0d3FF0000000000000, %fd86, %p19;
	neg.f64 	%fd15, %fd14;
	ld.f64 	%fd41, [%rd2];
	mov.f64 	%fd91, 0d0000000000000000;
	setp.geu.f64	%p20, %fd41, %fd15;
	@%p20 bra 	BB18_37;

	abs.f64 	%fd16, %fd1;
	// Callseq Start 65
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd16;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd36;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd88, [retval0+0];
	
	//{
	}// Callseq End 65
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd1;
	}
	setp.lt.s32	%p22, %r3, 0;
	and.pred  	%p2, %p22, %p3;
	@!%p2 bra 	BB18_19;
	bra.uni 	BB18_18;

BB18_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd88;
	}
	xor.b32  	%r34, %r33, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd88;
	}
	mov.b64 	%fd88, {%r35, %r34};

BB18_19:
	setp.eq.f64	%p23, %fd1, 0d0000000000000000;
	@%p23 bra 	BB18_22;
	bra.uni 	BB18_20;

BB18_22:
	selp.b32	%r36, %r3, 0, %p3;
	or.b32  	%r37, %r36, 2146435072;
	setp.lt.s32	%p27, %r2, 0;
	selp.b32	%r38, %r37, %r36, %p27;
	mov.u32 	%r39, 0;
	mov.b64 	%fd88, {%r39, %r38};
	bra.uni 	BB18_23;

BB18_20:
	setp.gt.s32	%p24, %r3, -1;
	@%p24 bra 	BB18_23;

	cvt.rzi.f64.f64	%fd44, %fd36;
	setp.neu.f64	%p25, %fd44, 0d4000000000000000;
	selp.f64	%fd88, 0dFFF8000000000000, %fd88, %p25;

BB18_23:
	add.f64 	%fd89, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd89;
	}
	and.b32  	%r41, %r40, 2146435072;
	setp.ne.s32	%p28, %r41, 2146435072;
	@%p28 bra 	BB18_24;

	setp.gtu.f64	%p29, %fd16, 0d7FF0000000000000;
	@%p29 bra 	BB18_33;

	and.b32  	%r42, %r2, 2147483647;
	setp.ne.s32	%p30, %r42, 2146435072;
	@%p30 bra 	BB18_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r43, %temp}, %fd36;
	}
	setp.eq.s32	%p31, %r43, 0;
	@%p31 bra 	BB18_32;

BB18_28:
	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p32, %r44, 2146435072;
	@%p32 bra 	BB18_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd1;
	}
	setp.ne.s32	%p33, %r45, 0;
	mov.f64 	%fd89, %fd88;
	@%p33 bra 	BB18_33;

	shr.s32 	%r46, %r2, 31;
	and.b32  	%r47, %r46, -2146435072;
	add.s32 	%r48, %r47, 2146435072;
	or.b32  	%r49, %r48, -2147483648;
	selp.b32	%r50, %r49, %r48, %p2;
	mov.u32 	%r51, 0;
	mov.b64 	%fd89, {%r51, %r50};
	bra.uni 	BB18_33;

BB18_24:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB18_33;

BB18_29:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB18_33;

BB18_32:
	setp.gt.f64	%p34, %fd16, 0d3FF0000000000000;
	selp.b32	%r52, 2146435072, 0, %p34;
	xor.b32  	%r53, %r52, 2146435072;
	setp.lt.s32	%p35, %r2, 0;
	selp.b32	%r54, %r53, %r52, %p35;
	setp.eq.f64	%p36, %fd1, 0dBFF0000000000000;
	selp.b32	%r55, 1072693248, %r54, %p36;
	mov.u32 	%r56, 0;
	mov.b64 	%fd89, {%r56, %r55};

BB18_33:
	setp.eq.f64	%p37, %fd1, 0d3FF0000000000000;
	selp.f64	%fd27, 0d3FF0000000000000, %fd89, %p37;
	mov.f64 	%fd46, 0d4338000000000000;
	mov.f64 	%fd47, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd48, %fd15, %fd47, %fd46;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd48;
	}
	mov.f64 	%fd49, 0dC338000000000000;
	add.rn.f64 	%fd50, %fd48, %fd49;
	mov.f64 	%fd51, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd52, %fd50, %fd51, %fd15;
	mov.f64 	%fd53, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd54, %fd50, %fd53, %fd52;
	mov.f64 	%fd55, 0d3E928AF3FCA213EA;
	mov.f64 	%fd56, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd57, %fd56, %fd54, %fd55;
	mov.f64 	%fd58, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd59, %fd57, %fd54, %fd58;
	mov.f64 	%fd60, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd61, %fd59, %fd54, %fd60;
	mov.f64 	%fd62, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd63, %fd61, %fd54, %fd62;
	mov.f64 	%fd64, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd65, %fd63, %fd54, %fd64;
	mov.f64 	%fd66, 0d3F81111111122322;
	fma.rn.f64 	%fd67, %fd65, %fd54, %fd66;
	mov.f64 	%fd68, 0d3FA55555555502A1;
	fma.rn.f64 	%fd69, %fd67, %fd54, %fd68;
	mov.f64 	%fd70, 0d3FC5555555555511;
	fma.rn.f64 	%fd71, %fd69, %fd54, %fd70;
	mov.f64 	%fd72, 0d3FE000000000000B;
	fma.rn.f64 	%fd73, %fd71, %fd54, %fd72;
	mov.f64 	%fd74, 0d3FF0000000000000;
	fma.rn.f64 	%fd75, %fd73, %fd54, %fd74;
	fma.rn.f64 	%fd76, %fd75, %fd54, %fd74;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd76;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd76;
	}
	shl.b32 	%r57, %r4, 20;
	add.s32 	%r58, %r6, %r57;
	mov.b64 	%fd90, {%r5, %r58};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd15;
	}
	mov.b32 	 %f2, %r59;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p38, %f1, 0f4086232B;
	@%p38 bra 	BB18_36;

	setp.gt.f64	%p39, %fd14, 0d8000000000000000;
	mov.f64 	%fd77, 0d7FF0000000000000;
	sub.f64 	%fd78, %fd77, %fd14;
	selp.f64	%fd90, 0d0000000000000000, %fd78, %p39;
	setp.geu.f32	%p40, %f1, 0f40874800;
	@%p40 bra 	BB18_36;

	shr.u32 	%r60, %r4, 31;
	add.s32 	%r61, %r4, %r60;
	shr.s32 	%r62, %r61, 1;
	shl.b32 	%r63, %r62, 20;
	add.s32 	%r64, %r63, %r6;
	mov.b64 	%fd79, {%r5, %r64};
	sub.s32 	%r65, %r4, %r62;
	shl.b32 	%r66, %r65, 20;
	add.s32 	%r67, %r66, 1072693248;
	mov.u32 	%r68, 0;
	mov.b64 	%fd80, {%r68, %r67};
	mul.f64 	%fd90, %fd79, %fd80;

BB18_36:
	fma.rn.f64 	%fd81, %fd14, 0dC010000000000000, 0d4018000000000000;
	mul.f64 	%fd82, %fd27, %fd34;
	mul.f64 	%fd83, %fd81, %fd82;
	mul.f64 	%fd91, %fd83, %fd90;

BB18_37:
	st.param.f64	[func_retval0+0], %fd91;
	ret;
}

	// .globl	_Z16RickerWavelet_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16RickerWavelet_omddPdiPii(
	.param .b64 _Z16RickerWavelet_omddPdiPii_param_0,
	.param .b64 _Z16RickerWavelet_omddPdiPii_param_1,
	.param .b64 _Z16RickerWavelet_omddPdiPii_param_2,
	.param .b32 _Z16RickerWavelet_omddPdiPii_param_3,
	.param .b64 _Z16RickerWavelet_omddPdiPii_param_4,
	.param .b32 _Z16RickerWavelet_omddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd21, [_Z16RickerWavelet_omddPdiPii_param_0];
	ld.param.f64 	%fd22, [_Z16RickerWavelet_omddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z16RickerWavelet_omddPdiPii_param_2];
	mul.f64 	%fd23, %fd21, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd23, %fd22;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 66
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd71, [retval0+0];
	
	//{
	}// Callseq End 66
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB19_2;
	bra.uni 	BB19_1;

BB19_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd71;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd71;
	}
	mov.b64 	%fd71, {%r10, %r9};

BB19_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB19_5;
	bra.uni 	BB19_3;

BB19_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd71, {%r14, %r13};
	bra.uni 	BB19_6;

BB19_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB19_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd71, 0dFFF8000000000000, %fd71, %p6;

BB19_6:
	add.f64 	%fd72, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd72;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB19_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB19_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB19_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB19_15;

BB19_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB19_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd72, %fd71;
	@%p14 bra 	BB19_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd72, {%r26, %r25};
	bra.uni 	BB19_16;

BB19_7:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB19_16;

BB19_12:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB19_16;

BB19_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd72, {%r31, %r30};

BB19_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd72, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd29, [%rd2];
	mov.f64 	%fd74, 0d0000000000000000;
	setp.geu.f64	%p19, %fd29, %fd14;
	@%p19 bra 	BB19_21;

	mov.f64 	%fd30, 0d4338000000000000;
	mov.f64 	%fd31, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd32, %fd14, %fd31, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd32;
	}
	mov.f64 	%fd33, 0dC338000000000000;
	add.rn.f64 	%fd34, %fd32, %fd33;
	mov.f64 	%fd35, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd36, %fd34, %fd35, %fd14;
	mov.f64 	%fd37, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd38, %fd34, %fd37, %fd36;
	mov.f64 	%fd39, 0d3E928AF3FCA213EA;
	mov.f64 	%fd40, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd41, %fd40, %fd38, %fd39;
	mov.f64 	%fd42, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd43, %fd41, %fd38, %fd42;
	mov.f64 	%fd44, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd45, %fd43, %fd38, %fd44;
	mov.f64 	%fd46, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd47, %fd45, %fd38, %fd46;
	mov.f64 	%fd48, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd49, %fd47, %fd38, %fd48;
	mov.f64 	%fd50, 0d3F81111111122322;
	fma.rn.f64 	%fd51, %fd49, %fd38, %fd50;
	mov.f64 	%fd52, 0d3FA55555555502A1;
	fma.rn.f64 	%fd53, %fd51, %fd38, %fd52;
	mov.f64 	%fd54, 0d3FC5555555555511;
	fma.rn.f64 	%fd55, %fd53, %fd38, %fd54;
	mov.f64 	%fd56, 0d3FE000000000000B;
	fma.rn.f64 	%fd57, %fd55, %fd38, %fd56;
	mov.f64 	%fd58, 0d3FF0000000000000;
	fma.rn.f64 	%fd59, %fd57, %fd38, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd38, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd60;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd73, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB19_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd61, 0d7FF0000000000000;
	sub.f64 	%fd62, %fd61, %fd13;
	selp.f64	%fd73, 0d0000000000000000, %fd62, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB19_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd63, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd64, {%r43, %r42};
	mul.f64 	%fd73, %fd63, %fd64;

BB19_20:
	fma.rn.f64 	%fd65, %fd13, 0dC010000000000000, 0d4018000000000000;
	mul.f64 	%fd66, %fd21, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd67, %fd66, %fd22;
	mul.f64 	%fd68, %fd67, %fd22;
	mul.f64 	%fd69, %fd68, %fd65;
	mul.f64 	%fd74, %fd69, %fd73;

BB19_21:
	st.param.f64	[func_retval0+0], %fd74;
	ret;
}

	// .globl	_Z16RickerWavelet_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16RickerWavelet_ttddPdiPii(
	.param .b64 _Z16RickerWavelet_ttddPdiPii_param_0,
	.param .b64 _Z16RickerWavelet_ttddPdiPii_param_1,
	.param .b64 _Z16RickerWavelet_ttddPdiPii_param_2,
	.param .b32 _Z16RickerWavelet_ttddPdiPii_param_3,
	.param .b64 _Z16RickerWavelet_ttddPdiPii_param_4,
	.param .b32 _Z16RickerWavelet_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<76>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z16RickerWavelet_ttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z16RickerWavelet_ttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z16RickerWavelet_ttddPdiPii_param_2];
	mul.f64 	%fd24, %fd22, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd24, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd25;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 67
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd72, [retval0+0];
	
	//{
	}// Callseq End 67
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB20_2;
	bra.uni 	BB20_1;

BB20_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd72;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd72;
	}
	mov.b64 	%fd72, {%r10, %r9};

BB20_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB20_5;
	bra.uni 	BB20_3;

BB20_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd72, {%r14, %r13};
	bra.uni 	BB20_6;

BB20_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB20_6;

	cvt.rzi.f64.f64	%fd27, %fd25;
	setp.neu.f64	%p6, %fd27, 0d4000000000000000;
	selp.f64	%fd72, 0dFFF8000000000000, %fd72, %p6;

BB20_6:
	add.f64 	%fd73, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd73;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB20_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB20_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB20_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd25;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB20_15;

BB20_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB20_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd73, %fd72;
	@%p14 bra 	BB20_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd73, {%r26, %r25};
	bra.uni 	BB20_16;

BB20_7:
	mov.f64 	%fd73, %fd72;
	bra.uni 	BB20_16;

BB20_12:
	mov.f64 	%fd73, %fd72;
	bra.uni 	BB20_16;

BB20_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd73, {%r31, %r30};

BB20_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd73, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd75, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB20_21;

	fma.rn.f64 	%fd31, %fd13, 0dC038000000000000, 0d4018000000000000;
	mul.f64 	%fd32, %fd13, 0d4020000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd32, %fd31;
	mov.f64 	%fd33, 0d4338000000000000;
	mov.f64 	%fd34, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd35, %fd14, %fd34, %fd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd35;
	}
	mov.f64 	%fd36, 0dC338000000000000;
	add.rn.f64 	%fd37, %fd35, %fd36;
	mov.f64 	%fd38, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd39, %fd37, %fd38, %fd14;
	mov.f64 	%fd40, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd41, %fd37, %fd40, %fd39;
	mov.f64 	%fd42, 0d3E928AF3FCA213EA;
	mov.f64 	%fd43, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd44, %fd43, %fd41, %fd42;
	mov.f64 	%fd45, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	mov.f64 	%fd47, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd48, %fd46, %fd41, %fd47;
	mov.f64 	%fd49, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd50, %fd48, %fd41, %fd49;
	mov.f64 	%fd51, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd52, %fd50, %fd41, %fd51;
	mov.f64 	%fd53, 0d3F81111111122322;
	fma.rn.f64 	%fd54, %fd52, %fd41, %fd53;
	mov.f64 	%fd55, 0d3FA55555555502A1;
	fma.rn.f64 	%fd56, %fd54, %fd41, %fd55;
	mov.f64 	%fd57, 0d3FC5555555555511;
	fma.rn.f64 	%fd58, %fd56, %fd41, %fd57;
	mov.f64 	%fd59, 0d3FE000000000000B;
	fma.rn.f64 	%fd60, %fd58, %fd41, %fd59;
	mov.f64 	%fd61, 0d3FF0000000000000;
	fma.rn.f64 	%fd62, %fd60, %fd41, %fd61;
	fma.rn.f64 	%fd63, %fd62, %fd41, %fd61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd63;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd63;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd74, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB20_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd64, 0d7FF0000000000000;
	sub.f64 	%fd65, %fd64, %fd13;
	selp.f64	%fd74, 0d0000000000000000, %fd65, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB20_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd66, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd67, {%r43, %r42};
	mul.f64 	%fd74, %fd66, %fd67;

BB20_20:
	mul.f64 	%fd68, %fd22, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd69, %fd68, %fd22;
	mul.f64 	%fd70, %fd69, %fd15;
	mul.f64 	%fd75, %fd70, %fd74;

BB20_21:
	st.param.f64	[func_retval0+0], %fd75;
	ret;
}

	// .globl	_Z17RickerWavelet_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17RickerWavelet_tttddPdiPii(
	.param .b64 _Z17RickerWavelet_tttddPdiPii_param_0,
	.param .b64 _Z17RickerWavelet_tttddPdiPii_param_1,
	.param .b64 _Z17RickerWavelet_tttddPdiPii_param_2,
	.param .b32 _Z17RickerWavelet_tttddPdiPii_param_3,
	.param .b64 _Z17RickerWavelet_tttddPdiPii_param_4,
	.param .b32 _Z17RickerWavelet_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<41>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<72>;
	.reg .f64 	%fd<94>;
	.reg .b64 	%rd<6>;


	ld.param.f64 	%fd35, [_Z17RickerWavelet_tttddPdiPii_param_0];
	ld.param.f64 	%fd34, [_Z17RickerWavelet_tttddPdiPii_param_1];
	ld.param.u64 	%rd3, [_Z17RickerWavelet_tttddPdiPii_param_2];
	mul.f64 	%fd1, %fd35, 0d400921FB54442D18;
	mul.f64 	%fd2, %fd1, %fd34;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd36, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd36;
	}
	bfe.u32 	%r8, %r2, 20, 11;
	add.s32 	%r9, %r8, -1012;
	mov.u64 	%rd4, 4611686018427387904;
	shl.b64 	%rd1, %rd4, %r9;
	setp.eq.s64	%p3, %rd1, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 68
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd36;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd87, [retval0+0];
	
	//{
	}// Callseq End 68
	setp.lt.s32	%p4, %r1, 0;
	and.pred  	%p1, %p4, %p3;
	@!%p1 bra 	BB21_2;
	bra.uni 	BB21_1;

BB21_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd87;
	}
	xor.b32  	%r11, %r10, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd87;
	}
	mov.b64 	%fd87, {%r12, %r11};

BB21_2:
	setp.eq.f64	%p5, %fd2, 0d0000000000000000;
	@%p5 bra 	BB21_5;
	bra.uni 	BB21_3;

BB21_5:
	selp.b32	%r13, %r1, 0, %p3;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p9, %r2, 0;
	selp.b32	%r15, %r14, %r13, %p9;
	mov.u32 	%r16, 0;
	mov.b64 	%fd87, {%r16, %r15};
	bra.uni 	BB21_6;

BB21_3:
	setp.gt.s32	%p6, %r1, -1;
	@%p6 bra 	BB21_6;

	cvt.rzi.f64.f64	%fd38, %fd36;
	setp.neu.f64	%p7, %fd38, 0d4000000000000000;
	selp.f64	%fd87, 0dFFF8000000000000, %fd87, %p7;

BB21_6:
	add.f64 	%fd88, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd88;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p10, %r18, 2146435072;
	@%p10 bra 	BB21_7;

	setp.gtu.f64	%p11, %fd3, 0d7FF0000000000000;
	@%p11 bra 	BB21_16;

	and.b32  	%r19, %r2, 2147483647;
	setp.ne.s32	%p12, %r19, 2146435072;
	@%p12 bra 	BB21_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd36;
	}
	setp.eq.s32	%p13, %r20, 0;
	@%p13 bra 	BB21_15;

BB21_11:
	and.b32  	%r21, %r1, 2147483647;
	setp.ne.s32	%p14, %r21, 2146435072;
	@%p14 bra 	BB21_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd2;
	}
	setp.ne.s32	%p15, %r22, 0;
	mov.f64 	%fd88, %fd87;
	@%p15 bra 	BB21_16;

	shr.s32 	%r23, %r2, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	selp.b32	%r27, %r26, %r25, %p1;
	mov.u32 	%r28, 0;
	mov.b64 	%fd88, {%r28, %r27};
	bra.uni 	BB21_16;

BB21_7:
	mov.f64 	%fd88, %fd87;
	bra.uni 	BB21_16;

BB21_12:
	mov.f64 	%fd88, %fd87;
	bra.uni 	BB21_16;

BB21_15:
	setp.gt.f64	%p16, %fd3, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p16;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p17, %r2, 0;
	selp.b32	%r31, %r30, %r29, %p17;
	setp.eq.f64	%p18, %fd2, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p18;
	mov.u32 	%r33, 0;
	mov.b64 	%fd88, {%r33, %r32};

BB21_16:
	setp.eq.f64	%p19, %fd2, 0d3FF0000000000000;
	selp.f64	%fd14, 0d3FF0000000000000, %fd88, %p19;
	neg.f64 	%fd15, %fd14;
	ld.f64 	%fd41, [%rd3];
	mov.f64 	%fd93, 0d0000000000000000;
	setp.geu.f64	%p20, %fd41, %fd15;
	@%p20 bra 	BB21_37;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd1;
	}
	mov.f64 	%fd42, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd42;
	}
	bfe.u32 	%r34, %r4, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd5, 4616189618054758400;
	shl.b64 	%rd2, %rd5, %r35;
	setp.eq.s64	%p21, %rd2, -9223372036854775808;
	abs.f64 	%fd16, %fd1;
	// Callseq Start 69
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd16;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd90, [retval0+0];
	
	//{
	}// Callseq End 69
	setp.lt.s32	%p22, %r3, 0;
	and.pred  	%p2, %p22, %p21;
	@!%p2 bra 	BB21_19;
	bra.uni 	BB21_18;

BB21_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd90;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd90;
	}
	mov.b64 	%fd90, {%r38, %r37};

BB21_19:
	setp.eq.f64	%p23, %fd1, 0d0000000000000000;
	@%p23 bra 	BB21_22;
	bra.uni 	BB21_20;

BB21_22:
	selp.b32	%r39, %r3, 0, %p21;
	or.b32  	%r40, %r39, 2146435072;
	setp.lt.s32	%p27, %r4, 0;
	selp.b32	%r41, %r40, %r39, %p27;
	mov.u32 	%r42, 0;
	mov.b64 	%fd90, {%r42, %r41};
	bra.uni 	BB21_23;

BB21_20:
	setp.gt.s32	%p24, %r3, -1;
	@%p24 bra 	BB21_23;

	cvt.rzi.f64.f64	%fd44, %fd42;
	setp.neu.f64	%p25, %fd44, 0d4010000000000000;
	selp.f64	%fd90, 0dFFF8000000000000, %fd90, %p25;

BB21_23:
	add.f64 	%fd91, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd91;
	}
	and.b32  	%r44, %r43, 2146435072;
	setp.ne.s32	%p28, %r44, 2146435072;
	@%p28 bra 	BB21_24;

	setp.gtu.f64	%p29, %fd16, 0d7FF0000000000000;
	@%p29 bra 	BB21_33;

	and.b32  	%r45, %r4, 2147483647;
	setp.ne.s32	%p30, %r45, 2146435072;
	@%p30 bra 	BB21_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd42;
	}
	setp.eq.s32	%p31, %r46, 0;
	@%p31 bra 	BB21_32;

BB21_28:
	and.b32  	%r47, %r3, 2147483647;
	setp.ne.s32	%p32, %r47, 2146435072;
	@%p32 bra 	BB21_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd1;
	}
	setp.ne.s32	%p33, %r48, 0;
	mov.f64 	%fd91, %fd90;
	@%p33 bra 	BB21_33;

	shr.s32 	%r49, %r4, 31;
	and.b32  	%r50, %r49, -2146435072;
	add.s32 	%r51, %r50, 2146435072;
	or.b32  	%r52, %r51, -2147483648;
	selp.b32	%r53, %r52, %r51, %p2;
	mov.u32 	%r54, 0;
	mov.b64 	%fd91, {%r54, %r53};
	bra.uni 	BB21_33;

BB21_24:
	mov.f64 	%fd91, %fd90;
	bra.uni 	BB21_33;

BB21_29:
	mov.f64 	%fd91, %fd90;
	bra.uni 	BB21_33;

BB21_32:
	setp.gt.f64	%p34, %fd16, 0d3FF0000000000000;
	selp.b32	%r55, 2146435072, 0, %p34;
	xor.b32  	%r56, %r55, 2146435072;
	setp.lt.s32	%p35, %r4, 0;
	selp.b32	%r57, %r56, %r55, %p35;
	setp.eq.f64	%p36, %fd1, 0dBFF0000000000000;
	selp.b32	%r58, 1072693248, %r57, %p36;
	mov.u32 	%r59, 0;
	mov.b64 	%fd91, {%r59, %r58};

BB21_33:
	setp.eq.f64	%p37, %fd1, 0d3FF0000000000000;
	selp.f64	%fd46, 0d3FF0000000000000, %fd91, %p37;
	mul.f64 	%fd47, %fd46, %fd34;
	fma.rn.f64 	%fd48, %fd14, 0d4054000000000000, 0dC04E000000000000;
	mul.f64 	%fd49, %fd14, 0dC030000000000000;
	fma.rn.f64 	%fd50, %fd14, %fd49, %fd48;
	mul.f64 	%fd27, %fd50, %fd47;
	mov.f64 	%fd51, 0d4338000000000000;
	mov.f64 	%fd52, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd53, %fd15, %fd52, %fd51;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd53;
	}
	mov.f64 	%fd54, 0dC338000000000000;
	add.rn.f64 	%fd55, %fd53, %fd54;
	mov.f64 	%fd56, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd57, %fd55, %fd56, %fd15;
	mov.f64 	%fd58, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd59, %fd55, %fd58, %fd57;
	mov.f64 	%fd60, 0d3E928AF3FCA213EA;
	mov.f64 	%fd61, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd62, %fd61, %fd59, %fd60;
	mov.f64 	%fd63, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd64, %fd62, %fd59, %fd63;
	mov.f64 	%fd65, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd66, %fd64, %fd59, %fd65;
	mov.f64 	%fd67, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd68, %fd66, %fd59, %fd67;
	mov.f64 	%fd69, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd70, %fd68, %fd59, %fd69;
	mov.f64 	%fd71, 0d3F81111111122322;
	fma.rn.f64 	%fd72, %fd70, %fd59, %fd71;
	mov.f64 	%fd73, 0d3FA55555555502A1;
	fma.rn.f64 	%fd74, %fd72, %fd59, %fd73;
	mov.f64 	%fd75, 0d3FC5555555555511;
	fma.rn.f64 	%fd76, %fd74, %fd59, %fd75;
	mov.f64 	%fd77, 0d3FE000000000000B;
	fma.rn.f64 	%fd78, %fd76, %fd59, %fd77;
	mov.f64 	%fd79, 0d3FF0000000000000;
	fma.rn.f64 	%fd80, %fd78, %fd59, %fd79;
	fma.rn.f64 	%fd81, %fd80, %fd59, %fd79;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r6, %temp}, %fd81;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd81;
	}
	shl.b32 	%r60, %r5, 20;
	add.s32 	%r61, %r7, %r60;
	mov.b64 	%fd92, {%r6, %r61};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd15;
	}
	mov.b32 	 %f2, %r62;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p38, %f1, 0f4086232B;
	@%p38 bra 	BB21_36;

	setp.gt.f64	%p39, %fd14, 0d8000000000000000;
	mov.f64 	%fd82, 0d7FF0000000000000;
	sub.f64 	%fd83, %fd82, %fd14;
	selp.f64	%fd92, 0d0000000000000000, %fd83, %p39;
	setp.geu.f32	%p40, %f1, 0f40874800;
	@%p40 bra 	BB21_36;

	shr.u32 	%r63, %r5, 31;
	add.s32 	%r64, %r5, %r63;
	shr.s32 	%r65, %r64, 1;
	shl.b32 	%r66, %r65, 20;
	add.s32 	%r67, %r66, %r7;
	mov.b64 	%fd84, {%r6, %r67};
	sub.s32 	%r68, %r5, %r65;
	shl.b32 	%r69, %r68, 20;
	add.s32 	%r70, %r69, 1072693248;
	mov.u32 	%r71, 0;
	mov.b64 	%fd85, {%r71, %r70};
	mul.f64 	%fd92, %fd84, %fd85;

BB21_36:
	mul.f64 	%fd93, %fd27, %fd92;

BB21_37:
	st.param.f64	[func_retval0+0], %fd93;
	ret;
}

	// .globl	_Z18RickerWavelet_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z18RickerWavelet_omttddPdiPii(
	.param .b64 _Z18RickerWavelet_omttddPdiPii_param_0,
	.param .b64 _Z18RickerWavelet_omttddPdiPii_param_1,
	.param .b64 _Z18RickerWavelet_omttddPdiPii_param_2,
	.param .b32 _Z18RickerWavelet_omttddPdiPii_param_3,
	.param .b64 _Z18RickerWavelet_omttddPdiPii_param_4,
	.param .b32 _Z18RickerWavelet_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<78>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z18RickerWavelet_omttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z18RickerWavelet_omttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z18RickerWavelet_omttddPdiPii_param_2];
	mul.f64 	%fd24, %fd22, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd24, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd25;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 70
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd74, [retval0+0];
	
	//{
	}// Callseq End 70
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB22_2;
	bra.uni 	BB22_1;

BB22_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd74;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd74;
	}
	mov.b64 	%fd74, {%r10, %r9};

BB22_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB22_5;
	bra.uni 	BB22_3;

BB22_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd74, {%r14, %r13};
	bra.uni 	BB22_6;

BB22_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB22_6;

	cvt.rzi.f64.f64	%fd27, %fd25;
	setp.neu.f64	%p6, %fd27, 0d4000000000000000;
	selp.f64	%fd74, 0dFFF8000000000000, %fd74, %p6;

BB22_6:
	add.f64 	%fd75, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd75;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB22_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB22_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB22_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd25;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB22_15;

BB22_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB22_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd75, %fd74;
	@%p14 bra 	BB22_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd75, {%r26, %r25};
	bra.uni 	BB22_16;

BB22_7:
	mov.f64 	%fd75, %fd74;
	bra.uni 	BB22_16;

BB22_12:
	mov.f64 	%fd75, %fd74;
	bra.uni 	BB22_16;

BB22_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd75, {%r31, %r30};

BB22_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd75, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd77, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB22_21;

	fma.rn.f64 	%fd31, %fd13, 0dC05B000000000000, 0d4028000000000000;
	mul.f64 	%fd32, %fd13, 0d4058000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd32, %fd31;
	mov.f64 	%fd33, 0d4338000000000000;
	mov.f64 	%fd34, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd35, %fd14, %fd34, %fd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd35;
	}
	mov.f64 	%fd36, 0dC338000000000000;
	add.rn.f64 	%fd37, %fd35, %fd36;
	mov.f64 	%fd38, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd39, %fd37, %fd38, %fd14;
	mov.f64 	%fd40, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd41, %fd37, %fd40, %fd39;
	mov.f64 	%fd42, 0d3E928AF3FCA213EA;
	mov.f64 	%fd43, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd44, %fd43, %fd41, %fd42;
	mov.f64 	%fd45, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	mov.f64 	%fd47, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd48, %fd46, %fd41, %fd47;
	mov.f64 	%fd49, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd50, %fd48, %fd41, %fd49;
	mov.f64 	%fd51, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd52, %fd50, %fd41, %fd51;
	mov.f64 	%fd53, 0d3F81111111122322;
	fma.rn.f64 	%fd54, %fd52, %fd41, %fd53;
	mov.f64 	%fd55, 0d3FA55555555502A1;
	fma.rn.f64 	%fd56, %fd54, %fd41, %fd55;
	mov.f64 	%fd57, 0d3FC5555555555511;
	fma.rn.f64 	%fd58, %fd56, %fd41, %fd57;
	mov.f64 	%fd59, 0d3FE000000000000B;
	fma.rn.f64 	%fd60, %fd58, %fd41, %fd59;
	mov.f64 	%fd61, 0d3FF0000000000000;
	fma.rn.f64 	%fd62, %fd60, %fd41, %fd61;
	fma.rn.f64 	%fd63, %fd62, %fd41, %fd61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd63;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd63;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd76, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB22_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd64, 0d7FF0000000000000;
	sub.f64 	%fd65, %fd64, %fd13;
	selp.f64	%fd76, 0d0000000000000000, %fd65, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB22_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd66, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd67, {%r43, %r42};
	mul.f64 	%fd76, %fd66, %fd67;

BB22_20:
	mul.f64 	%fd68, %fd13, 0dC030000000000000;
	mul.f64 	%fd69, %fd13, %fd68;
	fma.rn.f64 	%fd70, %fd13, %fd69, %fd15;
	mul.f64 	%fd71, %fd22, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd72, %fd71, %fd70;
	mul.f64 	%fd77, %fd72, %fd76;

BB22_21:
	st.param.f64	[func_retval0+0], %fd77;
	ret;
}

	// .globl	_Z9RickerIntddPdiPii
.visible .func  (.param .b64 func_retval0) _Z9RickerIntddPdiPii(
	.param .b64 _Z9RickerIntddPdiPii_param_0,
	.param .b64 _Z9RickerIntddPdiPii_param_1,
	.param .b64 _Z9RickerIntddPdiPii_param_2,
	.param .b32 _Z9RickerIntddPdiPii_param_3,
	.param .b64 _Z9RickerIntddPdiPii_param_4,
	.param .b32 _Z9RickerIntddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<70>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd21, [_Z9RickerIntddPdiPii_param_0];
	ld.param.f64 	%fd20, [_Z9RickerIntddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z9RickerIntddPdiPii_param_2];
	mul.f64 	%fd22, %fd21, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd22, %fd20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd23, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd23;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 71
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd23;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd66, [retval0+0];
	
	//{
	}// Callseq End 71
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB23_2;
	bra.uni 	BB23_1;

BB23_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd66;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd66;
	}
	mov.b64 	%fd66, {%r10, %r9};

BB23_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB23_5;
	bra.uni 	BB23_3;

BB23_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd66, {%r14, %r13};
	bra.uni 	BB23_6;

BB23_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB23_6;

	cvt.rzi.f64.f64	%fd25, %fd23;
	setp.neu.f64	%p6, %fd25, 0d4000000000000000;
	selp.f64	%fd66, 0dFFF8000000000000, %fd66, %p6;

BB23_6:
	add.f64 	%fd67, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd67;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB23_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB23_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB23_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd23;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB23_15;

BB23_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB23_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd67, %fd66;
	@%p14 bra 	BB23_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd67, {%r26, %r25};
	bra.uni 	BB23_16;

BB23_7:
	mov.f64 	%fd67, %fd66;
	bra.uni 	BB23_16;

BB23_12:
	mov.f64 	%fd67, %fd66;
	bra.uni 	BB23_16;

BB23_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd67, {%r31, %r30};

BB23_16:
	neg.f64 	%fd28, %fd67;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0dBFF0000000000000, %fd28, %p18;
	ld.f64 	%fd29, [%rd2];
	mov.f64 	%fd69, 0d0000000000000000;
	setp.geu.f64	%p19, %fd29, %fd13;
	@%p19 bra 	BB23_21;

	mov.f64 	%fd30, 0d4338000000000000;
	mov.f64 	%fd31, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd32, %fd13, %fd31, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd32;
	}
	mov.f64 	%fd33, 0dC338000000000000;
	add.rn.f64 	%fd34, %fd32, %fd33;
	mov.f64 	%fd35, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd36, %fd34, %fd35, %fd13;
	mov.f64 	%fd37, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd38, %fd34, %fd37, %fd36;
	mov.f64 	%fd39, 0d3E928AF3FCA213EA;
	mov.f64 	%fd40, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd41, %fd40, %fd38, %fd39;
	mov.f64 	%fd42, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd43, %fd41, %fd38, %fd42;
	mov.f64 	%fd44, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd45, %fd43, %fd38, %fd44;
	mov.f64 	%fd46, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd47, %fd45, %fd38, %fd46;
	mov.f64 	%fd48, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd49, %fd47, %fd38, %fd48;
	mov.f64 	%fd50, 0d3F81111111122322;
	fma.rn.f64 	%fd51, %fd49, %fd38, %fd50;
	mov.f64 	%fd52, 0d3FA55555555502A1;
	fma.rn.f64 	%fd53, %fd51, %fd38, %fd52;
	mov.f64 	%fd54, 0d3FC5555555555511;
	fma.rn.f64 	%fd55, %fd53, %fd38, %fd54;
	mov.f64 	%fd56, 0d3FE000000000000B;
	fma.rn.f64 	%fd57, %fd55, %fd38, %fd56;
	mov.f64 	%fd58, 0d3FF0000000000000;
	fma.rn.f64 	%fd59, %fd57, %fd38, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd38, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd60;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd68, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd13;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB23_20;

	setp.lt.f64	%p21, %fd13, 0d0000000000000000;
	add.f64 	%fd61, %fd13, 0d7FF0000000000000;
	selp.f64	%fd68, 0d0000000000000000, %fd61, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB23_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd62, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd63, {%r43, %r42};
	mul.f64 	%fd68, %fd62, %fd63;

BB23_20:
	mul.f64 	%fd64, %fd68, %fd20;
	neg.f64 	%fd69, %fd64;

BB23_21:
	st.param.f64	[func_retval0+0], %fd69;
	ret;
}

	// .globl	_Z11RickerInt_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11RickerInt_tddPdiPii(
	.param .b64 _Z11RickerInt_tddPdiPii_param_0,
	.param .b64 _Z11RickerInt_tddPdiPii_param_1,
	.param .b64 _Z11RickerInt_tddPdiPii_param_2,
	.param .b32 _Z11RickerInt_tddPdiPii_param_3,
	.param .b64 _Z11RickerInt_tddPdiPii_param_4,
	.param .b32 _Z11RickerInt_tddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<71>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z11RickerInt_tddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z11RickerInt_tddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z11RickerInt_tddPdiPii_param_2];
	mul.f64 	%fd24, %fd22, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd24, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd25;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 72
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd67, [retval0+0];
	
	//{
	}// Callseq End 72
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB24_2;
	bra.uni 	BB24_1;

BB24_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd67;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd67;
	}
	mov.b64 	%fd67, {%r10, %r9};

BB24_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB24_5;
	bra.uni 	BB24_3;

BB24_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd67, {%r14, %r13};
	bra.uni 	BB24_6;

BB24_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB24_6;

	cvt.rzi.f64.f64	%fd27, %fd25;
	setp.neu.f64	%p6, %fd27, 0d4000000000000000;
	selp.f64	%fd67, 0dFFF8000000000000, %fd67, %p6;

BB24_6:
	add.f64 	%fd68, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd68;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB24_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB24_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB24_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd25;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB24_15;

BB24_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB24_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd68, %fd67;
	@%p14 bra 	BB24_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd68, {%r26, %r25};
	bra.uni 	BB24_16;

BB24_7:
	mov.f64 	%fd68, %fd67;
	bra.uni 	BB24_16;

BB24_12:
	mov.f64 	%fd68, %fd67;
	bra.uni 	BB24_16;

BB24_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd68, {%r31, %r30};

BB24_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd68, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd70, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB24_21;

	fma.rn.f64 	%fd15, %fd13, 0d4000000000000000, 0dBFF0000000000000;
	mov.f64 	%fd31, 0d4338000000000000;
	mov.f64 	%fd32, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd33, %fd14, %fd32, %fd31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd33;
	}
	mov.f64 	%fd34, 0dC338000000000000;
	add.rn.f64 	%fd35, %fd33, %fd34;
	mov.f64 	%fd36, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd37, %fd35, %fd36, %fd14;
	mov.f64 	%fd38, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd39, %fd35, %fd38, %fd37;
	mov.f64 	%fd40, 0d3E928AF3FCA213EA;
	mov.f64 	%fd41, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F81111111122322;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FA55555555502A1;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	mov.f64 	%fd55, 0d3FC5555555555511;
	fma.rn.f64 	%fd56, %fd54, %fd39, %fd55;
	mov.f64 	%fd57, 0d3FE000000000000B;
	fma.rn.f64 	%fd58, %fd56, %fd39, %fd57;
	mov.f64 	%fd59, 0d3FF0000000000000;
	fma.rn.f64 	%fd60, %fd58, %fd39, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd61;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd61;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd69, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB24_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd62, 0d7FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd13;
	selp.f64	%fd69, 0d0000000000000000, %fd63, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB24_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd64, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd65, {%r43, %r42};
	mul.f64 	%fd69, %fd64, %fd65;

BB24_20:
	mul.f64 	%fd70, %fd15, %fd69;

BB24_21:
	st.param.f64	[func_retval0+0], %fd70;
	ret;
}

	// .globl	_Z12RickerInt_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12RickerInt_omddPdiPii(
	.param .b64 _Z12RickerInt_omddPdiPii_param_0,
	.param .b64 _Z12RickerInt_omddPdiPii_param_1,
	.param .b64 _Z12RickerInt_omddPdiPii_param_2,
	.param .b32 _Z12RickerInt_omddPdiPii_param_3,
	.param .b64 _Z12RickerInt_omddPdiPii_param_4,
	.param .b32 _Z12RickerInt_omddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd20, [_Z12RickerInt_omddPdiPii_param_0];
	ld.param.f64 	%fd21, [_Z12RickerInt_omddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z12RickerInt_omddPdiPii_param_2];
	mul.f64 	%fd22, %fd20, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd22, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd23, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd23;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 73
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd23;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd71, [retval0+0];
	
	//{
	}// Callseq End 73
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB25_2;
	bra.uni 	BB25_1;

BB25_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd71;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd71;
	}
	mov.b64 	%fd71, {%r10, %r9};

BB25_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB25_5;
	bra.uni 	BB25_3;

BB25_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd71, {%r14, %r13};
	bra.uni 	BB25_6;

BB25_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB25_6;

	cvt.rzi.f64.f64	%fd25, %fd23;
	setp.neu.f64	%p6, %fd25, 0d4000000000000000;
	selp.f64	%fd71, 0dFFF8000000000000, %fd71, %p6;

BB25_6:
	add.f64 	%fd72, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd72;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB25_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB25_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB25_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd23;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB25_15;

BB25_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB25_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd72, %fd71;
	@%p14 bra 	BB25_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd72, {%r26, %r25};
	bra.uni 	BB25_16;

BB25_7:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB25_16;

BB25_12:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB25_16;

BB25_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd72, {%r31, %r30};

BB25_16:
	neg.f64 	%fd28, %fd72;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0dBFF0000000000000, %fd28, %p18;
	ld.f64 	%fd29, [%rd2];
	mov.f64 	%fd74, 0d0000000000000000;
	setp.geu.f64	%p19, %fd29, %fd13;
	@%p19 bra 	BB25_21;

	mov.f64 	%fd30, 0d4338000000000000;
	mov.f64 	%fd31, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd32, %fd13, %fd31, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd32;
	}
	mov.f64 	%fd33, 0dC338000000000000;
	add.rn.f64 	%fd34, %fd32, %fd33;
	mov.f64 	%fd35, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd36, %fd34, %fd35, %fd13;
	mov.f64 	%fd37, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd38, %fd34, %fd37, %fd36;
	mov.f64 	%fd39, 0d3E928AF3FCA213EA;
	mov.f64 	%fd40, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd41, %fd40, %fd38, %fd39;
	mov.f64 	%fd42, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd43, %fd41, %fd38, %fd42;
	mov.f64 	%fd44, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd45, %fd43, %fd38, %fd44;
	mov.f64 	%fd46, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd47, %fd45, %fd38, %fd46;
	mov.f64 	%fd48, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd49, %fd47, %fd38, %fd48;
	mov.f64 	%fd50, 0d3F81111111122322;
	fma.rn.f64 	%fd51, %fd49, %fd38, %fd50;
	mov.f64 	%fd52, 0d3FA55555555502A1;
	fma.rn.f64 	%fd53, %fd51, %fd38, %fd52;
	mov.f64 	%fd54, 0d3FC5555555555511;
	fma.rn.f64 	%fd55, %fd53, %fd38, %fd54;
	mov.f64 	%fd56, 0d3FE000000000000B;
	fma.rn.f64 	%fd57, %fd55, %fd38, %fd56;
	mov.f64 	%fd58, 0d3FF0000000000000;
	fma.rn.f64 	%fd59, %fd57, %fd38, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd38, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd60;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd73, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd13;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB25_20;

	setp.lt.f64	%p21, %fd13, 0d0000000000000000;
	add.f64 	%fd61, %fd13, 0d7FF0000000000000;
	selp.f64	%fd73, 0d0000000000000000, %fd61, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB25_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd62, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd63, {%r43, %r42};
	mul.f64 	%fd73, %fd62, %fd63;

BB25_20:
	add.f64 	%fd64, %fd21, %fd21;
	mul.f64 	%fd65, %fd64, %fd21;
	mul.f64 	%fd66, %fd65, %fd21;
	mul.f64 	%fd67, %fd66, %fd20;
	mul.f64 	%fd68, %fd67, 0d400921FB54442D18;
	mul.f64 	%fd69, %fd68, 0d400921FB54442D18;
	mul.f64 	%fd74, %fd69, %fd73;

BB25_21:
	st.param.f64	[func_retval0+0], %fd74;
	ret;
}

	// .globl	_Z12RickerInt_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12RickerInt_ttddPdiPii(
	.param .b64 _Z12RickerInt_ttddPdiPii_param_0,
	.param .b64 _Z12RickerInt_ttddPdiPii_param_1,
	.param .b64 _Z12RickerInt_ttddPdiPii_param_2,
	.param .b32 _Z12RickerInt_ttddPdiPii_param_3,
	.param .b64 _Z12RickerInt_ttddPdiPii_param_4,
	.param .b32 _Z12RickerInt_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd21, [_Z12RickerInt_ttddPdiPii_param_0];
	ld.param.f64 	%fd22, [_Z12RickerInt_ttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z12RickerInt_ttddPdiPii_param_2];
	mul.f64 	%fd23, %fd21, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd23, %fd22;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 74
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd71, [retval0+0];
	
	//{
	}// Callseq End 74
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB26_2;
	bra.uni 	BB26_1;

BB26_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd71;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd71;
	}
	mov.b64 	%fd71, {%r10, %r9};

BB26_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB26_5;
	bra.uni 	BB26_3;

BB26_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd71, {%r14, %r13};
	bra.uni 	BB26_6;

BB26_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB26_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd71, 0dFFF8000000000000, %fd71, %p6;

BB26_6:
	add.f64 	%fd72, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd72;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB26_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB26_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB26_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB26_15;

BB26_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB26_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd72, %fd71;
	@%p14 bra 	BB26_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd72, {%r26, %r25};
	bra.uni 	BB26_16;

BB26_7:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB26_16;

BB26_12:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB26_16;

BB26_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd72, {%r31, %r30};

BB26_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd72, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd29, [%rd2];
	mov.f64 	%fd74, 0d0000000000000000;
	setp.geu.f64	%p19, %fd29, %fd14;
	@%p19 bra 	BB26_21;

	mov.f64 	%fd30, 0d4338000000000000;
	mov.f64 	%fd31, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd32, %fd14, %fd31, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd32;
	}
	mov.f64 	%fd33, 0dC338000000000000;
	add.rn.f64 	%fd34, %fd32, %fd33;
	mov.f64 	%fd35, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd36, %fd34, %fd35, %fd14;
	mov.f64 	%fd37, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd38, %fd34, %fd37, %fd36;
	mov.f64 	%fd39, 0d3E928AF3FCA213EA;
	mov.f64 	%fd40, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd41, %fd40, %fd38, %fd39;
	mov.f64 	%fd42, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd43, %fd41, %fd38, %fd42;
	mov.f64 	%fd44, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd45, %fd43, %fd38, %fd44;
	mov.f64 	%fd46, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd47, %fd45, %fd38, %fd46;
	mov.f64 	%fd48, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd49, %fd47, %fd38, %fd48;
	mov.f64 	%fd50, 0d3F81111111122322;
	fma.rn.f64 	%fd51, %fd49, %fd38, %fd50;
	mov.f64 	%fd52, 0d3FA55555555502A1;
	fma.rn.f64 	%fd53, %fd51, %fd38, %fd52;
	mov.f64 	%fd54, 0d3FC5555555555511;
	fma.rn.f64 	%fd55, %fd53, %fd38, %fd54;
	mov.f64 	%fd56, 0d3FE000000000000B;
	fma.rn.f64 	%fd57, %fd55, %fd38, %fd56;
	mov.f64 	%fd58, 0d3FF0000000000000;
	fma.rn.f64 	%fd59, %fd57, %fd38, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd38, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd60;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd73, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB26_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd61, 0d7FF0000000000000;
	sub.f64 	%fd62, %fd61, %fd13;
	selp.f64	%fd73, 0d0000000000000000, %fd62, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB26_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd63, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd64, {%r43, %r42};
	mul.f64 	%fd73, %fd63, %fd64;

BB26_20:
	fma.rn.f64 	%fd65, %fd13, 0dC010000000000000, 0d4018000000000000;
	mul.f64 	%fd66, %fd21, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd67, %fd66, %fd21;
	mul.f64 	%fd68, %fd67, %fd22;
	mul.f64 	%fd69, %fd68, %fd65;
	mul.f64 	%fd74, %fd69, %fd73;

BB26_21:
	st.param.f64	[func_retval0+0], %fd74;
	ret;
}

	// .globl	_Z13RickerInt_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13RickerInt_tttddPdiPii(
	.param .b64 _Z13RickerInt_tttddPdiPii_param_0,
	.param .b64 _Z13RickerInt_tttddPdiPii_param_1,
	.param .b64 _Z13RickerInt_tttddPdiPii_param_2,
	.param .b32 _Z13RickerInt_tttddPdiPii_param_3,
	.param .b64 _Z13RickerInt_tttddPdiPii_param_4,
	.param .b32 _Z13RickerInt_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<76>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z13RickerInt_tttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z13RickerInt_tttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z13RickerInt_tttddPdiPii_param_2];
	mul.f64 	%fd24, %fd22, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd24, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd25;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 75
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd72, [retval0+0];
	
	//{
	}// Callseq End 75
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB27_2;
	bra.uni 	BB27_1;

BB27_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd72;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd72;
	}
	mov.b64 	%fd72, {%r10, %r9};

BB27_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB27_5;
	bra.uni 	BB27_3;

BB27_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd72, {%r14, %r13};
	bra.uni 	BB27_6;

BB27_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB27_6;

	cvt.rzi.f64.f64	%fd27, %fd25;
	setp.neu.f64	%p6, %fd27, 0d4000000000000000;
	selp.f64	%fd72, 0dFFF8000000000000, %fd72, %p6;

BB27_6:
	add.f64 	%fd73, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd73;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB27_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB27_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB27_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd25;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB27_15;

BB27_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB27_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd73, %fd72;
	@%p14 bra 	BB27_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd73, {%r26, %r25};
	bra.uni 	BB27_16;

BB27_7:
	mov.f64 	%fd73, %fd72;
	bra.uni 	BB27_16;

BB27_12:
	mov.f64 	%fd73, %fd72;
	bra.uni 	BB27_16;

BB27_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd73, {%r31, %r30};

BB27_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd73, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd75, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB27_21;

	fma.rn.f64 	%fd31, %fd13, 0dC038000000000000, 0d4018000000000000;
	mul.f64 	%fd32, %fd13, 0d4020000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd32, %fd31;
	mov.f64 	%fd33, 0d4338000000000000;
	mov.f64 	%fd34, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd35, %fd14, %fd34, %fd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd35;
	}
	mov.f64 	%fd36, 0dC338000000000000;
	add.rn.f64 	%fd37, %fd35, %fd36;
	mov.f64 	%fd38, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd39, %fd37, %fd38, %fd14;
	mov.f64 	%fd40, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd41, %fd37, %fd40, %fd39;
	mov.f64 	%fd42, 0d3E928AF3FCA213EA;
	mov.f64 	%fd43, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd44, %fd43, %fd41, %fd42;
	mov.f64 	%fd45, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	mov.f64 	%fd47, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd48, %fd46, %fd41, %fd47;
	mov.f64 	%fd49, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd50, %fd48, %fd41, %fd49;
	mov.f64 	%fd51, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd52, %fd50, %fd41, %fd51;
	mov.f64 	%fd53, 0d3F81111111122322;
	fma.rn.f64 	%fd54, %fd52, %fd41, %fd53;
	mov.f64 	%fd55, 0d3FA55555555502A1;
	fma.rn.f64 	%fd56, %fd54, %fd41, %fd55;
	mov.f64 	%fd57, 0d3FC5555555555511;
	fma.rn.f64 	%fd58, %fd56, %fd41, %fd57;
	mov.f64 	%fd59, 0d3FE000000000000B;
	fma.rn.f64 	%fd60, %fd58, %fd41, %fd59;
	mov.f64 	%fd61, 0d3FF0000000000000;
	fma.rn.f64 	%fd62, %fd60, %fd41, %fd61;
	fma.rn.f64 	%fd63, %fd62, %fd41, %fd61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd63;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd63;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd74, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB27_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd64, 0d7FF0000000000000;
	sub.f64 	%fd65, %fd64, %fd13;
	selp.f64	%fd74, 0d0000000000000000, %fd65, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB27_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd66, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd67, {%r43, %r42};
	mul.f64 	%fd74, %fd66, %fd67;

BB27_20:
	mul.f64 	%fd68, %fd22, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd69, %fd68, %fd22;
	mul.f64 	%fd70, %fd69, %fd15;
	mul.f64 	%fd75, %fd70, %fd74;

BB27_21:
	st.param.f64	[func_retval0+0], %fd75;
	ret;
}

	// .globl	_Z14RickerInt_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z14RickerInt_omttddPdiPii(
	.param .b64 _Z14RickerInt_omttddPdiPii_param_0,
	.param .b64 _Z14RickerInt_omttddPdiPii_param_1,
	.param .b64 _Z14RickerInt_omttddPdiPii_param_2,
	.param .b32 _Z14RickerInt_omttddPdiPii_param_3,
	.param .b64 _Z14RickerInt_omttddPdiPii_param_4,
	.param .b32 _Z14RickerInt_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<77>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z14RickerInt_omttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z14RickerInt_omttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z14RickerInt_omttddPdiPii_param_2];
	mul.f64 	%fd24, %fd22, 0d400921FB54442D18;
	mul.f64 	%fd1, %fd24, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd25;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 76
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd73, [retval0+0];
	
	//{
	}// Callseq End 76
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB28_2;
	bra.uni 	BB28_1;

BB28_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd73;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd73;
	}
	mov.b64 	%fd73, {%r10, %r9};

BB28_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB28_5;
	bra.uni 	BB28_3;

BB28_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd73, {%r14, %r13};
	bra.uni 	BB28_6;

BB28_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB28_6;

	cvt.rzi.f64.f64	%fd27, %fd25;
	setp.neu.f64	%p6, %fd27, 0d4000000000000000;
	selp.f64	%fd73, 0dFFF8000000000000, %fd73, %p6;

BB28_6:
	add.f64 	%fd74, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd74;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB28_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB28_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB28_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd25;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB28_15;

BB28_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB28_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd74, %fd73;
	@%p14 bra 	BB28_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd74, {%r26, %r25};
	bra.uni 	BB28_16;

BB28_7:
	mov.f64 	%fd74, %fd73;
	bra.uni 	BB28_16;

BB28_12:
	mov.f64 	%fd74, %fd73;
	bra.uni 	BB28_16;

BB28_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd74, {%r31, %r30};

BB28_16:
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd74, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd76, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB28_21;

	fma.rn.f64 	%fd31, %fd13, 0dC03C000000000000, 0d4028000000000000;
	mul.f64 	%fd32, %fd13, 0d4020000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd32, %fd31;
	mov.f64 	%fd33, 0d4338000000000000;
	mov.f64 	%fd34, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd35, %fd14, %fd34, %fd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd35;
	}
	mov.f64 	%fd36, 0dC338000000000000;
	add.rn.f64 	%fd37, %fd35, %fd36;
	mov.f64 	%fd38, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd39, %fd37, %fd38, %fd14;
	mov.f64 	%fd40, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd41, %fd37, %fd40, %fd39;
	mov.f64 	%fd42, 0d3E928AF3FCA213EA;
	mov.f64 	%fd43, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd44, %fd43, %fd41, %fd42;
	mov.f64 	%fd45, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	mov.f64 	%fd47, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd48, %fd46, %fd41, %fd47;
	mov.f64 	%fd49, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd50, %fd48, %fd41, %fd49;
	mov.f64 	%fd51, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd52, %fd50, %fd41, %fd51;
	mov.f64 	%fd53, 0d3F81111111122322;
	fma.rn.f64 	%fd54, %fd52, %fd41, %fd53;
	mov.f64 	%fd55, 0d3FA55555555502A1;
	fma.rn.f64 	%fd56, %fd54, %fd41, %fd55;
	mov.f64 	%fd57, 0d3FC5555555555511;
	fma.rn.f64 	%fd58, %fd56, %fd41, %fd57;
	mov.f64 	%fd59, 0d3FE000000000000B;
	fma.rn.f64 	%fd60, %fd58, %fd41, %fd59;
	mov.f64 	%fd61, 0d3FF0000000000000;
	fma.rn.f64 	%fd62, %fd60, %fd41, %fd61;
	fma.rn.f64 	%fd63, %fd62, %fd41, %fd61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd63;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd63;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd75, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB28_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd64, 0d7FF0000000000000;
	sub.f64 	%fd65, %fd64, %fd13;
	selp.f64	%fd75, 0d0000000000000000, %fd65, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB28_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd66, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd67, {%r43, %r42};
	mul.f64 	%fd75, %fd66, %fd67;

BB28_20:
	mul.f64 	%fd68, %fd23, 0d400921FB54442D18;
	mul.f64 	%fd69, %fd68, 0d400921FB54442D18;
	mul.f64 	%fd70, %fd69, %fd22;
	mul.f64 	%fd71, %fd70, %fd15;
	mul.f64 	%fd76, %fd71, %fd75;

BB28_21:
	st.param.f64	[func_retval0+0], %fd76;
	ret;
}

	// .globl	_Z8GaussianddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8GaussianddPdiPii(
	.param .b64 _Z8GaussianddPdiPii_param_0,
	.param .b64 _Z8GaussianddPdiPii_param_1,
	.param .b64 _Z8GaussianddPdiPii_param_2,
	.param .b32 _Z8GaussianddPdiPii_param_3,
	.param .b64 _Z8GaussianddPdiPii_param_4,
	.param .b32 _Z8GaussianddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd20, [_Z8GaussianddPdiPii_param_0];
	ld.param.f64 	%fd21, [_Z8GaussianddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z8GaussianddPdiPii_param_2];
	mul.f64 	%fd1, %fd20, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd22, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd22;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 77
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd65, [retval0+0];
	
	//{
	}// Callseq End 77
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB29_2;
	bra.uni 	BB29_1;

BB29_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd65;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd65;
	}
	mov.b64 	%fd65, {%r10, %r9};

BB29_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB29_5;
	bra.uni 	BB29_3;

BB29_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd65, {%r14, %r13};
	bra.uni 	BB29_6;

BB29_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB29_6;

	cvt.rzi.f64.f64	%fd24, %fd22;
	setp.neu.f64	%p6, %fd24, 0d4000000000000000;
	selp.f64	%fd65, 0dFFF8000000000000, %fd65, %p6;

BB29_6:
	add.f64 	%fd66, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd66;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB29_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB29_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB29_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd22;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB29_15;

BB29_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB29_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd66, %fd65;
	@%p14 bra 	BB29_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd66, {%r26, %r25};
	bra.uni 	BB29_16;

BB29_7:
	mov.f64 	%fd66, %fd65;
	bra.uni 	BB29_16;

BB29_12:
	mov.f64 	%fd66, %fd65;
	bra.uni 	BB29_16;

BB29_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd66, {%r31, %r30};

BB29_16:
	mul.f64 	%fd27, %fd66, 0dBFE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0dBFE0000000000000, %fd27, %p18;
	ld.f64 	%fd28, [%rd2];
	mov.f64 	%fd68, 0d0000000000000000;
	setp.geu.f64	%p19, %fd28, %fd13;
	@%p19 bra 	BB29_21;

	mov.f64 	%fd29, 0d4338000000000000;
	mov.f64 	%fd30, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd31, %fd13, %fd30, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd31;
	}
	mov.f64 	%fd32, 0dC338000000000000;
	add.rn.f64 	%fd33, %fd31, %fd32;
	mov.f64 	%fd34, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd35, %fd33, %fd34, %fd13;
	mov.f64 	%fd36, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd37, %fd33, %fd36, %fd35;
	mov.f64 	%fd38, 0d3E928AF3FCA213EA;
	mov.f64 	%fd39, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd40, %fd39, %fd37, %fd38;
	mov.f64 	%fd41, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd42, %fd40, %fd37, %fd41;
	mov.f64 	%fd43, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd44, %fd42, %fd37, %fd43;
	mov.f64 	%fd45, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd46, %fd44, %fd37, %fd45;
	mov.f64 	%fd47, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd48, %fd46, %fd37, %fd47;
	mov.f64 	%fd49, 0d3F81111111122322;
	fma.rn.f64 	%fd50, %fd48, %fd37, %fd49;
	mov.f64 	%fd51, 0d3FA55555555502A1;
	fma.rn.f64 	%fd52, %fd50, %fd37, %fd51;
	mov.f64 	%fd53, 0d3FC5555555555511;
	fma.rn.f64 	%fd54, %fd52, %fd37, %fd53;
	mov.f64 	%fd55, 0d3FE000000000000B;
	fma.rn.f64 	%fd56, %fd54, %fd37, %fd55;
	mov.f64 	%fd57, 0d3FF0000000000000;
	fma.rn.f64 	%fd58, %fd56, %fd37, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd37, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd59;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd67, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd13;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB29_20;

	setp.lt.f64	%p21, %fd13, 0d0000000000000000;
	add.f64 	%fd60, %fd13, 0d7FF0000000000000;
	selp.f64	%fd67, 0d0000000000000000, %fd60, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB29_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd61, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd62, {%r43, %r42};
	mul.f64 	%fd67, %fd61, %fd62;

BB29_20:
	div.rn.f64 	%fd63, %fd20, 0d40040D931FF62705;
	mul.f64 	%fd68, %fd63, %fd67;

BB29_21:
	st.param.f64	[func_retval0+0], %fd68;
	ret;
}

	// .globl	_Z10Gaussian_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Gaussian_tddPdiPii(
	.param .b64 _Z10Gaussian_tddPdiPii_param_0,
	.param .b64 _Z10Gaussian_tddPdiPii_param_1,
	.param .b64 _Z10Gaussian_tddPdiPii_param_2,
	.param .b32 _Z10Gaussian_tddPdiPii_param_3,
	.param .b64 _Z10Gaussian_tddPdiPii_param_4,
	.param .b32 _Z10Gaussian_tddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<72>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd20, [_Z10Gaussian_tddPdiPii_param_0];
	ld.param.f64 	%fd21, [_Z10Gaussian_tddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z10Gaussian_tddPdiPii_param_2];
	mul.f64 	%fd1, %fd20, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd22, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd22;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 78
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd68, [retval0+0];
	
	//{
	}// Callseq End 78
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB30_2;
	bra.uni 	BB30_1;

BB30_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd68;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd68;
	}
	mov.b64 	%fd68, {%r10, %r9};

BB30_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB30_5;
	bra.uni 	BB30_3;

BB30_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd68, {%r14, %r13};
	bra.uni 	BB30_6;

BB30_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB30_6;

	cvt.rzi.f64.f64	%fd24, %fd22;
	setp.neu.f64	%p6, %fd24, 0d4000000000000000;
	selp.f64	%fd68, 0dFFF8000000000000, %fd68, %p6;

BB30_6:
	add.f64 	%fd69, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd69;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB30_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB30_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB30_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd22;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB30_15;

BB30_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB30_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd69, %fd68;
	@%p14 bra 	BB30_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd69, {%r26, %r25};
	bra.uni 	BB30_16;

BB30_7:
	mov.f64 	%fd69, %fd68;
	bra.uni 	BB30_16;

BB30_12:
	mov.f64 	%fd69, %fd68;
	bra.uni 	BB30_16;

BB30_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd69, {%r31, %r30};

BB30_16:
	mul.f64 	%fd27, %fd69, 0dBFE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0dBFE0000000000000, %fd27, %p18;
	ld.f64 	%fd28, [%rd2];
	mov.f64 	%fd71, 0d0000000000000000;
	setp.geu.f64	%p19, %fd28, %fd13;
	@%p19 bra 	BB30_21;

	mov.f64 	%fd29, 0d4338000000000000;
	mov.f64 	%fd30, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd31, %fd13, %fd30, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd31;
	}
	mov.f64 	%fd32, 0dC338000000000000;
	add.rn.f64 	%fd33, %fd31, %fd32;
	mov.f64 	%fd34, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd35, %fd33, %fd34, %fd13;
	mov.f64 	%fd36, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd37, %fd33, %fd36, %fd35;
	mov.f64 	%fd38, 0d3E928AF3FCA213EA;
	mov.f64 	%fd39, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd40, %fd39, %fd37, %fd38;
	mov.f64 	%fd41, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd42, %fd40, %fd37, %fd41;
	mov.f64 	%fd43, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd44, %fd42, %fd37, %fd43;
	mov.f64 	%fd45, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd46, %fd44, %fd37, %fd45;
	mov.f64 	%fd47, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd48, %fd46, %fd37, %fd47;
	mov.f64 	%fd49, 0d3F81111111122322;
	fma.rn.f64 	%fd50, %fd48, %fd37, %fd49;
	mov.f64 	%fd51, 0d3FA55555555502A1;
	fma.rn.f64 	%fd52, %fd50, %fd37, %fd51;
	mov.f64 	%fd53, 0d3FC5555555555511;
	fma.rn.f64 	%fd54, %fd52, %fd37, %fd53;
	mov.f64 	%fd55, 0d3FE000000000000B;
	fma.rn.f64 	%fd56, %fd54, %fd37, %fd55;
	mov.f64 	%fd57, 0d3FF0000000000000;
	fma.rn.f64 	%fd58, %fd56, %fd37, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd37, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd59;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd70, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd13;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB30_20;

	setp.lt.f64	%p21, %fd13, 0d0000000000000000;
	add.f64 	%fd60, %fd13, 0d7FF0000000000000;
	selp.f64	%fd70, 0d0000000000000000, %fd60, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB30_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd61, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd62, {%r43, %r42};
	mul.f64 	%fd70, %fd61, %fd62;

BB30_20:
	mul.f64 	%fd63, %fd20, %fd20;
	mul.f64 	%fd64, %fd63, %fd20;
	mul.f64 	%fd65, %fd64, %fd21;
	div.rn.f64 	%fd66, %fd65, 0dC0040D931FF62705;
	mul.f64 	%fd71, %fd66, %fd70;

BB30_21:
	st.param.f64	[func_retval0+0], %fd71;
	ret;
}

	// .globl	_Z11Gaussian_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Gaussian_omddPdiPii(
	.param .b64 _Z11Gaussian_omddPdiPii_param_0,
	.param .b64 _Z11Gaussian_omddPdiPii_param_1,
	.param .b64 _Z11Gaussian_omddPdiPii_param_2,
	.param .b32 _Z11Gaussian_omddPdiPii_param_3,
	.param .b64 _Z11Gaussian_omddPdiPii_param_4,
	.param .b32 _Z11Gaussian_omddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<72>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd21, [_Z11Gaussian_omddPdiPii_param_0];
	ld.param.f64 	%fd22, [_Z11Gaussian_omddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z11Gaussian_omddPdiPii_param_2];
	mul.f64 	%fd1, %fd21, %fd22;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd23, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd23;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 79
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd23;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd68, [retval0+0];
	
	//{
	}// Callseq End 79
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB31_2;
	bra.uni 	BB31_1;

BB31_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd68;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd68;
	}
	mov.b64 	%fd68, {%r10, %r9};

BB31_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB31_5;
	bra.uni 	BB31_3;

BB31_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd68, {%r14, %r13};
	bra.uni 	BB31_6;

BB31_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB31_6;

	cvt.rzi.f64.f64	%fd25, %fd23;
	setp.neu.f64	%p6, %fd25, 0d4000000000000000;
	selp.f64	%fd68, 0dFFF8000000000000, %fd68, %p6;

BB31_6:
	add.f64 	%fd69, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd69;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB31_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB31_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB31_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd23;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB31_15;

BB31_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB31_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd69, %fd68;
	@%p14 bra 	BB31_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd69, {%r26, %r25};
	bra.uni 	BB31_16;

BB31_7:
	mov.f64 	%fd69, %fd68;
	bra.uni 	BB31_16;

BB31_12:
	mov.f64 	%fd69, %fd68;
	bra.uni 	BB31_16;

BB31_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd69, {%r31, %r30};

BB31_16:
	mul.f64 	%fd28, %fd69, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd28, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd29, [%rd2];
	mov.f64 	%fd71, 0d0000000000000000;
	setp.geu.f64	%p19, %fd29, %fd14;
	@%p19 bra 	BB31_21;

	mov.f64 	%fd30, 0d4338000000000000;
	mov.f64 	%fd31, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd32, %fd14, %fd31, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd32;
	}
	mov.f64 	%fd33, 0dC338000000000000;
	add.rn.f64 	%fd34, %fd32, %fd33;
	mov.f64 	%fd35, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd36, %fd34, %fd35, %fd14;
	mov.f64 	%fd37, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd38, %fd34, %fd37, %fd36;
	mov.f64 	%fd39, 0d3E928AF3FCA213EA;
	mov.f64 	%fd40, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd41, %fd40, %fd38, %fd39;
	mov.f64 	%fd42, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd43, %fd41, %fd38, %fd42;
	mov.f64 	%fd44, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd45, %fd43, %fd38, %fd44;
	mov.f64 	%fd46, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd47, %fd45, %fd38, %fd46;
	mov.f64 	%fd48, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd49, %fd47, %fd38, %fd48;
	mov.f64 	%fd50, 0d3F81111111122322;
	fma.rn.f64 	%fd51, %fd49, %fd38, %fd50;
	mov.f64 	%fd52, 0d3FA55555555502A1;
	fma.rn.f64 	%fd53, %fd51, %fd38, %fd52;
	mov.f64 	%fd54, 0d3FC5555555555511;
	fma.rn.f64 	%fd55, %fd53, %fd38, %fd54;
	mov.f64 	%fd56, 0d3FE000000000000B;
	fma.rn.f64 	%fd57, %fd55, %fd38, %fd56;
	mov.f64 	%fd58, 0d3FF0000000000000;
	fma.rn.f64 	%fd59, %fd57, %fd38, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd38, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd60;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd70, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB31_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd61, 0d7FF0000000000000;
	sub.f64 	%fd62, %fd61, %fd13;
	selp.f64	%fd70, 0d0000000000000000, %fd62, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB31_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd63, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd64, {%r43, %r42};
	mul.f64 	%fd70, %fd63, %fd64;

BB31_20:
	fma.rn.f64 	%fd65, %fd13, 0dC000000000000000, 0d3FF0000000000000;
	div.rn.f64 	%fd66, %fd65, 0d40040D931FF62705;
	mul.f64 	%fd71, %fd66, %fd70;

BB31_21:
	st.param.f64	[func_retval0+0], %fd71;
	ret;
}

	// .globl	_Z11Gaussian_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Gaussian_ttddPdiPii(
	.param .b64 _Z11Gaussian_ttddPdiPii_param_0,
	.param .b64 _Z11Gaussian_ttddPdiPii_param_1,
	.param .b64 _Z11Gaussian_ttddPdiPii_param_2,
	.param .b32 _Z11Gaussian_ttddPdiPii_param_3,
	.param .b64 _Z11Gaussian_ttddPdiPii_param_4,
	.param .b32 _Z11Gaussian_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z11Gaussian_ttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z11Gaussian_ttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z11Gaussian_ttddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 80
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd71, [retval0+0];
	
	//{
	}// Callseq End 80
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB32_2;
	bra.uni 	BB32_1;

BB32_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd71;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd71;
	}
	mov.b64 	%fd71, {%r10, %r9};

BB32_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB32_5;
	bra.uni 	BB32_3;

BB32_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd71, {%r14, %r13};
	bra.uni 	BB32_6;

BB32_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB32_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd71, 0dFFF8000000000000, %fd71, %p6;

BB32_6:
	add.f64 	%fd72, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd72;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB32_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB32_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB32_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB32_15;

BB32_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB32_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd72, %fd71;
	@%p14 bra 	BB32_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd72, {%r26, %r25};
	bra.uni 	BB32_16;

BB32_7:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB32_16;

BB32_12:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB32_16;

BB32_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd72, {%r31, %r30};

BB32_16:
	mul.f64 	%fd29, %fd72, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd74, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB32_21;

	fma.rn.f64 	%fd15, %fd13, 0d4000000000000000, 0dBFF0000000000000;
	mov.f64 	%fd31, 0d4338000000000000;
	mov.f64 	%fd32, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd33, %fd14, %fd32, %fd31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd33;
	}
	mov.f64 	%fd34, 0dC338000000000000;
	add.rn.f64 	%fd35, %fd33, %fd34;
	mov.f64 	%fd36, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd37, %fd35, %fd36, %fd14;
	mov.f64 	%fd38, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd39, %fd35, %fd38, %fd37;
	mov.f64 	%fd40, 0d3E928AF3FCA213EA;
	mov.f64 	%fd41, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F81111111122322;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FA55555555502A1;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	mov.f64 	%fd55, 0d3FC5555555555511;
	fma.rn.f64 	%fd56, %fd54, %fd39, %fd55;
	mov.f64 	%fd57, 0d3FE000000000000B;
	fma.rn.f64 	%fd58, %fd56, %fd39, %fd57;
	mov.f64 	%fd59, 0d3FF0000000000000;
	fma.rn.f64 	%fd60, %fd58, %fd39, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd61;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd61;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd73, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB32_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd62, 0d7FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd13;
	selp.f64	%fd73, 0d0000000000000000, %fd63, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB32_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd64, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd65, {%r43, %r42};
	mul.f64 	%fd73, %fd64, %fd65;

BB32_20:
	div.rn.f64 	%fd66, %fd22, 0d40040D931FF62705;
	mul.f64 	%fd67, %fd66, %fd22;
	mul.f64 	%fd68, %fd67, %fd22;
	mul.f64 	%fd69, %fd15, %fd68;
	mul.f64 	%fd74, %fd69, %fd73;

BB32_21:
	st.param.f64	[func_retval0+0], %fd74;
	ret;
}

	// .globl	_Z12Gaussian_tomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12Gaussian_tomddPdiPii(
	.param .b64 _Z12Gaussian_tomddPdiPii_param_0,
	.param .b64 _Z12Gaussian_tomddPdiPii_param_1,
	.param .b64 _Z12Gaussian_tomddPdiPii_param_2,
	.param .b32 _Z12Gaussian_tomddPdiPii_param_3,
	.param .b64 _Z12Gaussian_tomddPdiPii_param_4,
	.param .b32 _Z12Gaussian_tomddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z12Gaussian_tomddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z12Gaussian_tomddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z12Gaussian_tomddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 81
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd71, [retval0+0];
	
	//{
	}// Callseq End 81
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB33_2;
	bra.uni 	BB33_1;

BB33_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd71;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd71;
	}
	mov.b64 	%fd71, {%r10, %r9};

BB33_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB33_5;
	bra.uni 	BB33_3;

BB33_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd71, {%r14, %r13};
	bra.uni 	BB33_6;

BB33_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB33_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd71, 0dFFF8000000000000, %fd71, %p6;

BB33_6:
	add.f64 	%fd72, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd72;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB33_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB33_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB33_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB33_15;

BB33_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB33_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd72, %fd71;
	@%p14 bra 	BB33_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd72, {%r26, %r25};
	bra.uni 	BB33_16;

BB33_7:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB33_16;

BB33_12:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB33_16;

BB33_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd72, {%r31, %r30};

BB33_16:
	mul.f64 	%fd29, %fd72, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd74, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB33_21;

	fma.rn.f64 	%fd15, %fd13, 0d4000000000000000, 0dC008000000000000;
	mov.f64 	%fd31, 0d4338000000000000;
	mov.f64 	%fd32, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd33, %fd14, %fd32, %fd31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd33;
	}
	mov.f64 	%fd34, 0dC338000000000000;
	add.rn.f64 	%fd35, %fd33, %fd34;
	mov.f64 	%fd36, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd37, %fd35, %fd36, %fd14;
	mov.f64 	%fd38, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd39, %fd35, %fd38, %fd37;
	mov.f64 	%fd40, 0d3E928AF3FCA213EA;
	mov.f64 	%fd41, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F81111111122322;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FA55555555502A1;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	mov.f64 	%fd55, 0d3FC5555555555511;
	fma.rn.f64 	%fd56, %fd54, %fd39, %fd55;
	mov.f64 	%fd57, 0d3FE000000000000B;
	fma.rn.f64 	%fd58, %fd56, %fd39, %fd57;
	mov.f64 	%fd59, 0d3FF0000000000000;
	fma.rn.f64 	%fd60, %fd58, %fd39, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd61;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd61;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd73, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB33_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd62, 0d7FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd13;
	selp.f64	%fd73, 0d0000000000000000, %fd63, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB33_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd64, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd65, {%r43, %r42};
	mul.f64 	%fd73, %fd64, %fd65;

BB33_20:
	mul.f64 	%fd66, %fd22, %fd22;
	mul.f64 	%fd67, %fd66, %fd23;
	div.rn.f64 	%fd68, %fd67, 0d40040D931FF62705;
	mul.f64 	%fd69, %fd15, %fd68;
	mul.f64 	%fd74, %fd69, %fd73;

BB33_21:
	st.param.f64	[func_retval0+0], %fd74;
	ret;
}

	// .globl	_Z13Gaussian_omomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Gaussian_omomddPdiPii(
	.param .b64 _Z13Gaussian_omomddPdiPii_param_0,
	.param .b64 _Z13Gaussian_omomddPdiPii_param_1,
	.param .b64 _Z13Gaussian_omomddPdiPii_param_2,
	.param .b32 _Z13Gaussian_omomddPdiPii_param_3,
	.param .b64 _Z13Gaussian_omomddPdiPii_param_4,
	.param .b32 _Z13Gaussian_omomddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<74>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd23, [_Z13Gaussian_omomddPdiPii_param_0];
	ld.param.f64 	%fd22, [_Z13Gaussian_omomddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z13Gaussian_omomddPdiPii_param_2];
	mul.f64 	%fd1, %fd23, %fd22;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 82
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd70, [retval0+0];
	
	//{
	}// Callseq End 82
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB34_2;
	bra.uni 	BB34_1;

BB34_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd70;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd70;
	}
	mov.b64 	%fd70, {%r10, %r9};

BB34_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB34_5;
	bra.uni 	BB34_3;

BB34_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd70, {%r14, %r13};
	bra.uni 	BB34_6;

BB34_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB34_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd70, 0dFFF8000000000000, %fd70, %p6;

BB34_6:
	add.f64 	%fd71, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd71;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB34_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB34_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB34_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB34_15;

BB34_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB34_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd71, %fd70;
	@%p14 bra 	BB34_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd71, {%r26, %r25};
	bra.uni 	BB34_16;

BB34_7:
	mov.f64 	%fd71, %fd70;
	bra.uni 	BB34_16;

BB34_12:
	mov.f64 	%fd71, %fd70;
	bra.uni 	BB34_16;

BB34_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd71, {%r31, %r30};

BB34_16:
	mul.f64 	%fd29, %fd71, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd73, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB34_21;

	mul.f64 	%fd31, %fd1, %fd22;
	div.rn.f64 	%fd32, %fd31, 0d40040D931FF62705;
	fma.rn.f64 	%fd33, %fd13, 0d4000000000000000, 0dC008000000000000;
	mul.f64 	%fd15, %fd33, %fd32;
	mov.f64 	%fd34, 0d4338000000000000;
	mov.f64 	%fd35, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd36, %fd14, %fd35, %fd34;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd36;
	}
	mov.f64 	%fd37, 0dC338000000000000;
	add.rn.f64 	%fd38, %fd36, %fd37;
	mov.f64 	%fd39, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd40, %fd38, %fd39, %fd14;
	mov.f64 	%fd41, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd42, %fd38, %fd41, %fd40;
	mov.f64 	%fd43, 0d3E928AF3FCA213EA;
	mov.f64 	%fd44, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd45, %fd44, %fd42, %fd43;
	mov.f64 	%fd46, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd47, %fd45, %fd42, %fd46;
	mov.f64 	%fd48, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd49, %fd47, %fd42, %fd48;
	mov.f64 	%fd50, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd51, %fd49, %fd42, %fd50;
	mov.f64 	%fd52, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd53, %fd51, %fd42, %fd52;
	mov.f64 	%fd54, 0d3F81111111122322;
	fma.rn.f64 	%fd55, %fd53, %fd42, %fd54;
	mov.f64 	%fd56, 0d3FA55555555502A1;
	fma.rn.f64 	%fd57, %fd55, %fd42, %fd56;
	mov.f64 	%fd58, 0d3FC5555555555511;
	fma.rn.f64 	%fd59, %fd57, %fd42, %fd58;
	mov.f64 	%fd60, 0d3FE000000000000B;
	fma.rn.f64 	%fd61, %fd59, %fd42, %fd60;
	mov.f64 	%fd62, 0d3FF0000000000000;
	fma.rn.f64 	%fd63, %fd61, %fd42, %fd62;
	fma.rn.f64 	%fd64, %fd63, %fd42, %fd62;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd64;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd64;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd72, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB34_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd65, 0d7FF0000000000000;
	sub.f64 	%fd66, %fd65, %fd13;
	selp.f64	%fd72, 0d0000000000000000, %fd66, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB34_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd67, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd68, {%r43, %r42};
	mul.f64 	%fd72, %fd67, %fd68;

BB34_20:
	mul.f64 	%fd73, %fd15, %fd72;

BB34_21:
	st.param.f64	[func_retval0+0], %fd73;
	ret;
}

	// .globl	_Z12Gaussian_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12Gaussian_tttddPdiPii(
	.param .b64 _Z12Gaussian_tttddPdiPii_param_0,
	.param .b64 _Z12Gaussian_tttddPdiPii_param_1,
	.param .b64 _Z12Gaussian_tttddPdiPii_param_2,
	.param .b32 _Z12Gaussian_tttddPdiPii_param_3,
	.param .b64 _Z12Gaussian_tttddPdiPii_param_4,
	.param .b32 _Z12Gaussian_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<78>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd21, [_Z12Gaussian_tttddPdiPii_param_0];
	ld.param.f64 	%fd22, [_Z12Gaussian_tttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z12Gaussian_tttddPdiPii_param_2];
	mul.f64 	%fd1, %fd21, %fd22;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd23, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd23;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 83
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd23;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd74, [retval0+0];
	
	//{
	}// Callseq End 83
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB35_2;
	bra.uni 	BB35_1;

BB35_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd74;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd74;
	}
	mov.b64 	%fd74, {%r10, %r9};

BB35_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB35_5;
	bra.uni 	BB35_3;

BB35_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd74, {%r14, %r13};
	bra.uni 	BB35_6;

BB35_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB35_6;

	cvt.rzi.f64.f64	%fd25, %fd23;
	setp.neu.f64	%p6, %fd25, 0d4000000000000000;
	selp.f64	%fd74, 0dFFF8000000000000, %fd74, %p6;

BB35_6:
	add.f64 	%fd75, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd75;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB35_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB35_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB35_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd23;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB35_15;

BB35_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB35_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd75, %fd74;
	@%p14 bra 	BB35_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd75, {%r26, %r25};
	bra.uni 	BB35_16;

BB35_7:
	mov.f64 	%fd75, %fd74;
	bra.uni 	BB35_16;

BB35_12:
	mov.f64 	%fd75, %fd74;
	bra.uni 	BB35_16;

BB35_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd75, {%r31, %r30};

BB35_16:
	mul.f64 	%fd28, %fd75, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd28, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd29, [%rd2];
	mov.f64 	%fd77, 0d0000000000000000;
	setp.geu.f64	%p19, %fd29, %fd14;
	@%p19 bra 	BB35_21;

	mov.f64 	%fd30, 0d4338000000000000;
	mov.f64 	%fd31, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd32, %fd14, %fd31, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd32;
	}
	mov.f64 	%fd33, 0dC338000000000000;
	add.rn.f64 	%fd34, %fd32, %fd33;
	mov.f64 	%fd35, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd36, %fd34, %fd35, %fd14;
	mov.f64 	%fd37, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd38, %fd34, %fd37, %fd36;
	mov.f64 	%fd39, 0d3E928AF3FCA213EA;
	mov.f64 	%fd40, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd41, %fd40, %fd38, %fd39;
	mov.f64 	%fd42, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd43, %fd41, %fd38, %fd42;
	mov.f64 	%fd44, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd45, %fd43, %fd38, %fd44;
	mov.f64 	%fd46, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd47, %fd45, %fd38, %fd46;
	mov.f64 	%fd48, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd49, %fd47, %fd38, %fd48;
	mov.f64 	%fd50, 0d3F81111111122322;
	fma.rn.f64 	%fd51, %fd49, %fd38, %fd50;
	mov.f64 	%fd52, 0d3FA55555555502A1;
	fma.rn.f64 	%fd53, %fd51, %fd38, %fd52;
	mov.f64 	%fd54, 0d3FC5555555555511;
	fma.rn.f64 	%fd55, %fd53, %fd38, %fd54;
	mov.f64 	%fd56, 0d3FE000000000000B;
	fma.rn.f64 	%fd57, %fd55, %fd38, %fd56;
	mov.f64 	%fd58, 0d3FF0000000000000;
	fma.rn.f64 	%fd59, %fd57, %fd38, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd38, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd60;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd76, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB35_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd61, 0d7FF0000000000000;
	sub.f64 	%fd62, %fd61, %fd13;
	selp.f64	%fd76, 0d0000000000000000, %fd62, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB35_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd63, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd64, {%r43, %r42};
	mul.f64 	%fd76, %fd63, %fd64;

BB35_20:
	fma.rn.f64 	%fd65, %fd13, 0dC000000000000000, 0d4008000000000000;
	mul.f64 	%fd66, %fd21, %fd21;
	mul.f64 	%fd67, %fd66, %fd21;
	mul.f64 	%fd68, %fd67, %fd21;
	mul.f64 	%fd69, %fd68, %fd21;
	mul.f64 	%fd70, %fd69, %fd22;
	div.rn.f64 	%fd71, %fd70, 0d40040D931FF62705;
	mul.f64 	%fd72, %fd65, %fd71;
	mul.f64 	%fd77, %fd72, %fd76;

BB35_21:
	st.param.f64	[func_retval0+0], %fd77;
	ret;
}

	// .globl	_Z13Gaussian_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Gaussian_omttddPdiPii(
	.param .b64 _Z13Gaussian_omttddPdiPii_param_0,
	.param .b64 _Z13Gaussian_omttddPdiPii_param_1,
	.param .b64 _Z13Gaussian_omttddPdiPii_param_2,
	.param .b32 _Z13Gaussian_omttddPdiPii_param_3,
	.param .b64 _Z13Gaussian_omttddPdiPii_param_4,
	.param .b32 _Z13Gaussian_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<76>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z13Gaussian_omttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z13Gaussian_omttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z13Gaussian_omttddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 84
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd72, [retval0+0];
	
	//{
	}// Callseq End 84
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB36_2;
	bra.uni 	BB36_1;

BB36_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd72;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd72;
	}
	mov.b64 	%fd72, {%r10, %r9};

BB36_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB36_5;
	bra.uni 	BB36_3;

BB36_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd72, {%r14, %r13};
	bra.uni 	BB36_6;

BB36_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB36_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd72, 0dFFF8000000000000, %fd72, %p6;

BB36_6:
	add.f64 	%fd73, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd73;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB36_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB36_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB36_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB36_15;

BB36_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB36_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd73, %fd72;
	@%p14 bra 	BB36_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd73, {%r26, %r25};
	bra.uni 	BB36_16;

BB36_7:
	mov.f64 	%fd73, %fd72;
	bra.uni 	BB36_16;

BB36_12:
	mov.f64 	%fd73, %fd72;
	bra.uni 	BB36_16;

BB36_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd73, {%r31, %r30};

BB36_16:
	mul.f64 	%fd29, %fd73, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd75, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB36_21;

	fma.rn.f64 	%fd15, %fd13, 0d4028000000000000, 0dC008000000000000;
	mov.f64 	%fd31, 0d4338000000000000;
	mov.f64 	%fd32, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd33, %fd14, %fd32, %fd31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd33;
	}
	mov.f64 	%fd34, 0dC338000000000000;
	add.rn.f64 	%fd35, %fd33, %fd34;
	mov.f64 	%fd36, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd37, %fd35, %fd36, %fd14;
	mov.f64 	%fd38, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd39, %fd35, %fd38, %fd37;
	mov.f64 	%fd40, 0d3E928AF3FCA213EA;
	mov.f64 	%fd41, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F81111111122322;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FA55555555502A1;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	mov.f64 	%fd55, 0d3FC5555555555511;
	fma.rn.f64 	%fd56, %fd54, %fd39, %fd55;
	mov.f64 	%fd57, 0d3FE000000000000B;
	fma.rn.f64 	%fd58, %fd56, %fd39, %fd57;
	mov.f64 	%fd59, 0d3FF0000000000000;
	fma.rn.f64 	%fd60, %fd58, %fd39, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd61;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd61;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd74, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB36_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd62, 0d7FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd13;
	selp.f64	%fd74, 0d0000000000000000, %fd63, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB36_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd64, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd65, {%r43, %r42};
	mul.f64 	%fd74, %fd64, %fd65;

BB36_20:
	mul.f64 	%fd66, %fd13, 0dC010000000000000;
	fma.rn.f64 	%fd67, %fd13, %fd66, %fd15;
	mul.f64 	%fd68, %fd22, %fd22;
	mul.f64 	%fd69, %fd68, %fd67;
	div.rn.f64 	%fd70, %fd69, 0d40040D931FF62705;
	mul.f64 	%fd75, %fd70, %fd74;

BB36_21:
	st.param.f64	[func_retval0+0], %fd75;
	ret;
}

	// .globl	_Z13Gaussian_ttttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Gaussian_ttttddPdiPii(
	.param .b64 _Z13Gaussian_ttttddPdiPii_param_0,
	.param .b64 _Z13Gaussian_ttttddPdiPii_param_1,
	.param .b64 _Z13Gaussian_ttttddPdiPii_param_2,
	.param .b32 _Z13Gaussian_ttttddPdiPii_param_3,
	.param .b64 _Z13Gaussian_ttttddPdiPii_param_4,
	.param .b32 _Z13Gaussian_ttttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<79>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z13Gaussian_ttttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z13Gaussian_ttttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z13Gaussian_ttttddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 85
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd75, [retval0+0];
	
	//{
	}// Callseq End 85
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB37_2;
	bra.uni 	BB37_1;

BB37_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd75;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd75;
	}
	mov.b64 	%fd75, {%r10, %r9};

BB37_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB37_5;
	bra.uni 	BB37_3;

BB37_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd75, {%r14, %r13};
	bra.uni 	BB37_6;

BB37_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB37_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd75, 0dFFF8000000000000, %fd75, %p6;

BB37_6:
	add.f64 	%fd76, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd76;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB37_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB37_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB37_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB37_15;

BB37_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB37_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd76, %fd75;
	@%p14 bra 	BB37_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd76, {%r26, %r25};
	bra.uni 	BB37_16;

BB37_7:
	mov.f64 	%fd76, %fd75;
	bra.uni 	BB37_16;

BB37_12:
	mov.f64 	%fd76, %fd75;
	bra.uni 	BB37_16;

BB37_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd76, {%r31, %r30};

BB37_16:
	mul.f64 	%fd29, %fd76, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd78, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB37_21;

	fma.rn.f64 	%fd31, %fd13, 0dC028000000000000, 0d4008000000000000;
	mul.f64 	%fd32, %fd13, 0d4010000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd32, %fd31;
	mov.f64 	%fd33, 0d4338000000000000;
	mov.f64 	%fd34, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd35, %fd14, %fd34, %fd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd35;
	}
	mov.f64 	%fd36, 0dC338000000000000;
	add.rn.f64 	%fd37, %fd35, %fd36;
	mov.f64 	%fd38, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd39, %fd37, %fd38, %fd14;
	mov.f64 	%fd40, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd41, %fd37, %fd40, %fd39;
	mov.f64 	%fd42, 0d3E928AF3FCA213EA;
	mov.f64 	%fd43, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd44, %fd43, %fd41, %fd42;
	mov.f64 	%fd45, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	mov.f64 	%fd47, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd48, %fd46, %fd41, %fd47;
	mov.f64 	%fd49, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd50, %fd48, %fd41, %fd49;
	mov.f64 	%fd51, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd52, %fd50, %fd41, %fd51;
	mov.f64 	%fd53, 0d3F81111111122322;
	fma.rn.f64 	%fd54, %fd52, %fd41, %fd53;
	mov.f64 	%fd55, 0d3FA55555555502A1;
	fma.rn.f64 	%fd56, %fd54, %fd41, %fd55;
	mov.f64 	%fd57, 0d3FC5555555555511;
	fma.rn.f64 	%fd58, %fd56, %fd41, %fd57;
	mov.f64 	%fd59, 0d3FE000000000000B;
	fma.rn.f64 	%fd60, %fd58, %fd41, %fd59;
	mov.f64 	%fd61, 0d3FF0000000000000;
	fma.rn.f64 	%fd62, %fd60, %fd41, %fd61;
	fma.rn.f64 	%fd63, %fd62, %fd41, %fd61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd63;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd63;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd77, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB37_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd64, 0d7FF0000000000000;
	sub.f64 	%fd65, %fd64, %fd13;
	selp.f64	%fd77, 0d0000000000000000, %fd65, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB37_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd66, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd67, {%r43, %r42};
	mul.f64 	%fd77, %fd66, %fd67;

BB37_20:
	mul.f64 	%fd68, %fd22, %fd22;
	mul.f64 	%fd69, %fd68, %fd22;
	mul.f64 	%fd70, %fd69, %fd22;
	mul.f64 	%fd71, %fd70, %fd22;
	div.rn.f64 	%fd72, %fd71, 0d40040D931FF62705;
	mul.f64 	%fd73, %fd15, %fd72;
	mul.f64 	%fd78, %fd73, %fd77;

BB37_21:
	st.param.f64	[func_retval0+0], %fd78;
	ret;
}

	// .globl	_Z14Gaussian_tttomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z14Gaussian_tttomddPdiPii(
	.param .b64 _Z14Gaussian_tttomddPdiPii_param_0,
	.param .b64 _Z14Gaussian_tttomddPdiPii_param_1,
	.param .b64 _Z14Gaussian_tttomddPdiPii_param_2,
	.param .b32 _Z14Gaussian_tttomddPdiPii_param_3,
	.param .b64 _Z14Gaussian_tttomddPdiPii_param_4,
	.param .b32 _Z14Gaussian_tttomddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<79>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z14Gaussian_tttomddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z14Gaussian_tttomddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z14Gaussian_tttomddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 86
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd75, [retval0+0];
	
	//{
	}// Callseq End 86
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB38_2;
	bra.uni 	BB38_1;

BB38_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd75;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd75;
	}
	mov.b64 	%fd75, {%r10, %r9};

BB38_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB38_5;
	bra.uni 	BB38_3;

BB38_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd75, {%r14, %r13};
	bra.uni 	BB38_6;

BB38_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB38_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd75, 0dFFF8000000000000, %fd75, %p6;

BB38_6:
	add.f64 	%fd76, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd76;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB38_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB38_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB38_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB38_15;

BB38_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB38_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd76, %fd75;
	@%p14 bra 	BB38_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd76, {%r26, %r25};
	bra.uni 	BB38_16;

BB38_7:
	mov.f64 	%fd76, %fd75;
	bra.uni 	BB38_16;

BB38_12:
	mov.f64 	%fd76, %fd75;
	bra.uni 	BB38_16;

BB38_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd76, {%r31, %r30};

BB38_16:
	mul.f64 	%fd29, %fd76, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd78, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB38_21;

	fma.rn.f64 	%fd31, %fd13, 0dC034000000000000, 0d402E000000000000;
	mul.f64 	%fd32, %fd13, 0d4010000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd32, %fd31;
	mov.f64 	%fd33, 0d4338000000000000;
	mov.f64 	%fd34, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd35, %fd14, %fd34, %fd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd35;
	}
	mov.f64 	%fd36, 0dC338000000000000;
	add.rn.f64 	%fd37, %fd35, %fd36;
	mov.f64 	%fd38, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd39, %fd37, %fd38, %fd14;
	mov.f64 	%fd40, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd41, %fd37, %fd40, %fd39;
	mov.f64 	%fd42, 0d3E928AF3FCA213EA;
	mov.f64 	%fd43, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd44, %fd43, %fd41, %fd42;
	mov.f64 	%fd45, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	mov.f64 	%fd47, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd48, %fd46, %fd41, %fd47;
	mov.f64 	%fd49, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd50, %fd48, %fd41, %fd49;
	mov.f64 	%fd51, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd52, %fd50, %fd41, %fd51;
	mov.f64 	%fd53, 0d3F81111111122322;
	fma.rn.f64 	%fd54, %fd52, %fd41, %fd53;
	mov.f64 	%fd55, 0d3FA55555555502A1;
	fma.rn.f64 	%fd56, %fd54, %fd41, %fd55;
	mov.f64 	%fd57, 0d3FC5555555555511;
	fma.rn.f64 	%fd58, %fd56, %fd41, %fd57;
	mov.f64 	%fd59, 0d3FE000000000000B;
	fma.rn.f64 	%fd60, %fd58, %fd41, %fd59;
	mov.f64 	%fd61, 0d3FF0000000000000;
	fma.rn.f64 	%fd62, %fd60, %fd41, %fd61;
	fma.rn.f64 	%fd63, %fd62, %fd41, %fd61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd63;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd63;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd77, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB38_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd64, 0d7FF0000000000000;
	sub.f64 	%fd65, %fd64, %fd13;
	selp.f64	%fd77, 0d0000000000000000, %fd65, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB38_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd66, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd67, {%r43, %r42};
	mul.f64 	%fd77, %fd66, %fd67;

BB38_20:
	mul.f64 	%fd68, %fd22, %fd22;
	mul.f64 	%fd69, %fd68, %fd22;
	mul.f64 	%fd70, %fd69, %fd22;
	mul.f64 	%fd71, %fd70, %fd23;
	div.rn.f64 	%fd72, %fd71, 0d40040D931FF62705;
	mul.f64 	%fd73, %fd15, %fd72;
	mul.f64 	%fd78, %fd73, %fd77;

BB38_21:
	st.param.f64	[func_retval0+0], %fd78;
	ret;
}

	// .globl	_Z15Gaussian_ttomomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z15Gaussian_ttomomddPdiPii(
	.param .b64 _Z15Gaussian_ttomomddPdiPii_param_0,
	.param .b64 _Z15Gaussian_ttomomddPdiPii_param_1,
	.param .b64 _Z15Gaussian_ttomomddPdiPii_param_2,
	.param .b32 _Z15Gaussian_ttomomddPdiPii_param_3,
	.param .b64 _Z15Gaussian_ttomomddPdiPii_param_4,
	.param .b32 _Z15Gaussian_ttomomddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<78>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z15Gaussian_ttomomddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z15Gaussian_ttomomddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z15Gaussian_ttomomddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 87
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd74, [retval0+0];
	
	//{
	}// Callseq End 87
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB39_2;
	bra.uni 	BB39_1;

BB39_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd74;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd74;
	}
	mov.b64 	%fd74, {%r10, %r9};

BB39_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB39_5;
	bra.uni 	BB39_3;

BB39_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd74, {%r14, %r13};
	bra.uni 	BB39_6;

BB39_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB39_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd74, 0dFFF8000000000000, %fd74, %p6;

BB39_6:
	add.f64 	%fd75, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd75;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB39_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB39_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB39_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB39_15;

BB39_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB39_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd75, %fd74;
	@%p14 bra 	BB39_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd75, {%r26, %r25};
	bra.uni 	BB39_16;

BB39_7:
	mov.f64 	%fd75, %fd74;
	bra.uni 	BB39_16;

BB39_12:
	mov.f64 	%fd75, %fd74;
	bra.uni 	BB39_16;

BB39_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd75, {%r31, %r30};

BB39_16:
	mul.f64 	%fd29, %fd75, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd77, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB39_21;

	fma.rn.f64 	%fd31, %fd13, 0d404B000000000000, 0dC018000000000000;
	mul.f64 	%fd32, %fd13, 0dC048000000000000;
	fma.rn.f64 	%fd33, %fd13, %fd32, %fd31;
	mul.f64 	%fd34, %fd13, 0d4020000000000000;
	mul.f64 	%fd35, %fd13, %fd34;
	fma.rn.f64 	%fd15, %fd13, %fd35, %fd33;
	mov.f64 	%fd36, 0d4338000000000000;
	mov.f64 	%fd37, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd38, %fd14, %fd37, %fd36;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd38;
	}
	mov.f64 	%fd39, 0dC338000000000000;
	add.rn.f64 	%fd40, %fd38, %fd39;
	mov.f64 	%fd41, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd42, %fd40, %fd41, %fd14;
	mov.f64 	%fd43, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd44, %fd40, %fd43, %fd42;
	mov.f64 	%fd45, 0d3E928AF3FCA213EA;
	mov.f64 	%fd46, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd47, %fd46, %fd44, %fd45;
	mov.f64 	%fd48, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd49, %fd47, %fd44, %fd48;
	mov.f64 	%fd50, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd51, %fd49, %fd44, %fd50;
	mov.f64 	%fd52, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd53, %fd51, %fd44, %fd52;
	mov.f64 	%fd54, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd55, %fd53, %fd44, %fd54;
	mov.f64 	%fd56, 0d3F81111111122322;
	fma.rn.f64 	%fd57, %fd55, %fd44, %fd56;
	mov.f64 	%fd58, 0d3FA55555555502A1;
	fma.rn.f64 	%fd59, %fd57, %fd44, %fd58;
	mov.f64 	%fd60, 0d3FC5555555555511;
	fma.rn.f64 	%fd61, %fd59, %fd44, %fd60;
	mov.f64 	%fd62, 0d3FE000000000000B;
	fma.rn.f64 	%fd63, %fd61, %fd44, %fd62;
	mov.f64 	%fd64, 0d3FF0000000000000;
	fma.rn.f64 	%fd65, %fd63, %fd44, %fd64;
	fma.rn.f64 	%fd66, %fd65, %fd44, %fd64;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd66;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd66;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd76, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB39_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd67, 0d7FF0000000000000;
	sub.f64 	%fd68, %fd67, %fd13;
	selp.f64	%fd76, 0d0000000000000000, %fd68, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB39_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd69, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd70, {%r43, %r42};
	mul.f64 	%fd76, %fd69, %fd70;

BB39_20:
	div.rn.f64 	%fd71, %fd22, 0d40040D931FF62705;
	mul.f64 	%fd72, %fd15, %fd71;
	mul.f64 	%fd77, %fd72, %fd76;

BB39_21:
	st.param.f64	[func_retval0+0], %fd77;
	ret;
}

	// .globl	_Z3ErfddPdiPii
.visible .func  (.param .b64 func_retval0) _Z3ErfddPdiPii(
	.param .b64 _Z3ErfddPdiPii_param_0,
	.param .b64 _Z3ErfddPdiPii_param_1,
	.param .b64 _Z3ErfddPdiPii_param_2,
	.param .b32 _Z3ErfddPdiPii_param_3,
	.param .b64 _Z3ErfddPdiPii_param_4,
	.param .b32 _Z3ErfddPdiPii_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<17>;
	.reg .f64 	%fd<116>;


	ld.param.f64 	%fd7, [_Z3ErfddPdiPii_param_0];
	ld.param.f64 	%fd8, [_Z3ErfddPdiPii_param_1];
	mul.f64 	%fd9, %fd7, %fd8;
	div.rn.f64 	%fd1, %fd9, 0d3FF6A09E667F3BCD;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	and.b32  	%r2, %r1, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd1;
	}
	setp.lt.u32	%p1, %r2, 1072693248;
	@%p1 bra 	BB40_6;
	bra.uni 	BB40_1;

BB40_6:
	mul.f64 	%fd89, %fd1, %fd1;
	mov.f64 	%fd90, 0d3E4D5F4BB7A316F6;
	mov.f64 	%fd91, 0dBE0A83AA3B08FBC2;
	fma.rn.f64 	%fd92, %fd91, %fd89, %fd90;
	mov.f64 	%fd93, 0dBE85BDCE301B3CDF;
	fma.rn.f64 	%fd94, %fd92, %fd89, %fd93;
	mov.f64 	%fd95, 0d3EBB978FADB81BC9;
	fma.rn.f64 	%fd96, %fd94, %fd89, %fd95;
	mov.f64 	%fd97, 0dBEEF4C99D6AE5FB8;
	fma.rn.f64 	%fd98, %fd96, %fd89, %fd97;
	mov.f64 	%fd99, 0d3F1F9A2AF549012E;
	fma.rn.f64 	%fd100, %fd98, %fd89, %fd99;
	mov.f64 	%fd101, 0dBF4C02DAFC636A47;
	fma.rn.f64 	%fd102, %fd100, %fd89, %fd101;
	mov.f64 	%fd103, 0d3F7565BCCF619AC0;
	fma.rn.f64 	%fd104, %fd102, %fd89, %fd103;
	mov.f64 	%fd105, 0dBF9B82CE311E321A;
	fma.rn.f64 	%fd106, %fd104, %fd89, %fd105;
	mov.f64 	%fd107, 0d3FBCE2F21A04075C;
	fma.rn.f64 	%fd108, %fd106, %fd89, %fd107;
	mov.f64 	%fd109, 0dBFD812746B0379B4;
	fma.rn.f64 	%fd110, %fd108, %fd89, %fd109;
	mov.f64 	%fd111, 0d3FF20DD750429B6D;
	fma.rn.f64 	%fd112, %fd110, %fd89, %fd111;
	mul.f64 	%fd115, %fd1, %fd112;
	bra.uni 	BB40_7;

BB40_1:
	setp.lt.u32	%p2, %r2, 2146435072;
	@%p2 bra 	BB40_5;
	bra.uni 	BB40_2;

BB40_5:
	mov.b64 	%fd11, {%r3, %r2};
	mov.f64 	%fd12, 0dBCF1384CE38C616A;
	mov.f64 	%fd13, 0d3C8B9C2B870030E8;
	fma.rn.f64 	%fd14, %fd13, %fd11, %fd12;
	mov.f64 	%fd15, 0d3D4458AE9746C2FD;
	fma.rn.f64 	%fd16, %fd14, %fd11, %fd15;
	mov.f64 	%fd17, 0dBD8E4A44D4F1AB56;
	fma.rn.f64 	%fd18, %fd16, %fd11, %fd17;
	mov.f64 	%fd19, 0d3DCFDF15265C58EE;
	fma.rn.f64 	%fd20, %fd18, %fd11, %fd19;
	mov.f64 	%fd21, 0dBE0933832F358D51;
	fma.rn.f64 	%fd22, %fd20, %fd11, %fd21;
	mov.f64 	%fd23, 0d3E3F136D3F719446;
	fma.rn.f64 	%fd24, %fd22, %fd11, %fd23;
	mov.f64 	%fd25, 0dBE6E94C2FE151B3B;
	fma.rn.f64 	%fd26, %fd24, %fd11, %fd25;
	mov.f64 	%fd27, 0d3E985A70310EE0A8;
	fma.rn.f64 	%fd28, %fd26, %fd11, %fd27;
	mov.f64 	%fd29, 0dBEBF944DA1520B74;
	fma.rn.f64 	%fd30, %fd28, %fd11, %fd29;
	mov.f64 	%fd31, 0d3EE09F503825C543;
	fma.rn.f64 	%fd32, %fd30, %fd11, %fd31;
	mov.f64 	%fd33, 0dBEFBEEFE9F949E59;
	fma.rn.f64 	%fd34, %fd32, %fd11, %fd33;
	mov.f64 	%fd35, 0d3F11D785C6E28857;
	fma.rn.f64 	%fd36, %fd34, %fd11, %fd35;
	mov.f64 	%fd37, 0dBF1D866B223048C7;
	fma.rn.f64 	%fd38, %fd36, %fd11, %fd37;
	mov.f64 	%fd39, 0d3EF258F0847E8908;
	fma.rn.f64 	%fd40, %fd38, %fd11, %fd39;
	mov.f64 	%fd41, 0d3F429CFC58DBB776;
	fma.rn.f64 	%fd42, %fd40, %fd11, %fd41;
	mov.f64 	%fd43, 0dBF5BE16D3F71F3C5;
	fma.rn.f64 	%fd44, %fd42, %fd11, %fd43;
	mov.f64 	%fd45, 0d3F2E8BDA60326B1A;
	fma.rn.f64 	%fd46, %fd44, %fd11, %fd45;
	mov.f64 	%fd47, 0d3F938FB20B0988A6;
	fma.rn.f64 	%fd48, %fd46, %fd11, %fd47;
	mov.f64 	%fd49, 0dBFBA4E3A80F64E33;
	fma.rn.f64 	%fd50, %fd48, %fd11, %fd49;
	mov.f64 	%fd51, 0dBFE45F3E88093928;
	fma.rn.f64 	%fd52, %fd50, %fd11, %fd51;
	mov.f64 	%fd53, 0dBFF20DD599CAEEA0;
	fma.rn.f64 	%fd54, %fd52, %fd11, %fd53;
	mov.f64 	%fd55, 0dBE883BE1E31CE133;
	fma.rn.f64 	%fd56, %fd54, %fd11, %fd55;
	mov.f64 	%fd57, 0d4338000000000000;
	mov.f64 	%fd58, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd59, %fd56, %fd58, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd59;
	}
	mov.f64 	%fd60, 0dC338000000000000;
	add.rn.f64 	%fd61, %fd59, %fd60;
	mov.f64 	%fd62, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd63, %fd61, %fd62, %fd56;
	mov.f64 	%fd64, 0d3E928AF3FCA213EA;
	mov.f64 	%fd65, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd66, %fd65, %fd63, %fd64;
	mov.f64 	%fd67, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd68, %fd66, %fd63, %fd67;
	mov.f64 	%fd69, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd70, %fd68, %fd63, %fd69;
	mov.f64 	%fd71, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd72, %fd70, %fd63, %fd71;
	mov.f64 	%fd73, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd74, %fd72, %fd63, %fd73;
	mov.f64 	%fd75, 0d3F81111111122322;
	fma.rn.f64 	%fd76, %fd74, %fd63, %fd75;
	mov.f64 	%fd77, 0d3FA55555555502A1;
	fma.rn.f64 	%fd78, %fd76, %fd63, %fd77;
	mov.f64 	%fd79, 0d3FC5555555555511;
	fma.rn.f64 	%fd80, %fd78, %fd63, %fd79;
	mov.f64 	%fd81, 0d3FE000000000000B;
	fma.rn.f64 	%fd82, %fd80, %fd63, %fd81;
	mov.f64 	%fd83, 0d3FF0000000000000;
	fma.rn.f64 	%fd84, %fd82, %fd63, %fd83;
	fma.rn.f64 	%fd85, %fd84, %fd63, %fd83;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd85;
	}
	shl.b32 	%r10, %r8, 20;
	add.s32 	%r11, %r9, %r10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd85;
	}
	mov.b64 	%fd86, {%r12, %r11};
	sub.f64 	%fd87, %fd83, %fd86;
	setp.gt.u32	%p6, %r2, 1075294207;
	selp.f64	%fd88, 0d3FF0000000000000, %fd87, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd88;
	}
	and.b32  	%r15, %r1, -2147483648;
	or.b32  	%r16, %r14, %r15;
	mov.b64 	%fd115, {%r13, %r16};
	bra.uni 	BB40_7;

BB40_2:
	setp.eq.s32	%p3, %r2, 2146435072;
	setp.eq.s32	%p4, %r3, 0;
	and.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB40_4;
	bra.uni 	BB40_3;

BB40_4:
	mov.f64 	%fd10, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd10;
	}
	and.b32  	%r5, %r1, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd10;
	}
	or.b32  	%r7, %r6, %r5;
	mov.b64 	%fd115, {%r4, %r7};
	bra.uni 	BB40_7;

BB40_3:
	add.f64 	%fd115, %fd1, %fd1;

BB40_7:
	add.f64 	%fd113, %fd115, 0d3FF0000000000000;
	mul.f64 	%fd114, %fd113, 0d3FE0000000000000;
	st.param.f64	[func_retval0+0], %fd114;
	ret;
}

	// .globl	_Z5Erf_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z5Erf_tddPdiPii(
	.param .b64 _Z5Erf_tddPdiPii_param_0,
	.param .b64 _Z5Erf_tddPdiPii_param_1,
	.param .b64 _Z5Erf_tddPdiPii_param_2,
	.param .b32 _Z5Erf_tddPdiPii_param_3,
	.param .b64 _Z5Erf_tddPdiPii_param_4,
	.param .b32 _Z5Erf_tddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd20, [_Z5Erf_tddPdiPii_param_0];
	ld.param.f64 	%fd21, [_Z5Erf_tddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z5Erf_tddPdiPii_param_2];
	mul.f64 	%fd1, %fd20, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd22, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd22;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 88
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd65, [retval0+0];
	
	//{
	}// Callseq End 88
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB41_2;
	bra.uni 	BB41_1;

BB41_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd65;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd65;
	}
	mov.b64 	%fd65, {%r10, %r9};

BB41_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB41_5;
	bra.uni 	BB41_3;

BB41_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd65, {%r14, %r13};
	bra.uni 	BB41_6;

BB41_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB41_6;

	cvt.rzi.f64.f64	%fd24, %fd22;
	setp.neu.f64	%p6, %fd24, 0d4000000000000000;
	selp.f64	%fd65, 0dFFF8000000000000, %fd65, %p6;

BB41_6:
	add.f64 	%fd66, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd66;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB41_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB41_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB41_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd22;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB41_15;

BB41_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB41_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd66, %fd65;
	@%p14 bra 	BB41_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd66, {%r26, %r25};
	bra.uni 	BB41_16;

BB41_7:
	mov.f64 	%fd66, %fd65;
	bra.uni 	BB41_16;

BB41_12:
	mov.f64 	%fd66, %fd65;
	bra.uni 	BB41_16;

BB41_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd66, {%r31, %r30};

BB41_16:
	mul.f64 	%fd27, %fd66, 0dBFE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0dBFE0000000000000, %fd27, %p18;
	ld.f64 	%fd28, [%rd2];
	mov.f64 	%fd68, 0d0000000000000000;
	setp.geu.f64	%p19, %fd28, %fd13;
	@%p19 bra 	BB41_21;

	mov.f64 	%fd29, 0d4338000000000000;
	mov.f64 	%fd30, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd31, %fd13, %fd30, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd31;
	}
	mov.f64 	%fd32, 0dC338000000000000;
	add.rn.f64 	%fd33, %fd31, %fd32;
	mov.f64 	%fd34, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd35, %fd33, %fd34, %fd13;
	mov.f64 	%fd36, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd37, %fd33, %fd36, %fd35;
	mov.f64 	%fd38, 0d3E928AF3FCA213EA;
	mov.f64 	%fd39, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd40, %fd39, %fd37, %fd38;
	mov.f64 	%fd41, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd42, %fd40, %fd37, %fd41;
	mov.f64 	%fd43, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd44, %fd42, %fd37, %fd43;
	mov.f64 	%fd45, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd46, %fd44, %fd37, %fd45;
	mov.f64 	%fd47, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd48, %fd46, %fd37, %fd47;
	mov.f64 	%fd49, 0d3F81111111122322;
	fma.rn.f64 	%fd50, %fd48, %fd37, %fd49;
	mov.f64 	%fd51, 0d3FA55555555502A1;
	fma.rn.f64 	%fd52, %fd50, %fd37, %fd51;
	mov.f64 	%fd53, 0d3FC5555555555511;
	fma.rn.f64 	%fd54, %fd52, %fd37, %fd53;
	mov.f64 	%fd55, 0d3FE000000000000B;
	fma.rn.f64 	%fd56, %fd54, %fd37, %fd55;
	mov.f64 	%fd57, 0d3FF0000000000000;
	fma.rn.f64 	%fd58, %fd56, %fd37, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd37, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd59;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd67, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd13;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB41_20;

	setp.lt.f64	%p21, %fd13, 0d0000000000000000;
	add.f64 	%fd60, %fd13, 0d7FF0000000000000;
	selp.f64	%fd67, 0d0000000000000000, %fd60, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB41_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd61, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd62, {%r43, %r42};
	mul.f64 	%fd67, %fd61, %fd62;

BB41_20:
	div.rn.f64 	%fd63, %fd20, 0d40040D931FF62705;
	mul.f64 	%fd68, %fd63, %fd67;

BB41_21:
	st.param.f64	[func_retval0+0], %fd68;
	ret;
}

	// .globl	_Z6Erf_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z6Erf_omddPdiPii(
	.param .b64 _Z6Erf_omddPdiPii_param_0,
	.param .b64 _Z6Erf_omddPdiPii_param_1,
	.param .b64 _Z6Erf_omddPdiPii_param_2,
	.param .b32 _Z6Erf_omddPdiPii_param_3,
	.param .b64 _Z6Erf_omddPdiPii_param_4,
	.param .b32 _Z6Erf_omddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd21, [_Z6Erf_omddPdiPii_param_0];
	ld.param.f64 	%fd20, [_Z6Erf_omddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z6Erf_omddPdiPii_param_2];
	mul.f64 	%fd1, %fd21, %fd20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd22, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd22;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 89
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd65, [retval0+0];
	
	//{
	}// Callseq End 89
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB42_2;
	bra.uni 	BB42_1;

BB42_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd65;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd65;
	}
	mov.b64 	%fd65, {%r10, %r9};

BB42_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB42_5;
	bra.uni 	BB42_3;

BB42_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd65, {%r14, %r13};
	bra.uni 	BB42_6;

BB42_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB42_6;

	cvt.rzi.f64.f64	%fd24, %fd22;
	setp.neu.f64	%p6, %fd24, 0d4000000000000000;
	selp.f64	%fd65, 0dFFF8000000000000, %fd65, %p6;

BB42_6:
	add.f64 	%fd66, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd66;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB42_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB42_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB42_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd22;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB42_15;

BB42_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB42_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd66, %fd65;
	@%p14 bra 	BB42_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd66, {%r26, %r25};
	bra.uni 	BB42_16;

BB42_7:
	mov.f64 	%fd66, %fd65;
	bra.uni 	BB42_16;

BB42_12:
	mov.f64 	%fd66, %fd65;
	bra.uni 	BB42_16;

BB42_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd66, {%r31, %r30};

BB42_16:
	mul.f64 	%fd27, %fd66, 0dBFE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0dBFE0000000000000, %fd27, %p18;
	ld.f64 	%fd28, [%rd2];
	mov.f64 	%fd68, 0d0000000000000000;
	setp.geu.f64	%p19, %fd28, %fd13;
	@%p19 bra 	BB42_21;

	mov.f64 	%fd29, 0d4338000000000000;
	mov.f64 	%fd30, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd31, %fd13, %fd30, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd31;
	}
	mov.f64 	%fd32, 0dC338000000000000;
	add.rn.f64 	%fd33, %fd31, %fd32;
	mov.f64 	%fd34, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd35, %fd33, %fd34, %fd13;
	mov.f64 	%fd36, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd37, %fd33, %fd36, %fd35;
	mov.f64 	%fd38, 0d3E928AF3FCA213EA;
	mov.f64 	%fd39, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd40, %fd39, %fd37, %fd38;
	mov.f64 	%fd41, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd42, %fd40, %fd37, %fd41;
	mov.f64 	%fd43, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd44, %fd42, %fd37, %fd43;
	mov.f64 	%fd45, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd46, %fd44, %fd37, %fd45;
	mov.f64 	%fd47, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd48, %fd46, %fd37, %fd47;
	mov.f64 	%fd49, 0d3F81111111122322;
	fma.rn.f64 	%fd50, %fd48, %fd37, %fd49;
	mov.f64 	%fd51, 0d3FA55555555502A1;
	fma.rn.f64 	%fd52, %fd50, %fd37, %fd51;
	mov.f64 	%fd53, 0d3FC5555555555511;
	fma.rn.f64 	%fd54, %fd52, %fd37, %fd53;
	mov.f64 	%fd55, 0d3FE000000000000B;
	fma.rn.f64 	%fd56, %fd54, %fd37, %fd55;
	mov.f64 	%fd57, 0d3FF0000000000000;
	fma.rn.f64 	%fd58, %fd56, %fd37, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd37, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd59;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd67, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd13;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB42_20;

	setp.lt.f64	%p21, %fd13, 0d0000000000000000;
	add.f64 	%fd60, %fd13, 0d7FF0000000000000;
	selp.f64	%fd67, 0d0000000000000000, %fd60, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB42_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd61, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd62, {%r43, %r42};
	mul.f64 	%fd67, %fd61, %fd62;

BB42_20:
	div.rn.f64 	%fd63, %fd20, 0d40040D931FF62705;
	mul.f64 	%fd68, %fd63, %fd67;

BB42_21:
	st.param.f64	[func_retval0+0], %fd68;
	ret;
}

	// .globl	_Z6Erf_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z6Erf_ttddPdiPii(
	.param .b64 _Z6Erf_ttddPdiPii_param_0,
	.param .b64 _Z6Erf_ttddPdiPii_param_1,
	.param .b64 _Z6Erf_ttddPdiPii_param_2,
	.param .b32 _Z6Erf_ttddPdiPii_param_3,
	.param .b64 _Z6Erf_ttddPdiPii_param_4,
	.param .b32 _Z6Erf_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<72>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd20, [_Z6Erf_ttddPdiPii_param_0];
	ld.param.f64 	%fd21, [_Z6Erf_ttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z6Erf_ttddPdiPii_param_2];
	mul.f64 	%fd1, %fd20, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd22, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd22;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 90
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd68, [retval0+0];
	
	//{
	}// Callseq End 90
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB43_2;
	bra.uni 	BB43_1;

BB43_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd68;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd68;
	}
	mov.b64 	%fd68, {%r10, %r9};

BB43_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB43_5;
	bra.uni 	BB43_3;

BB43_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd68, {%r14, %r13};
	bra.uni 	BB43_6;

BB43_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB43_6;

	cvt.rzi.f64.f64	%fd24, %fd22;
	setp.neu.f64	%p6, %fd24, 0d4000000000000000;
	selp.f64	%fd68, 0dFFF8000000000000, %fd68, %p6;

BB43_6:
	add.f64 	%fd69, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd69;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB43_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB43_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB43_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd22;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB43_15;

BB43_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB43_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd69, %fd68;
	@%p14 bra 	BB43_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd69, {%r26, %r25};
	bra.uni 	BB43_16;

BB43_7:
	mov.f64 	%fd69, %fd68;
	bra.uni 	BB43_16;

BB43_12:
	mov.f64 	%fd69, %fd68;
	bra.uni 	BB43_16;

BB43_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd69, {%r31, %r30};

BB43_16:
	mul.f64 	%fd27, %fd69, 0dBFE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0dBFE0000000000000, %fd27, %p18;
	ld.f64 	%fd28, [%rd2];
	mov.f64 	%fd71, 0d0000000000000000;
	setp.geu.f64	%p19, %fd28, %fd13;
	@%p19 bra 	BB43_21;

	mov.f64 	%fd29, 0d4338000000000000;
	mov.f64 	%fd30, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd31, %fd13, %fd30, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd31;
	}
	mov.f64 	%fd32, 0dC338000000000000;
	add.rn.f64 	%fd33, %fd31, %fd32;
	mov.f64 	%fd34, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd35, %fd33, %fd34, %fd13;
	mov.f64 	%fd36, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd37, %fd33, %fd36, %fd35;
	mov.f64 	%fd38, 0d3E928AF3FCA213EA;
	mov.f64 	%fd39, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd40, %fd39, %fd37, %fd38;
	mov.f64 	%fd41, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd42, %fd40, %fd37, %fd41;
	mov.f64 	%fd43, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd44, %fd42, %fd37, %fd43;
	mov.f64 	%fd45, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd46, %fd44, %fd37, %fd45;
	mov.f64 	%fd47, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd48, %fd46, %fd37, %fd47;
	mov.f64 	%fd49, 0d3F81111111122322;
	fma.rn.f64 	%fd50, %fd48, %fd37, %fd49;
	mov.f64 	%fd51, 0d3FA55555555502A1;
	fma.rn.f64 	%fd52, %fd50, %fd37, %fd51;
	mov.f64 	%fd53, 0d3FC5555555555511;
	fma.rn.f64 	%fd54, %fd52, %fd37, %fd53;
	mov.f64 	%fd55, 0d3FE000000000000B;
	fma.rn.f64 	%fd56, %fd54, %fd37, %fd55;
	mov.f64 	%fd57, 0d3FF0000000000000;
	fma.rn.f64 	%fd58, %fd56, %fd37, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd37, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd59;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd70, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd13;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB43_20;

	setp.lt.f64	%p21, %fd13, 0d0000000000000000;
	add.f64 	%fd60, %fd13, 0d7FF0000000000000;
	selp.f64	%fd70, 0d0000000000000000, %fd60, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB43_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd61, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd62, {%r43, %r42};
	mul.f64 	%fd70, %fd61, %fd62;

BB43_20:
	div.rn.f64 	%fd63, %fd20, 0dC0040D931FF62705;
	mul.f64 	%fd64, %fd63, %fd20;
	mul.f64 	%fd65, %fd64, %fd20;
	mul.f64 	%fd66, %fd65, %fd21;
	mul.f64 	%fd71, %fd66, %fd70;

BB43_21:
	st.param.f64	[func_retval0+0], %fd71;
	ret;
}

	// .globl	_Z7Erf_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z7Erf_tttddPdiPii(
	.param .b64 _Z7Erf_tttddPdiPii_param_0,
	.param .b64 _Z7Erf_tttddPdiPii_param_1,
	.param .b64 _Z7Erf_tttddPdiPii_param_2,
	.param .b32 _Z7Erf_tttddPdiPii_param_3,
	.param .b64 _Z7Erf_tttddPdiPii_param_4,
	.param .b32 _Z7Erf_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z7Erf_tttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z7Erf_tttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z7Erf_tttddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 91
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd71, [retval0+0];
	
	//{
	}// Callseq End 91
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB44_2;
	bra.uni 	BB44_1;

BB44_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd71;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd71;
	}
	mov.b64 	%fd71, {%r10, %r9};

BB44_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB44_5;
	bra.uni 	BB44_3;

BB44_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd71, {%r14, %r13};
	bra.uni 	BB44_6;

BB44_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB44_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd71, 0dFFF8000000000000, %fd71, %p6;

BB44_6:
	add.f64 	%fd72, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd72;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB44_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB44_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB44_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB44_15;

BB44_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB44_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd72, %fd71;
	@%p14 bra 	BB44_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd72, {%r26, %r25};
	bra.uni 	BB44_16;

BB44_7:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB44_16;

BB44_12:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB44_16;

BB44_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd72, {%r31, %r30};

BB44_16:
	mul.f64 	%fd29, %fd72, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd74, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB44_21;

	fma.rn.f64 	%fd15, %fd13, 0d4000000000000000, 0dBFF0000000000000;
	mov.f64 	%fd31, 0d4338000000000000;
	mov.f64 	%fd32, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd33, %fd14, %fd32, %fd31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd33;
	}
	mov.f64 	%fd34, 0dC338000000000000;
	add.rn.f64 	%fd35, %fd33, %fd34;
	mov.f64 	%fd36, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd37, %fd35, %fd36, %fd14;
	mov.f64 	%fd38, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd39, %fd35, %fd38, %fd37;
	mov.f64 	%fd40, 0d3E928AF3FCA213EA;
	mov.f64 	%fd41, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F81111111122322;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FA55555555502A1;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	mov.f64 	%fd55, 0d3FC5555555555511;
	fma.rn.f64 	%fd56, %fd54, %fd39, %fd55;
	mov.f64 	%fd57, 0d3FE000000000000B;
	fma.rn.f64 	%fd58, %fd56, %fd39, %fd57;
	mov.f64 	%fd59, 0d3FF0000000000000;
	fma.rn.f64 	%fd60, %fd58, %fd39, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd61;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd61;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd73, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB44_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd62, 0d7FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd13;
	selp.f64	%fd73, 0d0000000000000000, %fd63, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB44_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd64, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd65, {%r43, %r42};
	mul.f64 	%fd73, %fd64, %fd65;

BB44_20:
	div.rn.f64 	%fd66, %fd22, 0d40040D931FF62705;
	mul.f64 	%fd67, %fd66, %fd22;
	mul.f64 	%fd68, %fd67, %fd22;
	mul.f64 	%fd69, %fd15, %fd68;
	mul.f64 	%fd74, %fd69, %fd73;

BB44_21:
	st.param.f64	[func_retval0+0], %fd74;
	ret;
}

	// .globl	_Z8Erf_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8Erf_omttddPdiPii(
	.param .b64 _Z8Erf_omttddPdiPii_param_0,
	.param .b64 _Z8Erf_omttddPdiPii_param_1,
	.param .b64 _Z8Erf_omttddPdiPii_param_2,
	.param .b32 _Z8Erf_omttddPdiPii_param_3,
	.param .b64 _Z8Erf_omttddPdiPii_param_4,
	.param .b32 _Z8Erf_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<75>;
	.reg .b64 	%rd<4>;


	ld.param.f64 	%fd22, [_Z8Erf_omttddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z8Erf_omttddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z8Erf_omttddPdiPii_param_2];
	mul.f64 	%fd1, %fd22, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p2, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 92
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd71, [retval0+0];
	
	//{
	}// Callseq End 92
	setp.lt.s32	%p3, %r1, 0;
	and.pred  	%p1, %p3, %p2;
	@!%p1 bra 	BB45_2;
	bra.uni 	BB45_1;

BB45_1:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd71;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd71;
	}
	mov.b64 	%fd71, {%r10, %r9};

BB45_2:
	setp.eq.f64	%p4, %fd1, 0d0000000000000000;
	@%p4 bra 	BB45_5;
	bra.uni 	BB45_3;

BB45_5:
	selp.b32	%r11, %r1, 0, %p2;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p8, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p8;
	mov.u32 	%r14, 0;
	mov.b64 	%fd71, {%r14, %r13};
	bra.uni 	BB45_6;

BB45_3:
	setp.gt.s32	%p5, %r1, -1;
	@%p5 bra 	BB45_6;

	cvt.rzi.f64.f64	%fd26, %fd24;
	setp.neu.f64	%p6, %fd26, 0d4000000000000000;
	selp.f64	%fd71, 0dFFF8000000000000, %fd71, %p6;

BB45_6:
	add.f64 	%fd72, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd72;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p9, %r16, 2146435072;
	@%p9 bra 	BB45_7;

	setp.gtu.f64	%p10, %fd2, 0d7FF0000000000000;
	@%p10 bra 	BB45_16;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p11, %r17, 2146435072;
	@%p11 bra 	BB45_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd24;
	}
	setp.eq.s32	%p12, %r18, 0;
	@%p12 bra 	BB45_15;

BB45_11:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p13, %r19, 2146435072;
	@%p13 bra 	BB45_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p14, %r20, 0;
	mov.f64 	%fd72, %fd71;
	@%p14 bra 	BB45_16;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd72, {%r26, %r25};
	bra.uni 	BB45_16;

BB45_7:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB45_16;

BB45_12:
	mov.f64 	%fd72, %fd71;
	bra.uni 	BB45_16;

BB45_15:
	setp.gt.f64	%p15, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p15;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p16, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p16;
	setp.eq.f64	%p17, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p17;
	mov.u32 	%r31, 0;
	mov.b64 	%fd72, {%r31, %r30};

BB45_16:
	mul.f64 	%fd29, %fd72, 0d3FE0000000000000;
	setp.eq.f64	%p18, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FE0000000000000, %fd29, %p18;
	neg.f64 	%fd14, %fd13;
	ld.f64 	%fd30, [%rd2];
	mov.f64 	%fd74, 0d0000000000000000;
	setp.geu.f64	%p19, %fd30, %fd14;
	@%p19 bra 	BB45_21;

	fma.rn.f64 	%fd15, %fd13, 0d4000000000000000, 0dC008000000000000;
	mov.f64 	%fd31, 0d4338000000000000;
	mov.f64 	%fd32, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd33, %fd14, %fd32, %fd31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd33;
	}
	mov.f64 	%fd34, 0dC338000000000000;
	add.rn.f64 	%fd35, %fd33, %fd34;
	mov.f64 	%fd36, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd37, %fd35, %fd36, %fd14;
	mov.f64 	%fd38, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd39, %fd35, %fd38, %fd37;
	mov.f64 	%fd40, 0d3E928AF3FCA213EA;
	mov.f64 	%fd41, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F81111111122322;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FA55555555502A1;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	mov.f64 	%fd55, 0d3FC5555555555511;
	fma.rn.f64 	%fd56, %fd54, %fd39, %fd55;
	mov.f64 	%fd57, 0d3FE000000000000B;
	fma.rn.f64 	%fd58, %fd56, %fd39, %fd57;
	mov.f64 	%fd59, 0d3FF0000000000000;
	fma.rn.f64 	%fd60, %fd58, %fd39, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd61;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd61;
	}
	shl.b32 	%r32, %r3, 20;
	add.s32 	%r33, %r5, %r32;
	mov.b64 	%fd73, {%r4, %r33};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd14;
	}
	mov.b32 	 %f2, %r34;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p20, %f1, 0f4086232B;
	@%p20 bra 	BB45_20;

	setp.gt.f64	%p21, %fd13, 0d8000000000000000;
	mov.f64 	%fd62, 0d7FF0000000000000;
	sub.f64 	%fd63, %fd62, %fd13;
	selp.f64	%fd73, 0d0000000000000000, %fd63, %p21;
	setp.geu.f32	%p22, %f1, 0f40874800;
	@%p22 bra 	BB45_20;

	shr.u32 	%r35, %r3, 31;
	add.s32 	%r36, %r3, %r35;
	shr.s32 	%r37, %r36, 1;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, %r5;
	mov.b64 	%fd64, {%r4, %r39};
	sub.s32 	%r40, %r3, %r37;
	shl.b32 	%r41, %r40, 20;
	add.s32 	%r42, %r41, 1072693248;
	mov.u32 	%r43, 0;
	mov.b64 	%fd65, {%r43, %r42};
	mul.f64 	%fd73, %fd64, %fd65;

BB45_20:
	div.rn.f64 	%fd66, %fd23, 0d40040D931FF62705;
	mul.f64 	%fd67, %fd66, %fd22;
	mul.f64 	%fd68, %fd67, %fd22;
	mul.f64 	%fd69, %fd15, %fd68;
	mul.f64 	%fd74, %fd69, %fd73;

BB45_21:
	st.param.f64	[func_retval0+0], %fd74;
	ret;
}

	// .globl	_Z4RampddPdiPii
.visible .func  (.param .b64 func_retval0) _Z4RampddPdiPii(
	.param .b64 _Z4RampddPdiPii_param_0,
	.param .b64 _Z4RampddPdiPii_param_1,
	.param .b64 _Z4RampddPdiPii_param_2,
	.param .b32 _Z4RampddPdiPii_param_3,
	.param .b64 _Z4RampddPdiPii_param_4,
	.param .b32 _Z4RampddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot46[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<8>;
	.reg .b32 	%r<15>;
	.reg .f64 	%fd<53>;
	.reg .b64 	%rd<7>;


	mov.u64 	%SPL, __local_depot46;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd17, [_Z4RampddPdiPii_param_0];
	ld.param.f64 	%fd18, [_Z4RampddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd1, %fd17, %fd18;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd52, 0d0000000000000000;
	@%p1 bra 	BB46_12;

	setp.gt.f64	%p2, %fd1, 0d3FF0000000000000;
	mov.f64 	%fd52, 0d3FF0000000000000;
	@%p2 bra 	BB46_12;

	mul.f64 	%fd21, %fd18, 0d400921FB54442D18;
	mul.f64 	%fd48, %fd21, %fd17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd48;
	}
	and.b32  	%r6, %r5, 2147483647;
	setp.ne.s32	%p3, %r6, 2146435072;
	@%p3 bra 	BB46_5;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd48;
	}
	setp.ne.s32	%p4, %r7, 0;
	@%p4 bra 	BB46_5;

	mov.f64 	%fd22, 0d0000000000000000;
	mul.rn.f64 	%fd48, %fd48, %fd22;

BB46_5:
	mul.f64 	%fd23, %fd48, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r14, %fd23;
	st.local.u32 	[%rd1], %r14;
	cvt.rn.f64.s32	%fd24, %r14;
	neg.f64 	%fd25, %fd24;
	mov.f64 	%fd26, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd27, %fd25, %fd26, %fd48;
	mov.f64 	%fd28, 0d3C91A62633145C00;
	fma.rn.f64 	%fd29, %fd25, %fd28, %fd27;
	mov.f64 	%fd30, 0d397B839A252049C0;
	fma.rn.f64 	%fd49, %fd25, %fd30, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd48;
	}
	and.b32  	%r9, %r8, 2145386496;
	setp.lt.u32	%p5, %r9, 1105199104;
	@%p5 bra 	BB46_7;

	// Callseq Start 93
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd48;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd49, [retval0+0];
	
	//{
	}// Callseq End 93
	ld.local.u32 	%r14, [%rd1];

BB46_7:
	add.s32 	%r4, %r14, 1;
	and.b32  	%r10, %r4, 1;
	shl.b32 	%r11, %r10, 3;
	setp.eq.s32	%p6, %r10, 0;
	selp.f64	%fd31, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p6;
	add.s32 	%r12, %r11, 1;
	mul.wide.s32 	%rd4, %r12, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd32, [%rd6];
	mul.rn.f64 	%fd8, %fd49, %fd49;
	fma.rn.f64 	%fd33, %fd31, %fd8, %fd32;
	ld.const.f64 	%fd34, [%rd6+8];
	fma.rn.f64 	%fd35, %fd33, %fd8, %fd34;
	ld.const.f64 	%fd36, [%rd6+16];
	fma.rn.f64 	%fd37, %fd35, %fd8, %fd36;
	ld.const.f64 	%fd38, [%rd6+24];
	fma.rn.f64 	%fd39, %fd37, %fd8, %fd38;
	ld.const.f64 	%fd40, [%rd6+32];
	fma.rn.f64 	%fd41, %fd39, %fd8, %fd40;
	ld.const.f64 	%fd42, [%rd6+40];
	fma.rn.f64 	%fd9, %fd41, %fd8, %fd42;
	fma.rn.f64 	%fd50, %fd9, %fd49, %fd49;
	@%p6 bra 	BB46_9;

	mov.f64 	%fd43, 0d3FF0000000000000;
	fma.rn.f64 	%fd50, %fd9, %fd8, %fd43;

BB46_9:
	and.b32  	%r13, %r4, 2;
	setp.eq.s32	%p7, %r13, 0;
	@%p7 bra 	BB46_11;

	mov.f64 	%fd44, 0d0000000000000000;
	mov.f64 	%fd45, 0dBFF0000000000000;
	fma.rn.f64 	%fd50, %fd50, %fd45, %fd44;

BB46_11:
	mov.f64 	%fd46, 0d3FF0000000000000;
	sub.f64 	%fd47, %fd46, %fd50;
	mul.f64 	%fd52, %fd47, 0d3FE0000000000000;

BB46_12:
	st.param.f64	[func_retval0+0], %fd52;
	ret;
}

	// .globl	_Z6Ramp_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z6Ramp_tddPdiPii(
	.param .b64 _Z6Ramp_tddPdiPii_param_0,
	.param .b64 _Z6Ramp_tddPdiPii_param_1,
	.param .b64 _Z6Ramp_tddPdiPii_param_2,
	.param .b32 _Z6Ramp_tddPdiPii_param_3,
	.param .b64 _Z6Ramp_tddPdiPii_param_4,
	.param .b32 _Z6Ramp_tddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot47[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f64 	%fd<51>;
	.reg .b64 	%rd<7>;


	mov.u64 	%SPL, __local_depot47;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd16, [_Z6Ramp_tddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z6Ramp_tddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd19, %fd16, %fd17;
	setp.lt.f64	%p1, %fd19, 0d0000000000000000;
	setp.gt.f64	%p2, %fd19, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd50, 0d0000000000000000;
	@%p3 bra 	BB47_11;

	mul.f64 	%fd20, %fd17, 0d400921FB54442D18;
	mul.f64 	%fd46, %fd20, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd46;
	}
	and.b32  	%r5, %r4, 2147483647;
	setp.ne.s32	%p4, %r5, 2146435072;
	@%p4 bra 	BB47_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r6, %temp}, %fd46;
	}
	setp.ne.s32	%p5, %r6, 0;
	@%p5 bra 	BB47_4;

	mov.f64 	%fd21, 0d0000000000000000;
	mul.rn.f64 	%fd46, %fd46, %fd21;

BB47_4:
	mul.f64 	%fd22, %fd46, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r13, %fd22;
	st.local.u32 	[%rd1], %r13;
	cvt.rn.f64.s32	%fd23, %r13;
	neg.f64 	%fd24, %fd23;
	mov.f64 	%fd25, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd26, %fd24, %fd25, %fd46;
	mov.f64 	%fd27, 0d3C91A62633145C00;
	fma.rn.f64 	%fd28, %fd24, %fd27, %fd26;
	mov.f64 	%fd29, 0d397B839A252049C0;
	fma.rn.f64 	%fd47, %fd24, %fd29, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd46;
	}
	and.b32  	%r8, %r7, 2145386496;
	setp.lt.u32	%p6, %r8, 1105199104;
	@%p6 bra 	BB47_6;

	// Callseq Start 94
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd46;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd47, [retval0+0];
	
	//{
	}// Callseq End 94
	ld.local.u32 	%r13, [%rd1];

BB47_6:
	and.b32  	%r9, %r13, 1;
	shl.b32 	%r10, %r9, 3;
	setp.eq.s32	%p7, %r9, 0;
	selp.f64	%fd30, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r11, %r10, 1;
	mul.wide.s32 	%rd4, %r11, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd31, [%rd6];
	mul.rn.f64 	%fd7, %fd47, %fd47;
	fma.rn.f64 	%fd32, %fd30, %fd7, %fd31;
	ld.const.f64 	%fd33, [%rd6+8];
	fma.rn.f64 	%fd34, %fd32, %fd7, %fd33;
	ld.const.f64 	%fd35, [%rd6+16];
	fma.rn.f64 	%fd36, %fd34, %fd7, %fd35;
	ld.const.f64 	%fd37, [%rd6+24];
	fma.rn.f64 	%fd38, %fd36, %fd7, %fd37;
	ld.const.f64 	%fd39, [%rd6+32];
	fma.rn.f64 	%fd40, %fd38, %fd7, %fd39;
	ld.const.f64 	%fd41, [%rd6+40];
	fma.rn.f64 	%fd8, %fd40, %fd7, %fd41;
	fma.rn.f64 	%fd48, %fd8, %fd47, %fd47;
	@%p7 bra 	BB47_8;

	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd48, %fd8, %fd7, %fd42;

BB47_8:
	and.b32  	%r12, %r13, 2;
	setp.eq.s32	%p8, %r12, 0;
	@%p8 bra 	BB47_10;

	mov.f64 	%fd43, 0d0000000000000000;
	mov.f64 	%fd44, 0dBFF0000000000000;
	fma.rn.f64 	%fd48, %fd48, %fd44, %fd43;

BB47_10:
	mul.f64 	%fd45, %fd16, 0d3FF921FB54442D18;
	mul.f64 	%fd50, %fd45, %fd48;

BB47_11:
	st.param.f64	[func_retval0+0], %fd50;
	ret;
}

	// .globl	_Z7Ramp_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z7Ramp_omddPdiPii(
	.param .b64 _Z7Ramp_omddPdiPii_param_0,
	.param .b64 _Z7Ramp_omddPdiPii_param_1,
	.param .b64 _Z7Ramp_omddPdiPii_param_2,
	.param .b32 _Z7Ramp_omddPdiPii_param_3,
	.param .b64 _Z7Ramp_omddPdiPii_param_4,
	.param .b32 _Z7Ramp_omddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot48[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f64 	%fd<51>;
	.reg .b64 	%rd<7>;


	mov.u64 	%SPL, __local_depot48;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd16, [_Z7Ramp_omddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z7Ramp_omddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd19, %fd16, %fd17;
	setp.lt.f64	%p1, %fd19, 0d0000000000000000;
	setp.gt.f64	%p2, %fd19, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd50, 0d0000000000000000;
	@%p3 bra 	BB48_11;

	mul.f64 	%fd20, %fd17, 0d400921FB54442D18;
	mul.f64 	%fd46, %fd20, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd46;
	}
	and.b32  	%r5, %r4, 2147483647;
	setp.ne.s32	%p4, %r5, 2146435072;
	@%p4 bra 	BB48_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r6, %temp}, %fd46;
	}
	setp.ne.s32	%p5, %r6, 0;
	@%p5 bra 	BB48_4;

	mov.f64 	%fd21, 0d0000000000000000;
	mul.rn.f64 	%fd46, %fd46, %fd21;

BB48_4:
	mul.f64 	%fd22, %fd46, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r13, %fd22;
	st.local.u32 	[%rd1], %r13;
	cvt.rn.f64.s32	%fd23, %r13;
	neg.f64 	%fd24, %fd23;
	mov.f64 	%fd25, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd26, %fd24, %fd25, %fd46;
	mov.f64 	%fd27, 0d3C91A62633145C00;
	fma.rn.f64 	%fd28, %fd24, %fd27, %fd26;
	mov.f64 	%fd29, 0d397B839A252049C0;
	fma.rn.f64 	%fd47, %fd24, %fd29, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd46;
	}
	and.b32  	%r8, %r7, 2145386496;
	setp.lt.u32	%p6, %r8, 1105199104;
	@%p6 bra 	BB48_6;

	// Callseq Start 95
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd46;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd47, [retval0+0];
	
	//{
	}// Callseq End 95
	ld.local.u32 	%r13, [%rd1];

BB48_6:
	and.b32  	%r9, %r13, 1;
	shl.b32 	%r10, %r9, 3;
	setp.eq.s32	%p7, %r9, 0;
	selp.f64	%fd30, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r11, %r10, 1;
	mul.wide.s32 	%rd4, %r11, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd31, [%rd6];
	mul.rn.f64 	%fd7, %fd47, %fd47;
	fma.rn.f64 	%fd32, %fd30, %fd7, %fd31;
	ld.const.f64 	%fd33, [%rd6+8];
	fma.rn.f64 	%fd34, %fd32, %fd7, %fd33;
	ld.const.f64 	%fd35, [%rd6+16];
	fma.rn.f64 	%fd36, %fd34, %fd7, %fd35;
	ld.const.f64 	%fd37, [%rd6+24];
	fma.rn.f64 	%fd38, %fd36, %fd7, %fd37;
	ld.const.f64 	%fd39, [%rd6+32];
	fma.rn.f64 	%fd40, %fd38, %fd7, %fd39;
	ld.const.f64 	%fd41, [%rd6+40];
	fma.rn.f64 	%fd8, %fd40, %fd7, %fd41;
	fma.rn.f64 	%fd48, %fd8, %fd47, %fd47;
	@%p7 bra 	BB48_8;

	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd48, %fd8, %fd7, %fd42;

BB48_8:
	and.b32  	%r12, %r13, 2;
	setp.eq.s32	%p8, %r12, 0;
	@%p8 bra 	BB48_10;

	mov.f64 	%fd43, 0d0000000000000000;
	mov.f64 	%fd44, 0dBFF0000000000000;
	fma.rn.f64 	%fd48, %fd48, %fd44, %fd43;

BB48_10:
	mul.f64 	%fd45, %fd17, 0d3FF921FB54442D18;
	mul.f64 	%fd50, %fd45, %fd48;

BB48_11:
	st.param.f64	[func_retval0+0], %fd50;
	ret;
}

	// .globl	_Z7Ramp_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z7Ramp_ttddPdiPii(
	.param .b64 _Z7Ramp_ttddPdiPii_param_0,
	.param .b64 _Z7Ramp_ttddPdiPii_param_1,
	.param .b64 _Z7Ramp_ttddPdiPii_param_2,
	.param .b32 _Z7Ramp_ttddPdiPii_param_3,
	.param .b64 _Z7Ramp_ttddPdiPii_param_4,
	.param .b32 _Z7Ramp_ttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot49[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<15>;
	.reg .f64 	%fd<52>;
	.reg .b64 	%rd<7>;


	mov.u64 	%SPL, __local_depot49;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd16, [_Z7Ramp_ttddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z7Ramp_ttddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd19, %fd16, %fd17;
	setp.lt.f64	%p1, %fd19, 0d0000000000000000;
	setp.gt.f64	%p2, %fd19, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd51, 0d0000000000000000;
	@%p3 bra 	BB49_11;

	mul.f64 	%fd20, %fd17, 0d400921FB54442D18;
	mul.f64 	%fd47, %fd20, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd47;
	}
	and.b32  	%r6, %r5, 2147483647;
	setp.ne.s32	%p4, %r6, 2146435072;
	@%p4 bra 	BB49_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd47;
	}
	setp.ne.s32	%p5, %r7, 0;
	@%p5 bra 	BB49_4;

	mov.f64 	%fd21, 0d0000000000000000;
	mul.rn.f64 	%fd47, %fd47, %fd21;

BB49_4:
	mul.f64 	%fd22, %fd47, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r14, %fd22;
	st.local.u32 	[%rd1], %r14;
	cvt.rn.f64.s32	%fd23, %r14;
	neg.f64 	%fd24, %fd23;
	mov.f64 	%fd25, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd26, %fd24, %fd25, %fd47;
	mov.f64 	%fd27, 0d3C91A62633145C00;
	fma.rn.f64 	%fd28, %fd24, %fd27, %fd26;
	mov.f64 	%fd29, 0d397B839A252049C0;
	fma.rn.f64 	%fd48, %fd24, %fd29, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd47;
	}
	and.b32  	%r9, %r8, 2145386496;
	setp.lt.u32	%p6, %r9, 1105199104;
	@%p6 bra 	BB49_6;

	// Callseq Start 96
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd47;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd48, [retval0+0];
	
	//{
	}// Callseq End 96
	ld.local.u32 	%r14, [%rd1];

BB49_6:
	add.s32 	%r4, %r14, 1;
	and.b32  	%r10, %r4, 1;
	shl.b32 	%r11, %r10, 3;
	setp.eq.s32	%p7, %r10, 0;
	selp.f64	%fd30, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r12, %r11, 1;
	mul.wide.s32 	%rd4, %r12, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd31, [%rd6];
	mul.rn.f64 	%fd7, %fd48, %fd48;
	fma.rn.f64 	%fd32, %fd30, %fd7, %fd31;
	ld.const.f64 	%fd33, [%rd6+8];
	fma.rn.f64 	%fd34, %fd32, %fd7, %fd33;
	ld.const.f64 	%fd35, [%rd6+16];
	fma.rn.f64 	%fd36, %fd34, %fd7, %fd35;
	ld.const.f64 	%fd37, [%rd6+24];
	fma.rn.f64 	%fd38, %fd36, %fd7, %fd37;
	ld.const.f64 	%fd39, [%rd6+32];
	fma.rn.f64 	%fd40, %fd38, %fd7, %fd39;
	ld.const.f64 	%fd41, [%rd6+40];
	fma.rn.f64 	%fd8, %fd40, %fd7, %fd41;
	fma.rn.f64 	%fd49, %fd8, %fd48, %fd48;
	@%p7 bra 	BB49_8;

	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd49, %fd8, %fd7, %fd42;

BB49_8:
	and.b32  	%r13, %r4, 2;
	setp.eq.s32	%p8, %r13, 0;
	@%p8 bra 	BB49_10;

	mov.f64 	%fd43, 0d0000000000000000;
	mov.f64 	%fd44, 0dBFF0000000000000;
	fma.rn.f64 	%fd49, %fd49, %fd44, %fd43;

BB49_10:
	mul.f64 	%fd45, %fd16, 0d4013BD3CC9BE45DE;
	mul.f64 	%fd46, %fd45, %fd16;
	mul.f64 	%fd51, %fd46, %fd49;

BB49_11:
	st.param.f64	[func_retval0+0], %fd51;
	ret;
}

	// .globl	_Z8Ramp_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8Ramp_tttddPdiPii(
	.param .b64 _Z8Ramp_tttddPdiPii_param_0,
	.param .b64 _Z8Ramp_tttddPdiPii_param_1,
	.param .b64 _Z8Ramp_tttddPdiPii_param_2,
	.param .b32 _Z8Ramp_tttddPdiPii_param_3,
	.param .b64 _Z8Ramp_tttddPdiPii_param_4,
	.param .b32 _Z8Ramp_tttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot50[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<14>;
	.reg .f64 	%fd<53>;
	.reg .b64 	%rd<7>;


	mov.u64 	%SPL, __local_depot50;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd16, [_Z8Ramp_tttddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z8Ramp_tttddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd19, %fd16, %fd17;
	setp.lt.f64	%p1, %fd19, 0d0000000000000000;
	setp.gt.f64	%p2, %fd19, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd52, 0d0000000000000000;
	@%p3 bra 	BB50_11;

	mul.f64 	%fd20, %fd17, 0d400921FB54442D18;
	mul.f64 	%fd48, %fd20, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd48;
	}
	and.b32  	%r5, %r4, 2147483647;
	setp.ne.s32	%p4, %r5, 2146435072;
	@%p4 bra 	BB50_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r6, %temp}, %fd48;
	}
	setp.ne.s32	%p5, %r6, 0;
	@%p5 bra 	BB50_4;

	mov.f64 	%fd21, 0d0000000000000000;
	mul.rn.f64 	%fd48, %fd48, %fd21;

BB50_4:
	mul.f64 	%fd22, %fd48, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r13, %fd22;
	st.local.u32 	[%rd1], %r13;
	cvt.rn.f64.s32	%fd23, %r13;
	neg.f64 	%fd24, %fd23;
	mov.f64 	%fd25, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd26, %fd24, %fd25, %fd48;
	mov.f64 	%fd27, 0d3C91A62633145C00;
	fma.rn.f64 	%fd28, %fd24, %fd27, %fd26;
	mov.f64 	%fd29, 0d397B839A252049C0;
	fma.rn.f64 	%fd49, %fd24, %fd29, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd48;
	}
	and.b32  	%r8, %r7, 2145386496;
	setp.lt.u32	%p6, %r8, 1105199104;
	@%p6 bra 	BB50_6;

	// Callseq Start 97
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd48;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd49, [retval0+0];
	
	//{
	}// Callseq End 97
	ld.local.u32 	%r13, [%rd1];

BB50_6:
	and.b32  	%r9, %r13, 1;
	shl.b32 	%r10, %r9, 3;
	setp.eq.s32	%p7, %r9, 0;
	selp.f64	%fd30, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r11, %r10, 1;
	mul.wide.s32 	%rd4, %r11, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd31, [%rd6];
	mul.rn.f64 	%fd7, %fd49, %fd49;
	fma.rn.f64 	%fd32, %fd30, %fd7, %fd31;
	ld.const.f64 	%fd33, [%rd6+8];
	fma.rn.f64 	%fd34, %fd32, %fd7, %fd33;
	ld.const.f64 	%fd35, [%rd6+16];
	fma.rn.f64 	%fd36, %fd34, %fd7, %fd35;
	ld.const.f64 	%fd37, [%rd6+24];
	fma.rn.f64 	%fd38, %fd36, %fd7, %fd37;
	ld.const.f64 	%fd39, [%rd6+32];
	fma.rn.f64 	%fd40, %fd38, %fd7, %fd39;
	ld.const.f64 	%fd41, [%rd6+40];
	fma.rn.f64 	%fd8, %fd40, %fd7, %fd41;
	fma.rn.f64 	%fd50, %fd8, %fd49, %fd49;
	@%p7 bra 	BB50_8;

	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd50, %fd8, %fd7, %fd42;

BB50_8:
	and.b32  	%r12, %r13, 2;
	setp.eq.s32	%p8, %r12, 0;
	@%p8 bra 	BB50_10;

	mov.f64 	%fd43, 0d0000000000000000;
	mov.f64 	%fd44, 0dBFF0000000000000;
	fma.rn.f64 	%fd50, %fd50, %fd44, %fd43;

BB50_10:
	mul.f64 	%fd45, %fd16, 0dC02F019B59389D7B;
	mul.f64 	%fd46, %fd45, %fd16;
	mul.f64 	%fd47, %fd46, %fd16;
	mul.f64 	%fd52, %fd47, %fd50;

BB50_11:
	st.param.f64	[func_retval0+0], %fd52;
	ret;
}

	// .globl	_Z9Ramp_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z9Ramp_omttddPdiPii(
	.param .b64 _Z9Ramp_omttddPdiPii_param_0,
	.param .b64 _Z9Ramp_omttddPdiPii_param_1,
	.param .b64 _Z9Ramp_omttddPdiPii_param_2,
	.param .b32 _Z9Ramp_omttddPdiPii_param_3,
	.param .b64 _Z9Ramp_omttddPdiPii_param_4,
	.param .b32 _Z9Ramp_omttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot51[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<14>;
	.reg .b32 	%r<26>;
	.reg .f64 	%fd<94>;
	.reg .b64 	%rd<14>;


	mov.u64 	%SPL, __local_depot51;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd28, [_Z9Ramp_omttddPdiPii_param_0];
	ld.param.f64 	%fd29, [_Z9Ramp_omttddPdiPii_param_1];
	add.u64 	%rd2, %SP, 4;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd31, %fd28, %fd29;
	setp.lt.f64	%p1, %fd31, 0d0000000000000000;
	setp.gt.f64	%p2, %fd31, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd93, 0d0000000000000000;
	@%p3 bra 	BB51_20;

	mul.f64 	%fd32, %fd29, 0d400921FB54442D18;
	mul.f64 	%fd89, %fd32, %fd28;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd89;
	}
	and.b32  	%r1, %r9, 2147483647;
	setp.ne.s32	%p4, %r1, 2146435072;
	mov.f64 	%fd85, %fd89;
	@%p4 bra 	BB51_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd89;
	}
	setp.ne.s32	%p5, %r10, 0;
	mov.f64 	%fd85, %fd89;
	@%p5 bra 	BB51_4;

	mov.f64 	%fd33, 0d0000000000000000;
	mul.rn.f64 	%fd85, %fd89, %fd33;

BB51_4:
	mul.f64 	%fd34, %fd85, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r24, %fd34;
	st.local.u32 	[%rd1], %r24;
	cvt.rn.f64.s32	%fd35, %r24;
	neg.f64 	%fd36, %fd35;
	mov.f64 	%fd37, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd38, %fd36, %fd37, %fd85;
	mov.f64 	%fd39, 0d3C91A62633145C00;
	fma.rn.f64 	%fd40, %fd36, %fd39, %fd38;
	mov.f64 	%fd41, 0d397B839A252049C0;
	fma.rn.f64 	%fd86, %fd36, %fd41, %fd40;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd85;
	}
	and.b32  	%r12, %r11, 2145386496;
	setp.lt.u32	%p6, %r12, 1105199104;
	@%p6 bra 	BB51_6;

	// Callseq Start 98
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd85;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd86, [retval0+0];
	
	//{
	}// Callseq End 98
	ld.local.u32 	%r24, [%rd1];

BB51_6:
	add.s32 	%r5, %r24, 1;
	and.b32  	%r13, %r5, 1;
	shl.b32 	%r14, %r13, 3;
	setp.eq.s32	%p7, %r13, 0;
	selp.f64	%fd42, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r15, %r14, 1;
	mul.wide.s32 	%rd4, %r15, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd43, [%rd6];
	mul.rn.f64 	%fd7, %fd86, %fd86;
	fma.rn.f64 	%fd44, %fd42, %fd7, %fd43;
	ld.const.f64 	%fd45, [%rd6+8];
	fma.rn.f64 	%fd46, %fd44, %fd7, %fd45;
	ld.const.f64 	%fd47, [%rd6+16];
	fma.rn.f64 	%fd48, %fd46, %fd7, %fd47;
	ld.const.f64 	%fd49, [%rd6+24];
	fma.rn.f64 	%fd50, %fd48, %fd7, %fd49;
	ld.const.f64 	%fd51, [%rd6+32];
	fma.rn.f64 	%fd52, %fd50, %fd7, %fd51;
	ld.const.f64 	%fd53, [%rd6+40];
	fma.rn.f64 	%fd8, %fd52, %fd7, %fd53;
	fma.rn.f64 	%fd87, %fd8, %fd86, %fd86;
	@%p7 bra 	BB51_8;

	mov.f64 	%fd54, 0d3FF0000000000000;
	fma.rn.f64 	%fd87, %fd8, %fd7, %fd54;

BB51_8:
	and.b32  	%r16, %r5, 2;
	setp.eq.s32	%p8, %r16, 0;
	@%p8 bra 	BB51_10;

	mov.f64 	%fd55, 0d0000000000000000;
	mov.f64 	%fd56, 0dBFF0000000000000;
	fma.rn.f64 	%fd87, %fd87, %fd56, %fd55;

BB51_10:
	@%p4 bra 	BB51_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd89;
	}
	setp.ne.s32	%p10, %r17, 0;
	@%p10 bra 	BB51_13;

	mov.f64 	%fd57, 0d0000000000000000;
	mul.rn.f64 	%fd89, %fd89, %fd57;

BB51_13:
	mul.f64 	%fd58, %fd89, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r25, %fd58;
	add.u64 	%rd7, %SP, 0;
	cvta.to.local.u64 	%rd8, %rd7;
	st.local.u32 	[%rd8], %r25;
	cvt.rn.f64.s32	%fd59, %r25;
	neg.f64 	%fd60, %fd59;
	fma.rn.f64 	%fd62, %fd60, %fd37, %fd89;
	fma.rn.f64 	%fd64, %fd60, %fd39, %fd62;
	fma.rn.f64 	%fd90, %fd60, %fd41, %fd64;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r18}, %fd89;
	}
	and.b32  	%r19, %r18, 2145386496;
	setp.lt.u32	%p11, %r19, 1105199104;
	@%p11 bra 	BB51_15;

	// Callseq Start 99
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd89;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd90, [retval0+0];
	
	//{
	}// Callseq End 99
	ld.local.u32 	%r25, [%rd8];

BB51_15:
	and.b32  	%r20, %r25, 1;
	shl.b32 	%r21, %r20, 3;
	setp.eq.s32	%p12, %r20, 0;
	selp.f64	%fd66, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r22, %r21, 1;
	mul.wide.s32 	%rd11, %r22, 8;
	add.s64 	%rd13, %rd5, %rd11;
	ld.const.f64 	%fd67, [%rd13];
	mul.rn.f64 	%fd19, %fd90, %fd90;
	fma.rn.f64 	%fd68, %fd66, %fd19, %fd67;
	ld.const.f64 	%fd69, [%rd13+8];
	fma.rn.f64 	%fd70, %fd68, %fd19, %fd69;
	ld.const.f64 	%fd71, [%rd13+16];
	fma.rn.f64 	%fd72, %fd70, %fd19, %fd71;
	ld.const.f64 	%fd73, [%rd13+24];
	fma.rn.f64 	%fd74, %fd72, %fd19, %fd73;
	ld.const.f64 	%fd75, [%rd13+32];
	fma.rn.f64 	%fd76, %fd74, %fd19, %fd75;
	ld.const.f64 	%fd77, [%rd13+40];
	fma.rn.f64 	%fd20, %fd76, %fd19, %fd77;
	fma.rn.f64 	%fd91, %fd20, %fd90, %fd90;
	@%p12 bra 	BB51_17;

	mov.f64 	%fd78, 0d3FF0000000000000;
	fma.rn.f64 	%fd91, %fd20, %fd19, %fd78;

BB51_17:
	and.b32  	%r23, %r25, 2;
	setp.eq.s32	%p13, %r23, 0;
	@%p13 bra 	BB51_19;

	mov.f64 	%fd79, 0d0000000000000000;
	mov.f64 	%fd80, 0dBFF0000000000000;
	fma.rn.f64 	%fd91, %fd91, %fd80, %fd79;

BB51_19:
	mul.f64 	%fd81, %fd29, 0dBFF921FB54442D18;
	mul.f64 	%fd82, %fd81, %fd28;
	fma.rn.f64 	%fd83, %fd82, %fd91, %fd87;
	mul.f64 	%fd84, %fd28, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd93, %fd84, %fd83;

BB51_20:
	st.param.f64	[func_retval0+0], %fd93;
	ret;
}

	// .globl	_Z8TriangleddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8TriangleddPdiPii(
	.param .b64 _Z8TriangleddPdiPii_param_0,
	.param .b64 _Z8TriangleddPdiPii_param_1,
	.param .b64 _Z8TriangleddPdiPii_param_2,
	.param .b32 _Z8TriangleddPdiPii_param_3,
	.param .b64 _Z8TriangleddPdiPii_param_4,
	.param .b32 _Z8TriangleddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot52[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<181>;
	.reg .b64 	%rd<29>;


	mov.u64 	%SPL, __local_depot52;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd58, [_Z8TriangleddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z8TriangleddPdiPii_param_1];
	mul.f64 	%fd1, %fd58, %fd60;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	setp.gt.f64	%p2, %fd1, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd180, 0d0000000000000000;
	@%p3 bra 	BB52_38;

	mul.f64 	%fd164, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd164;
	}
	and.b32  	%r14, %r13, 2147483647;
	setp.ne.s32	%p4, %r14, 2146435072;
	@%p4 bra 	BB52_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r15, %temp}, %fd164;
	}
	setp.ne.s32	%p5, %r15, 0;
	@%p5 bra 	BB52_4;

	mov.f64 	%fd61, 0d0000000000000000;
	mul.rn.f64 	%fd164, %fd164, %fd61;

BB52_4:
	mul.f64 	%fd62, %fd164, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r49, %fd62;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r49;
	cvt.rn.f64.s32	%fd63, %r49;
	neg.f64 	%fd64, %fd63;
	mov.f64 	%fd65, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd66, %fd64, %fd65, %fd164;
	mov.f64 	%fd67, 0d3C91A62633145C00;
	fma.rn.f64 	%fd68, %fd64, %fd67, %fd66;
	mov.f64 	%fd69, 0d397B839A252049C0;
	fma.rn.f64 	%fd165, %fd64, %fd69, %fd68;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd164;
	}
	and.b32  	%r17, %r16, 2145386496;
	setp.lt.u32	%p6, %r17, 1105199104;
	@%p6 bra 	BB52_6;

	// Callseq Start 100
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd164;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd165, [retval0+0];
	
	//{
	}// Callseq End 100
	ld.local.u32 	%r49, [%rd2];

BB52_6:
	and.b32  	%r18, %r49, 1;
	shl.b32 	%r19, %r18, 3;
	setp.eq.s32	%p7, %r18, 0;
	selp.f64	%fd70, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r20, %r19, 1;
	mul.wide.s32 	%rd5, %r20, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd71, [%rd7];
	mul.rn.f64 	%fd8, %fd165, %fd165;
	fma.rn.f64 	%fd72, %fd70, %fd8, %fd71;
	ld.const.f64 	%fd73, [%rd7+8];
	fma.rn.f64 	%fd74, %fd72, %fd8, %fd73;
	ld.const.f64 	%fd75, [%rd7+16];
	fma.rn.f64 	%fd76, %fd74, %fd8, %fd75;
	ld.const.f64 	%fd77, [%rd7+24];
	fma.rn.f64 	%fd78, %fd76, %fd8, %fd77;
	ld.const.f64 	%fd79, [%rd7+32];
	fma.rn.f64 	%fd80, %fd78, %fd8, %fd79;
	ld.const.f64 	%fd81, [%rd7+40];
	fma.rn.f64 	%fd9, %fd80, %fd8, %fd81;
	fma.rn.f64 	%fd166, %fd9, %fd165, %fd165;
	@%p7 bra 	BB52_8;

	mov.f64 	%fd82, 0d3FF0000000000000;
	fma.rn.f64 	%fd166, %fd9, %fd8, %fd82;

BB52_8:
	and.b32  	%r21, %r49, 2;
	setp.eq.s32	%p8, %r21, 0;
	@%p8 bra 	BB52_10;

	mov.f64 	%fd83, 0d0000000000000000;
	mov.f64 	%fd84, 0dBFF0000000000000;
	fma.rn.f64 	%fd166, %fd166, %fd84, %fd83;

BB52_10:
	mul.f64 	%fd168, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd168;
	}
	and.b32  	%r23, %r22, 2147483647;
	setp.ne.s32	%p9, %r23, 2146435072;
	@%p9 bra 	BB52_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd168;
	}
	setp.ne.s32	%p10, %r24, 0;
	@%p10 bra 	BB52_13;

	mov.f64 	%fd85, 0d0000000000000000;
	mul.rn.f64 	%fd168, %fd168, %fd85;

BB52_13:
	mul.f64 	%fd86, %fd168, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r50, %fd86;
	st.local.u32 	[%rd2], %r50;
	cvt.rn.f64.s32	%fd87, %r50;
	neg.f64 	%fd88, %fd87;
	fma.rn.f64 	%fd90, %fd88, %fd65, %fd168;
	fma.rn.f64 	%fd92, %fd88, %fd67, %fd90;
	fma.rn.f64 	%fd169, %fd88, %fd69, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd168;
	}
	and.b32  	%r26, %r25, 2145386496;
	setp.lt.u32	%p11, %r26, 1105199104;
	@%p11 bra 	BB52_15;

	// Callseq Start 101
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd168;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd169, [retval0+0];
	
	//{
	}// Callseq End 101
	ld.local.u32 	%r50, [%rd2];

BB52_15:
	and.b32  	%r27, %r50, 1;
	shl.b32 	%r28, %r27, 3;
	setp.eq.s32	%p12, %r27, 0;
	selp.f64	%fd94, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r29, %r28, 1;
	mul.wide.s32 	%rd12, %r29, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd95, [%rd14];
	mul.rn.f64 	%fd21, %fd169, %fd169;
	fma.rn.f64 	%fd96, %fd94, %fd21, %fd95;
	ld.const.f64 	%fd97, [%rd14+8];
	fma.rn.f64 	%fd98, %fd96, %fd21, %fd97;
	ld.const.f64 	%fd99, [%rd14+16];
	fma.rn.f64 	%fd100, %fd98, %fd21, %fd99;
	ld.const.f64 	%fd101, [%rd14+24];
	fma.rn.f64 	%fd102, %fd100, %fd21, %fd101;
	ld.const.f64 	%fd103, [%rd14+32];
	fma.rn.f64 	%fd104, %fd102, %fd21, %fd103;
	ld.const.f64 	%fd105, [%rd14+40];
	fma.rn.f64 	%fd22, %fd104, %fd21, %fd105;
	fma.rn.f64 	%fd170, %fd22, %fd169, %fd169;
	@%p12 bra 	BB52_17;

	mov.f64 	%fd106, 0d3FF0000000000000;
	fma.rn.f64 	%fd170, %fd22, %fd21, %fd106;

BB52_17:
	and.b32  	%r30, %r50, 2;
	setp.eq.s32	%p13, %r30, 0;
	@%p13 bra 	BB52_19;

	mov.f64 	%fd107, 0d0000000000000000;
	mov.f64 	%fd108, 0dBFF0000000000000;
	fma.rn.f64 	%fd170, %fd170, %fd108, %fd107;

BB52_19:
	div.rn.f64 	%fd109, %fd170, 0dC022000000000000;
	add.f64 	%fd28, %fd166, %fd109;
	mul.f64 	%fd172, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd172;
	}
	and.b32  	%r32, %r31, 2147483647;
	setp.ne.s32	%p14, %r32, 2146435072;
	@%p14 bra 	BB52_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd172;
	}
	setp.ne.s32	%p15, %r33, 0;
	@%p15 bra 	BB52_22;

	mov.f64 	%fd110, 0d0000000000000000;
	mul.rn.f64 	%fd172, %fd172, %fd110;

BB52_22:
	mul.f64 	%fd111, %fd172, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r51, %fd111;
	st.local.u32 	[%rd2], %r51;
	cvt.rn.f64.s32	%fd112, %r51;
	neg.f64 	%fd113, %fd112;
	fma.rn.f64 	%fd115, %fd113, %fd65, %fd172;
	fma.rn.f64 	%fd117, %fd113, %fd67, %fd115;
	fma.rn.f64 	%fd173, %fd113, %fd69, %fd117;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd172;
	}
	and.b32  	%r35, %r34, 2145386496;
	setp.lt.u32	%p16, %r35, 1105199104;
	@%p16 bra 	BB52_24;

	// Callseq Start 102
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd172;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd173, [retval0+0];
	
	//{
	}// Callseq End 102
	ld.local.u32 	%r51, [%rd2];

BB52_24:
	and.b32  	%r36, %r51, 1;
	shl.b32 	%r37, %r36, 3;
	setp.eq.s32	%p17, %r36, 0;
	selp.f64	%fd119, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r38, %r37, 1;
	mul.wide.s32 	%rd19, %r38, 8;
	add.s64 	%rd21, %rd6, %rd19;
	ld.const.f64 	%fd120, [%rd21];
	mul.rn.f64 	%fd35, %fd173, %fd173;
	fma.rn.f64 	%fd121, %fd119, %fd35, %fd120;
	ld.const.f64 	%fd122, [%rd21+8];
	fma.rn.f64 	%fd123, %fd121, %fd35, %fd122;
	ld.const.f64 	%fd124, [%rd21+16];
	fma.rn.f64 	%fd125, %fd123, %fd35, %fd124;
	ld.const.f64 	%fd126, [%rd21+24];
	fma.rn.f64 	%fd127, %fd125, %fd35, %fd126;
	ld.const.f64 	%fd128, [%rd21+32];
	fma.rn.f64 	%fd129, %fd127, %fd35, %fd128;
	ld.const.f64 	%fd130, [%rd21+40];
	fma.rn.f64 	%fd36, %fd129, %fd35, %fd130;
	fma.rn.f64 	%fd174, %fd36, %fd173, %fd173;
	@%p17 bra 	BB52_26;

	mov.f64 	%fd131, 0d3FF0000000000000;
	fma.rn.f64 	%fd174, %fd36, %fd35, %fd131;

BB52_26:
	and.b32  	%r39, %r51, 2;
	setp.eq.s32	%p18, %r39, 0;
	@%p18 bra 	BB52_28;

	mov.f64 	%fd132, 0d0000000000000000;
	mov.f64 	%fd133, 0dBFF0000000000000;
	fma.rn.f64 	%fd174, %fd174, %fd133, %fd132;

BB52_28:
	div.rn.f64 	%fd134, %fd174, 0d4039000000000000;
	add.f64 	%fd42, %fd28, %fd134;
	mul.f64 	%fd176, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd176;
	}
	and.b32  	%r41, %r40, 2147483647;
	setp.ne.s32	%p19, %r41, 2146435072;
	@%p19 bra 	BB52_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd176;
	}
	setp.ne.s32	%p20, %r42, 0;
	@%p20 bra 	BB52_31;

	mov.f64 	%fd135, 0d0000000000000000;
	mul.rn.f64 	%fd176, %fd176, %fd135;

BB52_31:
	mul.f64 	%fd136, %fd176, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r52, %fd136;
	st.local.u32 	[%rd2], %r52;
	cvt.rn.f64.s32	%fd137, %r52;
	neg.f64 	%fd138, %fd137;
	fma.rn.f64 	%fd140, %fd138, %fd65, %fd176;
	fma.rn.f64 	%fd142, %fd138, %fd67, %fd140;
	fma.rn.f64 	%fd177, %fd138, %fd69, %fd142;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd176;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p21, %r44, 1105199104;
	@%p21 bra 	BB52_33;

	// Callseq Start 103
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd176;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd177, [retval0+0];
	
	//{
	}// Callseq End 103
	ld.local.u32 	%r52, [%rd2];

BB52_33:
	and.b32  	%r45, %r52, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p22, %r45, 0;
	selp.f64	%fd144, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd26, %r47, 8;
	add.s64 	%rd28, %rd6, %rd26;
	ld.const.f64 	%fd145, [%rd28];
	mul.rn.f64 	%fd49, %fd177, %fd177;
	fma.rn.f64 	%fd146, %fd144, %fd49, %fd145;
	ld.const.f64 	%fd147, [%rd28+8];
	fma.rn.f64 	%fd148, %fd146, %fd49, %fd147;
	ld.const.f64 	%fd149, [%rd28+16];
	fma.rn.f64 	%fd150, %fd148, %fd49, %fd149;
	ld.const.f64 	%fd151, [%rd28+24];
	fma.rn.f64 	%fd152, %fd150, %fd49, %fd151;
	ld.const.f64 	%fd153, [%rd28+32];
	fma.rn.f64 	%fd154, %fd152, %fd49, %fd153;
	ld.const.f64 	%fd155, [%rd28+40];
	fma.rn.f64 	%fd50, %fd154, %fd49, %fd155;
	fma.rn.f64 	%fd178, %fd50, %fd177, %fd177;
	@%p22 bra 	BB52_35;

	mov.f64 	%fd156, 0d3FF0000000000000;
	fma.rn.f64 	%fd178, %fd50, %fd49, %fd156;

BB52_35:
	and.b32  	%r48, %r52, 2;
	setp.eq.s32	%p23, %r48, 0;
	@%p23 bra 	BB52_37;

	mov.f64 	%fd157, 0d0000000000000000;
	mov.f64 	%fd158, 0dBFF0000000000000;
	fma.rn.f64 	%fd178, %fd178, %fd158, %fd157;

BB52_37:
	div.rn.f64 	%fd159, %fd178, 0dC048800000000000;
	add.f64 	%fd160, %fd42, %fd159;
	add.f64 	%fd161, %fd58, %fd58;
	mul.f64 	%fd162, %fd161, 0d4020000000000000;
	div.rn.f64 	%fd163, %fd162, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd180, %fd163, %fd160;

BB52_38:
	st.param.f64	[func_retval0+0], %fd180;
	ret;
}

	// .globl	_Z10Triangle_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Triangle_tddPdiPii(
	.param .b64 _Z10Triangle_tddPdiPii_param_0,
	.param .b64 _Z10Triangle_tddPdiPii_param_1,
	.param .b64 _Z10Triangle_tddPdiPii_param_2,
	.param .b32 _Z10Triangle_tddPdiPii_param_3,
	.param .b64 _Z10Triangle_tddPdiPii_param_4,
	.param .b32 _Z10Triangle_tddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot53[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<183>;
	.reg .b64 	%rd<29>;


	mov.u64 	%SPL, __local_depot53;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd58, [_Z10Triangle_tddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z10Triangle_tddPdiPii_param_1];
	mul.f64 	%fd1, %fd58, %fd60;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	setp.gt.f64	%p2, %fd1, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd182, 0d0000000000000000;
	@%p3 bra 	BB53_38;

	mul.f64 	%fd166, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd166;
	}
	and.b32  	%r18, %r17, 2147483647;
	setp.ne.s32	%p4, %r18, 2146435072;
	@%p4 bra 	BB53_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd166;
	}
	setp.ne.s32	%p5, %r19, 0;
	@%p5 bra 	BB53_4;

	mov.f64 	%fd61, 0d0000000000000000;
	mul.rn.f64 	%fd166, %fd166, %fd61;

BB53_4:
	mul.f64 	%fd62, %fd166, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd62;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r53;
	cvt.rn.f64.s32	%fd63, %r53;
	neg.f64 	%fd64, %fd63;
	mov.f64 	%fd65, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd66, %fd64, %fd65, %fd166;
	mov.f64 	%fd67, 0d3C91A62633145C00;
	fma.rn.f64 	%fd68, %fd64, %fd67, %fd66;
	mov.f64 	%fd69, 0d397B839A252049C0;
	fma.rn.f64 	%fd167, %fd64, %fd69, %fd68;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd166;
	}
	and.b32  	%r21, %r20, 2145386496;
	setp.lt.u32	%p6, %r21, 1105199104;
	@%p6 bra 	BB53_6;

	// Callseq Start 104
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd166;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd167, [retval0+0];
	
	//{
	}// Callseq End 104
	ld.local.u32 	%r53, [%rd2];

BB53_6:
	add.s32 	%r4, %r53, 1;
	and.b32  	%r22, %r4, 1;
	shl.b32 	%r23, %r22, 3;
	setp.eq.s32	%p7, %r22, 0;
	selp.f64	%fd70, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r24, %r23, 1;
	mul.wide.s32 	%rd5, %r24, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd71, [%rd7];
	mul.rn.f64 	%fd8, %fd167, %fd167;
	fma.rn.f64 	%fd72, %fd70, %fd8, %fd71;
	ld.const.f64 	%fd73, [%rd7+8];
	fma.rn.f64 	%fd74, %fd72, %fd8, %fd73;
	ld.const.f64 	%fd75, [%rd7+16];
	fma.rn.f64 	%fd76, %fd74, %fd8, %fd75;
	ld.const.f64 	%fd77, [%rd7+24];
	fma.rn.f64 	%fd78, %fd76, %fd8, %fd77;
	ld.const.f64 	%fd79, [%rd7+32];
	fma.rn.f64 	%fd80, %fd78, %fd8, %fd79;
	ld.const.f64 	%fd81, [%rd7+40];
	fma.rn.f64 	%fd9, %fd80, %fd8, %fd81;
	fma.rn.f64 	%fd168, %fd9, %fd167, %fd167;
	@%p7 bra 	BB53_8;

	mov.f64 	%fd82, 0d3FF0000000000000;
	fma.rn.f64 	%fd168, %fd9, %fd8, %fd82;

BB53_8:
	and.b32  	%r25, %r4, 2;
	setp.eq.s32	%p8, %r25, 0;
	@%p8 bra 	BB53_10;

	mov.f64 	%fd83, 0d0000000000000000;
	mov.f64 	%fd84, 0dBFF0000000000000;
	fma.rn.f64 	%fd168, %fd168, %fd84, %fd83;

BB53_10:
	mul.f64 	%fd170, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd170;
	}
	and.b32  	%r27, %r26, 2147483647;
	setp.ne.s32	%p9, %r27, 2146435072;
	@%p9 bra 	BB53_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd170;
	}
	setp.ne.s32	%p10, %r28, 0;
	@%p10 bra 	BB53_13;

	mov.f64 	%fd85, 0d0000000000000000;
	mul.rn.f64 	%fd170, %fd170, %fd85;

BB53_13:
	mul.f64 	%fd86, %fd170, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd86;
	st.local.u32 	[%rd2], %r54;
	cvt.rn.f64.s32	%fd87, %r54;
	neg.f64 	%fd88, %fd87;
	fma.rn.f64 	%fd90, %fd88, %fd65, %fd170;
	fma.rn.f64 	%fd92, %fd88, %fd67, %fd90;
	fma.rn.f64 	%fd171, %fd88, %fd69, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd170;
	}
	and.b32  	%r30, %r29, 2145386496;
	setp.lt.u32	%p11, %r30, 1105199104;
	@%p11 bra 	BB53_15;

	// Callseq Start 105
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd170;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd171, [retval0+0];
	
	//{
	}// Callseq End 105
	ld.local.u32 	%r54, [%rd2];

BB53_15:
	add.s32 	%r8, %r54, 1;
	and.b32  	%r31, %r8, 1;
	shl.b32 	%r32, %r31, 3;
	setp.eq.s32	%p12, %r31, 0;
	selp.f64	%fd94, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r33, %r32, 1;
	mul.wide.s32 	%rd12, %r33, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd95, [%rd14];
	mul.rn.f64 	%fd21, %fd171, %fd171;
	fma.rn.f64 	%fd96, %fd94, %fd21, %fd95;
	ld.const.f64 	%fd97, [%rd14+8];
	fma.rn.f64 	%fd98, %fd96, %fd21, %fd97;
	ld.const.f64 	%fd99, [%rd14+16];
	fma.rn.f64 	%fd100, %fd98, %fd21, %fd99;
	ld.const.f64 	%fd101, [%rd14+24];
	fma.rn.f64 	%fd102, %fd100, %fd21, %fd101;
	ld.const.f64 	%fd103, [%rd14+32];
	fma.rn.f64 	%fd104, %fd102, %fd21, %fd103;
	ld.const.f64 	%fd105, [%rd14+40];
	fma.rn.f64 	%fd22, %fd104, %fd21, %fd105;
	fma.rn.f64 	%fd172, %fd22, %fd171, %fd171;
	@%p12 bra 	BB53_17;

	mov.f64 	%fd106, 0d3FF0000000000000;
	fma.rn.f64 	%fd172, %fd22, %fd21, %fd106;

BB53_17:
	and.b32  	%r34, %r8, 2;
	setp.eq.s32	%p13, %r34, 0;
	@%p13 bra 	BB53_19;

	mov.f64 	%fd107, 0d0000000000000000;
	mov.f64 	%fd108, 0dBFF0000000000000;
	fma.rn.f64 	%fd172, %fd172, %fd108, %fd107;

BB53_19:
	div.rn.f64 	%fd109, %fd172, 0dC008000000000000;
	add.f64 	%fd28, %fd168, %fd109;
	mul.f64 	%fd174, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd174;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p14, %r36, 2146435072;
	@%p14 bra 	BB53_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd174;
	}
	setp.ne.s32	%p15, %r37, 0;
	@%p15 bra 	BB53_22;

	mov.f64 	%fd110, 0d0000000000000000;
	mul.rn.f64 	%fd174, %fd174, %fd110;

BB53_22:
	mul.f64 	%fd111, %fd174, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r55, %fd111;
	st.local.u32 	[%rd2], %r55;
	cvt.rn.f64.s32	%fd112, %r55;
	neg.f64 	%fd113, %fd112;
	fma.rn.f64 	%fd115, %fd113, %fd65, %fd174;
	fma.rn.f64 	%fd117, %fd113, %fd67, %fd115;
	fma.rn.f64 	%fd175, %fd113, %fd69, %fd117;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd174;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p16, %r39, 1105199104;
	@%p16 bra 	BB53_24;

	// Callseq Start 106
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd174;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd175, [retval0+0];
	
	//{
	}// Callseq End 106
	ld.local.u32 	%r55, [%rd2];

BB53_24:
	add.s32 	%r12, %r55, 1;
	and.b32  	%r40, %r12, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p17, %r40, 0;
	selp.f64	%fd119, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r42, %r41, 1;
	mul.wide.s32 	%rd19, %r42, 8;
	add.s64 	%rd21, %rd6, %rd19;
	ld.const.f64 	%fd120, [%rd21];
	mul.rn.f64 	%fd35, %fd175, %fd175;
	fma.rn.f64 	%fd121, %fd119, %fd35, %fd120;
	ld.const.f64 	%fd122, [%rd21+8];
	fma.rn.f64 	%fd123, %fd121, %fd35, %fd122;
	ld.const.f64 	%fd124, [%rd21+16];
	fma.rn.f64 	%fd125, %fd123, %fd35, %fd124;
	ld.const.f64 	%fd126, [%rd21+24];
	fma.rn.f64 	%fd127, %fd125, %fd35, %fd126;
	ld.const.f64 	%fd128, [%rd21+32];
	fma.rn.f64 	%fd129, %fd127, %fd35, %fd128;
	ld.const.f64 	%fd130, [%rd21+40];
	fma.rn.f64 	%fd36, %fd129, %fd35, %fd130;
	fma.rn.f64 	%fd176, %fd36, %fd175, %fd175;
	@%p17 bra 	BB53_26;

	mov.f64 	%fd131, 0d3FF0000000000000;
	fma.rn.f64 	%fd176, %fd36, %fd35, %fd131;

BB53_26:
	and.b32  	%r43, %r12, 2;
	setp.eq.s32	%p18, %r43, 0;
	@%p18 bra 	BB53_28;

	mov.f64 	%fd132, 0d0000000000000000;
	mov.f64 	%fd133, 0dBFF0000000000000;
	fma.rn.f64 	%fd176, %fd176, %fd133, %fd132;

BB53_28:
	div.rn.f64 	%fd134, %fd176, 0d4014000000000000;
	add.f64 	%fd42, %fd28, %fd134;
	mul.f64 	%fd178, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd178;
	}
	and.b32  	%r45, %r44, 2147483647;
	setp.ne.s32	%p19, %r45, 2146435072;
	@%p19 bra 	BB53_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd178;
	}
	setp.ne.s32	%p20, %r46, 0;
	@%p20 bra 	BB53_31;

	mov.f64 	%fd135, 0d0000000000000000;
	mul.rn.f64 	%fd178, %fd178, %fd135;

BB53_31:
	mul.f64 	%fd136, %fd178, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r56, %fd136;
	st.local.u32 	[%rd2], %r56;
	cvt.rn.f64.s32	%fd137, %r56;
	neg.f64 	%fd138, %fd137;
	fma.rn.f64 	%fd140, %fd138, %fd65, %fd178;
	fma.rn.f64 	%fd142, %fd138, %fd67, %fd140;
	fma.rn.f64 	%fd179, %fd138, %fd69, %fd142;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd178;
	}
	and.b32  	%r48, %r47, 2145386496;
	setp.lt.u32	%p21, %r48, 1105199104;
	@%p21 bra 	BB53_33;

	// Callseq Start 107
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd178;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd179, [retval0+0];
	
	//{
	}// Callseq End 107
	ld.local.u32 	%r56, [%rd2];

BB53_33:
	add.s32 	%r16, %r56, 1;
	and.b32  	%r49, %r16, 1;
	shl.b32 	%r50, %r49, 3;
	setp.eq.s32	%p22, %r49, 0;
	selp.f64	%fd144, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r51, %r50, 1;
	mul.wide.s32 	%rd26, %r51, 8;
	add.s64 	%rd28, %rd6, %rd26;
	ld.const.f64 	%fd145, [%rd28];
	mul.rn.f64 	%fd49, %fd179, %fd179;
	fma.rn.f64 	%fd146, %fd144, %fd49, %fd145;
	ld.const.f64 	%fd147, [%rd28+8];
	fma.rn.f64 	%fd148, %fd146, %fd49, %fd147;
	ld.const.f64 	%fd149, [%rd28+16];
	fma.rn.f64 	%fd150, %fd148, %fd49, %fd149;
	ld.const.f64 	%fd151, [%rd28+24];
	fma.rn.f64 	%fd152, %fd150, %fd49, %fd151;
	ld.const.f64 	%fd153, [%rd28+32];
	fma.rn.f64 	%fd154, %fd152, %fd49, %fd153;
	ld.const.f64 	%fd155, [%rd28+40];
	fma.rn.f64 	%fd50, %fd154, %fd49, %fd155;
	fma.rn.f64 	%fd180, %fd50, %fd179, %fd179;
	@%p22 bra 	BB53_35;

	mov.f64 	%fd156, 0d3FF0000000000000;
	fma.rn.f64 	%fd180, %fd50, %fd49, %fd156;

BB53_35:
	and.b32  	%r52, %r16, 2;
	setp.eq.s32	%p23, %r52, 0;
	@%p23 bra 	BB53_37;

	mov.f64 	%fd157, 0d0000000000000000;
	mov.f64 	%fd158, 0dBFF0000000000000;
	fma.rn.f64 	%fd180, %fd180, %fd158, %fd157;

BB53_37:
	div.rn.f64 	%fd159, %fd180, 0dC01C000000000000;
	add.f64 	%fd160, %fd42, %fd159;
	add.f64 	%fd161, %fd58, %fd58;
	mul.f64 	%fd162, %fd161, 0d4020000000000000;
	div.rn.f64 	%fd163, %fd162, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd164, %fd163, 0d400921FB54442D18;
	mul.f64 	%fd165, %fd164, %fd58;
	mul.f64 	%fd182, %fd165, %fd160;

BB53_38:
	st.param.f64	[func_retval0+0], %fd182;
	ret;
}

	// .globl	_Z11Triangle_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Triangle_omddPdiPii(
	.param .b64 _Z11Triangle_omddPdiPii_param_0,
	.param .b64 _Z11Triangle_omddPdiPii_param_1,
	.param .b64 _Z11Triangle_omddPdiPii_param_2,
	.param .b32 _Z11Triangle_omddPdiPii_param_3,
	.param .b64 _Z11Triangle_omddPdiPii_param_4,
	.param .b32 _Z11Triangle_omddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot54[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<44>;
	.reg .b32 	%r<101>;
	.reg .f64 	%fd<347>;
	.reg .b64 	%rd<49>;


	mov.u64 	%SPL, __local_depot54;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd109, [_Z11Triangle_omddPdiPii_param_0];
	ld.param.f64 	%fd110, [_Z11Triangle_omddPdiPii_param_1];
	add.u64 	%rd9, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd9;
	mul.f64 	%fd1, %fd109, %fd110;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	setp.gt.f64	%p2, %fd1, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd346, 0d0000000000000000;
	@%p3 bra 	BB54_74;

	mul.f64 	%fd330, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd330;
	}
	and.b32  	%r1, %r33, 2147483647;
	setp.ne.s32	%p4, %r1, 2146435072;
	mov.f64 	%fd314, %fd330;
	@%p4 bra 	BB54_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd330;
	}
	setp.ne.s32	%p5, %r34, 0;
	mov.f64 	%fd314, %fd330;
	@%p5 bra 	BB54_4;

	mov.f64 	%fd112, 0d0000000000000000;
	mul.rn.f64 	%fd314, %fd330, %fd112;

BB54_4:
	mul.f64 	%fd113, %fd314, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r93, %fd113;
	st.local.u32 	[%rd1], %r93;
	cvt.rn.f64.s32	%fd114, %r93;
	neg.f64 	%fd115, %fd114;
	mov.f64 	%fd116, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd117, %fd115, %fd116, %fd314;
	mov.f64 	%fd118, 0d3C91A62633145C00;
	fma.rn.f64 	%fd119, %fd115, %fd118, %fd117;
	mov.f64 	%fd120, 0d397B839A252049C0;
	fma.rn.f64 	%fd315, %fd115, %fd120, %fd119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd314;
	}
	and.b32  	%r36, %r35, 2145386496;
	setp.lt.u32	%p6, %r36, 1105199104;
	@%p6 bra 	BB54_6;

	// Callseq Start 108
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd314;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd315, [retval0+0];
	
	//{
	}// Callseq End 108
	ld.local.u32 	%r93, [%rd1];

BB54_6:
	add.s32 	%r5, %r93, 1;
	and.b32  	%r37, %r5, 1;
	shl.b32 	%r38, %r37, 3;
	setp.eq.s32	%p7, %r37, 0;
	selp.f64	%fd121, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r39, %r38, 1;
	mul.wide.s32 	%rd18, %r39, 8;
	mov.u64 	%rd19, __cudart_sin_cos_coeffs;
	add.s64 	%rd20, %rd19, %rd18;
	ld.const.f64 	%fd122, [%rd20];
	mul.rn.f64 	%fd8, %fd315, %fd315;
	fma.rn.f64 	%fd123, %fd121, %fd8, %fd122;
	ld.const.f64 	%fd124, [%rd20+8];
	fma.rn.f64 	%fd125, %fd123, %fd8, %fd124;
	ld.const.f64 	%fd126, [%rd20+16];
	fma.rn.f64 	%fd127, %fd125, %fd8, %fd126;
	ld.const.f64 	%fd128, [%rd20+24];
	fma.rn.f64 	%fd129, %fd127, %fd8, %fd128;
	ld.const.f64 	%fd130, [%rd20+32];
	fma.rn.f64 	%fd131, %fd129, %fd8, %fd130;
	ld.const.f64 	%fd132, [%rd20+40];
	fma.rn.f64 	%fd9, %fd131, %fd8, %fd132;
	fma.rn.f64 	%fd316, %fd9, %fd315, %fd315;
	@%p7 bra 	BB54_8;

	mov.f64 	%fd133, 0d3FF0000000000000;
	fma.rn.f64 	%fd316, %fd9, %fd8, %fd133;

BB54_8:
	and.b32  	%r40, %r5, 2;
	setp.eq.s32	%p8, %r40, 0;
	@%p8 bra 	BB54_10;

	mov.f64 	%fd134, 0d0000000000000000;
	mov.f64 	%fd135, 0dBFF0000000000000;
	fma.rn.f64 	%fd316, %fd316, %fd135, %fd134;

BB54_10:
	mul.f64 	%fd334, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd334;
	}
	and.b32  	%r6, %r41, 2147483647;
	setp.ne.s32	%p9, %r6, 2146435072;
	mov.f64 	%fd318, %fd334;
	@%p9 bra 	BB54_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd334;
	}
	setp.ne.s32	%p10, %r42, 0;
	mov.f64 	%fd318, %fd334;
	@%p10 bra 	BB54_13;

	mov.f64 	%fd136, 0d0000000000000000;
	mul.rn.f64 	%fd318, %fd334, %fd136;

BB54_13:
	mul.f64 	%fd137, %fd318, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r94, %fd137;
	st.local.u32 	[%rd1], %r94;
	cvt.rn.f64.s32	%fd138, %r94;
	neg.f64 	%fd139, %fd138;
	fma.rn.f64 	%fd141, %fd139, %fd116, %fd318;
	fma.rn.f64 	%fd143, %fd139, %fd118, %fd141;
	fma.rn.f64 	%fd319, %fd139, %fd120, %fd143;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd318;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p11, %r44, 1105199104;
	@%p11 bra 	BB54_15;

	// Callseq Start 109
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd318;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd319, [retval0+0];
	
	//{
	}// Callseq End 109
	ld.local.u32 	%r94, [%rd1];

BB54_15:
	add.s32 	%r10, %r94, 1;
	and.b32  	%r45, %r10, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p12, %r45, 0;
	selp.f64	%fd145, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd22, %r47, 8;
	add.s64 	%rd24, %rd19, %rd22;
	ld.const.f64 	%fd146, [%rd24];
	mul.rn.f64 	%fd21, %fd319, %fd319;
	fma.rn.f64 	%fd147, %fd145, %fd21, %fd146;
	ld.const.f64 	%fd148, [%rd24+8];
	fma.rn.f64 	%fd149, %fd147, %fd21, %fd148;
	ld.const.f64 	%fd150, [%rd24+16];
	fma.rn.f64 	%fd151, %fd149, %fd21, %fd150;
	ld.const.f64 	%fd152, [%rd24+24];
	fma.rn.f64 	%fd153, %fd151, %fd21, %fd152;
	ld.const.f64 	%fd154, [%rd24+32];
	fma.rn.f64 	%fd155, %fd153, %fd21, %fd154;
	ld.const.f64 	%fd156, [%rd24+40];
	fma.rn.f64 	%fd22, %fd155, %fd21, %fd156;
	fma.rn.f64 	%fd320, %fd22, %fd319, %fd319;
	@%p12 bra 	BB54_17;

	mov.f64 	%fd157, 0d3FF0000000000000;
	fma.rn.f64 	%fd320, %fd22, %fd21, %fd157;

BB54_17:
	and.b32  	%r48, %r10, 2;
	setp.eq.s32	%p13, %r48, 0;
	@%p13 bra 	BB54_19;

	mov.f64 	%fd158, 0d0000000000000000;
	mov.f64 	%fd159, 0dBFF0000000000000;
	fma.rn.f64 	%fd320, %fd320, %fd159, %fd158;

BB54_19:
	div.rn.f64 	%fd160, %fd320, 0dC008000000000000;
	add.f64 	%fd28, %fd316, %fd160;
	mul.f64 	%fd338, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd338;
	}
	and.b32  	%r11, %r49, 2147483647;
	setp.ne.s32	%p14, %r11, 2146435072;
	mov.f64 	%fd322, %fd338;
	@%p14 bra 	BB54_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd338;
	}
	setp.ne.s32	%p15, %r50, 0;
	mov.f64 	%fd322, %fd338;
	@%p15 bra 	BB54_22;

	mov.f64 	%fd161, 0d0000000000000000;
	mul.rn.f64 	%fd322, %fd338, %fd161;

BB54_22:
	mul.f64 	%fd162, %fd322, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r95, %fd162;
	st.local.u32 	[%rd1], %r95;
	cvt.rn.f64.s32	%fd163, %r95;
	neg.f64 	%fd164, %fd163;
	fma.rn.f64 	%fd166, %fd164, %fd116, %fd322;
	fma.rn.f64 	%fd168, %fd164, %fd118, %fd166;
	fma.rn.f64 	%fd323, %fd164, %fd120, %fd168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd322;
	}
	and.b32  	%r52, %r51, 2145386496;
	setp.lt.u32	%p16, %r52, 1105199104;
	@%p16 bra 	BB54_24;

	// Callseq Start 110
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd322;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd323, [retval0+0];
	
	//{
	}// Callseq End 110
	ld.local.u32 	%r95, [%rd1];

BB54_24:
	add.s32 	%r15, %r95, 1;
	and.b32  	%r53, %r15, 1;
	shl.b32 	%r54, %r53, 3;
	setp.eq.s32	%p17, %r53, 0;
	selp.f64	%fd170, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r55, %r54, 1;
	mul.wide.s32 	%rd26, %r55, 8;
	add.s64 	%rd28, %rd19, %rd26;
	ld.const.f64 	%fd171, [%rd28];
	mul.rn.f64 	%fd35, %fd323, %fd323;
	fma.rn.f64 	%fd172, %fd170, %fd35, %fd171;
	ld.const.f64 	%fd173, [%rd28+8];
	fma.rn.f64 	%fd174, %fd172, %fd35, %fd173;
	ld.const.f64 	%fd175, [%rd28+16];
	fma.rn.f64 	%fd176, %fd174, %fd35, %fd175;
	ld.const.f64 	%fd177, [%rd28+24];
	fma.rn.f64 	%fd178, %fd176, %fd35, %fd177;
	ld.const.f64 	%fd179, [%rd28+32];
	fma.rn.f64 	%fd180, %fd178, %fd35, %fd179;
	ld.const.f64 	%fd181, [%rd28+40];
	fma.rn.f64 	%fd36, %fd180, %fd35, %fd181;
	fma.rn.f64 	%fd324, %fd36, %fd323, %fd323;
	@%p17 bra 	BB54_26;

	mov.f64 	%fd182, 0d3FF0000000000000;
	fma.rn.f64 	%fd324, %fd36, %fd35, %fd182;

BB54_26:
	and.b32  	%r56, %r15, 2;
	setp.eq.s32	%p18, %r56, 0;
	@%p18 bra 	BB54_28;

	mov.f64 	%fd183, 0d0000000000000000;
	mov.f64 	%fd184, 0dBFF0000000000000;
	fma.rn.f64 	%fd324, %fd324, %fd184, %fd183;

BB54_28:
	div.rn.f64 	%fd185, %fd324, 0d4014000000000000;
	add.f64 	%fd42, %fd28, %fd185;
	mul.f64 	%fd342, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r57}, %fd342;
	}
	and.b32  	%r16, %r57, 2147483647;
	setp.ne.s32	%p19, %r16, 2146435072;
	mov.f64 	%fd326, %fd342;
	@%p19 bra 	BB54_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd342;
	}
	setp.ne.s32	%p20, %r58, 0;
	mov.f64 	%fd326, %fd342;
	@%p20 bra 	BB54_31;

	mov.f64 	%fd186, 0d0000000000000000;
	mul.rn.f64 	%fd326, %fd342, %fd186;

BB54_31:
	mul.f64 	%fd187, %fd326, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r96, %fd187;
	st.local.u32 	[%rd1], %r96;
	cvt.rn.f64.s32	%fd188, %r96;
	neg.f64 	%fd189, %fd188;
	fma.rn.f64 	%fd191, %fd189, %fd116, %fd326;
	fma.rn.f64 	%fd193, %fd189, %fd118, %fd191;
	fma.rn.f64 	%fd327, %fd189, %fd120, %fd193;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd326;
	}
	and.b32  	%r60, %r59, 2145386496;
	setp.lt.u32	%p21, %r60, 1105199104;
	@%p21 bra 	BB54_33;

	// Callseq Start 111
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd326;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd327, [retval0+0];
	
	//{
	}// Callseq End 111
	ld.local.u32 	%r96, [%rd1];

BB54_33:
	add.s32 	%r20, %r96, 1;
	and.b32  	%r61, %r20, 1;
	shl.b32 	%r62, %r61, 3;
	setp.eq.s32	%p22, %r61, 0;
	selp.f64	%fd195, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r63, %r62, 1;
	mul.wide.s32 	%rd30, %r63, 8;
	add.s64 	%rd32, %rd19, %rd30;
	ld.const.f64 	%fd196, [%rd32];
	mul.rn.f64 	%fd49, %fd327, %fd327;
	fma.rn.f64 	%fd197, %fd195, %fd49, %fd196;
	ld.const.f64 	%fd198, [%rd32+8];
	fma.rn.f64 	%fd199, %fd197, %fd49, %fd198;
	ld.const.f64 	%fd200, [%rd32+16];
	fma.rn.f64 	%fd201, %fd199, %fd49, %fd200;
	ld.const.f64 	%fd202, [%rd32+24];
	fma.rn.f64 	%fd203, %fd201, %fd49, %fd202;
	ld.const.f64 	%fd204, [%rd32+32];
	fma.rn.f64 	%fd205, %fd203, %fd49, %fd204;
	ld.const.f64 	%fd206, [%rd32+40];
	fma.rn.f64 	%fd50, %fd205, %fd49, %fd206;
	fma.rn.f64 	%fd328, %fd50, %fd327, %fd327;
	@%p22 bra 	BB54_35;

	mov.f64 	%fd207, 0d3FF0000000000000;
	fma.rn.f64 	%fd328, %fd50, %fd49, %fd207;

BB54_35:
	and.b32  	%r64, %r20, 2;
	setp.eq.s32	%p23, %r64, 0;
	@%p23 bra 	BB54_37;

	mov.f64 	%fd208, 0d0000000000000000;
	mov.f64 	%fd209, 0dBFF0000000000000;
	fma.rn.f64 	%fd328, %fd328, %fd209, %fd208;

BB54_37:
	div.rn.f64 	%fd210, %fd328, 0dC01C000000000000;
	add.f64 	%fd56, %fd42, %fd210;
	@%p4 bra 	BB54_40;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r65, %temp}, %fd330;
	}
	setp.ne.s32	%p25, %r65, 0;
	@%p25 bra 	BB54_40;

	mov.f64 	%fd211, 0d0000000000000000;
	mul.rn.f64 	%fd330, %fd330, %fd211;

BB54_40:
	mul.f64 	%fd212, %fd330, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r97, %fd212;
	st.local.u32 	[%rd1], %r97;
	cvt.rn.f64.s32	%fd213, %r97;
	neg.f64 	%fd214, %fd213;
	fma.rn.f64 	%fd216, %fd214, %fd116, %fd330;
	fma.rn.f64 	%fd218, %fd214, %fd118, %fd216;
	fma.rn.f64 	%fd331, %fd214, %fd120, %fd218;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd330;
	}
	and.b32  	%r67, %r66, 2145386496;
	setp.lt.u32	%p26, %r67, 1105199104;
	@%p26 bra 	BB54_42;

	// Callseq Start 112
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd330;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd331, [retval0+0];
	
	//{
	}// Callseq End 112
	ld.local.u32 	%r97, [%rd1];

BB54_42:
	and.b32  	%r68, %r97, 1;
	shl.b32 	%r69, %r68, 3;
	setp.eq.s32	%p27, %r68, 0;
	selp.f64	%fd220, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p27;
	add.s32 	%r70, %r69, 1;
	mul.wide.s32 	%rd34, %r70, 8;
	add.s64 	%rd36, %rd19, %rd34;
	ld.const.f64 	%fd221, [%rd36];
	mul.rn.f64 	%fd62, %fd331, %fd331;
	fma.rn.f64 	%fd222, %fd220, %fd62, %fd221;
	ld.const.f64 	%fd223, [%rd36+8];
	fma.rn.f64 	%fd224, %fd222, %fd62, %fd223;
	ld.const.f64 	%fd225, [%rd36+16];
	fma.rn.f64 	%fd226, %fd224, %fd62, %fd225;
	ld.const.f64 	%fd227, [%rd36+24];
	fma.rn.f64 	%fd228, %fd226, %fd62, %fd227;
	ld.const.f64 	%fd229, [%rd36+32];
	fma.rn.f64 	%fd230, %fd228, %fd62, %fd229;
	ld.const.f64 	%fd231, [%rd36+40];
	fma.rn.f64 	%fd63, %fd230, %fd62, %fd231;
	fma.rn.f64 	%fd332, %fd63, %fd331, %fd331;
	@%p27 bra 	BB54_44;

	mov.f64 	%fd232, 0d3FF0000000000000;
	fma.rn.f64 	%fd332, %fd63, %fd62, %fd232;

BB54_44:
	and.b32  	%r71, %r97, 2;
	setp.eq.s32	%p28, %r71, 0;
	@%p28 bra 	BB54_46;

	mov.f64 	%fd233, 0d0000000000000000;
	mov.f64 	%fd234, 0dBFF0000000000000;
	fma.rn.f64 	%fd332, %fd332, %fd234, %fd233;

BB54_46:
	@%p9 bra 	BB54_49;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd334;
	}
	setp.ne.s32	%p30, %r72, 0;
	@%p30 bra 	BB54_49;

	mov.f64 	%fd235, 0d0000000000000000;
	mul.rn.f64 	%fd334, %fd334, %fd235;

BB54_49:
	mul.f64 	%fd236, %fd334, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r98, %fd236;
	st.local.u32 	[%rd1], %r98;
	cvt.rn.f64.s32	%fd237, %r98;
	neg.f64 	%fd238, %fd237;
	fma.rn.f64 	%fd240, %fd238, %fd116, %fd334;
	fma.rn.f64 	%fd242, %fd238, %fd118, %fd240;
	fma.rn.f64 	%fd335, %fd238, %fd120, %fd242;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd334;
	}
	and.b32  	%r74, %r73, 2145386496;
	setp.lt.u32	%p31, %r74, 1105199104;
	@%p31 bra 	BB54_51;

	// Callseq Start 113
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd334;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd335, [retval0+0];
	
	//{
	}// Callseq End 113
	ld.local.u32 	%r98, [%rd1];

BB54_51:
	and.b32  	%r75, %r98, 1;
	shl.b32 	%r76, %r75, 3;
	setp.eq.s32	%p32, %r75, 0;
	selp.f64	%fd244, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	add.s32 	%r77, %r76, 1;
	mul.wide.s32 	%rd38, %r77, 8;
	add.s64 	%rd40, %rd19, %rd38;
	ld.const.f64 	%fd245, [%rd40];
	mul.rn.f64 	%fd74, %fd335, %fd335;
	fma.rn.f64 	%fd246, %fd244, %fd74, %fd245;
	ld.const.f64 	%fd247, [%rd40+8];
	fma.rn.f64 	%fd248, %fd246, %fd74, %fd247;
	ld.const.f64 	%fd249, [%rd40+16];
	fma.rn.f64 	%fd250, %fd248, %fd74, %fd249;
	ld.const.f64 	%fd251, [%rd40+24];
	fma.rn.f64 	%fd252, %fd250, %fd74, %fd251;
	ld.const.f64 	%fd253, [%rd40+32];
	fma.rn.f64 	%fd254, %fd252, %fd74, %fd253;
	ld.const.f64 	%fd255, [%rd40+40];
	fma.rn.f64 	%fd75, %fd254, %fd74, %fd255;
	fma.rn.f64 	%fd336, %fd75, %fd335, %fd335;
	@%p32 bra 	BB54_53;

	mov.f64 	%fd256, 0d3FF0000000000000;
	fma.rn.f64 	%fd336, %fd75, %fd74, %fd256;

BB54_53:
	and.b32  	%r78, %r98, 2;
	setp.eq.s32	%p33, %r78, 0;
	@%p33 bra 	BB54_55;

	mov.f64 	%fd257, 0d0000000000000000;
	mov.f64 	%fd258, 0dBFF0000000000000;
	fma.rn.f64 	%fd336, %fd336, %fd258, %fd257;

BB54_55:
	div.rn.f64 	%fd259, %fd336, 0dC022000000000000;
	add.f64 	%fd81, %fd332, %fd259;
	@%p14 bra 	BB54_58;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd338;
	}
	setp.ne.s32	%p35, %r79, 0;
	@%p35 bra 	BB54_58;

	mov.f64 	%fd260, 0d0000000000000000;
	mul.rn.f64 	%fd338, %fd338, %fd260;

BB54_58:
	mul.f64 	%fd261, %fd338, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r99, %fd261;
	st.local.u32 	[%rd1], %r99;
	cvt.rn.f64.s32	%fd262, %r99;
	neg.f64 	%fd263, %fd262;
	fma.rn.f64 	%fd265, %fd263, %fd116, %fd338;
	fma.rn.f64 	%fd267, %fd263, %fd118, %fd265;
	fma.rn.f64 	%fd339, %fd263, %fd120, %fd267;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd338;
	}
	and.b32  	%r81, %r80, 2145386496;
	setp.lt.u32	%p36, %r81, 1105199104;
	@%p36 bra 	BB54_60;

	// Callseq Start 114
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd338;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd339, [retval0+0];
	
	//{
	}// Callseq End 114
	ld.local.u32 	%r99, [%rd1];

BB54_60:
	and.b32  	%r82, %r99, 1;
	shl.b32 	%r83, %r82, 3;
	setp.eq.s32	%p37, %r82, 0;
	selp.f64	%fd269, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p37;
	add.s32 	%r84, %r83, 1;
	mul.wide.s32 	%rd42, %r84, 8;
	add.s64 	%rd44, %rd19, %rd42;
	ld.const.f64 	%fd270, [%rd44];
	mul.rn.f64 	%fd87, %fd339, %fd339;
	fma.rn.f64 	%fd271, %fd269, %fd87, %fd270;
	ld.const.f64 	%fd272, [%rd44+8];
	fma.rn.f64 	%fd273, %fd271, %fd87, %fd272;
	ld.const.f64 	%fd274, [%rd44+16];
	fma.rn.f64 	%fd275, %fd273, %fd87, %fd274;
	ld.const.f64 	%fd276, [%rd44+24];
	fma.rn.f64 	%fd277, %fd275, %fd87, %fd276;
	ld.const.f64 	%fd278, [%rd44+32];
	fma.rn.f64 	%fd279, %fd277, %fd87, %fd278;
	ld.const.f64 	%fd280, [%rd44+40];
	fma.rn.f64 	%fd88, %fd279, %fd87, %fd280;
	fma.rn.f64 	%fd340, %fd88, %fd339, %fd339;
	@%p37 bra 	BB54_62;

	mov.f64 	%fd281, 0d3FF0000000000000;
	fma.rn.f64 	%fd340, %fd88, %fd87, %fd281;

BB54_62:
	and.b32  	%r85, %r99, 2;
	setp.eq.s32	%p38, %r85, 0;
	@%p38 bra 	BB54_64;

	mov.f64 	%fd282, 0d0000000000000000;
	mov.f64 	%fd283, 0dBFF0000000000000;
	fma.rn.f64 	%fd340, %fd340, %fd283, %fd282;

BB54_64:
	div.rn.f64 	%fd284, %fd340, 0d4039000000000000;
	add.f64 	%fd94, %fd81, %fd284;
	@%p19 bra 	BB54_67;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd342;
	}
	setp.ne.s32	%p40, %r86, 0;
	@%p40 bra 	BB54_67;

	mov.f64 	%fd285, 0d0000000000000000;
	mul.rn.f64 	%fd342, %fd342, %fd285;

BB54_67:
	mul.f64 	%fd286, %fd342, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r100, %fd286;
	st.local.u32 	[%rd1], %r100;
	cvt.rn.f64.s32	%fd287, %r100;
	neg.f64 	%fd288, %fd287;
	fma.rn.f64 	%fd290, %fd288, %fd116, %fd342;
	fma.rn.f64 	%fd292, %fd288, %fd118, %fd290;
	fma.rn.f64 	%fd343, %fd288, %fd120, %fd292;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd342;
	}
	and.b32  	%r88, %r87, 2145386496;
	setp.lt.u32	%p41, %r88, 1105199104;
	@%p41 bra 	BB54_69;

	// Callseq Start 115
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd342;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd343, [retval0+0];
	
	//{
	}// Callseq End 115
	ld.local.u32 	%r100, [%rd1];

BB54_69:
	and.b32  	%r89, %r100, 1;
	shl.b32 	%r90, %r89, 3;
	setp.eq.s32	%p42, %r89, 0;
	selp.f64	%fd294, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p42;
	add.s32 	%r91, %r90, 1;
	mul.wide.s32 	%rd46, %r91, 8;
	add.s64 	%rd48, %rd19, %rd46;
	ld.const.f64 	%fd295, [%rd48];
	mul.rn.f64 	%fd100, %fd343, %fd343;
	fma.rn.f64 	%fd296, %fd294, %fd100, %fd295;
	ld.const.f64 	%fd297, [%rd48+8];
	fma.rn.f64 	%fd298, %fd296, %fd100, %fd297;
	ld.const.f64 	%fd299, [%rd48+16];
	fma.rn.f64 	%fd300, %fd298, %fd100, %fd299;
	ld.const.f64 	%fd301, [%rd48+24];
	fma.rn.f64 	%fd302, %fd300, %fd100, %fd301;
	ld.const.f64 	%fd303, [%rd48+32];
	fma.rn.f64 	%fd304, %fd302, %fd100, %fd303;
	ld.const.f64 	%fd305, [%rd48+40];
	fma.rn.f64 	%fd101, %fd304, %fd100, %fd305;
	fma.rn.f64 	%fd344, %fd101, %fd343, %fd343;
	@%p42 bra 	BB54_71;

	mov.f64 	%fd306, 0d3FF0000000000000;
	fma.rn.f64 	%fd344, %fd101, %fd100, %fd306;

BB54_71:
	and.b32  	%r92, %r100, 2;
	setp.eq.s32	%p43, %r92, 0;
	@%p43 bra 	BB54_73;

	mov.f64 	%fd307, 0d0000000000000000;
	mov.f64 	%fd308, 0dBFF0000000000000;
	fma.rn.f64 	%fd344, %fd344, %fd308, %fd307;

BB54_73:
	div.rn.f64 	%fd309, %fd344, 0dC048800000000000;
	add.f64 	%fd310, %fd94, %fd309;
	mul.f64 	%fd311, %fd109, 0d400921FB54442D18;
	mul.f64 	%fd312, %fd311, %fd110;
	fma.rn.f64 	%fd313, %fd312, %fd56, %fd310;
	mul.f64 	%fd346, %fd313, 0d3FF9F02F6222C720;

BB54_74:
	st.param.f64	[func_retval0+0], %fd346;
	ret;
}

	// .globl	_Z11Triangle_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Triangle_ttddPdiPii(
	.param .b64 _Z11Triangle_ttddPdiPii_param_0,
	.param .b64 _Z11Triangle_ttddPdiPii_param_1,
	.param .b64 _Z11Triangle_ttddPdiPii_param_2,
	.param .b32 _Z11Triangle_ttddPdiPii_param_3,
	.param .b64 _Z11Triangle_ttddPdiPii_param_4,
	.param .b32 _Z11Triangle_ttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot55[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<181>;
	.reg .b64 	%rd<29>;


	mov.u64 	%SPL, __local_depot55;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd58, [_Z11Triangle_ttddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z11Triangle_ttddPdiPii_param_1];
	mul.f64 	%fd1, %fd58, %fd60;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	setp.gt.f64	%p2, %fd1, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd180, 0d0000000000000000;
	@%p3 bra 	BB55_38;

	mul.f64 	%fd164, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd164;
	}
	and.b32  	%r14, %r13, 2147483647;
	setp.ne.s32	%p4, %r14, 2146435072;
	@%p4 bra 	BB55_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r15, %temp}, %fd164;
	}
	setp.ne.s32	%p5, %r15, 0;
	@%p5 bra 	BB55_4;

	mov.f64 	%fd61, 0d0000000000000000;
	mul.rn.f64 	%fd164, %fd164, %fd61;

BB55_4:
	mul.f64 	%fd62, %fd164, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r49, %fd62;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r49;
	cvt.rn.f64.s32	%fd63, %r49;
	neg.f64 	%fd64, %fd63;
	mov.f64 	%fd65, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd66, %fd64, %fd65, %fd164;
	mov.f64 	%fd67, 0d3C91A62633145C00;
	fma.rn.f64 	%fd68, %fd64, %fd67, %fd66;
	mov.f64 	%fd69, 0d397B839A252049C0;
	fma.rn.f64 	%fd165, %fd64, %fd69, %fd68;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd164;
	}
	and.b32  	%r17, %r16, 2145386496;
	setp.lt.u32	%p6, %r17, 1105199104;
	@%p6 bra 	BB55_6;

	// Callseq Start 116
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd164;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd165, [retval0+0];
	
	//{
	}// Callseq End 116
	ld.local.u32 	%r49, [%rd2];

BB55_6:
	and.b32  	%r18, %r49, 1;
	shl.b32 	%r19, %r18, 3;
	setp.eq.s32	%p7, %r18, 0;
	selp.f64	%fd70, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r20, %r19, 1;
	mul.wide.s32 	%rd5, %r20, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd71, [%rd7];
	mul.rn.f64 	%fd8, %fd165, %fd165;
	fma.rn.f64 	%fd72, %fd70, %fd8, %fd71;
	ld.const.f64 	%fd73, [%rd7+8];
	fma.rn.f64 	%fd74, %fd72, %fd8, %fd73;
	ld.const.f64 	%fd75, [%rd7+16];
	fma.rn.f64 	%fd76, %fd74, %fd8, %fd75;
	ld.const.f64 	%fd77, [%rd7+24];
	fma.rn.f64 	%fd78, %fd76, %fd8, %fd77;
	ld.const.f64 	%fd79, [%rd7+32];
	fma.rn.f64 	%fd80, %fd78, %fd8, %fd79;
	ld.const.f64 	%fd81, [%rd7+40];
	fma.rn.f64 	%fd9, %fd80, %fd8, %fd81;
	fma.rn.f64 	%fd166, %fd9, %fd165, %fd165;
	@%p7 bra 	BB55_8;

	mov.f64 	%fd82, 0d3FF0000000000000;
	fma.rn.f64 	%fd166, %fd9, %fd8, %fd82;

BB55_8:
	and.b32  	%r21, %r49, 2;
	setp.eq.s32	%p8, %r21, 0;
	@%p8 bra 	BB55_10;

	mov.f64 	%fd83, 0d0000000000000000;
	mov.f64 	%fd84, 0dBFF0000000000000;
	fma.rn.f64 	%fd166, %fd166, %fd84, %fd83;

BB55_10:
	mul.f64 	%fd168, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd168;
	}
	and.b32  	%r23, %r22, 2147483647;
	setp.ne.s32	%p9, %r23, 2146435072;
	@%p9 bra 	BB55_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd168;
	}
	setp.ne.s32	%p10, %r24, 0;
	@%p10 bra 	BB55_13;

	mov.f64 	%fd85, 0d0000000000000000;
	mul.rn.f64 	%fd168, %fd168, %fd85;

BB55_13:
	mul.f64 	%fd86, %fd168, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r50, %fd86;
	st.local.u32 	[%rd2], %r50;
	cvt.rn.f64.s32	%fd87, %r50;
	neg.f64 	%fd88, %fd87;
	fma.rn.f64 	%fd90, %fd88, %fd65, %fd168;
	fma.rn.f64 	%fd92, %fd88, %fd67, %fd90;
	fma.rn.f64 	%fd169, %fd88, %fd69, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd168;
	}
	and.b32  	%r26, %r25, 2145386496;
	setp.lt.u32	%p11, %r26, 1105199104;
	@%p11 bra 	BB55_15;

	// Callseq Start 117
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd168;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd169, [retval0+0];
	
	//{
	}// Callseq End 117
	ld.local.u32 	%r50, [%rd2];

BB55_15:
	and.b32  	%r27, %r50, 1;
	shl.b32 	%r28, %r27, 3;
	setp.eq.s32	%p12, %r27, 0;
	selp.f64	%fd94, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r29, %r28, 1;
	mul.wide.s32 	%rd12, %r29, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd95, [%rd14];
	mul.rn.f64 	%fd21, %fd169, %fd169;
	fma.rn.f64 	%fd96, %fd94, %fd21, %fd95;
	ld.const.f64 	%fd97, [%rd14+8];
	fma.rn.f64 	%fd98, %fd96, %fd21, %fd97;
	ld.const.f64 	%fd99, [%rd14+16];
	fma.rn.f64 	%fd100, %fd98, %fd21, %fd99;
	ld.const.f64 	%fd101, [%rd14+24];
	fma.rn.f64 	%fd102, %fd100, %fd21, %fd101;
	ld.const.f64 	%fd103, [%rd14+32];
	fma.rn.f64 	%fd104, %fd102, %fd21, %fd103;
	ld.const.f64 	%fd105, [%rd14+40];
	fma.rn.f64 	%fd22, %fd104, %fd21, %fd105;
	fma.rn.f64 	%fd170, %fd22, %fd169, %fd169;
	@%p12 bra 	BB55_17;

	mov.f64 	%fd106, 0d3FF0000000000000;
	fma.rn.f64 	%fd170, %fd22, %fd21, %fd106;

BB55_17:
	and.b32  	%r30, %r50, 2;
	setp.eq.s32	%p13, %r30, 0;
	@%p13 bra 	BB55_19;

	mov.f64 	%fd107, 0d0000000000000000;
	mov.f64 	%fd108, 0dBFF0000000000000;
	fma.rn.f64 	%fd170, %fd170, %fd108, %fd107;

BB55_19:
	sub.f64 	%fd28, %fd166, %fd170;
	mul.f64 	%fd172, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd172;
	}
	and.b32  	%r32, %r31, 2147483647;
	setp.ne.s32	%p14, %r32, 2146435072;
	@%p14 bra 	BB55_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd172;
	}
	setp.ne.s32	%p15, %r33, 0;
	@%p15 bra 	BB55_22;

	mov.f64 	%fd109, 0d0000000000000000;
	mul.rn.f64 	%fd172, %fd172, %fd109;

BB55_22:
	mul.f64 	%fd110, %fd172, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r51, %fd110;
	st.local.u32 	[%rd2], %r51;
	cvt.rn.f64.s32	%fd111, %r51;
	neg.f64 	%fd112, %fd111;
	fma.rn.f64 	%fd114, %fd112, %fd65, %fd172;
	fma.rn.f64 	%fd116, %fd112, %fd67, %fd114;
	fma.rn.f64 	%fd173, %fd112, %fd69, %fd116;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd172;
	}
	and.b32  	%r35, %r34, 2145386496;
	setp.lt.u32	%p16, %r35, 1105199104;
	@%p16 bra 	BB55_24;

	// Callseq Start 118
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd172;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd173, [retval0+0];
	
	//{
	}// Callseq End 118
	ld.local.u32 	%r51, [%rd2];

BB55_24:
	and.b32  	%r36, %r51, 1;
	shl.b32 	%r37, %r36, 3;
	setp.eq.s32	%p17, %r36, 0;
	selp.f64	%fd118, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r38, %r37, 1;
	mul.wide.s32 	%rd19, %r38, 8;
	add.s64 	%rd21, %rd6, %rd19;
	ld.const.f64 	%fd119, [%rd21];
	mul.rn.f64 	%fd35, %fd173, %fd173;
	fma.rn.f64 	%fd120, %fd118, %fd35, %fd119;
	ld.const.f64 	%fd121, [%rd21+8];
	fma.rn.f64 	%fd122, %fd120, %fd35, %fd121;
	ld.const.f64 	%fd123, [%rd21+16];
	fma.rn.f64 	%fd124, %fd122, %fd35, %fd123;
	ld.const.f64 	%fd125, [%rd21+24];
	fma.rn.f64 	%fd126, %fd124, %fd35, %fd125;
	ld.const.f64 	%fd127, [%rd21+32];
	fma.rn.f64 	%fd128, %fd126, %fd35, %fd127;
	ld.const.f64 	%fd129, [%rd21+40];
	fma.rn.f64 	%fd36, %fd128, %fd35, %fd129;
	fma.rn.f64 	%fd174, %fd36, %fd173, %fd173;
	@%p17 bra 	BB55_26;

	mov.f64 	%fd130, 0d3FF0000000000000;
	fma.rn.f64 	%fd174, %fd36, %fd35, %fd130;

BB55_26:
	and.b32  	%r39, %r51, 2;
	setp.eq.s32	%p18, %r39, 0;
	@%p18 bra 	BB55_28;

	mov.f64 	%fd131, 0d0000000000000000;
	mov.f64 	%fd132, 0dBFF0000000000000;
	fma.rn.f64 	%fd174, %fd174, %fd132, %fd131;

BB55_28:
	add.f64 	%fd42, %fd28, %fd174;
	mul.f64 	%fd176, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd176;
	}
	and.b32  	%r41, %r40, 2147483647;
	setp.ne.s32	%p19, %r41, 2146435072;
	@%p19 bra 	BB55_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd176;
	}
	setp.ne.s32	%p20, %r42, 0;
	@%p20 bra 	BB55_31;

	mov.f64 	%fd133, 0d0000000000000000;
	mul.rn.f64 	%fd176, %fd176, %fd133;

BB55_31:
	mul.f64 	%fd134, %fd176, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r52, %fd134;
	st.local.u32 	[%rd2], %r52;
	cvt.rn.f64.s32	%fd135, %r52;
	neg.f64 	%fd136, %fd135;
	fma.rn.f64 	%fd138, %fd136, %fd65, %fd176;
	fma.rn.f64 	%fd140, %fd136, %fd67, %fd138;
	fma.rn.f64 	%fd177, %fd136, %fd69, %fd140;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd176;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p21, %r44, 1105199104;
	@%p21 bra 	BB55_33;

	// Callseq Start 119
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd176;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd177, [retval0+0];
	
	//{
	}// Callseq End 119
	ld.local.u32 	%r52, [%rd2];

BB55_33:
	and.b32  	%r45, %r52, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p22, %r45, 0;
	selp.f64	%fd142, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd26, %r47, 8;
	add.s64 	%rd28, %rd6, %rd26;
	ld.const.f64 	%fd143, [%rd28];
	mul.rn.f64 	%fd49, %fd177, %fd177;
	fma.rn.f64 	%fd144, %fd142, %fd49, %fd143;
	ld.const.f64 	%fd145, [%rd28+8];
	fma.rn.f64 	%fd146, %fd144, %fd49, %fd145;
	ld.const.f64 	%fd147, [%rd28+16];
	fma.rn.f64 	%fd148, %fd146, %fd49, %fd147;
	ld.const.f64 	%fd149, [%rd28+24];
	fma.rn.f64 	%fd150, %fd148, %fd49, %fd149;
	ld.const.f64 	%fd151, [%rd28+32];
	fma.rn.f64 	%fd152, %fd150, %fd49, %fd151;
	ld.const.f64 	%fd153, [%rd28+40];
	fma.rn.f64 	%fd50, %fd152, %fd49, %fd153;
	fma.rn.f64 	%fd178, %fd50, %fd177, %fd177;
	@%p22 bra 	BB55_35;

	mov.f64 	%fd154, 0d3FF0000000000000;
	fma.rn.f64 	%fd178, %fd50, %fd49, %fd154;

BB55_35:
	and.b32  	%r48, %r52, 2;
	setp.eq.s32	%p23, %r48, 0;
	@%p23 bra 	BB55_37;

	mov.f64 	%fd155, 0d0000000000000000;
	mov.f64 	%fd156, 0dBFF0000000000000;
	fma.rn.f64 	%fd178, %fd178, %fd156, %fd155;

BB55_37:
	sub.f64 	%fd157, %fd42, %fd178;
	add.f64 	%fd158, %fd58, %fd58;
	mul.f64 	%fd159, %fd158, 0d4020000000000000;
	div.rn.f64 	%fd160, %fd159, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd161, %fd58, 0dC023BD3CC9BE45DE;
	mul.f64 	%fd162, %fd161, %fd58;
	mul.f64 	%fd163, %fd162, %fd160;
	mul.f64 	%fd180, %fd163, %fd157;

BB55_38:
	st.param.f64	[func_retval0+0], %fd180;
	ret;
}

	// .globl	_Z12Triangle_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12Triangle_tttddPdiPii(
	.param .b64 _Z12Triangle_tttddPdiPii_param_0,
	.param .b64 _Z12Triangle_tttddPdiPii_param_1,
	.param .b64 _Z12Triangle_tttddPdiPii_param_2,
	.param .b32 _Z12Triangle_tttddPdiPii_param_3,
	.param .b64 _Z12Triangle_tttddPdiPii_param_4,
	.param .b32 _Z12Triangle_tttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot56[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<182>;
	.reg .b64 	%rd<29>;


	mov.u64 	%SPL, __local_depot56;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd58, [_Z12Triangle_tttddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z12Triangle_tttddPdiPii_param_1];
	mul.f64 	%fd1, %fd58, %fd60;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	setp.gt.f64	%p2, %fd1, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd181, 0d0000000000000000;
	@%p3 bra 	BB56_38;

	mul.f64 	%fd165, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd165;
	}
	and.b32  	%r18, %r17, 2147483647;
	setp.ne.s32	%p4, %r18, 2146435072;
	@%p4 bra 	BB56_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd165;
	}
	setp.ne.s32	%p5, %r19, 0;
	@%p5 bra 	BB56_4;

	mov.f64 	%fd61, 0d0000000000000000;
	mul.rn.f64 	%fd165, %fd165, %fd61;

BB56_4:
	mul.f64 	%fd62, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd62;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r53;
	cvt.rn.f64.s32	%fd63, %r53;
	neg.f64 	%fd64, %fd63;
	mov.f64 	%fd65, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd66, %fd64, %fd65, %fd165;
	mov.f64 	%fd67, 0d3C91A62633145C00;
	fma.rn.f64 	%fd68, %fd64, %fd67, %fd66;
	mov.f64 	%fd69, 0d397B839A252049C0;
	fma.rn.f64 	%fd166, %fd64, %fd69, %fd68;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd165;
	}
	and.b32  	%r21, %r20, 2145386496;
	setp.lt.u32	%p6, %r21, 1105199104;
	@%p6 bra 	BB56_6;

	// Callseq Start 120
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd166, [retval0+0];
	
	//{
	}// Callseq End 120
	ld.local.u32 	%r53, [%rd2];

BB56_6:
	add.s32 	%r4, %r53, 1;
	and.b32  	%r22, %r4, 1;
	shl.b32 	%r23, %r22, 3;
	setp.eq.s32	%p7, %r22, 0;
	selp.f64	%fd70, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r24, %r23, 1;
	mul.wide.s32 	%rd5, %r24, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd71, [%rd7];
	mul.rn.f64 	%fd8, %fd166, %fd166;
	fma.rn.f64 	%fd72, %fd70, %fd8, %fd71;
	ld.const.f64 	%fd73, [%rd7+8];
	fma.rn.f64 	%fd74, %fd72, %fd8, %fd73;
	ld.const.f64 	%fd75, [%rd7+16];
	fma.rn.f64 	%fd76, %fd74, %fd8, %fd75;
	ld.const.f64 	%fd77, [%rd7+24];
	fma.rn.f64 	%fd78, %fd76, %fd8, %fd77;
	ld.const.f64 	%fd79, [%rd7+32];
	fma.rn.f64 	%fd80, %fd78, %fd8, %fd79;
	ld.const.f64 	%fd81, [%rd7+40];
	fma.rn.f64 	%fd9, %fd80, %fd8, %fd81;
	fma.rn.f64 	%fd167, %fd9, %fd166, %fd166;
	@%p7 bra 	BB56_8;

	mov.f64 	%fd82, 0d3FF0000000000000;
	fma.rn.f64 	%fd167, %fd9, %fd8, %fd82;

BB56_8:
	and.b32  	%r25, %r4, 2;
	setp.eq.s32	%p8, %r25, 0;
	@%p8 bra 	BB56_10;

	mov.f64 	%fd83, 0d0000000000000000;
	mov.f64 	%fd84, 0dBFF0000000000000;
	fma.rn.f64 	%fd167, %fd167, %fd84, %fd83;

BB56_10:
	mul.f64 	%fd169, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd169;
	}
	and.b32  	%r27, %r26, 2147483647;
	setp.ne.s32	%p9, %r27, 2146435072;
	@%p9 bra 	BB56_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd169;
	}
	setp.ne.s32	%p10, %r28, 0;
	@%p10 bra 	BB56_13;

	mov.f64 	%fd85, 0d0000000000000000;
	mul.rn.f64 	%fd169, %fd169, %fd85;

BB56_13:
	mul.f64 	%fd86, %fd169, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd86;
	st.local.u32 	[%rd2], %r54;
	cvt.rn.f64.s32	%fd87, %r54;
	neg.f64 	%fd88, %fd87;
	fma.rn.f64 	%fd90, %fd88, %fd65, %fd169;
	fma.rn.f64 	%fd92, %fd88, %fd67, %fd90;
	fma.rn.f64 	%fd170, %fd88, %fd69, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd169;
	}
	and.b32  	%r30, %r29, 2145386496;
	setp.lt.u32	%p11, %r30, 1105199104;
	@%p11 bra 	BB56_15;

	// Callseq Start 121
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd169;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd170, [retval0+0];
	
	//{
	}// Callseq End 121
	ld.local.u32 	%r54, [%rd2];

BB56_15:
	add.s32 	%r8, %r54, 1;
	and.b32  	%r31, %r8, 1;
	shl.b32 	%r32, %r31, 3;
	setp.eq.s32	%p12, %r31, 0;
	selp.f64	%fd94, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r33, %r32, 1;
	mul.wide.s32 	%rd12, %r33, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd95, [%rd14];
	mul.rn.f64 	%fd21, %fd170, %fd170;
	fma.rn.f64 	%fd96, %fd94, %fd21, %fd95;
	ld.const.f64 	%fd97, [%rd14+8];
	fma.rn.f64 	%fd98, %fd96, %fd21, %fd97;
	ld.const.f64 	%fd99, [%rd14+16];
	fma.rn.f64 	%fd100, %fd98, %fd21, %fd99;
	ld.const.f64 	%fd101, [%rd14+24];
	fma.rn.f64 	%fd102, %fd100, %fd21, %fd101;
	ld.const.f64 	%fd103, [%rd14+32];
	fma.rn.f64 	%fd104, %fd102, %fd21, %fd103;
	ld.const.f64 	%fd105, [%rd14+40];
	fma.rn.f64 	%fd22, %fd104, %fd21, %fd105;
	fma.rn.f64 	%fd171, %fd22, %fd170, %fd170;
	@%p12 bra 	BB56_17;

	mov.f64 	%fd106, 0d3FF0000000000000;
	fma.rn.f64 	%fd171, %fd22, %fd21, %fd106;

BB56_17:
	and.b32  	%r34, %r8, 2;
	setp.eq.s32	%p13, %r34, 0;
	@%p13 bra 	BB56_19;

	mov.f64 	%fd107, 0d0000000000000000;
	mov.f64 	%fd108, 0dBFF0000000000000;
	fma.rn.f64 	%fd171, %fd171, %fd108, %fd107;

BB56_19:
	fma.rn.f64 	%fd28, %fd171, 0dC008000000000000, %fd167;
	mul.f64 	%fd173, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd173;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p14, %r36, 2146435072;
	@%p14 bra 	BB56_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd173;
	}
	setp.ne.s32	%p15, %r37, 0;
	@%p15 bra 	BB56_22;

	mov.f64 	%fd109, 0d0000000000000000;
	mul.rn.f64 	%fd173, %fd173, %fd109;

BB56_22:
	mul.f64 	%fd110, %fd173, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r55, %fd110;
	st.local.u32 	[%rd2], %r55;
	cvt.rn.f64.s32	%fd111, %r55;
	neg.f64 	%fd112, %fd111;
	fma.rn.f64 	%fd114, %fd112, %fd65, %fd173;
	fma.rn.f64 	%fd116, %fd112, %fd67, %fd114;
	fma.rn.f64 	%fd174, %fd112, %fd69, %fd116;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd173;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p16, %r39, 1105199104;
	@%p16 bra 	BB56_24;

	// Callseq Start 122
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd173;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd174, [retval0+0];
	
	//{
	}// Callseq End 122
	ld.local.u32 	%r55, [%rd2];

BB56_24:
	add.s32 	%r12, %r55, 1;
	and.b32  	%r40, %r12, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p17, %r40, 0;
	selp.f64	%fd118, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r42, %r41, 1;
	mul.wide.s32 	%rd19, %r42, 8;
	add.s64 	%rd21, %rd6, %rd19;
	ld.const.f64 	%fd119, [%rd21];
	mul.rn.f64 	%fd35, %fd174, %fd174;
	fma.rn.f64 	%fd120, %fd118, %fd35, %fd119;
	ld.const.f64 	%fd121, [%rd21+8];
	fma.rn.f64 	%fd122, %fd120, %fd35, %fd121;
	ld.const.f64 	%fd123, [%rd21+16];
	fma.rn.f64 	%fd124, %fd122, %fd35, %fd123;
	ld.const.f64 	%fd125, [%rd21+24];
	fma.rn.f64 	%fd126, %fd124, %fd35, %fd125;
	ld.const.f64 	%fd127, [%rd21+32];
	fma.rn.f64 	%fd128, %fd126, %fd35, %fd127;
	ld.const.f64 	%fd129, [%rd21+40];
	fma.rn.f64 	%fd36, %fd128, %fd35, %fd129;
	fma.rn.f64 	%fd175, %fd36, %fd174, %fd174;
	@%p17 bra 	BB56_26;

	mov.f64 	%fd130, 0d3FF0000000000000;
	fma.rn.f64 	%fd175, %fd36, %fd35, %fd130;

BB56_26:
	and.b32  	%r43, %r12, 2;
	setp.eq.s32	%p18, %r43, 0;
	@%p18 bra 	BB56_28;

	mov.f64 	%fd131, 0d0000000000000000;
	mov.f64 	%fd132, 0dBFF0000000000000;
	fma.rn.f64 	%fd175, %fd175, %fd132, %fd131;

BB56_28:
	fma.rn.f64 	%fd42, %fd175, 0d4014000000000000, %fd28;
	mul.f64 	%fd177, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd177;
	}
	and.b32  	%r45, %r44, 2147483647;
	setp.ne.s32	%p19, %r45, 2146435072;
	@%p19 bra 	BB56_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd177;
	}
	setp.ne.s32	%p20, %r46, 0;
	@%p20 bra 	BB56_31;

	mov.f64 	%fd133, 0d0000000000000000;
	mul.rn.f64 	%fd177, %fd177, %fd133;

BB56_31:
	mul.f64 	%fd134, %fd177, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r56, %fd134;
	st.local.u32 	[%rd2], %r56;
	cvt.rn.f64.s32	%fd135, %r56;
	neg.f64 	%fd136, %fd135;
	fma.rn.f64 	%fd138, %fd136, %fd65, %fd177;
	fma.rn.f64 	%fd140, %fd136, %fd67, %fd138;
	fma.rn.f64 	%fd178, %fd136, %fd69, %fd140;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd177;
	}
	and.b32  	%r48, %r47, 2145386496;
	setp.lt.u32	%p21, %r48, 1105199104;
	@%p21 bra 	BB56_33;

	// Callseq Start 123
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd177;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd178, [retval0+0];
	
	//{
	}// Callseq End 123
	ld.local.u32 	%r56, [%rd2];

BB56_33:
	add.s32 	%r16, %r56, 1;
	and.b32  	%r49, %r16, 1;
	shl.b32 	%r50, %r49, 3;
	setp.eq.s32	%p22, %r49, 0;
	selp.f64	%fd142, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r51, %r50, 1;
	mul.wide.s32 	%rd26, %r51, 8;
	add.s64 	%rd28, %rd6, %rd26;
	ld.const.f64 	%fd143, [%rd28];
	mul.rn.f64 	%fd49, %fd178, %fd178;
	fma.rn.f64 	%fd144, %fd142, %fd49, %fd143;
	ld.const.f64 	%fd145, [%rd28+8];
	fma.rn.f64 	%fd146, %fd144, %fd49, %fd145;
	ld.const.f64 	%fd147, [%rd28+16];
	fma.rn.f64 	%fd148, %fd146, %fd49, %fd147;
	ld.const.f64 	%fd149, [%rd28+24];
	fma.rn.f64 	%fd150, %fd148, %fd49, %fd149;
	ld.const.f64 	%fd151, [%rd28+32];
	fma.rn.f64 	%fd152, %fd150, %fd49, %fd151;
	ld.const.f64 	%fd153, [%rd28+40];
	fma.rn.f64 	%fd50, %fd152, %fd49, %fd153;
	fma.rn.f64 	%fd179, %fd50, %fd178, %fd178;
	@%p22 bra 	BB56_35;

	mov.f64 	%fd154, 0d3FF0000000000000;
	fma.rn.f64 	%fd179, %fd50, %fd49, %fd154;

BB56_35:
	and.b32  	%r52, %r16, 2;
	setp.eq.s32	%p23, %r52, 0;
	@%p23 bra 	BB56_37;

	mov.f64 	%fd155, 0d0000000000000000;
	mov.f64 	%fd156, 0dBFF0000000000000;
	fma.rn.f64 	%fd179, %fd179, %fd156, %fd155;

BB56_37:
	fma.rn.f64 	%fd157, %fd179, 0dC01C000000000000, %fd42;
	add.f64 	%fd158, %fd58, %fd58;
	mul.f64 	%fd159, %fd158, 0d4020000000000000;
	div.rn.f64 	%fd160, %fd159, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd161, %fd58, 0dC03F019B59389D7B;
	mul.f64 	%fd162, %fd161, %fd58;
	mul.f64 	%fd163, %fd162, %fd58;
	mul.f64 	%fd164, %fd163, %fd160;
	mul.f64 	%fd181, %fd164, %fd157;

BB56_38:
	st.param.f64	[func_retval0+0], %fd181;
	ret;
}

	// .globl	_Z13Triangle_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Triangle_omttddPdiPii(
	.param .b64 _Z13Triangle_omttddPdiPii_param_0,
	.param .b64 _Z13Triangle_omttddPdiPii_param_1,
	.param .b64 _Z13Triangle_omttddPdiPii_param_2,
	.param .b32 _Z13Triangle_omttddPdiPii_param_3,
	.param .b64 _Z13Triangle_omttddPdiPii_param_4,
	.param .b32 _Z13Triangle_omttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot57[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<44>;
	.reg .b32 	%r<101>;
	.reg .f64 	%fd<347>;
	.reg .b64 	%rd<49>;


	mov.u64 	%SPL, __local_depot57;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd109, [_Z13Triangle_omttddPdiPii_param_0];
	ld.param.f64 	%fd111, [_Z13Triangle_omttddPdiPii_param_1];
	add.u64 	%rd9, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd9;
	mul.f64 	%fd1, %fd109, %fd111;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	setp.gt.f64	%p2, %fd1, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd346, 0d0000000000000000;
	@%p3 bra 	BB57_74;

	mul.f64 	%fd2, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd2;
	}
	and.b32  	%r1, %r33, 2147483647;
	setp.ne.s32	%p4, %r1, 2146435072;
	mov.f64 	%fd314, %fd2;
	@%p4 bra 	BB57_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd2;
	}
	setp.ne.s32	%p5, %r34, 0;
	mov.f64 	%fd314, %fd2;
	@%p5 bra 	BB57_4;

	mov.f64 	%fd112, 0d0000000000000000;
	mul.rn.f64 	%fd314, %fd2, %fd112;

BB57_4:
	mul.f64 	%fd113, %fd314, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r93, %fd113;
	st.local.u32 	[%rd1], %r93;
	cvt.rn.f64.s32	%fd114, %r93;
	neg.f64 	%fd115, %fd114;
	mov.f64 	%fd116, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd117, %fd115, %fd116, %fd314;
	mov.f64 	%fd118, 0d3C91A62633145C00;
	fma.rn.f64 	%fd119, %fd115, %fd118, %fd117;
	mov.f64 	%fd120, 0d397B839A252049C0;
	fma.rn.f64 	%fd315, %fd115, %fd120, %fd119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd314;
	}
	and.b32  	%r36, %r35, 2145386496;
	setp.lt.u32	%p6, %r36, 1105199104;
	@%p6 bra 	BB57_6;

	// Callseq Start 124
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd314;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd315, [retval0+0];
	
	//{
	}// Callseq End 124
	ld.local.u32 	%r93, [%rd1];

BB57_6:
	and.b32  	%r37, %r93, 1;
	shl.b32 	%r38, %r37, 3;
	setp.eq.s32	%p7, %r37, 0;
	selp.f64	%fd121, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r39, %r38, 1;
	mul.wide.s32 	%rd18, %r39, 8;
	mov.u64 	%rd19, __cudart_sin_cos_coeffs;
	add.s64 	%rd20, %rd19, %rd18;
	ld.const.f64 	%fd122, [%rd20];
	mul.rn.f64 	%fd8, %fd315, %fd315;
	fma.rn.f64 	%fd123, %fd121, %fd8, %fd122;
	ld.const.f64 	%fd124, [%rd20+8];
	fma.rn.f64 	%fd125, %fd123, %fd8, %fd124;
	ld.const.f64 	%fd126, [%rd20+16];
	fma.rn.f64 	%fd127, %fd125, %fd8, %fd126;
	ld.const.f64 	%fd128, [%rd20+24];
	fma.rn.f64 	%fd129, %fd127, %fd8, %fd128;
	ld.const.f64 	%fd130, [%rd20+32];
	fma.rn.f64 	%fd131, %fd129, %fd8, %fd130;
	ld.const.f64 	%fd132, [%rd20+40];
	fma.rn.f64 	%fd9, %fd131, %fd8, %fd132;
	fma.rn.f64 	%fd316, %fd9, %fd315, %fd315;
	@%p7 bra 	BB57_8;

	mov.f64 	%fd133, 0d3FF0000000000000;
	fma.rn.f64 	%fd316, %fd9, %fd8, %fd133;

BB57_8:
	and.b32  	%r40, %r93, 2;
	setp.eq.s32	%p8, %r40, 0;
	@%p8 bra 	BB57_10;

	mov.f64 	%fd134, 0d0000000000000000;
	mov.f64 	%fd135, 0dBFF0000000000000;
	fma.rn.f64 	%fd316, %fd316, %fd135, %fd134;

BB57_10:
	mul.f64 	%fd334, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd334;
	}
	and.b32  	%r5, %r41, 2147483647;
	setp.ne.s32	%p9, %r5, 2146435072;
	mov.f64 	%fd318, %fd334;
	@%p9 bra 	BB57_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd334;
	}
	setp.ne.s32	%p10, %r42, 0;
	mov.f64 	%fd318, %fd334;
	@%p10 bra 	BB57_13;

	mov.f64 	%fd136, 0d0000000000000000;
	mul.rn.f64 	%fd318, %fd334, %fd136;

BB57_13:
	mul.f64 	%fd137, %fd318, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r94, %fd137;
	st.local.u32 	[%rd1], %r94;
	cvt.rn.f64.s32	%fd138, %r94;
	neg.f64 	%fd139, %fd138;
	fma.rn.f64 	%fd141, %fd139, %fd116, %fd318;
	fma.rn.f64 	%fd143, %fd139, %fd118, %fd141;
	fma.rn.f64 	%fd319, %fd139, %fd120, %fd143;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd318;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p11, %r44, 1105199104;
	@%p11 bra 	BB57_15;

	// Callseq Start 125
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd318;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd319, [retval0+0];
	
	//{
	}// Callseq End 125
	ld.local.u32 	%r94, [%rd1];

BB57_15:
	and.b32  	%r45, %r94, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p12, %r45, 0;
	selp.f64	%fd145, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd22, %r47, 8;
	add.s64 	%rd24, %rd19, %rd22;
	ld.const.f64 	%fd146, [%rd24];
	mul.rn.f64 	%fd21, %fd319, %fd319;
	fma.rn.f64 	%fd147, %fd145, %fd21, %fd146;
	ld.const.f64 	%fd148, [%rd24+8];
	fma.rn.f64 	%fd149, %fd147, %fd21, %fd148;
	ld.const.f64 	%fd150, [%rd24+16];
	fma.rn.f64 	%fd151, %fd149, %fd21, %fd150;
	ld.const.f64 	%fd152, [%rd24+24];
	fma.rn.f64 	%fd153, %fd151, %fd21, %fd152;
	ld.const.f64 	%fd154, [%rd24+32];
	fma.rn.f64 	%fd155, %fd153, %fd21, %fd154;
	ld.const.f64 	%fd156, [%rd24+40];
	fma.rn.f64 	%fd22, %fd155, %fd21, %fd156;
	fma.rn.f64 	%fd320, %fd22, %fd319, %fd319;
	@%p12 bra 	BB57_17;

	mov.f64 	%fd157, 0d3FF0000000000000;
	fma.rn.f64 	%fd320, %fd22, %fd21, %fd157;

BB57_17:
	and.b32  	%r48, %r94, 2;
	setp.eq.s32	%p13, %r48, 0;
	@%p13 bra 	BB57_19;

	mov.f64 	%fd158, 0d0000000000000000;
	mov.f64 	%fd159, 0dBFF0000000000000;
	fma.rn.f64 	%fd320, %fd320, %fd159, %fd158;

BB57_19:
	sub.f64 	%fd28, %fd316, %fd320;
	mul.f64 	%fd338, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd338;
	}
	and.b32  	%r9, %r49, 2147483647;
	setp.ne.s32	%p14, %r9, 2146435072;
	mov.f64 	%fd322, %fd338;
	@%p14 bra 	BB57_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd338;
	}
	setp.ne.s32	%p15, %r50, 0;
	mov.f64 	%fd322, %fd338;
	@%p15 bra 	BB57_22;

	mov.f64 	%fd160, 0d0000000000000000;
	mul.rn.f64 	%fd322, %fd338, %fd160;

BB57_22:
	mul.f64 	%fd161, %fd322, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r95, %fd161;
	st.local.u32 	[%rd1], %r95;
	cvt.rn.f64.s32	%fd162, %r95;
	neg.f64 	%fd163, %fd162;
	fma.rn.f64 	%fd165, %fd163, %fd116, %fd322;
	fma.rn.f64 	%fd167, %fd163, %fd118, %fd165;
	fma.rn.f64 	%fd323, %fd163, %fd120, %fd167;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd322;
	}
	and.b32  	%r52, %r51, 2145386496;
	setp.lt.u32	%p16, %r52, 1105199104;
	@%p16 bra 	BB57_24;

	// Callseq Start 126
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd322;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd323, [retval0+0];
	
	//{
	}// Callseq End 126
	ld.local.u32 	%r95, [%rd1];

BB57_24:
	and.b32  	%r53, %r95, 1;
	shl.b32 	%r54, %r53, 3;
	setp.eq.s32	%p17, %r53, 0;
	selp.f64	%fd169, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r55, %r54, 1;
	mul.wide.s32 	%rd26, %r55, 8;
	add.s64 	%rd28, %rd19, %rd26;
	ld.const.f64 	%fd170, [%rd28];
	mul.rn.f64 	%fd35, %fd323, %fd323;
	fma.rn.f64 	%fd171, %fd169, %fd35, %fd170;
	ld.const.f64 	%fd172, [%rd28+8];
	fma.rn.f64 	%fd173, %fd171, %fd35, %fd172;
	ld.const.f64 	%fd174, [%rd28+16];
	fma.rn.f64 	%fd175, %fd173, %fd35, %fd174;
	ld.const.f64 	%fd176, [%rd28+24];
	fma.rn.f64 	%fd177, %fd175, %fd35, %fd176;
	ld.const.f64 	%fd178, [%rd28+32];
	fma.rn.f64 	%fd179, %fd177, %fd35, %fd178;
	ld.const.f64 	%fd180, [%rd28+40];
	fma.rn.f64 	%fd36, %fd179, %fd35, %fd180;
	fma.rn.f64 	%fd324, %fd36, %fd323, %fd323;
	@%p17 bra 	BB57_26;

	mov.f64 	%fd181, 0d3FF0000000000000;
	fma.rn.f64 	%fd324, %fd36, %fd35, %fd181;

BB57_26:
	and.b32  	%r56, %r95, 2;
	setp.eq.s32	%p18, %r56, 0;
	@%p18 bra 	BB57_28;

	mov.f64 	%fd182, 0d0000000000000000;
	mov.f64 	%fd183, 0dBFF0000000000000;
	fma.rn.f64 	%fd324, %fd324, %fd183, %fd182;

BB57_28:
	add.f64 	%fd42, %fd28, %fd324;
	mul.f64 	%fd342, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r57}, %fd342;
	}
	and.b32  	%r13, %r57, 2147483647;
	setp.ne.s32	%p19, %r13, 2146435072;
	mov.f64 	%fd326, %fd342;
	@%p19 bra 	BB57_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd342;
	}
	setp.ne.s32	%p20, %r58, 0;
	mov.f64 	%fd326, %fd342;
	@%p20 bra 	BB57_31;

	mov.f64 	%fd184, 0d0000000000000000;
	mul.rn.f64 	%fd326, %fd342, %fd184;

BB57_31:
	mul.f64 	%fd185, %fd326, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r96, %fd185;
	st.local.u32 	[%rd1], %r96;
	cvt.rn.f64.s32	%fd186, %r96;
	neg.f64 	%fd187, %fd186;
	fma.rn.f64 	%fd189, %fd187, %fd116, %fd326;
	fma.rn.f64 	%fd191, %fd187, %fd118, %fd189;
	fma.rn.f64 	%fd327, %fd187, %fd120, %fd191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd326;
	}
	and.b32  	%r60, %r59, 2145386496;
	setp.lt.u32	%p21, %r60, 1105199104;
	@%p21 bra 	BB57_33;

	// Callseq Start 127
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd326;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd327, [retval0+0];
	
	//{
	}// Callseq End 127
	ld.local.u32 	%r96, [%rd1];

BB57_33:
	and.b32  	%r61, %r96, 1;
	shl.b32 	%r62, %r61, 3;
	setp.eq.s32	%p22, %r61, 0;
	selp.f64	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r63, %r62, 1;
	mul.wide.s32 	%rd30, %r63, 8;
	add.s64 	%rd32, %rd19, %rd30;
	ld.const.f64 	%fd194, [%rd32];
	mul.rn.f64 	%fd49, %fd327, %fd327;
	fma.rn.f64 	%fd195, %fd193, %fd49, %fd194;
	ld.const.f64 	%fd196, [%rd32+8];
	fma.rn.f64 	%fd197, %fd195, %fd49, %fd196;
	ld.const.f64 	%fd198, [%rd32+16];
	fma.rn.f64 	%fd199, %fd197, %fd49, %fd198;
	ld.const.f64 	%fd200, [%rd32+24];
	fma.rn.f64 	%fd201, %fd199, %fd49, %fd200;
	ld.const.f64 	%fd202, [%rd32+32];
	fma.rn.f64 	%fd203, %fd201, %fd49, %fd202;
	ld.const.f64 	%fd204, [%rd32+40];
	fma.rn.f64 	%fd50, %fd203, %fd49, %fd204;
	fma.rn.f64 	%fd328, %fd50, %fd327, %fd327;
	@%p22 bra 	BB57_35;

	mov.f64 	%fd205, 0d3FF0000000000000;
	fma.rn.f64 	%fd328, %fd50, %fd49, %fd205;

BB57_35:
	and.b32  	%r64, %r96, 2;
	setp.eq.s32	%p23, %r64, 0;
	@%p23 bra 	BB57_37;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd328, %fd328, %fd207, %fd206;

BB57_37:
	sub.f64 	%fd56, %fd42, %fd328;
	mov.f64 	%fd330, %fd2;
	@%p4 bra 	BB57_40;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r65, %temp}, %fd2;
	}
	setp.ne.s32	%p25, %r65, 0;
	mov.f64 	%fd330, %fd2;
	@%p25 bra 	BB57_40;

	mov.f64 	%fd208, 0d0000000000000000;
	mul.rn.f64 	%fd330, %fd2, %fd208;

BB57_40:
	mul.f64 	%fd209, %fd330, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r97, %fd209;
	st.local.u32 	[%rd1], %r97;
	cvt.rn.f64.s32	%fd210, %r97;
	neg.f64 	%fd211, %fd210;
	fma.rn.f64 	%fd213, %fd211, %fd116, %fd330;
	fma.rn.f64 	%fd215, %fd211, %fd118, %fd213;
	fma.rn.f64 	%fd331, %fd211, %fd120, %fd215;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd330;
	}
	and.b32  	%r67, %r66, 2145386496;
	setp.lt.u32	%p26, %r67, 1105199104;
	@%p26 bra 	BB57_42;

	// Callseq Start 128
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd330;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd331, [retval0+0];
	
	//{
	}// Callseq End 128
	ld.local.u32 	%r97, [%rd1];

BB57_42:
	add.s32 	%r20, %r97, 1;
	and.b32  	%r68, %r20, 1;
	shl.b32 	%r69, %r68, 3;
	setp.eq.s32	%p27, %r68, 0;
	selp.f64	%fd217, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p27;
	add.s32 	%r70, %r69, 1;
	mul.wide.s32 	%rd34, %r70, 8;
	add.s64 	%rd36, %rd19, %rd34;
	ld.const.f64 	%fd218, [%rd36];
	mul.rn.f64 	%fd62, %fd331, %fd331;
	fma.rn.f64 	%fd219, %fd217, %fd62, %fd218;
	ld.const.f64 	%fd220, [%rd36+8];
	fma.rn.f64 	%fd221, %fd219, %fd62, %fd220;
	ld.const.f64 	%fd222, [%rd36+16];
	fma.rn.f64 	%fd223, %fd221, %fd62, %fd222;
	ld.const.f64 	%fd224, [%rd36+24];
	fma.rn.f64 	%fd225, %fd223, %fd62, %fd224;
	ld.const.f64 	%fd226, [%rd36+32];
	fma.rn.f64 	%fd227, %fd225, %fd62, %fd226;
	ld.const.f64 	%fd228, [%rd36+40];
	fma.rn.f64 	%fd63, %fd227, %fd62, %fd228;
	fma.rn.f64 	%fd332, %fd63, %fd331, %fd331;
	@%p27 bra 	BB57_44;

	mov.f64 	%fd229, 0d3FF0000000000000;
	fma.rn.f64 	%fd332, %fd63, %fd62, %fd229;

BB57_44:
	and.b32  	%r71, %r20, 2;
	setp.eq.s32	%p28, %r71, 0;
	@%p28 bra 	BB57_46;

	mov.f64 	%fd230, 0d0000000000000000;
	mov.f64 	%fd231, 0dBFF0000000000000;
	fma.rn.f64 	%fd332, %fd332, %fd231, %fd230;

BB57_46:
	@%p9 bra 	BB57_49;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd334;
	}
	setp.ne.s32	%p30, %r72, 0;
	@%p30 bra 	BB57_49;

	mov.f64 	%fd232, 0d0000000000000000;
	mul.rn.f64 	%fd334, %fd334, %fd232;

BB57_49:
	mul.f64 	%fd233, %fd334, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r98, %fd233;
	st.local.u32 	[%rd1], %r98;
	cvt.rn.f64.s32	%fd234, %r98;
	neg.f64 	%fd235, %fd234;
	fma.rn.f64 	%fd237, %fd235, %fd116, %fd334;
	fma.rn.f64 	%fd239, %fd235, %fd118, %fd237;
	fma.rn.f64 	%fd335, %fd235, %fd120, %fd239;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd334;
	}
	and.b32  	%r74, %r73, 2145386496;
	setp.lt.u32	%p31, %r74, 1105199104;
	@%p31 bra 	BB57_51;

	// Callseq Start 129
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd334;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd335, [retval0+0];
	
	//{
	}// Callseq End 129
	ld.local.u32 	%r98, [%rd1];

BB57_51:
	add.s32 	%r24, %r98, 1;
	and.b32  	%r75, %r24, 1;
	shl.b32 	%r76, %r75, 3;
	setp.eq.s32	%p32, %r75, 0;
	selp.f64	%fd241, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	add.s32 	%r77, %r76, 1;
	mul.wide.s32 	%rd38, %r77, 8;
	add.s64 	%rd40, %rd19, %rd38;
	ld.const.f64 	%fd242, [%rd40];
	mul.rn.f64 	%fd74, %fd335, %fd335;
	fma.rn.f64 	%fd243, %fd241, %fd74, %fd242;
	ld.const.f64 	%fd244, [%rd40+8];
	fma.rn.f64 	%fd245, %fd243, %fd74, %fd244;
	ld.const.f64 	%fd246, [%rd40+16];
	fma.rn.f64 	%fd247, %fd245, %fd74, %fd246;
	ld.const.f64 	%fd248, [%rd40+24];
	fma.rn.f64 	%fd249, %fd247, %fd74, %fd248;
	ld.const.f64 	%fd250, [%rd40+32];
	fma.rn.f64 	%fd251, %fd249, %fd74, %fd250;
	ld.const.f64 	%fd252, [%rd40+40];
	fma.rn.f64 	%fd75, %fd251, %fd74, %fd252;
	fma.rn.f64 	%fd336, %fd75, %fd335, %fd335;
	@%p32 bra 	BB57_53;

	mov.f64 	%fd253, 0d3FF0000000000000;
	fma.rn.f64 	%fd336, %fd75, %fd74, %fd253;

BB57_53:
	and.b32  	%r78, %r24, 2;
	setp.eq.s32	%p33, %r78, 0;
	@%p33 bra 	BB57_55;

	mov.f64 	%fd254, 0d0000000000000000;
	mov.f64 	%fd255, 0dBFF0000000000000;
	fma.rn.f64 	%fd336, %fd336, %fd255, %fd254;

BB57_55:
	fma.rn.f64 	%fd81, %fd336, 0dC008000000000000, %fd332;
	@%p14 bra 	BB57_58;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd338;
	}
	setp.ne.s32	%p35, %r79, 0;
	@%p35 bra 	BB57_58;

	mov.f64 	%fd256, 0d0000000000000000;
	mul.rn.f64 	%fd338, %fd338, %fd256;

BB57_58:
	mul.f64 	%fd257, %fd338, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r99, %fd257;
	st.local.u32 	[%rd1], %r99;
	cvt.rn.f64.s32	%fd258, %r99;
	neg.f64 	%fd259, %fd258;
	fma.rn.f64 	%fd261, %fd259, %fd116, %fd338;
	fma.rn.f64 	%fd263, %fd259, %fd118, %fd261;
	fma.rn.f64 	%fd339, %fd259, %fd120, %fd263;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd338;
	}
	and.b32  	%r81, %r80, 2145386496;
	setp.lt.u32	%p36, %r81, 1105199104;
	@%p36 bra 	BB57_60;

	// Callseq Start 130
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd338;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd339, [retval0+0];
	
	//{
	}// Callseq End 130
	ld.local.u32 	%r99, [%rd1];

BB57_60:
	add.s32 	%r28, %r99, 1;
	and.b32  	%r82, %r28, 1;
	shl.b32 	%r83, %r82, 3;
	setp.eq.s32	%p37, %r82, 0;
	selp.f64	%fd265, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p37;
	add.s32 	%r84, %r83, 1;
	mul.wide.s32 	%rd42, %r84, 8;
	add.s64 	%rd44, %rd19, %rd42;
	ld.const.f64 	%fd266, [%rd44];
	mul.rn.f64 	%fd87, %fd339, %fd339;
	fma.rn.f64 	%fd267, %fd265, %fd87, %fd266;
	ld.const.f64 	%fd268, [%rd44+8];
	fma.rn.f64 	%fd269, %fd267, %fd87, %fd268;
	ld.const.f64 	%fd270, [%rd44+16];
	fma.rn.f64 	%fd271, %fd269, %fd87, %fd270;
	ld.const.f64 	%fd272, [%rd44+24];
	fma.rn.f64 	%fd273, %fd271, %fd87, %fd272;
	ld.const.f64 	%fd274, [%rd44+32];
	fma.rn.f64 	%fd275, %fd273, %fd87, %fd274;
	ld.const.f64 	%fd276, [%rd44+40];
	fma.rn.f64 	%fd88, %fd275, %fd87, %fd276;
	fma.rn.f64 	%fd340, %fd88, %fd339, %fd339;
	@%p37 bra 	BB57_62;

	mov.f64 	%fd277, 0d3FF0000000000000;
	fma.rn.f64 	%fd340, %fd88, %fd87, %fd277;

BB57_62:
	and.b32  	%r85, %r28, 2;
	setp.eq.s32	%p38, %r85, 0;
	@%p38 bra 	BB57_64;

	mov.f64 	%fd278, 0d0000000000000000;
	mov.f64 	%fd279, 0dBFF0000000000000;
	fma.rn.f64 	%fd340, %fd340, %fd279, %fd278;

BB57_64:
	fma.rn.f64 	%fd94, %fd340, 0d4014000000000000, %fd81;
	@%p19 bra 	BB57_67;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd342;
	}
	setp.ne.s32	%p40, %r86, 0;
	@%p40 bra 	BB57_67;

	mov.f64 	%fd280, 0d0000000000000000;
	mul.rn.f64 	%fd342, %fd342, %fd280;

BB57_67:
	mul.f64 	%fd281, %fd342, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r100, %fd281;
	st.local.u32 	[%rd1], %r100;
	cvt.rn.f64.s32	%fd282, %r100;
	neg.f64 	%fd283, %fd282;
	fma.rn.f64 	%fd285, %fd283, %fd116, %fd342;
	fma.rn.f64 	%fd287, %fd283, %fd118, %fd285;
	fma.rn.f64 	%fd343, %fd283, %fd120, %fd287;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd342;
	}
	and.b32  	%r88, %r87, 2145386496;
	setp.lt.u32	%p41, %r88, 1105199104;
	@%p41 bra 	BB57_69;

	// Callseq Start 131
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd342;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd343, [retval0+0];
	
	//{
	}// Callseq End 131
	ld.local.u32 	%r100, [%rd1];

BB57_69:
	add.s32 	%r32, %r100, 1;
	and.b32  	%r89, %r32, 1;
	shl.b32 	%r90, %r89, 3;
	setp.eq.s32	%p42, %r89, 0;
	selp.f64	%fd289, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p42;
	add.s32 	%r91, %r90, 1;
	mul.wide.s32 	%rd46, %r91, 8;
	add.s64 	%rd48, %rd19, %rd46;
	ld.const.f64 	%fd290, [%rd48];
	mul.rn.f64 	%fd100, %fd343, %fd343;
	fma.rn.f64 	%fd291, %fd289, %fd100, %fd290;
	ld.const.f64 	%fd292, [%rd48+8];
	fma.rn.f64 	%fd293, %fd291, %fd100, %fd292;
	ld.const.f64 	%fd294, [%rd48+16];
	fma.rn.f64 	%fd295, %fd293, %fd100, %fd294;
	ld.const.f64 	%fd296, [%rd48+24];
	fma.rn.f64 	%fd297, %fd295, %fd100, %fd296;
	ld.const.f64 	%fd298, [%rd48+32];
	fma.rn.f64 	%fd299, %fd297, %fd100, %fd298;
	ld.const.f64 	%fd300, [%rd48+40];
	fma.rn.f64 	%fd101, %fd299, %fd100, %fd300;
	fma.rn.f64 	%fd344, %fd101, %fd343, %fd343;
	@%p42 bra 	BB57_71;

	mov.f64 	%fd301, 0d3FF0000000000000;
	fma.rn.f64 	%fd344, %fd101, %fd100, %fd301;

BB57_71:
	and.b32  	%r92, %r32, 2;
	setp.eq.s32	%p43, %r92, 0;
	@%p43 bra 	BB57_73;

	mov.f64 	%fd302, 0d0000000000000000;
	mov.f64 	%fd303, 0dBFF0000000000000;
	fma.rn.f64 	%fd344, %fd344, %fd303, %fd302;

BB57_73:
	fma.rn.f64 	%fd304, %fd344, 0dC01C000000000000, %fd94;
	mul.f64 	%fd305, %fd2, %fd304;
	mul.f64 	%fd306, %fd56, 0dC008000000000000;
	sub.f64 	%fd307, %fd306, %fd305;
	add.f64 	%fd308, %fd109, %fd109;
	mul.f64 	%fd309, %fd308, %fd109;
	mul.f64 	%fd310, %fd309, 0d400921FB54442D18;
	mul.f64 	%fd311, %fd310, 0d400921FB54442D18;
	mul.f64 	%fd312, %fd311, 0d4020000000000000;
	div.rn.f64 	%fd313, %fd312, 0d4023BD3CC9BE45DE;
	mul.f64 	%fd346, %fd313, %fd307;

BB57_74:
	st.param.f64	[func_retval0+0], %fd346;
	ret;
}

	// .globl	_Z8SawtoothddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8SawtoothddPdiPii(
	.param .b64 _Z8SawtoothddPdiPii_param_0,
	.param .b64 _Z8SawtoothddPdiPii_param_1,
	.param .b64 _Z8SawtoothddPdiPii_param_2,
	.param .b32 _Z8SawtoothddPdiPii_param_3,
	.param .b64 _Z8SawtoothddPdiPii_param_4,
	.param .b32 _Z8SawtoothddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot58[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<180>;
	.reg .b64 	%rd<29>;


	mov.u64 	%SPL, __local_depot58;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd58, [_Z8SawtoothddPdiPii_param_0];
	ld.param.f64 	%fd59, [_Z8SawtoothddPdiPii_param_1];
	mul.f64 	%fd61, %fd58, %fd59;
	setp.lt.f64	%p1, %fd61, 0d0000000000000000;
	setp.gt.f64	%p2, %fd61, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd179, 0d0000000000000000;
	@%p3 bra 	BB58_38;

	add.f64 	%fd62, %fd59, %fd59;
	mul.f64 	%fd1, %fd62, %fd58;
	mul.f64 	%fd163, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd163;
	}
	and.b32  	%r14, %r13, 2147483647;
	setp.ne.s32	%p4, %r14, 2146435072;
	@%p4 bra 	BB58_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r15, %temp}, %fd163;
	}
	setp.ne.s32	%p5, %r15, 0;
	@%p5 bra 	BB58_4;

	mov.f64 	%fd63, 0d0000000000000000;
	mul.rn.f64 	%fd163, %fd163, %fd63;

BB58_4:
	mul.f64 	%fd64, %fd163, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r49, %fd64;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r49;
	cvt.rn.f64.s32	%fd65, %r49;
	neg.f64 	%fd66, %fd65;
	mov.f64 	%fd67, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd68, %fd66, %fd67, %fd163;
	mov.f64 	%fd69, 0d3C91A62633145C00;
	fma.rn.f64 	%fd70, %fd66, %fd69, %fd68;
	mov.f64 	%fd71, 0d397B839A252049C0;
	fma.rn.f64 	%fd164, %fd66, %fd71, %fd70;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd163;
	}
	and.b32  	%r17, %r16, 2145386496;
	setp.lt.u32	%p6, %r17, 1105199104;
	@%p6 bra 	BB58_6;

	// Callseq Start 132
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd163;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd164, [retval0+0];
	
	//{
	}// Callseq End 132
	ld.local.u32 	%r49, [%rd2];

BB58_6:
	and.b32  	%r18, %r49, 1;
	shl.b32 	%r19, %r18, 3;
	setp.eq.s32	%p7, %r18, 0;
	selp.f64	%fd72, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r20, %r19, 1;
	mul.wide.s32 	%rd5, %r20, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd73, [%rd7];
	mul.rn.f64 	%fd8, %fd164, %fd164;
	fma.rn.f64 	%fd74, %fd72, %fd8, %fd73;
	ld.const.f64 	%fd75, [%rd7+8];
	fma.rn.f64 	%fd76, %fd74, %fd8, %fd75;
	ld.const.f64 	%fd77, [%rd7+16];
	fma.rn.f64 	%fd78, %fd76, %fd8, %fd77;
	ld.const.f64 	%fd79, [%rd7+24];
	fma.rn.f64 	%fd80, %fd78, %fd8, %fd79;
	ld.const.f64 	%fd81, [%rd7+32];
	fma.rn.f64 	%fd82, %fd80, %fd8, %fd81;
	ld.const.f64 	%fd83, [%rd7+40];
	fma.rn.f64 	%fd9, %fd82, %fd8, %fd83;
	fma.rn.f64 	%fd165, %fd9, %fd164, %fd164;
	@%p7 bra 	BB58_8;

	mov.f64 	%fd84, 0d3FF0000000000000;
	fma.rn.f64 	%fd165, %fd9, %fd8, %fd84;

BB58_8:
	and.b32  	%r21, %r49, 2;
	setp.eq.s32	%p8, %r21, 0;
	@%p8 bra 	BB58_10;

	mov.f64 	%fd85, 0d0000000000000000;
	mov.f64 	%fd86, 0dBFF0000000000000;
	fma.rn.f64 	%fd165, %fd165, %fd86, %fd85;

BB58_10:
	mul.f64 	%fd167, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd167;
	}
	and.b32  	%r23, %r22, 2147483647;
	setp.ne.s32	%p9, %r23, 2146435072;
	@%p9 bra 	BB58_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd167;
	}
	setp.ne.s32	%p10, %r24, 0;
	@%p10 bra 	BB58_13;

	mov.f64 	%fd87, 0d0000000000000000;
	mul.rn.f64 	%fd167, %fd167, %fd87;

BB58_13:
	mul.f64 	%fd88, %fd167, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r50, %fd88;
	st.local.u32 	[%rd2], %r50;
	cvt.rn.f64.s32	%fd89, %r50;
	neg.f64 	%fd90, %fd89;
	fma.rn.f64 	%fd92, %fd90, %fd67, %fd167;
	fma.rn.f64 	%fd94, %fd90, %fd69, %fd92;
	fma.rn.f64 	%fd168, %fd90, %fd71, %fd94;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd167;
	}
	and.b32  	%r26, %r25, 2145386496;
	setp.lt.u32	%p11, %r26, 1105199104;
	@%p11 bra 	BB58_15;

	// Callseq Start 133
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd167;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd168, [retval0+0];
	
	//{
	}// Callseq End 133
	ld.local.u32 	%r50, [%rd2];

BB58_15:
	and.b32  	%r27, %r50, 1;
	shl.b32 	%r28, %r27, 3;
	setp.eq.s32	%p12, %r27, 0;
	selp.f64	%fd96, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r29, %r28, 1;
	mul.wide.s32 	%rd12, %r29, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd97, [%rd14];
	mul.rn.f64 	%fd21, %fd168, %fd168;
	fma.rn.f64 	%fd98, %fd96, %fd21, %fd97;
	ld.const.f64 	%fd99, [%rd14+8];
	fma.rn.f64 	%fd100, %fd98, %fd21, %fd99;
	ld.const.f64 	%fd101, [%rd14+16];
	fma.rn.f64 	%fd102, %fd100, %fd21, %fd101;
	ld.const.f64 	%fd103, [%rd14+24];
	fma.rn.f64 	%fd104, %fd102, %fd21, %fd103;
	ld.const.f64 	%fd105, [%rd14+32];
	fma.rn.f64 	%fd106, %fd104, %fd21, %fd105;
	ld.const.f64 	%fd107, [%rd14+40];
	fma.rn.f64 	%fd22, %fd106, %fd21, %fd107;
	fma.rn.f64 	%fd169, %fd22, %fd168, %fd168;
	@%p12 bra 	BB58_17;

	mov.f64 	%fd108, 0d3FF0000000000000;
	fma.rn.f64 	%fd169, %fd22, %fd21, %fd108;

BB58_17:
	and.b32  	%r30, %r50, 2;
	setp.eq.s32	%p13, %r30, 0;
	@%p13 bra 	BB58_19;

	mov.f64 	%fd109, 0d0000000000000000;
	mov.f64 	%fd110, 0dBFF0000000000000;
	fma.rn.f64 	%fd169, %fd169, %fd110, %fd109;

BB58_19:
	div.rn.f64 	%fd111, %fd169, 0dC022000000000000;
	add.f64 	%fd28, %fd165, %fd111;
	mul.f64 	%fd171, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd171;
	}
	and.b32  	%r32, %r31, 2147483647;
	setp.ne.s32	%p14, %r32, 2146435072;
	@%p14 bra 	BB58_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd171;
	}
	setp.ne.s32	%p15, %r33, 0;
	@%p15 bra 	BB58_22;

	mov.f64 	%fd112, 0d0000000000000000;
	mul.rn.f64 	%fd171, %fd171, %fd112;

BB58_22:
	mul.f64 	%fd113, %fd171, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r51, %fd113;
	st.local.u32 	[%rd2], %r51;
	cvt.rn.f64.s32	%fd114, %r51;
	neg.f64 	%fd115, %fd114;
	fma.rn.f64 	%fd117, %fd115, %fd67, %fd171;
	fma.rn.f64 	%fd119, %fd115, %fd69, %fd117;
	fma.rn.f64 	%fd172, %fd115, %fd71, %fd119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd171;
	}
	and.b32  	%r35, %r34, 2145386496;
	setp.lt.u32	%p16, %r35, 1105199104;
	@%p16 bra 	BB58_24;

	// Callseq Start 134
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd171;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd172, [retval0+0];
	
	//{
	}// Callseq End 134
	ld.local.u32 	%r51, [%rd2];

BB58_24:
	and.b32  	%r36, %r51, 1;
	shl.b32 	%r37, %r36, 3;
	setp.eq.s32	%p17, %r36, 0;
	selp.f64	%fd121, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r38, %r37, 1;
	mul.wide.s32 	%rd19, %r38, 8;
	add.s64 	%rd21, %rd6, %rd19;
	ld.const.f64 	%fd122, [%rd21];
	mul.rn.f64 	%fd35, %fd172, %fd172;
	fma.rn.f64 	%fd123, %fd121, %fd35, %fd122;
	ld.const.f64 	%fd124, [%rd21+8];
	fma.rn.f64 	%fd125, %fd123, %fd35, %fd124;
	ld.const.f64 	%fd126, [%rd21+16];
	fma.rn.f64 	%fd127, %fd125, %fd35, %fd126;
	ld.const.f64 	%fd128, [%rd21+24];
	fma.rn.f64 	%fd129, %fd127, %fd35, %fd128;
	ld.const.f64 	%fd130, [%rd21+32];
	fma.rn.f64 	%fd131, %fd129, %fd35, %fd130;
	ld.const.f64 	%fd132, [%rd21+40];
	fma.rn.f64 	%fd36, %fd131, %fd35, %fd132;
	fma.rn.f64 	%fd173, %fd36, %fd172, %fd172;
	@%p17 bra 	BB58_26;

	mov.f64 	%fd133, 0d3FF0000000000000;
	fma.rn.f64 	%fd173, %fd36, %fd35, %fd133;

BB58_26:
	and.b32  	%r39, %r51, 2;
	setp.eq.s32	%p18, %r39, 0;
	@%p18 bra 	BB58_28;

	mov.f64 	%fd134, 0d0000000000000000;
	mov.f64 	%fd135, 0dBFF0000000000000;
	fma.rn.f64 	%fd173, %fd173, %fd135, %fd134;

BB58_28:
	div.rn.f64 	%fd136, %fd173, 0d4039000000000000;
	add.f64 	%fd42, %fd28, %fd136;
	mul.f64 	%fd175, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd175;
	}
	and.b32  	%r41, %r40, 2147483647;
	setp.ne.s32	%p19, %r41, 2146435072;
	@%p19 bra 	BB58_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd175;
	}
	setp.ne.s32	%p20, %r42, 0;
	@%p20 bra 	BB58_31;

	mov.f64 	%fd137, 0d0000000000000000;
	mul.rn.f64 	%fd175, %fd175, %fd137;

BB58_31:
	mul.f64 	%fd138, %fd175, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r52, %fd138;
	st.local.u32 	[%rd2], %r52;
	cvt.rn.f64.s32	%fd139, %r52;
	neg.f64 	%fd140, %fd139;
	fma.rn.f64 	%fd142, %fd140, %fd67, %fd175;
	fma.rn.f64 	%fd144, %fd140, %fd69, %fd142;
	fma.rn.f64 	%fd176, %fd140, %fd71, %fd144;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd175;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p21, %r44, 1105199104;
	@%p21 bra 	BB58_33;

	// Callseq Start 135
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd175;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd176, [retval0+0];
	
	//{
	}// Callseq End 135
	ld.local.u32 	%r52, [%rd2];

BB58_33:
	and.b32  	%r45, %r52, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p22, %r45, 0;
	selp.f64	%fd146, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd26, %r47, 8;
	add.s64 	%rd28, %rd6, %rd26;
	ld.const.f64 	%fd147, [%rd28];
	mul.rn.f64 	%fd49, %fd176, %fd176;
	fma.rn.f64 	%fd148, %fd146, %fd49, %fd147;
	ld.const.f64 	%fd149, [%rd28+8];
	fma.rn.f64 	%fd150, %fd148, %fd49, %fd149;
	ld.const.f64 	%fd151, [%rd28+16];
	fma.rn.f64 	%fd152, %fd150, %fd49, %fd151;
	ld.const.f64 	%fd153, [%rd28+24];
	fma.rn.f64 	%fd154, %fd152, %fd49, %fd153;
	ld.const.f64 	%fd155, [%rd28+32];
	fma.rn.f64 	%fd156, %fd154, %fd49, %fd155;
	ld.const.f64 	%fd157, [%rd28+40];
	fma.rn.f64 	%fd50, %fd156, %fd49, %fd157;
	fma.rn.f64 	%fd177, %fd50, %fd176, %fd176;
	@%p22 bra 	BB58_35;

	mov.f64 	%fd158, 0d3FF0000000000000;
	fma.rn.f64 	%fd177, %fd50, %fd49, %fd158;

BB58_35:
	and.b32  	%r48, %r52, 2;
	setp.eq.s32	%p23, %r48, 0;
	@%p23 bra 	BB58_37;

	mov.f64 	%fd159, 0d0000000000000000;
	mov.f64 	%fd160, 0dBFF0000000000000;
	fma.rn.f64 	%fd177, %fd177, %fd160, %fd159;

BB58_37:
	div.rn.f64 	%fd161, %fd177, 0dC048800000000000;
	add.f64 	%fd162, %fd42, %fd161;
	mul.f64 	%fd179, %fd162, 0d3FE9F02F6222C720;

BB58_38:
	st.param.f64	[func_retval0+0], %fd179;
	ret;
}

	// .globl	_Z10Sawtooth_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Sawtooth_tddPdiPii(
	.param .b64 _Z10Sawtooth_tddPdiPii_param_0,
	.param .b64 _Z10Sawtooth_tddPdiPii_param_1,
	.param .b64 _Z10Sawtooth_tddPdiPii_param_2,
	.param .b32 _Z10Sawtooth_tddPdiPii_param_3,
	.param .b64 _Z10Sawtooth_tddPdiPii_param_4,
	.param .b32 _Z10Sawtooth_tddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot59[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<182>;
	.reg .b64 	%rd<28>;


	mov.u64 	%SPL, __local_depot59;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd59, [_Z10Sawtooth_tddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z10Sawtooth_tddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd62, %fd59, %fd60;
	setp.lt.f64	%p1, %fd62, 0d0000000000000000;
	setp.gt.f64	%p2, %fd62, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd181, 0d0000000000000000;
	@%p3 bra 	BB59_38;

	mul.f64 	%fd63, %fd59, 0d401921FB54442D18;
	mul.f64 	%fd1, %fd63, 0d3FE9F02F6222C720;
	add.f64 	%fd64, %fd60, %fd60;
	mul.f64 	%fd2, %fd64, %fd59;
	mul.f64 	%fd165, %fd2, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd165;
	}
	and.b32  	%r18, %r17, 2147483647;
	setp.ne.s32	%p4, %r18, 2146435072;
	@%p4 bra 	BB59_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd165;
	}
	setp.ne.s32	%p5, %r19, 0;
	@%p5 bra 	BB59_4;

	mov.f64 	%fd65, 0d0000000000000000;
	mul.rn.f64 	%fd165, %fd165, %fd65;

BB59_4:
	mul.f64 	%fd66, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd66;
	st.local.u32 	[%rd1], %r53;
	cvt.rn.f64.s32	%fd67, %r53;
	neg.f64 	%fd68, %fd67;
	mov.f64 	%fd69, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd70, %fd68, %fd69, %fd165;
	mov.f64 	%fd71, 0d3C91A62633145C00;
	fma.rn.f64 	%fd72, %fd68, %fd71, %fd70;
	mov.f64 	%fd73, 0d397B839A252049C0;
	fma.rn.f64 	%fd166, %fd68, %fd73, %fd72;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd165;
	}
	and.b32  	%r21, %r20, 2145386496;
	setp.lt.u32	%p6, %r21, 1105199104;
	@%p6 bra 	BB59_6;

	// Callseq Start 136
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd166, [retval0+0];
	
	//{
	}// Callseq End 136
	ld.local.u32 	%r53, [%rd1];

BB59_6:
	add.s32 	%r4, %r53, 1;
	and.b32  	%r22, %r4, 1;
	shl.b32 	%r23, %r22, 3;
	setp.eq.s32	%p7, %r22, 0;
	selp.f64	%fd74, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r24, %r23, 1;
	mul.wide.s32 	%rd4, %r24, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd75, [%rd6];
	mul.rn.f64 	%fd9, %fd166, %fd166;
	fma.rn.f64 	%fd76, %fd74, %fd9, %fd75;
	ld.const.f64 	%fd77, [%rd6+8];
	fma.rn.f64 	%fd78, %fd76, %fd9, %fd77;
	ld.const.f64 	%fd79, [%rd6+16];
	fma.rn.f64 	%fd80, %fd78, %fd9, %fd79;
	ld.const.f64 	%fd81, [%rd6+24];
	fma.rn.f64 	%fd82, %fd80, %fd9, %fd81;
	ld.const.f64 	%fd83, [%rd6+32];
	fma.rn.f64 	%fd84, %fd82, %fd9, %fd83;
	ld.const.f64 	%fd85, [%rd6+40];
	fma.rn.f64 	%fd10, %fd84, %fd9, %fd85;
	fma.rn.f64 	%fd167, %fd10, %fd166, %fd166;
	@%p7 bra 	BB59_8;

	mov.f64 	%fd86, 0d3FF0000000000000;
	fma.rn.f64 	%fd167, %fd10, %fd9, %fd86;

BB59_8:
	and.b32  	%r25, %r4, 2;
	setp.eq.s32	%p8, %r25, 0;
	@%p8 bra 	BB59_10;

	mov.f64 	%fd87, 0d0000000000000000;
	mov.f64 	%fd88, 0dBFF0000000000000;
	fma.rn.f64 	%fd167, %fd167, %fd88, %fd87;

BB59_10:
	mul.f64 	%fd169, %fd2, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd169;
	}
	and.b32  	%r27, %r26, 2147483647;
	setp.ne.s32	%p9, %r27, 2146435072;
	@%p9 bra 	BB59_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd169;
	}
	setp.ne.s32	%p10, %r28, 0;
	@%p10 bra 	BB59_13;

	mov.f64 	%fd89, 0d0000000000000000;
	mul.rn.f64 	%fd169, %fd169, %fd89;

BB59_13:
	mul.f64 	%fd90, %fd169, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd90;
	st.local.u32 	[%rd1], %r54;
	cvt.rn.f64.s32	%fd91, %r54;
	neg.f64 	%fd92, %fd91;
	fma.rn.f64 	%fd94, %fd92, %fd69, %fd169;
	fma.rn.f64 	%fd96, %fd92, %fd71, %fd94;
	fma.rn.f64 	%fd170, %fd92, %fd73, %fd96;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd169;
	}
	and.b32  	%r30, %r29, 2145386496;
	setp.lt.u32	%p11, %r30, 1105199104;
	@%p11 bra 	BB59_15;

	// Callseq Start 137
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd169;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd170, [retval0+0];
	
	//{
	}// Callseq End 137
	ld.local.u32 	%r54, [%rd1];

BB59_15:
	add.s32 	%r8, %r54, 1;
	and.b32  	%r31, %r8, 1;
	shl.b32 	%r32, %r31, 3;
	setp.eq.s32	%p12, %r31, 0;
	selp.f64	%fd98, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r33, %r32, 1;
	mul.wide.s32 	%rd11, %r33, 8;
	add.s64 	%rd13, %rd5, %rd11;
	ld.const.f64 	%fd99, [%rd13];
	mul.rn.f64 	%fd22, %fd170, %fd170;
	fma.rn.f64 	%fd100, %fd98, %fd22, %fd99;
	ld.const.f64 	%fd101, [%rd13+8];
	fma.rn.f64 	%fd102, %fd100, %fd22, %fd101;
	ld.const.f64 	%fd103, [%rd13+16];
	fma.rn.f64 	%fd104, %fd102, %fd22, %fd103;
	ld.const.f64 	%fd105, [%rd13+24];
	fma.rn.f64 	%fd106, %fd104, %fd22, %fd105;
	ld.const.f64 	%fd107, [%rd13+32];
	fma.rn.f64 	%fd108, %fd106, %fd22, %fd107;
	ld.const.f64 	%fd109, [%rd13+40];
	fma.rn.f64 	%fd23, %fd108, %fd22, %fd109;
	fma.rn.f64 	%fd171, %fd23, %fd170, %fd170;
	@%p12 bra 	BB59_17;

	mov.f64 	%fd110, 0d3FF0000000000000;
	fma.rn.f64 	%fd171, %fd23, %fd22, %fd110;

BB59_17:
	and.b32  	%r34, %r8, 2;
	setp.eq.s32	%p13, %r34, 0;
	@%p13 bra 	BB59_19;

	mov.f64 	%fd111, 0d0000000000000000;
	mov.f64 	%fd112, 0dBFF0000000000000;
	fma.rn.f64 	%fd171, %fd171, %fd112, %fd111;

BB59_19:
	div.rn.f64 	%fd113, %fd171, 0dC008000000000000;
	add.f64 	%fd29, %fd167, %fd113;
	mul.f64 	%fd173, %fd2, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd173;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p14, %r36, 2146435072;
	@%p14 bra 	BB59_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd173;
	}
	setp.ne.s32	%p15, %r37, 0;
	@%p15 bra 	BB59_22;

	mov.f64 	%fd114, 0d0000000000000000;
	mul.rn.f64 	%fd173, %fd173, %fd114;

BB59_22:
	mul.f64 	%fd115, %fd173, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r55, %fd115;
	st.local.u32 	[%rd1], %r55;
	cvt.rn.f64.s32	%fd116, %r55;
	neg.f64 	%fd117, %fd116;
	fma.rn.f64 	%fd119, %fd117, %fd69, %fd173;
	fma.rn.f64 	%fd121, %fd117, %fd71, %fd119;
	fma.rn.f64 	%fd174, %fd117, %fd73, %fd121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd173;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p16, %r39, 1105199104;
	@%p16 bra 	BB59_24;

	// Callseq Start 138
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd173;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd174, [retval0+0];
	
	//{
	}// Callseq End 138
	ld.local.u32 	%r55, [%rd1];

BB59_24:
	add.s32 	%r12, %r55, 1;
	and.b32  	%r40, %r12, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p17, %r40, 0;
	selp.f64	%fd123, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r42, %r41, 1;
	mul.wide.s32 	%rd18, %r42, 8;
	add.s64 	%rd20, %rd5, %rd18;
	ld.const.f64 	%fd124, [%rd20];
	mul.rn.f64 	%fd36, %fd174, %fd174;
	fma.rn.f64 	%fd125, %fd123, %fd36, %fd124;
	ld.const.f64 	%fd126, [%rd20+8];
	fma.rn.f64 	%fd127, %fd125, %fd36, %fd126;
	ld.const.f64 	%fd128, [%rd20+16];
	fma.rn.f64 	%fd129, %fd127, %fd36, %fd128;
	ld.const.f64 	%fd130, [%rd20+24];
	fma.rn.f64 	%fd131, %fd129, %fd36, %fd130;
	ld.const.f64 	%fd132, [%rd20+32];
	fma.rn.f64 	%fd133, %fd131, %fd36, %fd132;
	ld.const.f64 	%fd134, [%rd20+40];
	fma.rn.f64 	%fd37, %fd133, %fd36, %fd134;
	fma.rn.f64 	%fd175, %fd37, %fd174, %fd174;
	@%p17 bra 	BB59_26;

	mov.f64 	%fd135, 0d3FF0000000000000;
	fma.rn.f64 	%fd175, %fd37, %fd36, %fd135;

BB59_26:
	and.b32  	%r43, %r12, 2;
	setp.eq.s32	%p18, %r43, 0;
	@%p18 bra 	BB59_28;

	mov.f64 	%fd136, 0d0000000000000000;
	mov.f64 	%fd137, 0dBFF0000000000000;
	fma.rn.f64 	%fd175, %fd175, %fd137, %fd136;

BB59_28:
	div.rn.f64 	%fd138, %fd175, 0d4014000000000000;
	add.f64 	%fd43, %fd29, %fd138;
	mul.f64 	%fd177, %fd2, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd177;
	}
	and.b32  	%r45, %r44, 2147483647;
	setp.ne.s32	%p19, %r45, 2146435072;
	@%p19 bra 	BB59_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd177;
	}
	setp.ne.s32	%p20, %r46, 0;
	@%p20 bra 	BB59_31;

	mov.f64 	%fd139, 0d0000000000000000;
	mul.rn.f64 	%fd177, %fd177, %fd139;

BB59_31:
	mul.f64 	%fd140, %fd177, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r56, %fd140;
	st.local.u32 	[%rd1], %r56;
	cvt.rn.f64.s32	%fd141, %r56;
	neg.f64 	%fd142, %fd141;
	fma.rn.f64 	%fd144, %fd142, %fd69, %fd177;
	fma.rn.f64 	%fd146, %fd142, %fd71, %fd144;
	fma.rn.f64 	%fd178, %fd142, %fd73, %fd146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd177;
	}
	and.b32  	%r48, %r47, 2145386496;
	setp.lt.u32	%p21, %r48, 1105199104;
	@%p21 bra 	BB59_33;

	// Callseq Start 139
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd177;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd178, [retval0+0];
	
	//{
	}// Callseq End 139
	ld.local.u32 	%r56, [%rd1];

BB59_33:
	add.s32 	%r16, %r56, 1;
	and.b32  	%r49, %r16, 1;
	shl.b32 	%r50, %r49, 3;
	setp.eq.s32	%p22, %r49, 0;
	selp.f64	%fd148, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r51, %r50, 1;
	mul.wide.s32 	%rd25, %r51, 8;
	add.s64 	%rd27, %rd5, %rd25;
	ld.const.f64 	%fd149, [%rd27];
	mul.rn.f64 	%fd50, %fd178, %fd178;
	fma.rn.f64 	%fd150, %fd148, %fd50, %fd149;
	ld.const.f64 	%fd151, [%rd27+8];
	fma.rn.f64 	%fd152, %fd150, %fd50, %fd151;
	ld.const.f64 	%fd153, [%rd27+16];
	fma.rn.f64 	%fd154, %fd152, %fd50, %fd153;
	ld.const.f64 	%fd155, [%rd27+24];
	fma.rn.f64 	%fd156, %fd154, %fd50, %fd155;
	ld.const.f64 	%fd157, [%rd27+32];
	fma.rn.f64 	%fd158, %fd156, %fd50, %fd157;
	ld.const.f64 	%fd159, [%rd27+40];
	fma.rn.f64 	%fd51, %fd158, %fd50, %fd159;
	fma.rn.f64 	%fd179, %fd51, %fd178, %fd178;
	@%p22 bra 	BB59_35;

	mov.f64 	%fd160, 0d3FF0000000000000;
	fma.rn.f64 	%fd179, %fd51, %fd50, %fd160;

BB59_35:
	and.b32  	%r52, %r16, 2;
	setp.eq.s32	%p23, %r52, 0;
	@%p23 bra 	BB59_37;

	mov.f64 	%fd161, 0d0000000000000000;
	mov.f64 	%fd162, 0dBFF0000000000000;
	fma.rn.f64 	%fd179, %fd179, %fd162, %fd161;

BB59_37:
	div.rn.f64 	%fd163, %fd179, 0dC01C000000000000;
	add.f64 	%fd164, %fd43, %fd163;
	mul.f64 	%fd181, %fd1, %fd164;

BB59_38:
	st.param.f64	[func_retval0+0], %fd181;
	ret;
}

	// .globl	_Z11Sawtooth_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Sawtooth_omddPdiPii(
	.param .b64 _Z11Sawtooth_omddPdiPii_param_0,
	.param .b64 _Z11Sawtooth_omddPdiPii_param_1,
	.param .b64 _Z11Sawtooth_omddPdiPii_param_2,
	.param .b32 _Z11Sawtooth_omddPdiPii_param_3,
	.param .b64 _Z11Sawtooth_omddPdiPii_param_4,
	.param .b32 _Z11Sawtooth_omddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot60[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<182>;
	.reg .b64 	%rd<28>;


	mov.u64 	%SPL, __local_depot60;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd59, [_Z11Sawtooth_omddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z11Sawtooth_omddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd62, %fd59, %fd60;
	setp.lt.f64	%p1, %fd62, 0d0000000000000000;
	setp.gt.f64	%p2, %fd62, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd181, 0d0000000000000000;
	@%p3 bra 	BB60_38;

	mul.f64 	%fd63, %fd60, 0d401921FB54442D18;
	mul.f64 	%fd1, %fd63, 0d3FE9F02F6222C720;
	add.f64 	%fd64, %fd60, %fd60;
	mul.f64 	%fd2, %fd64, %fd59;
	mul.f64 	%fd165, %fd2, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd165;
	}
	and.b32  	%r18, %r17, 2147483647;
	setp.ne.s32	%p4, %r18, 2146435072;
	@%p4 bra 	BB60_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd165;
	}
	setp.ne.s32	%p5, %r19, 0;
	@%p5 bra 	BB60_4;

	mov.f64 	%fd65, 0d0000000000000000;
	mul.rn.f64 	%fd165, %fd165, %fd65;

BB60_4:
	mul.f64 	%fd66, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd66;
	st.local.u32 	[%rd1], %r53;
	cvt.rn.f64.s32	%fd67, %r53;
	neg.f64 	%fd68, %fd67;
	mov.f64 	%fd69, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd70, %fd68, %fd69, %fd165;
	mov.f64 	%fd71, 0d3C91A62633145C00;
	fma.rn.f64 	%fd72, %fd68, %fd71, %fd70;
	mov.f64 	%fd73, 0d397B839A252049C0;
	fma.rn.f64 	%fd166, %fd68, %fd73, %fd72;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd165;
	}
	and.b32  	%r21, %r20, 2145386496;
	setp.lt.u32	%p6, %r21, 1105199104;
	@%p6 bra 	BB60_6;

	// Callseq Start 140
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd166, [retval0+0];
	
	//{
	}// Callseq End 140
	ld.local.u32 	%r53, [%rd1];

BB60_6:
	add.s32 	%r4, %r53, 1;
	and.b32  	%r22, %r4, 1;
	shl.b32 	%r23, %r22, 3;
	setp.eq.s32	%p7, %r22, 0;
	selp.f64	%fd74, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r24, %r23, 1;
	mul.wide.s32 	%rd4, %r24, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd75, [%rd6];
	mul.rn.f64 	%fd9, %fd166, %fd166;
	fma.rn.f64 	%fd76, %fd74, %fd9, %fd75;
	ld.const.f64 	%fd77, [%rd6+8];
	fma.rn.f64 	%fd78, %fd76, %fd9, %fd77;
	ld.const.f64 	%fd79, [%rd6+16];
	fma.rn.f64 	%fd80, %fd78, %fd9, %fd79;
	ld.const.f64 	%fd81, [%rd6+24];
	fma.rn.f64 	%fd82, %fd80, %fd9, %fd81;
	ld.const.f64 	%fd83, [%rd6+32];
	fma.rn.f64 	%fd84, %fd82, %fd9, %fd83;
	ld.const.f64 	%fd85, [%rd6+40];
	fma.rn.f64 	%fd10, %fd84, %fd9, %fd85;
	fma.rn.f64 	%fd167, %fd10, %fd166, %fd166;
	@%p7 bra 	BB60_8;

	mov.f64 	%fd86, 0d3FF0000000000000;
	fma.rn.f64 	%fd167, %fd10, %fd9, %fd86;

BB60_8:
	and.b32  	%r25, %r4, 2;
	setp.eq.s32	%p8, %r25, 0;
	@%p8 bra 	BB60_10;

	mov.f64 	%fd87, 0d0000000000000000;
	mov.f64 	%fd88, 0dBFF0000000000000;
	fma.rn.f64 	%fd167, %fd167, %fd88, %fd87;

BB60_10:
	mul.f64 	%fd169, %fd2, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd169;
	}
	and.b32  	%r27, %r26, 2147483647;
	setp.ne.s32	%p9, %r27, 2146435072;
	@%p9 bra 	BB60_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd169;
	}
	setp.ne.s32	%p10, %r28, 0;
	@%p10 bra 	BB60_13;

	mov.f64 	%fd89, 0d0000000000000000;
	mul.rn.f64 	%fd169, %fd169, %fd89;

BB60_13:
	mul.f64 	%fd90, %fd169, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd90;
	st.local.u32 	[%rd1], %r54;
	cvt.rn.f64.s32	%fd91, %r54;
	neg.f64 	%fd92, %fd91;
	fma.rn.f64 	%fd94, %fd92, %fd69, %fd169;
	fma.rn.f64 	%fd96, %fd92, %fd71, %fd94;
	fma.rn.f64 	%fd170, %fd92, %fd73, %fd96;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd169;
	}
	and.b32  	%r30, %r29, 2145386496;
	setp.lt.u32	%p11, %r30, 1105199104;
	@%p11 bra 	BB60_15;

	// Callseq Start 141
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd169;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd170, [retval0+0];
	
	//{
	}// Callseq End 141
	ld.local.u32 	%r54, [%rd1];

BB60_15:
	add.s32 	%r8, %r54, 1;
	and.b32  	%r31, %r8, 1;
	shl.b32 	%r32, %r31, 3;
	setp.eq.s32	%p12, %r31, 0;
	selp.f64	%fd98, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r33, %r32, 1;
	mul.wide.s32 	%rd11, %r33, 8;
	add.s64 	%rd13, %rd5, %rd11;
	ld.const.f64 	%fd99, [%rd13];
	mul.rn.f64 	%fd22, %fd170, %fd170;
	fma.rn.f64 	%fd100, %fd98, %fd22, %fd99;
	ld.const.f64 	%fd101, [%rd13+8];
	fma.rn.f64 	%fd102, %fd100, %fd22, %fd101;
	ld.const.f64 	%fd103, [%rd13+16];
	fma.rn.f64 	%fd104, %fd102, %fd22, %fd103;
	ld.const.f64 	%fd105, [%rd13+24];
	fma.rn.f64 	%fd106, %fd104, %fd22, %fd105;
	ld.const.f64 	%fd107, [%rd13+32];
	fma.rn.f64 	%fd108, %fd106, %fd22, %fd107;
	ld.const.f64 	%fd109, [%rd13+40];
	fma.rn.f64 	%fd23, %fd108, %fd22, %fd109;
	fma.rn.f64 	%fd171, %fd23, %fd170, %fd170;
	@%p12 bra 	BB60_17;

	mov.f64 	%fd110, 0d3FF0000000000000;
	fma.rn.f64 	%fd171, %fd23, %fd22, %fd110;

BB60_17:
	and.b32  	%r34, %r8, 2;
	setp.eq.s32	%p13, %r34, 0;
	@%p13 bra 	BB60_19;

	mov.f64 	%fd111, 0d0000000000000000;
	mov.f64 	%fd112, 0dBFF0000000000000;
	fma.rn.f64 	%fd171, %fd171, %fd112, %fd111;

BB60_19:
	div.rn.f64 	%fd113, %fd171, 0dC008000000000000;
	add.f64 	%fd29, %fd167, %fd113;
	mul.f64 	%fd173, %fd2, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd173;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p14, %r36, 2146435072;
	@%p14 bra 	BB60_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd173;
	}
	setp.ne.s32	%p15, %r37, 0;
	@%p15 bra 	BB60_22;

	mov.f64 	%fd114, 0d0000000000000000;
	mul.rn.f64 	%fd173, %fd173, %fd114;

BB60_22:
	mul.f64 	%fd115, %fd173, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r55, %fd115;
	st.local.u32 	[%rd1], %r55;
	cvt.rn.f64.s32	%fd116, %r55;
	neg.f64 	%fd117, %fd116;
	fma.rn.f64 	%fd119, %fd117, %fd69, %fd173;
	fma.rn.f64 	%fd121, %fd117, %fd71, %fd119;
	fma.rn.f64 	%fd174, %fd117, %fd73, %fd121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd173;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p16, %r39, 1105199104;
	@%p16 bra 	BB60_24;

	// Callseq Start 142
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd173;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd174, [retval0+0];
	
	//{
	}// Callseq End 142
	ld.local.u32 	%r55, [%rd1];

BB60_24:
	add.s32 	%r12, %r55, 1;
	and.b32  	%r40, %r12, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p17, %r40, 0;
	selp.f64	%fd123, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r42, %r41, 1;
	mul.wide.s32 	%rd18, %r42, 8;
	add.s64 	%rd20, %rd5, %rd18;
	ld.const.f64 	%fd124, [%rd20];
	mul.rn.f64 	%fd36, %fd174, %fd174;
	fma.rn.f64 	%fd125, %fd123, %fd36, %fd124;
	ld.const.f64 	%fd126, [%rd20+8];
	fma.rn.f64 	%fd127, %fd125, %fd36, %fd126;
	ld.const.f64 	%fd128, [%rd20+16];
	fma.rn.f64 	%fd129, %fd127, %fd36, %fd128;
	ld.const.f64 	%fd130, [%rd20+24];
	fma.rn.f64 	%fd131, %fd129, %fd36, %fd130;
	ld.const.f64 	%fd132, [%rd20+32];
	fma.rn.f64 	%fd133, %fd131, %fd36, %fd132;
	ld.const.f64 	%fd134, [%rd20+40];
	fma.rn.f64 	%fd37, %fd133, %fd36, %fd134;
	fma.rn.f64 	%fd175, %fd37, %fd174, %fd174;
	@%p17 bra 	BB60_26;

	mov.f64 	%fd135, 0d3FF0000000000000;
	fma.rn.f64 	%fd175, %fd37, %fd36, %fd135;

BB60_26:
	and.b32  	%r43, %r12, 2;
	setp.eq.s32	%p18, %r43, 0;
	@%p18 bra 	BB60_28;

	mov.f64 	%fd136, 0d0000000000000000;
	mov.f64 	%fd137, 0dBFF0000000000000;
	fma.rn.f64 	%fd175, %fd175, %fd137, %fd136;

BB60_28:
	div.rn.f64 	%fd138, %fd175, 0d4014000000000000;
	add.f64 	%fd43, %fd29, %fd138;
	mul.f64 	%fd177, %fd2, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd177;
	}
	and.b32  	%r45, %r44, 2147483647;
	setp.ne.s32	%p19, %r45, 2146435072;
	@%p19 bra 	BB60_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd177;
	}
	setp.ne.s32	%p20, %r46, 0;
	@%p20 bra 	BB60_31;

	mov.f64 	%fd139, 0d0000000000000000;
	mul.rn.f64 	%fd177, %fd177, %fd139;

BB60_31:
	mul.f64 	%fd140, %fd177, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r56, %fd140;
	st.local.u32 	[%rd1], %r56;
	cvt.rn.f64.s32	%fd141, %r56;
	neg.f64 	%fd142, %fd141;
	fma.rn.f64 	%fd144, %fd142, %fd69, %fd177;
	fma.rn.f64 	%fd146, %fd142, %fd71, %fd144;
	fma.rn.f64 	%fd178, %fd142, %fd73, %fd146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd177;
	}
	and.b32  	%r48, %r47, 2145386496;
	setp.lt.u32	%p21, %r48, 1105199104;
	@%p21 bra 	BB60_33;

	// Callseq Start 143
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd177;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd178, [retval0+0];
	
	//{
	}// Callseq End 143
	ld.local.u32 	%r56, [%rd1];

BB60_33:
	add.s32 	%r16, %r56, 1;
	and.b32  	%r49, %r16, 1;
	shl.b32 	%r50, %r49, 3;
	setp.eq.s32	%p22, %r49, 0;
	selp.f64	%fd148, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r51, %r50, 1;
	mul.wide.s32 	%rd25, %r51, 8;
	add.s64 	%rd27, %rd5, %rd25;
	ld.const.f64 	%fd149, [%rd27];
	mul.rn.f64 	%fd50, %fd178, %fd178;
	fma.rn.f64 	%fd150, %fd148, %fd50, %fd149;
	ld.const.f64 	%fd151, [%rd27+8];
	fma.rn.f64 	%fd152, %fd150, %fd50, %fd151;
	ld.const.f64 	%fd153, [%rd27+16];
	fma.rn.f64 	%fd154, %fd152, %fd50, %fd153;
	ld.const.f64 	%fd155, [%rd27+24];
	fma.rn.f64 	%fd156, %fd154, %fd50, %fd155;
	ld.const.f64 	%fd157, [%rd27+32];
	fma.rn.f64 	%fd158, %fd156, %fd50, %fd157;
	ld.const.f64 	%fd159, [%rd27+40];
	fma.rn.f64 	%fd51, %fd158, %fd50, %fd159;
	fma.rn.f64 	%fd179, %fd51, %fd178, %fd178;
	@%p22 bra 	BB60_35;

	mov.f64 	%fd160, 0d3FF0000000000000;
	fma.rn.f64 	%fd179, %fd51, %fd50, %fd160;

BB60_35:
	and.b32  	%r52, %r16, 2;
	setp.eq.s32	%p23, %r52, 0;
	@%p23 bra 	BB60_37;

	mov.f64 	%fd161, 0d0000000000000000;
	mov.f64 	%fd162, 0dBFF0000000000000;
	fma.rn.f64 	%fd179, %fd179, %fd162, %fd161;

BB60_37:
	div.rn.f64 	%fd163, %fd179, 0dC01C000000000000;
	add.f64 	%fd164, %fd43, %fd163;
	mul.f64 	%fd181, %fd1, %fd164;

BB60_38:
	st.param.f64	[func_retval0+0], %fd181;
	ret;
}

	// .globl	_Z11Sawtooth_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Sawtooth_ttddPdiPii(
	.param .b64 _Z11Sawtooth_ttddPdiPii_param_0,
	.param .b64 _Z11Sawtooth_ttddPdiPii_param_1,
	.param .b64 _Z11Sawtooth_ttddPdiPii_param_2,
	.param .b32 _Z11Sawtooth_ttddPdiPii_param_3,
	.param .b64 _Z11Sawtooth_ttddPdiPii_param_4,
	.param .b32 _Z11Sawtooth_ttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot61[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<180>;
	.reg .b64 	%rd<28>;


	mov.u64 	%SPL, __local_depot61;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd59, [_Z11Sawtooth_ttddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z11Sawtooth_ttddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd62, %fd59, %fd60;
	setp.lt.f64	%p1, %fd62, 0d0000000000000000;
	setp.gt.f64	%p2, %fd62, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd179, 0d0000000000000000;
	@%p3 bra 	BB61_38;

	mul.f64 	%fd63, %fd59, 0dC043BD3CC9BE45DE;
	mul.f64 	%fd64, %fd63, %fd59;
	mul.f64 	%fd1, %fd64, 0d3FE9F02F6222C720;
	add.f64 	%fd65, %fd60, %fd60;
	mul.f64 	%fd2, %fd65, %fd59;
	mul.f64 	%fd163, %fd2, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd163;
	}
	and.b32  	%r14, %r13, 2147483647;
	setp.ne.s32	%p4, %r14, 2146435072;
	@%p4 bra 	BB61_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r15, %temp}, %fd163;
	}
	setp.ne.s32	%p5, %r15, 0;
	@%p5 bra 	BB61_4;

	mov.f64 	%fd66, 0d0000000000000000;
	mul.rn.f64 	%fd163, %fd163, %fd66;

BB61_4:
	mul.f64 	%fd67, %fd163, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r49, %fd67;
	st.local.u32 	[%rd1], %r49;
	cvt.rn.f64.s32	%fd68, %r49;
	neg.f64 	%fd69, %fd68;
	mov.f64 	%fd70, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd71, %fd69, %fd70, %fd163;
	mov.f64 	%fd72, 0d3C91A62633145C00;
	fma.rn.f64 	%fd73, %fd69, %fd72, %fd71;
	mov.f64 	%fd74, 0d397B839A252049C0;
	fma.rn.f64 	%fd164, %fd69, %fd74, %fd73;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd163;
	}
	and.b32  	%r17, %r16, 2145386496;
	setp.lt.u32	%p6, %r17, 1105199104;
	@%p6 bra 	BB61_6;

	// Callseq Start 144
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd163;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd164, [retval0+0];
	
	//{
	}// Callseq End 144
	ld.local.u32 	%r49, [%rd1];

BB61_6:
	and.b32  	%r18, %r49, 1;
	shl.b32 	%r19, %r18, 3;
	setp.eq.s32	%p7, %r18, 0;
	selp.f64	%fd75, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r20, %r19, 1;
	mul.wide.s32 	%rd4, %r20, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd76, [%rd6];
	mul.rn.f64 	%fd9, %fd164, %fd164;
	fma.rn.f64 	%fd77, %fd75, %fd9, %fd76;
	ld.const.f64 	%fd78, [%rd6+8];
	fma.rn.f64 	%fd79, %fd77, %fd9, %fd78;
	ld.const.f64 	%fd80, [%rd6+16];
	fma.rn.f64 	%fd81, %fd79, %fd9, %fd80;
	ld.const.f64 	%fd82, [%rd6+24];
	fma.rn.f64 	%fd83, %fd81, %fd9, %fd82;
	ld.const.f64 	%fd84, [%rd6+32];
	fma.rn.f64 	%fd85, %fd83, %fd9, %fd84;
	ld.const.f64 	%fd86, [%rd6+40];
	fma.rn.f64 	%fd10, %fd85, %fd9, %fd86;
	fma.rn.f64 	%fd165, %fd10, %fd164, %fd164;
	@%p7 bra 	BB61_8;

	mov.f64 	%fd87, 0d3FF0000000000000;
	fma.rn.f64 	%fd165, %fd10, %fd9, %fd87;

BB61_8:
	and.b32  	%r21, %r49, 2;
	setp.eq.s32	%p8, %r21, 0;
	@%p8 bra 	BB61_10;

	mov.f64 	%fd88, 0d0000000000000000;
	mov.f64 	%fd89, 0dBFF0000000000000;
	fma.rn.f64 	%fd165, %fd165, %fd89, %fd88;

BB61_10:
	mul.f64 	%fd167, %fd2, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd167;
	}
	and.b32  	%r23, %r22, 2147483647;
	setp.ne.s32	%p9, %r23, 2146435072;
	@%p9 bra 	BB61_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd167;
	}
	setp.ne.s32	%p10, %r24, 0;
	@%p10 bra 	BB61_13;

	mov.f64 	%fd90, 0d0000000000000000;
	mul.rn.f64 	%fd167, %fd167, %fd90;

BB61_13:
	mul.f64 	%fd91, %fd167, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r50, %fd91;
	st.local.u32 	[%rd1], %r50;
	cvt.rn.f64.s32	%fd92, %r50;
	neg.f64 	%fd93, %fd92;
	fma.rn.f64 	%fd95, %fd93, %fd70, %fd167;
	fma.rn.f64 	%fd97, %fd93, %fd72, %fd95;
	fma.rn.f64 	%fd168, %fd93, %fd74, %fd97;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd167;
	}
	and.b32  	%r26, %r25, 2145386496;
	setp.lt.u32	%p11, %r26, 1105199104;
	@%p11 bra 	BB61_15;

	// Callseq Start 145
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd167;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd168, [retval0+0];
	
	//{
	}// Callseq End 145
	ld.local.u32 	%r50, [%rd1];

BB61_15:
	and.b32  	%r27, %r50, 1;
	shl.b32 	%r28, %r27, 3;
	setp.eq.s32	%p12, %r27, 0;
	selp.f64	%fd99, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r29, %r28, 1;
	mul.wide.s32 	%rd11, %r29, 8;
	add.s64 	%rd13, %rd5, %rd11;
	ld.const.f64 	%fd100, [%rd13];
	mul.rn.f64 	%fd22, %fd168, %fd168;
	fma.rn.f64 	%fd101, %fd99, %fd22, %fd100;
	ld.const.f64 	%fd102, [%rd13+8];
	fma.rn.f64 	%fd103, %fd101, %fd22, %fd102;
	ld.const.f64 	%fd104, [%rd13+16];
	fma.rn.f64 	%fd105, %fd103, %fd22, %fd104;
	ld.const.f64 	%fd106, [%rd13+24];
	fma.rn.f64 	%fd107, %fd105, %fd22, %fd106;
	ld.const.f64 	%fd108, [%rd13+32];
	fma.rn.f64 	%fd109, %fd107, %fd22, %fd108;
	ld.const.f64 	%fd110, [%rd13+40];
	fma.rn.f64 	%fd23, %fd109, %fd22, %fd110;
	fma.rn.f64 	%fd169, %fd23, %fd168, %fd168;
	@%p12 bra 	BB61_17;

	mov.f64 	%fd111, 0d3FF0000000000000;
	fma.rn.f64 	%fd169, %fd23, %fd22, %fd111;

BB61_17:
	and.b32  	%r30, %r50, 2;
	setp.eq.s32	%p13, %r30, 0;
	@%p13 bra 	BB61_19;

	mov.f64 	%fd112, 0d0000000000000000;
	mov.f64 	%fd113, 0dBFF0000000000000;
	fma.rn.f64 	%fd169, %fd169, %fd113, %fd112;

BB61_19:
	sub.f64 	%fd29, %fd165, %fd169;
	mul.f64 	%fd171, %fd2, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd171;
	}
	and.b32  	%r32, %r31, 2147483647;
	setp.ne.s32	%p14, %r32, 2146435072;
	@%p14 bra 	BB61_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd171;
	}
	setp.ne.s32	%p15, %r33, 0;
	@%p15 bra 	BB61_22;

	mov.f64 	%fd114, 0d0000000000000000;
	mul.rn.f64 	%fd171, %fd171, %fd114;

BB61_22:
	mul.f64 	%fd115, %fd171, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r51, %fd115;
	st.local.u32 	[%rd1], %r51;
	cvt.rn.f64.s32	%fd116, %r51;
	neg.f64 	%fd117, %fd116;
	fma.rn.f64 	%fd119, %fd117, %fd70, %fd171;
	fma.rn.f64 	%fd121, %fd117, %fd72, %fd119;
	fma.rn.f64 	%fd172, %fd117, %fd74, %fd121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd171;
	}
	and.b32  	%r35, %r34, 2145386496;
	setp.lt.u32	%p16, %r35, 1105199104;
	@%p16 bra 	BB61_24;

	// Callseq Start 146
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd171;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd172, [retval0+0];
	
	//{
	}// Callseq End 146
	ld.local.u32 	%r51, [%rd1];

BB61_24:
	and.b32  	%r36, %r51, 1;
	shl.b32 	%r37, %r36, 3;
	setp.eq.s32	%p17, %r36, 0;
	selp.f64	%fd123, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r38, %r37, 1;
	mul.wide.s32 	%rd18, %r38, 8;
	add.s64 	%rd20, %rd5, %rd18;
	ld.const.f64 	%fd124, [%rd20];
	mul.rn.f64 	%fd36, %fd172, %fd172;
	fma.rn.f64 	%fd125, %fd123, %fd36, %fd124;
	ld.const.f64 	%fd126, [%rd20+8];
	fma.rn.f64 	%fd127, %fd125, %fd36, %fd126;
	ld.const.f64 	%fd128, [%rd20+16];
	fma.rn.f64 	%fd129, %fd127, %fd36, %fd128;
	ld.const.f64 	%fd130, [%rd20+24];
	fma.rn.f64 	%fd131, %fd129, %fd36, %fd130;
	ld.const.f64 	%fd132, [%rd20+32];
	fma.rn.f64 	%fd133, %fd131, %fd36, %fd132;
	ld.const.f64 	%fd134, [%rd20+40];
	fma.rn.f64 	%fd37, %fd133, %fd36, %fd134;
	fma.rn.f64 	%fd173, %fd37, %fd172, %fd172;
	@%p17 bra 	BB61_26;

	mov.f64 	%fd135, 0d3FF0000000000000;
	fma.rn.f64 	%fd173, %fd37, %fd36, %fd135;

BB61_26:
	and.b32  	%r39, %r51, 2;
	setp.eq.s32	%p18, %r39, 0;
	@%p18 bra 	BB61_28;

	mov.f64 	%fd136, 0d0000000000000000;
	mov.f64 	%fd137, 0dBFF0000000000000;
	fma.rn.f64 	%fd173, %fd173, %fd137, %fd136;

BB61_28:
	add.f64 	%fd43, %fd29, %fd173;
	mul.f64 	%fd175, %fd2, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd175;
	}
	and.b32  	%r41, %r40, 2147483647;
	setp.ne.s32	%p19, %r41, 2146435072;
	@%p19 bra 	BB61_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd175;
	}
	setp.ne.s32	%p20, %r42, 0;
	@%p20 bra 	BB61_31;

	mov.f64 	%fd138, 0d0000000000000000;
	mul.rn.f64 	%fd175, %fd175, %fd138;

BB61_31:
	mul.f64 	%fd139, %fd175, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r52, %fd139;
	st.local.u32 	[%rd1], %r52;
	cvt.rn.f64.s32	%fd140, %r52;
	neg.f64 	%fd141, %fd140;
	fma.rn.f64 	%fd143, %fd141, %fd70, %fd175;
	fma.rn.f64 	%fd145, %fd141, %fd72, %fd143;
	fma.rn.f64 	%fd176, %fd141, %fd74, %fd145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd175;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p21, %r44, 1105199104;
	@%p21 bra 	BB61_33;

	// Callseq Start 147
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd175;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd176, [retval0+0];
	
	//{
	}// Callseq End 147
	ld.local.u32 	%r52, [%rd1];

BB61_33:
	and.b32  	%r45, %r52, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p22, %r45, 0;
	selp.f64	%fd147, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd25, %r47, 8;
	add.s64 	%rd27, %rd5, %rd25;
	ld.const.f64 	%fd148, [%rd27];
	mul.rn.f64 	%fd50, %fd176, %fd176;
	fma.rn.f64 	%fd149, %fd147, %fd50, %fd148;
	ld.const.f64 	%fd150, [%rd27+8];
	fma.rn.f64 	%fd151, %fd149, %fd50, %fd150;
	ld.const.f64 	%fd152, [%rd27+16];
	fma.rn.f64 	%fd153, %fd151, %fd50, %fd152;
	ld.const.f64 	%fd154, [%rd27+24];
	fma.rn.f64 	%fd155, %fd153, %fd50, %fd154;
	ld.const.f64 	%fd156, [%rd27+32];
	fma.rn.f64 	%fd157, %fd155, %fd50, %fd156;
	ld.const.f64 	%fd158, [%rd27+40];
	fma.rn.f64 	%fd51, %fd157, %fd50, %fd158;
	fma.rn.f64 	%fd177, %fd51, %fd176, %fd176;
	@%p22 bra 	BB61_35;

	mov.f64 	%fd159, 0d3FF0000000000000;
	fma.rn.f64 	%fd177, %fd51, %fd50, %fd159;

BB61_35:
	and.b32  	%r48, %r52, 2;
	setp.eq.s32	%p23, %r48, 0;
	@%p23 bra 	BB61_37;

	mov.f64 	%fd160, 0d0000000000000000;
	mov.f64 	%fd161, 0dBFF0000000000000;
	fma.rn.f64 	%fd177, %fd177, %fd161, %fd160;

BB61_37:
	sub.f64 	%fd162, %fd43, %fd177;
	mul.f64 	%fd179, %fd1, %fd162;

BB61_38:
	st.param.f64	[func_retval0+0], %fd179;
	ret;
}

	// .globl	_Z12Sawtooth_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12Sawtooth_tttddPdiPii(
	.param .b64 _Z12Sawtooth_tttddPdiPii_param_0,
	.param .b64 _Z12Sawtooth_tttddPdiPii_param_1,
	.param .b64 _Z12Sawtooth_tttddPdiPii_param_2,
	.param .b32 _Z12Sawtooth_tttddPdiPii_param_3,
	.param .b64 _Z12Sawtooth_tttddPdiPii_param_4,
	.param .b32 _Z12Sawtooth_tttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot62[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<181>;
	.reg .b64 	%rd<28>;


	mov.u64 	%SPL, __local_depot62;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd58, [_Z12Sawtooth_tttddPdiPii_param_0];
	ld.param.f64 	%fd59, [_Z12Sawtooth_tttddPdiPii_param_1];
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mul.f64 	%fd61, %fd58, %fd59;
	setp.lt.f64	%p1, %fd61, 0d0000000000000000;
	setp.gt.f64	%p2, %fd61, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd180, 0d0000000000000000;
	@%p3 bra 	BB62_38;

	add.f64 	%fd62, %fd59, %fd59;
	mul.f64 	%fd1, %fd62, %fd58;
	mul.f64 	%fd164, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd164;
	}
	and.b32  	%r18, %r17, 2147483647;
	setp.ne.s32	%p4, %r18, 2146435072;
	@%p4 bra 	BB62_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd164;
	}
	setp.ne.s32	%p5, %r19, 0;
	@%p5 bra 	BB62_4;

	mov.f64 	%fd63, 0d0000000000000000;
	mul.rn.f64 	%fd164, %fd164, %fd63;

BB62_4:
	mul.f64 	%fd64, %fd164, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd64;
	st.local.u32 	[%rd1], %r53;
	cvt.rn.f64.s32	%fd65, %r53;
	neg.f64 	%fd66, %fd65;
	mov.f64 	%fd67, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd68, %fd66, %fd67, %fd164;
	mov.f64 	%fd69, 0d3C91A62633145C00;
	fma.rn.f64 	%fd70, %fd66, %fd69, %fd68;
	mov.f64 	%fd71, 0d397B839A252049C0;
	fma.rn.f64 	%fd165, %fd66, %fd71, %fd70;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd164;
	}
	and.b32  	%r21, %r20, 2145386496;
	setp.lt.u32	%p6, %r21, 1105199104;
	@%p6 bra 	BB62_6;

	// Callseq Start 148
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd164;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd165, [retval0+0];
	
	//{
	}// Callseq End 148
	ld.local.u32 	%r53, [%rd1];

BB62_6:
	add.s32 	%r4, %r53, 1;
	and.b32  	%r22, %r4, 1;
	shl.b32 	%r23, %r22, 3;
	setp.eq.s32	%p7, %r22, 0;
	selp.f64	%fd72, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r24, %r23, 1;
	mul.wide.s32 	%rd4, %r24, 8;
	mov.u64 	%rd5, __cudart_sin_cos_coeffs;
	add.s64 	%rd6, %rd5, %rd4;
	ld.const.f64 	%fd73, [%rd6];
	mul.rn.f64 	%fd8, %fd165, %fd165;
	fma.rn.f64 	%fd74, %fd72, %fd8, %fd73;
	ld.const.f64 	%fd75, [%rd6+8];
	fma.rn.f64 	%fd76, %fd74, %fd8, %fd75;
	ld.const.f64 	%fd77, [%rd6+16];
	fma.rn.f64 	%fd78, %fd76, %fd8, %fd77;
	ld.const.f64 	%fd79, [%rd6+24];
	fma.rn.f64 	%fd80, %fd78, %fd8, %fd79;
	ld.const.f64 	%fd81, [%rd6+32];
	fma.rn.f64 	%fd82, %fd80, %fd8, %fd81;
	ld.const.f64 	%fd83, [%rd6+40];
	fma.rn.f64 	%fd9, %fd82, %fd8, %fd83;
	fma.rn.f64 	%fd166, %fd9, %fd165, %fd165;
	@%p7 bra 	BB62_8;

	mov.f64 	%fd84, 0d3FF0000000000000;
	fma.rn.f64 	%fd166, %fd9, %fd8, %fd84;

BB62_8:
	and.b32  	%r25, %r4, 2;
	setp.eq.s32	%p8, %r25, 0;
	@%p8 bra 	BB62_10;

	mov.f64 	%fd85, 0d0000000000000000;
	mov.f64 	%fd86, 0dBFF0000000000000;
	fma.rn.f64 	%fd166, %fd166, %fd86, %fd85;

BB62_10:
	mul.f64 	%fd168, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd168;
	}
	and.b32  	%r27, %r26, 2147483647;
	setp.ne.s32	%p9, %r27, 2146435072;
	@%p9 bra 	BB62_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd168;
	}
	setp.ne.s32	%p10, %r28, 0;
	@%p10 bra 	BB62_13;

	mov.f64 	%fd87, 0d0000000000000000;
	mul.rn.f64 	%fd168, %fd168, %fd87;

BB62_13:
	mul.f64 	%fd88, %fd168, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd88;
	st.local.u32 	[%rd1], %r54;
	cvt.rn.f64.s32	%fd89, %r54;
	neg.f64 	%fd90, %fd89;
	fma.rn.f64 	%fd92, %fd90, %fd67, %fd168;
	fma.rn.f64 	%fd94, %fd90, %fd69, %fd92;
	fma.rn.f64 	%fd169, %fd90, %fd71, %fd94;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd168;
	}
	and.b32  	%r30, %r29, 2145386496;
	setp.lt.u32	%p11, %r30, 1105199104;
	@%p11 bra 	BB62_15;

	// Callseq Start 149
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd168;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd169, [retval0+0];
	
	//{
	}// Callseq End 149
	ld.local.u32 	%r54, [%rd1];

BB62_15:
	add.s32 	%r8, %r54, 1;
	and.b32  	%r31, %r8, 1;
	shl.b32 	%r32, %r31, 3;
	setp.eq.s32	%p12, %r31, 0;
	selp.f64	%fd96, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r33, %r32, 1;
	mul.wide.s32 	%rd11, %r33, 8;
	add.s64 	%rd13, %rd5, %rd11;
	ld.const.f64 	%fd97, [%rd13];
	mul.rn.f64 	%fd21, %fd169, %fd169;
	fma.rn.f64 	%fd98, %fd96, %fd21, %fd97;
	ld.const.f64 	%fd99, [%rd13+8];
	fma.rn.f64 	%fd100, %fd98, %fd21, %fd99;
	ld.const.f64 	%fd101, [%rd13+16];
	fma.rn.f64 	%fd102, %fd100, %fd21, %fd101;
	ld.const.f64 	%fd103, [%rd13+24];
	fma.rn.f64 	%fd104, %fd102, %fd21, %fd103;
	ld.const.f64 	%fd105, [%rd13+32];
	fma.rn.f64 	%fd106, %fd104, %fd21, %fd105;
	ld.const.f64 	%fd107, [%rd13+40];
	fma.rn.f64 	%fd22, %fd106, %fd21, %fd107;
	fma.rn.f64 	%fd170, %fd22, %fd169, %fd169;
	@%p12 bra 	BB62_17;

	mov.f64 	%fd108, 0d3FF0000000000000;
	fma.rn.f64 	%fd170, %fd22, %fd21, %fd108;

BB62_17:
	and.b32  	%r34, %r8, 2;
	setp.eq.s32	%p13, %r34, 0;
	@%p13 bra 	BB62_19;

	mov.f64 	%fd109, 0d0000000000000000;
	mov.f64 	%fd110, 0dBFF0000000000000;
	fma.rn.f64 	%fd170, %fd170, %fd110, %fd109;

BB62_19:
	fma.rn.f64 	%fd28, %fd170, 0dC008000000000000, %fd166;
	mul.f64 	%fd172, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd172;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p14, %r36, 2146435072;
	@%p14 bra 	BB62_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd172;
	}
	setp.ne.s32	%p15, %r37, 0;
	@%p15 bra 	BB62_22;

	mov.f64 	%fd111, 0d0000000000000000;
	mul.rn.f64 	%fd172, %fd172, %fd111;

BB62_22:
	mul.f64 	%fd112, %fd172, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r55, %fd112;
	st.local.u32 	[%rd1], %r55;
	cvt.rn.f64.s32	%fd113, %r55;
	neg.f64 	%fd114, %fd113;
	fma.rn.f64 	%fd116, %fd114, %fd67, %fd172;
	fma.rn.f64 	%fd118, %fd114, %fd69, %fd116;
	fma.rn.f64 	%fd173, %fd114, %fd71, %fd118;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd172;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p16, %r39, 1105199104;
	@%p16 bra 	BB62_24;

	// Callseq Start 150
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd172;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd173, [retval0+0];
	
	//{
	}// Callseq End 150
	ld.local.u32 	%r55, [%rd1];

BB62_24:
	add.s32 	%r12, %r55, 1;
	and.b32  	%r40, %r12, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p17, %r40, 0;
	selp.f64	%fd120, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r42, %r41, 1;
	mul.wide.s32 	%rd18, %r42, 8;
	add.s64 	%rd20, %rd5, %rd18;
	ld.const.f64 	%fd121, [%rd20];
	mul.rn.f64 	%fd35, %fd173, %fd173;
	fma.rn.f64 	%fd122, %fd120, %fd35, %fd121;
	ld.const.f64 	%fd123, [%rd20+8];
	fma.rn.f64 	%fd124, %fd122, %fd35, %fd123;
	ld.const.f64 	%fd125, [%rd20+16];
	fma.rn.f64 	%fd126, %fd124, %fd35, %fd125;
	ld.const.f64 	%fd127, [%rd20+24];
	fma.rn.f64 	%fd128, %fd126, %fd35, %fd127;
	ld.const.f64 	%fd129, [%rd20+32];
	fma.rn.f64 	%fd130, %fd128, %fd35, %fd129;
	ld.const.f64 	%fd131, [%rd20+40];
	fma.rn.f64 	%fd36, %fd130, %fd35, %fd131;
	fma.rn.f64 	%fd174, %fd36, %fd173, %fd173;
	@%p17 bra 	BB62_26;

	mov.f64 	%fd132, 0d3FF0000000000000;
	fma.rn.f64 	%fd174, %fd36, %fd35, %fd132;

BB62_26:
	and.b32  	%r43, %r12, 2;
	setp.eq.s32	%p18, %r43, 0;
	@%p18 bra 	BB62_28;

	mov.f64 	%fd133, 0d0000000000000000;
	mov.f64 	%fd134, 0dBFF0000000000000;
	fma.rn.f64 	%fd174, %fd174, %fd134, %fd133;

BB62_28:
	fma.rn.f64 	%fd42, %fd174, 0d4014000000000000, %fd28;
	mul.f64 	%fd176, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd176;
	}
	and.b32  	%r45, %r44, 2147483647;
	setp.ne.s32	%p19, %r45, 2146435072;
	@%p19 bra 	BB62_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd176;
	}
	setp.ne.s32	%p20, %r46, 0;
	@%p20 bra 	BB62_31;

	mov.f64 	%fd135, 0d0000000000000000;
	mul.rn.f64 	%fd176, %fd176, %fd135;

BB62_31:
	mul.f64 	%fd136, %fd176, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r56, %fd136;
	st.local.u32 	[%rd1], %r56;
	cvt.rn.f64.s32	%fd137, %r56;
	neg.f64 	%fd138, %fd137;
	fma.rn.f64 	%fd140, %fd138, %fd67, %fd176;
	fma.rn.f64 	%fd142, %fd138, %fd69, %fd140;
	fma.rn.f64 	%fd177, %fd138, %fd71, %fd142;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd176;
	}
	and.b32  	%r48, %r47, 2145386496;
	setp.lt.u32	%p21, %r48, 1105199104;
	@%p21 bra 	BB62_33;

	// Callseq Start 151
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd176;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd177, [retval0+0];
	
	//{
	}// Callseq End 151
	ld.local.u32 	%r56, [%rd1];

BB62_33:
	add.s32 	%r16, %r56, 1;
	and.b32  	%r49, %r16, 1;
	shl.b32 	%r50, %r49, 3;
	setp.eq.s32	%p22, %r49, 0;
	selp.f64	%fd144, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r51, %r50, 1;
	mul.wide.s32 	%rd25, %r51, 8;
	add.s64 	%rd27, %rd5, %rd25;
	ld.const.f64 	%fd145, [%rd27];
	mul.rn.f64 	%fd49, %fd177, %fd177;
	fma.rn.f64 	%fd146, %fd144, %fd49, %fd145;
	ld.const.f64 	%fd147, [%rd27+8];
	fma.rn.f64 	%fd148, %fd146, %fd49, %fd147;
	ld.const.f64 	%fd149, [%rd27+16];
	fma.rn.f64 	%fd150, %fd148, %fd49, %fd149;
	ld.const.f64 	%fd151, [%rd27+24];
	fma.rn.f64 	%fd152, %fd150, %fd49, %fd151;
	ld.const.f64 	%fd153, [%rd27+32];
	fma.rn.f64 	%fd154, %fd152, %fd49, %fd153;
	ld.const.f64 	%fd155, [%rd27+40];
	fma.rn.f64 	%fd50, %fd154, %fd49, %fd155;
	fma.rn.f64 	%fd178, %fd50, %fd177, %fd177;
	@%p22 bra 	BB62_35;

	mov.f64 	%fd156, 0d3FF0000000000000;
	fma.rn.f64 	%fd178, %fd50, %fd49, %fd156;

BB62_35:
	and.b32  	%r52, %r16, 2;
	setp.eq.s32	%p23, %r52, 0;
	@%p23 bra 	BB62_37;

	mov.f64 	%fd157, 0d0000000000000000;
	mov.f64 	%fd158, 0dBFF0000000000000;
	fma.rn.f64 	%fd178, %fd178, %fd158, %fd157;

BB62_37:
	fma.rn.f64 	%fd159, %fd178, 0dC01C000000000000, %fd42;
	mul.f64 	%fd160, %fd58, 0d400921FB54442D18;
	mul.f64 	%fd161, %fd160, %fd58;
	mul.f64 	%fd162, %fd161, %fd58;
	mul.f64 	%fd163, %fd162, 0dC050000000000000;
	mul.f64 	%fd180, %fd163, %fd159;

BB62_38:
	st.param.f64	[func_retval0+0], %fd180;
	ret;
}

	// .globl	_Z13Sawtooth_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Sawtooth_omttddPdiPii(
	.param .b64 _Z13Sawtooth_omttddPdiPii_param_0,
	.param .b64 _Z13Sawtooth_omttddPdiPii_param_1,
	.param .b64 _Z13Sawtooth_omttddPdiPii_param_2,
	.param .b32 _Z13Sawtooth_omttddPdiPii_param_3,
	.param .b64 _Z13Sawtooth_omttddPdiPii_param_4,
	.param .b32 _Z13Sawtooth_omttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot63[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<44>;
	.reg .b32 	%r<101>;
	.reg .f64 	%fd<345>;
	.reg .b64 	%rd<49>;


	mov.u64 	%SPL, __local_depot63;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd109, [_Z13Sawtooth_omttddPdiPii_param_0];
	ld.param.f64 	%fd110, [_Z13Sawtooth_omttddPdiPii_param_1];
	add.u64 	%rd9, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd9;
	mul.f64 	%fd112, %fd109, %fd110;
	setp.lt.f64	%p1, %fd112, 0d0000000000000000;
	setp.gt.f64	%p2, %fd112, 0d3FF0000000000000;
	or.pred  	%p3, %p1, %p2;
	mov.f64 	%fd344, 0d0000000000000000;
	@%p3 bra 	BB63_74;

	add.f64 	%fd113, %fd110, %fd110;
	mul.f64 	%fd1, %fd113, %fd109;
	mul.f64 	%fd328, %fd1, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd328;
	}
	and.b32  	%r1, %r33, 2147483647;
	setp.ne.s32	%p4, %r1, 2146435072;
	mov.f64 	%fd312, %fd328;
	@%p4 bra 	BB63_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd328;
	}
	setp.ne.s32	%p5, %r34, 0;
	mov.f64 	%fd312, %fd328;
	@%p5 bra 	BB63_4;

	mov.f64 	%fd114, 0d0000000000000000;
	mul.rn.f64 	%fd312, %fd328, %fd114;

BB63_4:
	mul.f64 	%fd115, %fd312, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r93, %fd115;
	st.local.u32 	[%rd1], %r93;
	cvt.rn.f64.s32	%fd116, %r93;
	neg.f64 	%fd117, %fd116;
	mov.f64 	%fd118, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd119, %fd117, %fd118, %fd312;
	mov.f64 	%fd120, 0d3C91A62633145C00;
	fma.rn.f64 	%fd121, %fd117, %fd120, %fd119;
	mov.f64 	%fd122, 0d397B839A252049C0;
	fma.rn.f64 	%fd313, %fd117, %fd122, %fd121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd312;
	}
	and.b32  	%r36, %r35, 2145386496;
	setp.lt.u32	%p6, %r36, 1105199104;
	@%p6 bra 	BB63_6;

	// Callseq Start 152
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd312;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd313, [retval0+0];
	
	//{
	}// Callseq End 152
	ld.local.u32 	%r93, [%rd1];

BB63_6:
	and.b32  	%r37, %r93, 1;
	shl.b32 	%r38, %r37, 3;
	setp.eq.s32	%p7, %r37, 0;
	selp.f64	%fd123, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r39, %r38, 1;
	mul.wide.s32 	%rd18, %r39, 8;
	mov.u64 	%rd19, __cudart_sin_cos_coeffs;
	add.s64 	%rd20, %rd19, %rd18;
	ld.const.f64 	%fd124, [%rd20];
	mul.rn.f64 	%fd8, %fd313, %fd313;
	fma.rn.f64 	%fd125, %fd123, %fd8, %fd124;
	ld.const.f64 	%fd126, [%rd20+8];
	fma.rn.f64 	%fd127, %fd125, %fd8, %fd126;
	ld.const.f64 	%fd128, [%rd20+16];
	fma.rn.f64 	%fd129, %fd127, %fd8, %fd128;
	ld.const.f64 	%fd130, [%rd20+24];
	fma.rn.f64 	%fd131, %fd129, %fd8, %fd130;
	ld.const.f64 	%fd132, [%rd20+32];
	fma.rn.f64 	%fd133, %fd131, %fd8, %fd132;
	ld.const.f64 	%fd134, [%rd20+40];
	fma.rn.f64 	%fd9, %fd133, %fd8, %fd134;
	fma.rn.f64 	%fd314, %fd9, %fd313, %fd313;
	@%p7 bra 	BB63_8;

	mov.f64 	%fd135, 0d3FF0000000000000;
	fma.rn.f64 	%fd314, %fd9, %fd8, %fd135;

BB63_8:
	and.b32  	%r40, %r93, 2;
	setp.eq.s32	%p8, %r40, 0;
	@%p8 bra 	BB63_10;

	mov.f64 	%fd136, 0d0000000000000000;
	mov.f64 	%fd137, 0dBFF0000000000000;
	fma.rn.f64 	%fd314, %fd314, %fd137, %fd136;

BB63_10:
	mul.f64 	%fd332, %fd1, 0d4022D97C7F3321D2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd332;
	}
	and.b32  	%r5, %r41, 2147483647;
	setp.ne.s32	%p9, %r5, 2146435072;
	mov.f64 	%fd316, %fd332;
	@%p9 bra 	BB63_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd332;
	}
	setp.ne.s32	%p10, %r42, 0;
	mov.f64 	%fd316, %fd332;
	@%p10 bra 	BB63_13;

	mov.f64 	%fd138, 0d0000000000000000;
	mul.rn.f64 	%fd316, %fd332, %fd138;

BB63_13:
	mul.f64 	%fd139, %fd316, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r94, %fd139;
	st.local.u32 	[%rd1], %r94;
	cvt.rn.f64.s32	%fd140, %r94;
	neg.f64 	%fd141, %fd140;
	fma.rn.f64 	%fd143, %fd141, %fd118, %fd316;
	fma.rn.f64 	%fd145, %fd141, %fd120, %fd143;
	fma.rn.f64 	%fd317, %fd141, %fd122, %fd145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd316;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p11, %r44, 1105199104;
	@%p11 bra 	BB63_15;

	// Callseq Start 153
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd316;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd317, [retval0+0];
	
	//{
	}// Callseq End 153
	ld.local.u32 	%r94, [%rd1];

BB63_15:
	and.b32  	%r45, %r94, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p12, %r45, 0;
	selp.f64	%fd147, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd22, %r47, 8;
	add.s64 	%rd24, %rd19, %rd22;
	ld.const.f64 	%fd148, [%rd24];
	mul.rn.f64 	%fd21, %fd317, %fd317;
	fma.rn.f64 	%fd149, %fd147, %fd21, %fd148;
	ld.const.f64 	%fd150, [%rd24+8];
	fma.rn.f64 	%fd151, %fd149, %fd21, %fd150;
	ld.const.f64 	%fd152, [%rd24+16];
	fma.rn.f64 	%fd153, %fd151, %fd21, %fd152;
	ld.const.f64 	%fd154, [%rd24+24];
	fma.rn.f64 	%fd155, %fd153, %fd21, %fd154;
	ld.const.f64 	%fd156, [%rd24+32];
	fma.rn.f64 	%fd157, %fd155, %fd21, %fd156;
	ld.const.f64 	%fd158, [%rd24+40];
	fma.rn.f64 	%fd22, %fd157, %fd21, %fd158;
	fma.rn.f64 	%fd318, %fd22, %fd317, %fd317;
	@%p12 bra 	BB63_17;

	mov.f64 	%fd159, 0d3FF0000000000000;
	fma.rn.f64 	%fd318, %fd22, %fd21, %fd159;

BB63_17:
	and.b32  	%r48, %r94, 2;
	setp.eq.s32	%p13, %r48, 0;
	@%p13 bra 	BB63_19;

	mov.f64 	%fd160, 0d0000000000000000;
	mov.f64 	%fd161, 0dBFF0000000000000;
	fma.rn.f64 	%fd318, %fd318, %fd161, %fd160;

BB63_19:
	sub.f64 	%fd28, %fd314, %fd318;
	mul.f64 	%fd336, %fd1, 0d402F6A7A2955385E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd336;
	}
	and.b32  	%r9, %r49, 2147483647;
	setp.ne.s32	%p14, %r9, 2146435072;
	mov.f64 	%fd320, %fd336;
	@%p14 bra 	BB63_22;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd336;
	}
	setp.ne.s32	%p15, %r50, 0;
	mov.f64 	%fd320, %fd336;
	@%p15 bra 	BB63_22;

	mov.f64 	%fd162, 0d0000000000000000;
	mul.rn.f64 	%fd320, %fd336, %fd162;

BB63_22:
	mul.f64 	%fd163, %fd320, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r95, %fd163;
	st.local.u32 	[%rd1], %r95;
	cvt.rn.f64.s32	%fd164, %r95;
	neg.f64 	%fd165, %fd164;
	fma.rn.f64 	%fd167, %fd165, %fd118, %fd320;
	fma.rn.f64 	%fd169, %fd165, %fd120, %fd167;
	fma.rn.f64 	%fd321, %fd165, %fd122, %fd169;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd320;
	}
	and.b32  	%r52, %r51, 2145386496;
	setp.lt.u32	%p16, %r52, 1105199104;
	@%p16 bra 	BB63_24;

	// Callseq Start 154
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd320;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd321, [retval0+0];
	
	//{
	}// Callseq End 154
	ld.local.u32 	%r95, [%rd1];

BB63_24:
	and.b32  	%r53, %r95, 1;
	shl.b32 	%r54, %r53, 3;
	setp.eq.s32	%p17, %r53, 0;
	selp.f64	%fd171, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	add.s32 	%r55, %r54, 1;
	mul.wide.s32 	%rd26, %r55, 8;
	add.s64 	%rd28, %rd19, %rd26;
	ld.const.f64 	%fd172, [%rd28];
	mul.rn.f64 	%fd35, %fd321, %fd321;
	fma.rn.f64 	%fd173, %fd171, %fd35, %fd172;
	ld.const.f64 	%fd174, [%rd28+8];
	fma.rn.f64 	%fd175, %fd173, %fd35, %fd174;
	ld.const.f64 	%fd176, [%rd28+16];
	fma.rn.f64 	%fd177, %fd175, %fd35, %fd176;
	ld.const.f64 	%fd178, [%rd28+24];
	fma.rn.f64 	%fd179, %fd177, %fd35, %fd178;
	ld.const.f64 	%fd180, [%rd28+32];
	fma.rn.f64 	%fd181, %fd179, %fd35, %fd180;
	ld.const.f64 	%fd182, [%rd28+40];
	fma.rn.f64 	%fd36, %fd181, %fd35, %fd182;
	fma.rn.f64 	%fd322, %fd36, %fd321, %fd321;
	@%p17 bra 	BB63_26;

	mov.f64 	%fd183, 0d3FF0000000000000;
	fma.rn.f64 	%fd322, %fd36, %fd35, %fd183;

BB63_26:
	and.b32  	%r56, %r95, 2;
	setp.eq.s32	%p18, %r56, 0;
	@%p18 bra 	BB63_28;

	mov.f64 	%fd184, 0d0000000000000000;
	mov.f64 	%fd185, 0dBFF0000000000000;
	fma.rn.f64 	%fd322, %fd322, %fd185, %fd184;

BB63_28:
	add.f64 	%fd42, %fd28, %fd322;
	mul.f64 	%fd340, %fd1, 0d4035FDBBE9BBA775;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r57}, %fd340;
	}
	and.b32  	%r13, %r57, 2147483647;
	setp.ne.s32	%p19, %r13, 2146435072;
	mov.f64 	%fd324, %fd340;
	@%p19 bra 	BB63_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd340;
	}
	setp.ne.s32	%p20, %r58, 0;
	mov.f64 	%fd324, %fd340;
	@%p20 bra 	BB63_31;

	mov.f64 	%fd186, 0d0000000000000000;
	mul.rn.f64 	%fd324, %fd340, %fd186;

BB63_31:
	mul.f64 	%fd187, %fd324, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r96, %fd187;
	st.local.u32 	[%rd1], %r96;
	cvt.rn.f64.s32	%fd188, %r96;
	neg.f64 	%fd189, %fd188;
	fma.rn.f64 	%fd191, %fd189, %fd118, %fd324;
	fma.rn.f64 	%fd193, %fd189, %fd120, %fd191;
	fma.rn.f64 	%fd325, %fd189, %fd122, %fd193;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd324;
	}
	and.b32  	%r60, %r59, 2145386496;
	setp.lt.u32	%p21, %r60, 1105199104;
	@%p21 bra 	BB63_33;

	// Callseq Start 155
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd324;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd325, [retval0+0];
	
	//{
	}// Callseq End 155
	ld.local.u32 	%r96, [%rd1];

BB63_33:
	and.b32  	%r61, %r96, 1;
	shl.b32 	%r62, %r61, 3;
	setp.eq.s32	%p22, %r61, 0;
	selp.f64	%fd195, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	add.s32 	%r63, %r62, 1;
	mul.wide.s32 	%rd30, %r63, 8;
	add.s64 	%rd32, %rd19, %rd30;
	ld.const.f64 	%fd196, [%rd32];
	mul.rn.f64 	%fd49, %fd325, %fd325;
	fma.rn.f64 	%fd197, %fd195, %fd49, %fd196;
	ld.const.f64 	%fd198, [%rd32+8];
	fma.rn.f64 	%fd199, %fd197, %fd49, %fd198;
	ld.const.f64 	%fd200, [%rd32+16];
	fma.rn.f64 	%fd201, %fd199, %fd49, %fd200;
	ld.const.f64 	%fd202, [%rd32+24];
	fma.rn.f64 	%fd203, %fd201, %fd49, %fd202;
	ld.const.f64 	%fd204, [%rd32+32];
	fma.rn.f64 	%fd205, %fd203, %fd49, %fd204;
	ld.const.f64 	%fd206, [%rd32+40];
	fma.rn.f64 	%fd50, %fd205, %fd49, %fd206;
	fma.rn.f64 	%fd326, %fd50, %fd325, %fd325;
	@%p22 bra 	BB63_35;

	mov.f64 	%fd207, 0d3FF0000000000000;
	fma.rn.f64 	%fd326, %fd50, %fd49, %fd207;

BB63_35:
	and.b32  	%r64, %r96, 2;
	setp.eq.s32	%p23, %r64, 0;
	@%p23 bra 	BB63_37;

	mov.f64 	%fd208, 0d0000000000000000;
	mov.f64 	%fd209, 0dBFF0000000000000;
	fma.rn.f64 	%fd326, %fd326, %fd209, %fd208;

BB63_37:
	sub.f64 	%fd56, %fd42, %fd326;
	@%p4 bra 	BB63_40;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r65, %temp}, %fd328;
	}
	setp.ne.s32	%p25, %r65, 0;
	@%p25 bra 	BB63_40;

	mov.f64 	%fd210, 0d0000000000000000;
	mul.rn.f64 	%fd328, %fd328, %fd210;

BB63_40:
	mul.f64 	%fd211, %fd328, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r97, %fd211;
	st.local.u32 	[%rd1], %r97;
	cvt.rn.f64.s32	%fd212, %r97;
	neg.f64 	%fd213, %fd212;
	fma.rn.f64 	%fd215, %fd213, %fd118, %fd328;
	fma.rn.f64 	%fd217, %fd213, %fd120, %fd215;
	fma.rn.f64 	%fd329, %fd213, %fd122, %fd217;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd328;
	}
	and.b32  	%r67, %r66, 2145386496;
	setp.lt.u32	%p26, %r67, 1105199104;
	@%p26 bra 	BB63_42;

	// Callseq Start 156
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd328;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd329, [retval0+0];
	
	//{
	}// Callseq End 156
	ld.local.u32 	%r97, [%rd1];

BB63_42:
	add.s32 	%r20, %r97, 1;
	and.b32  	%r68, %r20, 1;
	shl.b32 	%r69, %r68, 3;
	setp.eq.s32	%p27, %r68, 0;
	selp.f64	%fd219, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p27;
	add.s32 	%r70, %r69, 1;
	mul.wide.s32 	%rd34, %r70, 8;
	add.s64 	%rd36, %rd19, %rd34;
	ld.const.f64 	%fd220, [%rd36];
	mul.rn.f64 	%fd62, %fd329, %fd329;
	fma.rn.f64 	%fd221, %fd219, %fd62, %fd220;
	ld.const.f64 	%fd222, [%rd36+8];
	fma.rn.f64 	%fd223, %fd221, %fd62, %fd222;
	ld.const.f64 	%fd224, [%rd36+16];
	fma.rn.f64 	%fd225, %fd223, %fd62, %fd224;
	ld.const.f64 	%fd226, [%rd36+24];
	fma.rn.f64 	%fd227, %fd225, %fd62, %fd226;
	ld.const.f64 	%fd228, [%rd36+32];
	fma.rn.f64 	%fd229, %fd227, %fd62, %fd228;
	ld.const.f64 	%fd230, [%rd36+40];
	fma.rn.f64 	%fd63, %fd229, %fd62, %fd230;
	fma.rn.f64 	%fd330, %fd63, %fd329, %fd329;
	@%p27 bra 	BB63_44;

	mov.f64 	%fd231, 0d3FF0000000000000;
	fma.rn.f64 	%fd330, %fd63, %fd62, %fd231;

BB63_44:
	and.b32  	%r71, %r20, 2;
	setp.eq.s32	%p28, %r71, 0;
	@%p28 bra 	BB63_46;

	mov.f64 	%fd232, 0d0000000000000000;
	mov.f64 	%fd233, 0dBFF0000000000000;
	fma.rn.f64 	%fd330, %fd330, %fd233, %fd232;

BB63_46:
	@%p9 bra 	BB63_49;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd332;
	}
	setp.ne.s32	%p30, %r72, 0;
	@%p30 bra 	BB63_49;

	mov.f64 	%fd234, 0d0000000000000000;
	mul.rn.f64 	%fd332, %fd332, %fd234;

BB63_49:
	mul.f64 	%fd235, %fd332, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r98, %fd235;
	st.local.u32 	[%rd1], %r98;
	cvt.rn.f64.s32	%fd236, %r98;
	neg.f64 	%fd237, %fd236;
	fma.rn.f64 	%fd239, %fd237, %fd118, %fd332;
	fma.rn.f64 	%fd241, %fd237, %fd120, %fd239;
	fma.rn.f64 	%fd333, %fd237, %fd122, %fd241;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd332;
	}
	and.b32  	%r74, %r73, 2145386496;
	setp.lt.u32	%p31, %r74, 1105199104;
	@%p31 bra 	BB63_51;

	// Callseq Start 157
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd332;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd333, [retval0+0];
	
	//{
	}// Callseq End 157
	ld.local.u32 	%r98, [%rd1];

BB63_51:
	add.s32 	%r24, %r98, 1;
	and.b32  	%r75, %r24, 1;
	shl.b32 	%r76, %r75, 3;
	setp.eq.s32	%p32, %r75, 0;
	selp.f64	%fd243, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	add.s32 	%r77, %r76, 1;
	mul.wide.s32 	%rd38, %r77, 8;
	add.s64 	%rd40, %rd19, %rd38;
	ld.const.f64 	%fd244, [%rd40];
	mul.rn.f64 	%fd74, %fd333, %fd333;
	fma.rn.f64 	%fd245, %fd243, %fd74, %fd244;
	ld.const.f64 	%fd246, [%rd40+8];
	fma.rn.f64 	%fd247, %fd245, %fd74, %fd246;
	ld.const.f64 	%fd248, [%rd40+16];
	fma.rn.f64 	%fd249, %fd247, %fd74, %fd248;
	ld.const.f64 	%fd250, [%rd40+24];
	fma.rn.f64 	%fd251, %fd249, %fd74, %fd250;
	ld.const.f64 	%fd252, [%rd40+32];
	fma.rn.f64 	%fd253, %fd251, %fd74, %fd252;
	ld.const.f64 	%fd254, [%rd40+40];
	fma.rn.f64 	%fd75, %fd253, %fd74, %fd254;
	fma.rn.f64 	%fd334, %fd75, %fd333, %fd333;
	@%p32 bra 	BB63_53;

	mov.f64 	%fd255, 0d3FF0000000000000;
	fma.rn.f64 	%fd334, %fd75, %fd74, %fd255;

BB63_53:
	and.b32  	%r78, %r24, 2;
	setp.eq.s32	%p33, %r78, 0;
	@%p33 bra 	BB63_55;

	mov.f64 	%fd256, 0d0000000000000000;
	mov.f64 	%fd257, 0dBFF0000000000000;
	fma.rn.f64 	%fd334, %fd334, %fd257, %fd256;

BB63_55:
	fma.rn.f64 	%fd81, %fd334, 0dC008000000000000, %fd330;
	@%p14 bra 	BB63_58;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd336;
	}
	setp.ne.s32	%p35, %r79, 0;
	@%p35 bra 	BB63_58;

	mov.f64 	%fd258, 0d0000000000000000;
	mul.rn.f64 	%fd336, %fd336, %fd258;

BB63_58:
	mul.f64 	%fd259, %fd336, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r99, %fd259;
	st.local.u32 	[%rd1], %r99;
	cvt.rn.f64.s32	%fd260, %r99;
	neg.f64 	%fd261, %fd260;
	fma.rn.f64 	%fd263, %fd261, %fd118, %fd336;
	fma.rn.f64 	%fd265, %fd261, %fd120, %fd263;
	fma.rn.f64 	%fd337, %fd261, %fd122, %fd265;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd336;
	}
	and.b32  	%r81, %r80, 2145386496;
	setp.lt.u32	%p36, %r81, 1105199104;
	@%p36 bra 	BB63_60;

	// Callseq Start 158
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd336;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd337, [retval0+0];
	
	//{
	}// Callseq End 158
	ld.local.u32 	%r99, [%rd1];

BB63_60:
	add.s32 	%r28, %r99, 1;
	and.b32  	%r82, %r28, 1;
	shl.b32 	%r83, %r82, 3;
	setp.eq.s32	%p37, %r82, 0;
	selp.f64	%fd267, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p37;
	add.s32 	%r84, %r83, 1;
	mul.wide.s32 	%rd42, %r84, 8;
	add.s64 	%rd44, %rd19, %rd42;
	ld.const.f64 	%fd268, [%rd44];
	mul.rn.f64 	%fd87, %fd337, %fd337;
	fma.rn.f64 	%fd269, %fd267, %fd87, %fd268;
	ld.const.f64 	%fd270, [%rd44+8];
	fma.rn.f64 	%fd271, %fd269, %fd87, %fd270;
	ld.const.f64 	%fd272, [%rd44+16];
	fma.rn.f64 	%fd273, %fd271, %fd87, %fd272;
	ld.const.f64 	%fd274, [%rd44+24];
	fma.rn.f64 	%fd275, %fd273, %fd87, %fd274;
	ld.const.f64 	%fd276, [%rd44+32];
	fma.rn.f64 	%fd277, %fd275, %fd87, %fd276;
	ld.const.f64 	%fd278, [%rd44+40];
	fma.rn.f64 	%fd88, %fd277, %fd87, %fd278;
	fma.rn.f64 	%fd338, %fd88, %fd337, %fd337;
	@%p37 bra 	BB63_62;

	mov.f64 	%fd279, 0d3FF0000000000000;
	fma.rn.f64 	%fd338, %fd88, %fd87, %fd279;

BB63_62:
	and.b32  	%r85, %r28, 2;
	setp.eq.s32	%p38, %r85, 0;
	@%p38 bra 	BB63_64;

	mov.f64 	%fd280, 0d0000000000000000;
	mov.f64 	%fd281, 0dBFF0000000000000;
	fma.rn.f64 	%fd338, %fd338, %fd281, %fd280;

BB63_64:
	fma.rn.f64 	%fd94, %fd338, 0d4014000000000000, %fd81;
	@%p19 bra 	BB63_67;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd340;
	}
	setp.ne.s32	%p40, %r86, 0;
	@%p40 bra 	BB63_67;

	mov.f64 	%fd282, 0d0000000000000000;
	mul.rn.f64 	%fd340, %fd340, %fd282;

BB63_67:
	mul.f64 	%fd283, %fd340, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r100, %fd283;
	st.local.u32 	[%rd1], %r100;
	cvt.rn.f64.s32	%fd284, %r100;
	neg.f64 	%fd285, %fd284;
	fma.rn.f64 	%fd287, %fd285, %fd118, %fd340;
	fma.rn.f64 	%fd289, %fd285, %fd120, %fd287;
	fma.rn.f64 	%fd341, %fd285, %fd122, %fd289;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd340;
	}
	and.b32  	%r88, %r87, 2145386496;
	setp.lt.u32	%p41, %r88, 1105199104;
	@%p41 bra 	BB63_69;

	// Callseq Start 159
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd340;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd9;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd341, [retval0+0];
	
	//{
	}// Callseq End 159
	ld.local.u32 	%r100, [%rd1];

BB63_69:
	add.s32 	%r32, %r100, 1;
	and.b32  	%r89, %r32, 1;
	shl.b32 	%r90, %r89, 3;
	setp.eq.s32	%p42, %r89, 0;
	selp.f64	%fd291, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p42;
	add.s32 	%r91, %r90, 1;
	mul.wide.s32 	%rd46, %r91, 8;
	add.s64 	%rd48, %rd19, %rd46;
	ld.const.f64 	%fd292, [%rd48];
	mul.rn.f64 	%fd100, %fd341, %fd341;
	fma.rn.f64 	%fd293, %fd291, %fd100, %fd292;
	ld.const.f64 	%fd294, [%rd48+8];
	fma.rn.f64 	%fd295, %fd293, %fd100, %fd294;
	ld.const.f64 	%fd296, [%rd48+16];
	fma.rn.f64 	%fd297, %fd295, %fd100, %fd296;
	ld.const.f64 	%fd298, [%rd48+24];
	fma.rn.f64 	%fd299, %fd297, %fd100, %fd298;
	ld.const.f64 	%fd300, [%rd48+32];
	fma.rn.f64 	%fd301, %fd299, %fd100, %fd300;
	ld.const.f64 	%fd302, [%rd48+40];
	fma.rn.f64 	%fd101, %fd301, %fd100, %fd302;
	fma.rn.f64 	%fd342, %fd101, %fd341, %fd341;
	@%p42 bra 	BB63_71;

	mov.f64 	%fd303, 0d3FF0000000000000;
	fma.rn.f64 	%fd342, %fd101, %fd100, %fd303;

BB63_71:
	and.b32  	%r92, %r32, 2;
	setp.eq.s32	%p43, %r92, 0;
	@%p43 bra 	BB63_73;

	mov.f64 	%fd304, 0d0000000000000000;
	mov.f64 	%fd305, 0dBFF0000000000000;
	fma.rn.f64 	%fd342, %fd342, %fd305, %fd304;

BB63_73:
	fma.rn.f64 	%fd306, %fd342, 0dC01C000000000000, %fd94;
	mul.f64 	%fd307, %fd109, 0dC06921FB54442D18;
	mul.f64 	%fd308, %fd307, %fd109;
	mul.f64 	%fd309, %fd308, %fd110;
	mul.f64 	%fd310, %fd309, %fd306;
	mul.f64 	%fd311, %fd109, 0dC050000000000000;
	fma.rn.f64 	%fd344, %fd311, %fd56, %fd310;

BB63_74:
	st.param.f64	[func_retval0+0], %fd344;
	ret;
}

	// .globl	_Z10SmoothWaveddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10SmoothWaveddPdiPii(
	.param .b64 _Z10SmoothWaveddPdiPii_param_0,
	.param .b64 _Z10SmoothWaveddPdiPii_param_1,
	.param .b64 _Z10SmoothWaveddPdiPii_param_2,
	.param .b32 _Z10SmoothWaveddPdiPii_param_3,
	.param .b64 _Z10SmoothWaveddPdiPii_param_4,
	.param .b32 _Z10SmoothWaveddPdiPii_param_5
)
{
	.reg .pred 	%p<93>;
	.reg .b32 	%r<137>;
	.reg .f64 	%fd<107>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd59, [_Z10SmoothWaveddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z10SmoothWaveddPdiPii_param_1];
	mul.f64 	%fd1, %fd59, %fd60;
	setp.lt.f64	%p6, %fd1, 0d0000000000000000;
	setp.gt.f64	%p7, %fd1, 0d3FF0000000000000;
	or.pred  	%p8, %p6, %p7;
	mov.f64 	%fd106, 0d0000000000000000;
	@%p8 bra 	BB64_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd61, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd61;
	}
	bfe.u32 	%r7, %r2, 20, 11;
	add.s32 	%r8, %r7, -1012;
	mov.u64 	%rd6, 4613937818241073152;
	shl.b64 	%rd1, %rd6, %r8;
	setp.eq.s64	%p9, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 160
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd92, [retval0+0];
	
	//{
	}// Callseq End 160
	setp.lt.s32	%p10, %r1, 0;
	and.pred  	%p1, %p10, %p9;
	@!%p1 bra 	BB64_3;
	bra.uni 	BB64_2;

BB64_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd92;
	}
	xor.b32  	%r10, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r11, %temp}, %fd92;
	}
	mov.b64 	%fd92, {%r11, %r10};

BB64_3:
	setp.eq.f64	%p11, %fd1, 0d0000000000000000;
	@%p11 bra 	BB64_6;
	bra.uni 	BB64_4;

BB64_6:
	selp.b32	%r12, %r1, 0, %p9;
	or.b32  	%r13, %r12, 2146435072;
	setp.lt.s32	%p15, %r2, 0;
	selp.b32	%r14, %r13, %r12, %p15;
	mov.u32 	%r15, 0;
	mov.b64 	%fd92, {%r15, %r14};
	bra.uni 	BB64_7;

BB64_4:
	setp.gt.s32	%p12, %r1, -1;
	@%p12 bra 	BB64_7;

	cvt.rzi.f64.f64	%fd63, %fd61;
	setp.neu.f64	%p13, %fd63, 0d4008000000000000;
	selp.f64	%fd92, 0dFFF8000000000000, %fd92, %p13;

BB64_7:
	add.f64 	%fd93, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd93;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.ne.s32	%p16, %r17, 2146435072;
	@%p16 bra 	BB64_8;

	setp.gtu.f64	%p17, %fd2, 0d7FF0000000000000;
	@%p17 bra 	BB64_17;

	and.b32  	%r18, %r2, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB64_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd61;
	}
	setp.eq.s32	%p19, %r19, 0;
	@%p19 bra 	BB64_16;

BB64_12:
	and.b32  	%r20, %r1, 2147483647;
	setp.ne.s32	%p20, %r20, 2146435072;
	@%p20 bra 	BB64_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd1;
	}
	setp.ne.s32	%p21, %r21, 0;
	mov.f64 	%fd93, %fd92;
	@%p21 bra 	BB64_17;

	shr.s32 	%r22, %r2, 31;
	and.b32  	%r23, %r22, -2146435072;
	add.s32 	%r24, %r23, 2146435072;
	or.b32  	%r25, %r24, -2147483648;
	selp.b32	%r26, %r25, %r24, %p1;
	mov.u32 	%r27, 0;
	mov.b64 	%fd93, {%r27, %r26};
	bra.uni 	BB64_17;

BB64_8:
	mov.f64 	%fd93, %fd92;
	bra.uni 	BB64_17;

BB64_13:
	mov.f64 	%fd93, %fd92;
	bra.uni 	BB64_17;

BB64_16:
	setp.gt.f64	%p22, %fd2, 0d3FF0000000000000;
	selp.b32	%r28, 2146435072, 0, %p22;
	xor.b32  	%r29, %r28, 2146435072;
	setp.lt.s32	%p23, %r2, 0;
	selp.b32	%r30, %r29, %r28, %p23;
	setp.eq.f64	%p24, %fd1, 0dBFF0000000000000;
	selp.b32	%r31, 1072693248, %r30, %p24;
	mov.u32 	%r32, 0;
	mov.b64 	%fd93, {%r32, %r31};

BB64_17:
	mov.f64 	%fd65, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd65;
	}
	bfe.u32 	%r33, %r3, 20, 11;
	add.s32 	%r34, %r33, -1012;
	mov.u64 	%rd7, 4616189618054758400;
	shl.b64 	%rd2, %rd7, %r34;
	setp.eq.s64	%p25, %rd2, -9223372036854775808;
	// Callseq Start 161
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd65;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd95, [retval0+0];
	
	//{
	}// Callseq End 161
	and.pred  	%p2, %p10, %p25;
	@!%p2 bra 	BB64_19;
	bra.uni 	BB64_18;

BB64_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd95;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd95;
	}
	mov.b64 	%fd95, {%r37, %r36};

BB64_19:
	@%p11 bra 	BB64_22;
	bra.uni 	BB64_20;

BB64_22:
	selp.b32	%r38, %r1, 0, %p25;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p31;
	mov.u32 	%r41, 0;
	mov.b64 	%fd95, {%r41, %r40};
	bra.uni 	BB64_23;

BB64_20:
	setp.gt.s32	%p28, %r1, -1;
	@%p28 bra 	BB64_23;

	cvt.rzi.f64.f64	%fd67, %fd65;
	setp.neu.f64	%p29, %fd67, 0d4010000000000000;
	selp.f64	%fd95, 0dFFF8000000000000, %fd95, %p29;

BB64_23:
	add.f64 	%fd96, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd96;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p32, %r43, 2146435072;
	@%p32 bra 	BB64_24;

	setp.gtu.f64	%p33, %fd2, 0d7FF0000000000000;
	@%p33 bra 	BB64_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p34, %r44, 2146435072;
	@%p34 bra 	BB64_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd65;
	}
	setp.eq.s32	%p35, %r45, 0;
	@%p35 bra 	BB64_32;

BB64_28:
	and.b32  	%r46, %r1, 2147483647;
	setp.ne.s32	%p36, %r46, 2146435072;
	@%p36 bra 	BB64_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd1;
	}
	setp.ne.s32	%p37, %r47, 0;
	mov.f64 	%fd96, %fd95;
	@%p37 bra 	BB64_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd96, {%r53, %r52};
	bra.uni 	BB64_33;

BB64_24:
	mov.f64 	%fd96, %fd95;
	bra.uni 	BB64_33;

BB64_29:
	mov.f64 	%fd96, %fd95;
	bra.uni 	BB64_33;

BB64_32:
	setp.gt.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p38;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p39;
	setp.eq.f64	%p40, %fd1, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p40;
	mov.u32 	%r58, 0;
	mov.b64 	%fd96, {%r58, %r57};

BB64_33:
	mul.f64 	%fd69, %fd96, 0dC0955B8000000000;
	setp.eq.f64	%p41, %fd1, 0d3FF0000000000000;
	selp.f64	%fd70, 0dC0955B8000000000, %fd69, %p41;
	mul.f64 	%fd71, %fd93, 0d4071160000000000;
	selp.f64	%fd72, 0d4071160000000000, %fd71, %p41;
	add.f64 	%fd23, %fd72, %fd70;
	mov.f64 	%fd73, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd73;
	}
	bfe.u32 	%r59, %r4, 20, 11;
	add.s32 	%r60, %r59, -1012;
	mov.u64 	%rd8, 4617315517961601024;
	shl.b64 	%rd3, %rd8, %r60;
	setp.eq.s64	%p42, %rd3, -9223372036854775808;
	// Callseq Start 162
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd73;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd98, [retval0+0];
	
	//{
	}// Callseq End 162
	and.pred  	%p3, %p10, %p42;
	@!%p3 bra 	BB64_35;
	bra.uni 	BB64_34;

BB64_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd98;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd98;
	}
	mov.b64 	%fd98, {%r63, %r62};

BB64_35:
	@%p11 bra 	BB64_38;
	bra.uni 	BB64_36;

BB64_38:
	selp.b32	%r64, %r1, 0, %p42;
	or.b32  	%r65, %r64, 2146435072;
	setp.lt.s32	%p48, %r4, 0;
	selp.b32	%r66, %r65, %r64, %p48;
	mov.u32 	%r67, 0;
	mov.b64 	%fd98, {%r67, %r66};
	bra.uni 	BB64_39;

BB64_36:
	setp.gt.s32	%p45, %r1, -1;
	@%p45 bra 	BB64_39;

	cvt.rzi.f64.f64	%fd75, %fd73;
	setp.neu.f64	%p46, %fd75, 0d4014000000000000;
	selp.f64	%fd98, 0dFFF8000000000000, %fd98, %p46;

BB64_39:
	add.f64 	%fd99, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd99;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.ne.s32	%p49, %r69, 2146435072;
	@%p49 bra 	BB64_40;

	setp.gtu.f64	%p50, %fd2, 0d7FF0000000000000;
	@%p50 bra 	BB64_49;

	and.b32  	%r70, %r4, 2147483647;
	setp.ne.s32	%p51, %r70, 2146435072;
	@%p51 bra 	BB64_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd73;
	}
	setp.eq.s32	%p52, %r71, 0;
	@%p52 bra 	BB64_48;

BB64_44:
	and.b32  	%r72, %r1, 2147483647;
	setp.ne.s32	%p53, %r72, 2146435072;
	@%p53 bra 	BB64_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r73, 0;
	mov.f64 	%fd99, %fd98;
	@%p54 bra 	BB64_49;

	shr.s32 	%r74, %r4, 31;
	and.b32  	%r75, %r74, -2146435072;
	add.s32 	%r76, %r75, 2146435072;
	or.b32  	%r77, %r76, -2147483648;
	selp.b32	%r78, %r77, %r76, %p3;
	mov.u32 	%r79, 0;
	mov.b64 	%fd99, {%r79, %r78};
	bra.uni 	BB64_49;

BB64_40:
	mov.f64 	%fd99, %fd98;
	bra.uni 	BB64_49;

BB64_45:
	mov.f64 	%fd99, %fd98;
	bra.uni 	BB64_49;

BB64_48:
	setp.gt.f64	%p55, %fd2, 0d3FF0000000000000;
	selp.b32	%r80, 2146435072, 0, %p55;
	xor.b32  	%r81, %r80, 2146435072;
	setp.lt.s32	%p56, %r4, 0;
	selp.b32	%r82, %r81, %r80, %p56;
	setp.eq.f64	%p57, %fd1, 0dBFF0000000000000;
	selp.b32	%r83, 1072693248, %r82, %p57;
	mov.u32 	%r84, 0;
	mov.b64 	%fd99, {%r84, %r83};

BB64_49:
	mul.f64 	%fd77, %fd99, 0d40A338C000000000;
	selp.f64	%fd78, 0d40A338C000000000, %fd77, %p41;
	add.f64 	%fd34, %fd23, %fd78;
	mov.f64 	%fd79, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd79;
	}
	bfe.u32 	%r85, %r5, 20, 11;
	add.s32 	%r86, %r85, -1012;
	mov.u64 	%rd9, 4618441417868443648;
	shl.b64 	%rd4, %rd9, %r86;
	setp.eq.s64	%p59, %rd4, -9223372036854775808;
	// Callseq Start 163
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd79;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd101, [retval0+0];
	
	//{
	}// Callseq End 163
	and.pred  	%p4, %p10, %p59;
	@!%p4 bra 	BB64_51;
	bra.uni 	BB64_50;

BB64_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd101;
	}
	xor.b32  	%r88, %r87, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd101;
	}
	mov.b64 	%fd101, {%r89, %r88};

BB64_51:
	@%p11 bra 	BB64_54;
	bra.uni 	BB64_52;

BB64_54:
	selp.b32	%r90, %r1, 0, %p59;
	or.b32  	%r91, %r90, 2146435072;
	setp.lt.s32	%p65, %r5, 0;
	selp.b32	%r92, %r91, %r90, %p65;
	mov.u32 	%r93, 0;
	mov.b64 	%fd101, {%r93, %r92};
	bra.uni 	BB64_55;

BB64_52:
	setp.gt.s32	%p62, %r1, -1;
	@%p62 bra 	BB64_55;

	cvt.rzi.f64.f64	%fd81, %fd79;
	setp.neu.f64	%p63, %fd81, 0d4018000000000000;
	selp.f64	%fd101, 0dFFF8000000000000, %fd101, %p63;

BB64_55:
	add.f64 	%fd102, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd102;
	}
	and.b32  	%r95, %r94, 2146435072;
	setp.ne.s32	%p66, %r95, 2146435072;
	@%p66 bra 	BB64_56;

	setp.gtu.f64	%p67, %fd2, 0d7FF0000000000000;
	@%p67 bra 	BB64_65;

	and.b32  	%r96, %r5, 2147483647;
	setp.ne.s32	%p68, %r96, 2146435072;
	@%p68 bra 	BB64_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd79;
	}
	setp.eq.s32	%p69, %r97, 0;
	@%p69 bra 	BB64_64;

BB64_60:
	and.b32  	%r98, %r1, 2147483647;
	setp.ne.s32	%p70, %r98, 2146435072;
	@%p70 bra 	BB64_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd1;
	}
	setp.ne.s32	%p71, %r99, 0;
	mov.f64 	%fd102, %fd101;
	@%p71 bra 	BB64_65;

	shr.s32 	%r100, %r5, 31;
	and.b32  	%r101, %r100, -2146435072;
	add.s32 	%r102, %r101, 2146435072;
	or.b32  	%r103, %r102, -2147483648;
	selp.b32	%r104, %r103, %r102, %p4;
	mov.u32 	%r105, 0;
	mov.b64 	%fd102, {%r105, %r104};
	bra.uni 	BB64_65;

BB64_56:
	mov.f64 	%fd102, %fd101;
	bra.uni 	BB64_65;

BB64_61:
	mov.f64 	%fd102, %fd101;
	bra.uni 	BB64_65;

BB64_64:
	setp.gt.f64	%p72, %fd2, 0d3FF0000000000000;
	selp.b32	%r106, 2146435072, 0, %p72;
	xor.b32  	%r107, %r106, 2146435072;
	setp.lt.s32	%p73, %r5, 0;
	selp.b32	%r108, %r107, %r106, %p73;
	setp.eq.f64	%p74, %fd1, 0dBFF0000000000000;
	selp.b32	%r109, 1072693248, %r108, %p74;
	mov.u32 	%r110, 0;
	mov.b64 	%fd102, {%r110, %r109};

BB64_65:
	mul.f64 	%fd83, %fd102, 0dC09DE68000000000;
	selp.f64	%fd84, 0dC09DE68000000000, %fd83, %p41;
	add.f64 	%fd45, %fd34, %fd84;
	mov.f64 	%fd85, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd85;
	}
	bfe.u32 	%r111, %r6, 20, 11;
	add.s32 	%r112, %r111, -1012;
	mov.u64 	%rd10, 4619567317775286272;
	shl.b64 	%rd5, %rd10, %r112;
	setp.eq.s64	%p76, %rd5, -9223372036854775808;
	// Callseq Start 164
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd104, [retval0+0];
	
	//{
	}// Callseq End 164
	and.pred  	%p5, %p10, %p76;
	@!%p5 bra 	BB64_67;
	bra.uni 	BB64_66;

BB64_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd104;
	}
	xor.b32  	%r114, %r113, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd104;
	}
	mov.b64 	%fd104, {%r115, %r114};

BB64_67:
	@%p11 bra 	BB64_70;
	bra.uni 	BB64_68;

BB64_70:
	selp.b32	%r116, %r1, 0, %p76;
	or.b32  	%r117, %r116, 2146435072;
	setp.lt.s32	%p82, %r6, 0;
	selp.b32	%r118, %r117, %r116, %p82;
	mov.u32 	%r119, 0;
	mov.b64 	%fd104, {%r119, %r118};
	bra.uni 	BB64_71;

BB64_68:
	setp.gt.s32	%p79, %r1, -1;
	@%p79 bra 	BB64_71;

	cvt.rzi.f64.f64	%fd87, %fd85;
	setp.neu.f64	%p80, %fd87, 0d401C000000000000;
	selp.f64	%fd104, 0dFFF8000000000000, %fd104, %p80;

BB64_71:
	add.f64 	%fd105, %fd1, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd105;
	}
	and.b32  	%r121, %r120, 2146435072;
	setp.ne.s32	%p83, %r121, 2146435072;
	@%p83 bra 	BB64_72;

	setp.gtu.f64	%p84, %fd2, 0d7FF0000000000000;
	@%p84 bra 	BB64_81;

	and.b32  	%r122, %r6, 2147483647;
	setp.ne.s32	%p85, %r122, 2146435072;
	@%p85 bra 	BB64_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd85;
	}
	setp.eq.s32	%p86, %r123, 0;
	@%p86 bra 	BB64_80;

BB64_76:
	and.b32  	%r124, %r1, 2147483647;
	setp.ne.s32	%p87, %r124, 2146435072;
	@%p87 bra 	BB64_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd1;
	}
	setp.ne.s32	%p88, %r125, 0;
	mov.f64 	%fd105, %fd104;
	@%p88 bra 	BB64_81;

	shr.s32 	%r126, %r6, 31;
	and.b32  	%r127, %r126, -2146435072;
	add.s32 	%r128, %r127, 2146435072;
	or.b32  	%r129, %r128, -2147483648;
	selp.b32	%r130, %r129, %r128, %p5;
	mov.u32 	%r131, 0;
	mov.b64 	%fd105, {%r131, %r130};
	bra.uni 	BB64_81;

BB64_72:
	mov.f64 	%fd105, %fd104;
	bra.uni 	BB64_81;

BB64_77:
	mov.f64 	%fd105, %fd104;
	bra.uni 	BB64_81;

BB64_80:
	setp.gt.f64	%p89, %fd2, 0d3FF0000000000000;
	selp.b32	%r132, 2146435072, 0, %p89;
	xor.b32  	%r133, %r132, 2146435072;
	setp.lt.s32	%p90, %r6, 0;
	selp.b32	%r134, %r133, %r132, %p90;
	setp.eq.f64	%p91, %fd1, 0dBFF0000000000000;
	selp.b32	%r135, 1072693248, %r134, %p91;
	mov.u32 	%r136, 0;
	mov.b64 	%fd105, {%r136, %r135};

BB64_81:
	mul.f64 	%fd89, %fd105, 0d4081160000000000;
	selp.f64	%fd90, 0d4081160000000000, %fd89, %p41;
	add.f64 	%fd106, %fd45, %fd90;

BB64_82:
	st.param.f64	[func_retval0+0], %fd106;
	ret;
}

	// .globl	_Z12SmoothWave_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12SmoothWave_tddPdiPii(
	.param .b64 _Z12SmoothWave_tddPdiPii_param_0,
	.param .b64 _Z12SmoothWave_tddPdiPii_param_1,
	.param .b64 _Z12SmoothWave_tddPdiPii_param_2,
	.param .b32 _Z12SmoothWave_tddPdiPii_param_3,
	.param .b64 _Z12SmoothWave_tddPdiPii_param_4,
	.param .b32 _Z12SmoothWave_tddPdiPii_param_5
)
{
	.reg .pred 	%p<93>;
	.reg .b32 	%r<137>;
	.reg .f64 	%fd<108>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd58, [_Z12SmoothWave_tddPdiPii_param_0];
	ld.param.f64 	%fd60, [_Z12SmoothWave_tddPdiPii_param_1];
	mul.f64 	%fd1, %fd58, %fd60;
	setp.lt.f64	%p6, %fd1, 0d0000000000000000;
	setp.gt.f64	%p7, %fd1, 0d3FF0000000000000;
	or.pred  	%p8, %p6, %p7;
	mov.f64 	%fd107, 0d0000000000000000;
	@%p8 bra 	BB65_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd61, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd61;
	}
	bfe.u32 	%r7, %r2, 20, 11;
	add.s32 	%r8, %r7, -1012;
	mov.u64 	%rd6, 4611686018427387904;
	shl.b64 	%rd1, %rd6, %r8;
	setp.eq.s64	%p9, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 165
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd93, [retval0+0];
	
	//{
	}// Callseq End 165
	setp.lt.s32	%p10, %r1, 0;
	and.pred  	%p1, %p10, %p9;
	@!%p1 bra 	BB65_3;
	bra.uni 	BB65_2;

BB65_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd93;
	}
	xor.b32  	%r10, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r11, %temp}, %fd93;
	}
	mov.b64 	%fd93, {%r11, %r10};

BB65_3:
	setp.eq.f64	%p11, %fd1, 0d0000000000000000;
	@%p11 bra 	BB65_6;
	bra.uni 	BB65_4;

BB65_6:
	selp.b32	%r12, %r1, 0, %p9;
	or.b32  	%r13, %r12, 2146435072;
	setp.lt.s32	%p15, %r2, 0;
	selp.b32	%r14, %r13, %r12, %p15;
	mov.u32 	%r15, 0;
	mov.b64 	%fd93, {%r15, %r14};
	bra.uni 	BB65_7;

BB65_4:
	setp.gt.s32	%p12, %r1, -1;
	@%p12 bra 	BB65_7;

	cvt.rzi.f64.f64	%fd63, %fd61;
	setp.neu.f64	%p13, %fd63, 0d4000000000000000;
	selp.f64	%fd93, 0dFFF8000000000000, %fd93, %p13;

BB65_7:
	add.f64 	%fd94, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd94;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.ne.s32	%p16, %r17, 2146435072;
	@%p16 bra 	BB65_8;

	setp.gtu.f64	%p17, %fd2, 0d7FF0000000000000;
	@%p17 bra 	BB65_17;

	and.b32  	%r18, %r2, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB65_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd61;
	}
	setp.eq.s32	%p19, %r19, 0;
	@%p19 bra 	BB65_16;

BB65_12:
	and.b32  	%r20, %r1, 2147483647;
	setp.ne.s32	%p20, %r20, 2146435072;
	@%p20 bra 	BB65_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd1;
	}
	setp.ne.s32	%p21, %r21, 0;
	mov.f64 	%fd94, %fd93;
	@%p21 bra 	BB65_17;

	shr.s32 	%r22, %r2, 31;
	and.b32  	%r23, %r22, -2146435072;
	add.s32 	%r24, %r23, 2146435072;
	or.b32  	%r25, %r24, -2147483648;
	selp.b32	%r26, %r25, %r24, %p1;
	mov.u32 	%r27, 0;
	mov.b64 	%fd94, {%r27, %r26};
	bra.uni 	BB65_17;

BB65_8:
	mov.f64 	%fd94, %fd93;
	bra.uni 	BB65_17;

BB65_13:
	mov.f64 	%fd94, %fd93;
	bra.uni 	BB65_17;

BB65_16:
	setp.gt.f64	%p22, %fd2, 0d3FF0000000000000;
	selp.b32	%r28, 2146435072, 0, %p22;
	xor.b32  	%r29, %r28, 2146435072;
	setp.lt.s32	%p23, %r2, 0;
	selp.b32	%r30, %r29, %r28, %p23;
	setp.eq.f64	%p24, %fd1, 0dBFF0000000000000;
	selp.b32	%r31, 1072693248, %r30, %p24;
	mov.u32 	%r32, 0;
	mov.b64 	%fd94, {%r32, %r31};

BB65_17:
	mov.f64 	%fd65, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd65;
	}
	bfe.u32 	%r33, %r3, 20, 11;
	add.s32 	%r34, %r33, -1012;
	mov.u64 	%rd7, 4613937818241073152;
	shl.b64 	%rd2, %rd7, %r34;
	setp.eq.s64	%p25, %rd2, -9223372036854775808;
	// Callseq Start 166
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd65;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd96, [retval0+0];
	
	//{
	}// Callseq End 166
	and.pred  	%p2, %p10, %p25;
	@!%p2 bra 	BB65_19;
	bra.uni 	BB65_18;

BB65_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd96;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd96;
	}
	mov.b64 	%fd96, {%r37, %r36};

BB65_19:
	@%p11 bra 	BB65_22;
	bra.uni 	BB65_20;

BB65_22:
	selp.b32	%r38, %r1, 0, %p25;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p31;
	mov.u32 	%r41, 0;
	mov.b64 	%fd96, {%r41, %r40};
	bra.uni 	BB65_23;

BB65_20:
	setp.gt.s32	%p28, %r1, -1;
	@%p28 bra 	BB65_23;

	cvt.rzi.f64.f64	%fd67, %fd65;
	setp.neu.f64	%p29, %fd67, 0d4008000000000000;
	selp.f64	%fd96, 0dFFF8000000000000, %fd96, %p29;

BB65_23:
	add.f64 	%fd97, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd97;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p32, %r43, 2146435072;
	@%p32 bra 	BB65_24;

	setp.gtu.f64	%p33, %fd2, 0d7FF0000000000000;
	@%p33 bra 	BB65_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p34, %r44, 2146435072;
	@%p34 bra 	BB65_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd65;
	}
	setp.eq.s32	%p35, %r45, 0;
	@%p35 bra 	BB65_32;

BB65_28:
	and.b32  	%r46, %r1, 2147483647;
	setp.ne.s32	%p36, %r46, 2146435072;
	@%p36 bra 	BB65_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd1;
	}
	setp.ne.s32	%p37, %r47, 0;
	mov.f64 	%fd97, %fd96;
	@%p37 bra 	BB65_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd97, {%r53, %r52};
	bra.uni 	BB65_33;

BB65_24:
	mov.f64 	%fd97, %fd96;
	bra.uni 	BB65_33;

BB65_29:
	mov.f64 	%fd97, %fd96;
	bra.uni 	BB65_33;

BB65_32:
	setp.gt.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p38;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p39;
	setp.eq.f64	%p40, %fd1, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p40;
	mov.u32 	%r58, 0;
	mov.b64 	%fd97, {%r58, %r57};

BB65_33:
	mul.f64 	%fd69, %fd97, 0dC0B55B8000000000;
	setp.eq.f64	%p41, %fd1, 0d3FF0000000000000;
	selp.f64	%fd70, 0dC0B55B8000000000, %fd69, %p41;
	mul.f64 	%fd71, %fd94, 0d4089A10000000000;
	selp.f64	%fd72, 0d4089A10000000000, %fd71, %p41;
	add.f64 	%fd23, %fd72, %fd70;
	mov.f64 	%fd73, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd73;
	}
	bfe.u32 	%r59, %r4, 20, 11;
	add.s32 	%r60, %r59, -1012;
	mov.u64 	%rd8, 4616189618054758400;
	shl.b64 	%rd3, %rd8, %r60;
	setp.eq.s64	%p42, %rd3, -9223372036854775808;
	// Callseq Start 167
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd73;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd99, [retval0+0];
	
	//{
	}// Callseq End 167
	and.pred  	%p3, %p10, %p42;
	@!%p3 bra 	BB65_35;
	bra.uni 	BB65_34;

BB65_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd99;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd99;
	}
	mov.b64 	%fd99, {%r63, %r62};

BB65_35:
	@%p11 bra 	BB65_38;
	bra.uni 	BB65_36;

BB65_38:
	selp.b32	%r64, %r1, 0, %p42;
	or.b32  	%r65, %r64, 2146435072;
	setp.lt.s32	%p48, %r4, 0;
	selp.b32	%r66, %r65, %r64, %p48;
	mov.u32 	%r67, 0;
	mov.b64 	%fd99, {%r67, %r66};
	bra.uni 	BB65_39;

BB65_36:
	setp.gt.s32	%p45, %r1, -1;
	@%p45 bra 	BB65_39;

	cvt.rzi.f64.f64	%fd75, %fd73;
	setp.neu.f64	%p46, %fd75, 0d4010000000000000;
	selp.f64	%fd99, 0dFFF8000000000000, %fd99, %p46;

BB65_39:
	add.f64 	%fd100, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd100;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.ne.s32	%p49, %r69, 2146435072;
	@%p49 bra 	BB65_40;

	setp.gtu.f64	%p50, %fd2, 0d7FF0000000000000;
	@%p50 bra 	BB65_49;

	and.b32  	%r70, %r4, 2147483647;
	setp.ne.s32	%p51, %r70, 2146435072;
	@%p51 bra 	BB65_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd73;
	}
	setp.eq.s32	%p52, %r71, 0;
	@%p52 bra 	BB65_48;

BB65_44:
	and.b32  	%r72, %r1, 2147483647;
	setp.ne.s32	%p53, %r72, 2146435072;
	@%p53 bra 	BB65_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r73, 0;
	mov.f64 	%fd100, %fd99;
	@%p54 bra 	BB65_49;

	shr.s32 	%r74, %r4, 31;
	and.b32  	%r75, %r74, -2146435072;
	add.s32 	%r76, %r75, 2146435072;
	or.b32  	%r77, %r76, -2147483648;
	selp.b32	%r78, %r77, %r76, %p3;
	mov.u32 	%r79, 0;
	mov.b64 	%fd100, {%r79, %r78};
	bra.uni 	BB65_49;

BB65_40:
	mov.f64 	%fd100, %fd99;
	bra.uni 	BB65_49;

BB65_45:
	mov.f64 	%fd100, %fd99;
	bra.uni 	BB65_49;

BB65_48:
	setp.gt.f64	%p55, %fd2, 0d3FF0000000000000;
	selp.b32	%r80, 2146435072, 0, %p55;
	xor.b32  	%r81, %r80, 2146435072;
	setp.lt.s32	%p56, %r4, 0;
	selp.b32	%r82, %r81, %r80, %p56;
	setp.eq.f64	%p57, %fd1, 0dBFF0000000000000;
	selp.b32	%r83, 1072693248, %r82, %p57;
	mov.u32 	%r84, 0;
	mov.b64 	%fd100, {%r84, %r83};

BB65_49:
	mul.f64 	%fd77, %fd100, 0d40C806F000000000;
	selp.f64	%fd78, 0d40C806F000000000, %fd77, %p41;
	add.f64 	%fd34, %fd23, %fd78;
	mov.f64 	%fd79, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd79;
	}
	bfe.u32 	%r85, %r5, 20, 11;
	add.s32 	%r86, %r85, -1012;
	mov.u64 	%rd9, 4617315517961601024;
	shl.b64 	%rd4, %rd9, %r86;
	setp.eq.s64	%p59, %rd4, -9223372036854775808;
	// Callseq Start 168
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd79;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd102, [retval0+0];
	
	//{
	}// Callseq End 168
	and.pred  	%p4, %p10, %p59;
	@!%p4 bra 	BB65_51;
	bra.uni 	BB65_50;

BB65_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd102;
	}
	xor.b32  	%r88, %r87, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd102;
	}
	mov.b64 	%fd102, {%r89, %r88};

BB65_51:
	@%p11 bra 	BB65_54;
	bra.uni 	BB65_52;

BB65_54:
	selp.b32	%r90, %r1, 0, %p59;
	or.b32  	%r91, %r90, 2146435072;
	setp.lt.s32	%p65, %r5, 0;
	selp.b32	%r92, %r91, %r90, %p65;
	mov.u32 	%r93, 0;
	mov.b64 	%fd102, {%r93, %r92};
	bra.uni 	BB65_55;

BB65_52:
	setp.gt.s32	%p62, %r1, -1;
	@%p62 bra 	BB65_55;

	cvt.rzi.f64.f64	%fd81, %fd79;
	setp.neu.f64	%p63, %fd81, 0d4014000000000000;
	selp.f64	%fd102, 0dFFF8000000000000, %fd102, %p63;

BB65_55:
	add.f64 	%fd103, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd103;
	}
	and.b32  	%r95, %r94, 2146435072;
	setp.ne.s32	%p66, %r95, 2146435072;
	@%p66 bra 	BB65_56;

	setp.gtu.f64	%p67, %fd2, 0d7FF0000000000000;
	@%p67 bra 	BB65_65;

	and.b32  	%r96, %r5, 2147483647;
	setp.ne.s32	%p68, %r96, 2146435072;
	@%p68 bra 	BB65_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd79;
	}
	setp.eq.s32	%p69, %r97, 0;
	@%p69 bra 	BB65_64;

BB65_60:
	and.b32  	%r98, %r1, 2147483647;
	setp.ne.s32	%p70, %r98, 2146435072;
	@%p70 bra 	BB65_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd1;
	}
	setp.ne.s32	%p71, %r99, 0;
	mov.f64 	%fd103, %fd102;
	@%p71 bra 	BB65_65;

	shr.s32 	%r100, %r5, 31;
	and.b32  	%r101, %r100, -2146435072;
	add.s32 	%r102, %r101, 2146435072;
	or.b32  	%r103, %r102, -2147483648;
	selp.b32	%r104, %r103, %r102, %p4;
	mov.u32 	%r105, 0;
	mov.b64 	%fd103, {%r105, %r104};
	bra.uni 	BB65_65;

BB65_56:
	mov.f64 	%fd103, %fd102;
	bra.uni 	BB65_65;

BB65_61:
	mov.f64 	%fd103, %fd102;
	bra.uni 	BB65_65;

BB65_64:
	setp.gt.f64	%p72, %fd2, 0d3FF0000000000000;
	selp.b32	%r106, 2146435072, 0, %p72;
	xor.b32  	%r107, %r106, 2146435072;
	setp.lt.s32	%p73, %r5, 0;
	selp.b32	%r108, %r107, %r106, %p73;
	setp.eq.f64	%p74, %fd1, 0dBFF0000000000000;
	selp.b32	%r109, 1072693248, %r108, %p74;
	mov.u32 	%r110, 0;
	mov.b64 	%fd103, {%r110, %r109};

BB65_65:
	mul.f64 	%fd83, %fd103, 0dC0C66CE000000000;
	selp.f64	%fd84, 0dC0C66CE000000000, %fd83, %p41;
	add.f64 	%fd45, %fd34, %fd84;
	mov.f64 	%fd85, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd85;
	}
	bfe.u32 	%r111, %r6, 20, 11;
	add.s32 	%r112, %r111, -1012;
	mov.u64 	%rd10, 4618441417868443648;
	shl.b64 	%rd5, %rd10, %r112;
	setp.eq.s64	%p76, %rd5, -9223372036854775808;
	// Callseq Start 169
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd105, [retval0+0];
	
	//{
	}// Callseq End 169
	and.pred  	%p5, %p10, %p76;
	@!%p5 bra 	BB65_67;
	bra.uni 	BB65_66;

BB65_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd105;
	}
	xor.b32  	%r114, %r113, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd105;
	}
	mov.b64 	%fd105, {%r115, %r114};

BB65_67:
	@%p11 bra 	BB65_70;
	bra.uni 	BB65_68;

BB65_70:
	selp.b32	%r116, %r1, 0, %p76;
	or.b32  	%r117, %r116, 2146435072;
	setp.lt.s32	%p82, %r6, 0;
	selp.b32	%r118, %r117, %r116, %p82;
	mov.u32 	%r119, 0;
	mov.b64 	%fd105, {%r119, %r118};
	bra.uni 	BB65_71;

BB65_68:
	setp.gt.s32	%p79, %r1, -1;
	@%p79 bra 	BB65_71;

	cvt.rzi.f64.f64	%fd87, %fd85;
	setp.neu.f64	%p80, %fd87, 0d4018000000000000;
	selp.f64	%fd105, 0dFFF8000000000000, %fd105, %p80;

BB65_71:
	add.f64 	%fd106, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd106;
	}
	and.b32  	%r121, %r120, 2146435072;
	setp.ne.s32	%p83, %r121, 2146435072;
	@%p83 bra 	BB65_72;

	setp.gtu.f64	%p84, %fd2, 0d7FF0000000000000;
	@%p84 bra 	BB65_81;

	and.b32  	%r122, %r6, 2147483647;
	setp.ne.s32	%p85, %r122, 2146435072;
	@%p85 bra 	BB65_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd85;
	}
	setp.eq.s32	%p86, %r123, 0;
	@%p86 bra 	BB65_80;

BB65_76:
	and.b32  	%r124, %r1, 2147483647;
	setp.ne.s32	%p87, %r124, 2146435072;
	@%p87 bra 	BB65_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd1;
	}
	setp.ne.s32	%p88, %r125, 0;
	mov.f64 	%fd106, %fd105;
	@%p88 bra 	BB65_81;

	shr.s32 	%r126, %r6, 31;
	and.b32  	%r127, %r126, -2146435072;
	add.s32 	%r128, %r127, 2146435072;
	or.b32  	%r129, %r128, -2147483648;
	selp.b32	%r130, %r129, %r128, %p5;
	mov.u32 	%r131, 0;
	mov.b64 	%fd106, {%r131, %r130};
	bra.uni 	BB65_81;

BB65_72:
	mov.f64 	%fd106, %fd105;
	bra.uni 	BB65_81;

BB65_77:
	mov.f64 	%fd106, %fd105;
	bra.uni 	BB65_81;

BB65_80:
	setp.gt.f64	%p89, %fd2, 0d3FF0000000000000;
	selp.b32	%r132, 2146435072, 0, %p89;
	xor.b32  	%r133, %r132, 2146435072;
	setp.lt.s32	%p90, %r6, 0;
	selp.b32	%r134, %r133, %r132, %p90;
	setp.eq.f64	%p91, %fd1, 0dBFF0000000000000;
	selp.b32	%r135, 1072693248, %r134, %p91;
	mov.u32 	%r136, 0;
	mov.b64 	%fd106, {%r136, %r135};

BB65_81:
	mul.f64 	%fd89, %fd106, 0d40ADE68000000000;
	selp.f64	%fd90, 0d40ADE68000000000, %fd89, %p41;
	add.f64 	%fd91, %fd45, %fd90;
	mul.f64 	%fd107, %fd91, %fd58;

BB65_82:
	st.param.f64	[func_retval0+0], %fd107;
	ret;
}

	// .globl	_Z13SmoothWave_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13SmoothWave_omddPdiPii(
	.param .b64 _Z13SmoothWave_omddPdiPii_param_0,
	.param .b64 _Z13SmoothWave_omddPdiPii_param_1,
	.param .b64 _Z13SmoothWave_omddPdiPii_param_2,
	.param .b32 _Z13SmoothWave_omddPdiPii_param_3,
	.param .b64 _Z13SmoothWave_omddPdiPii_param_4,
	.param .b32 _Z13SmoothWave_omddPdiPii_param_5
)
{
	.reg .pred 	%p<93>;
	.reg .b32 	%r<137>;
	.reg .f64 	%fd<108>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd60, [_Z13SmoothWave_omddPdiPii_param_0];
	ld.param.f64 	%fd58, [_Z13SmoothWave_omddPdiPii_param_1];
	mul.f64 	%fd1, %fd60, %fd58;
	setp.lt.f64	%p6, %fd1, 0d0000000000000000;
	setp.gt.f64	%p7, %fd1, 0d3FF0000000000000;
	or.pred  	%p8, %p6, %p7;
	mov.f64 	%fd107, 0d0000000000000000;
	@%p8 bra 	BB66_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd61, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd61;
	}
	bfe.u32 	%r7, %r2, 20, 11;
	add.s32 	%r8, %r7, -1012;
	mov.u64 	%rd6, 4611686018427387904;
	shl.b64 	%rd1, %rd6, %r8;
	setp.eq.s64	%p9, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 170
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd93, [retval0+0];
	
	//{
	}// Callseq End 170
	setp.lt.s32	%p10, %r1, 0;
	and.pred  	%p1, %p10, %p9;
	@!%p1 bra 	BB66_3;
	bra.uni 	BB66_2;

BB66_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd93;
	}
	xor.b32  	%r10, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r11, %temp}, %fd93;
	}
	mov.b64 	%fd93, {%r11, %r10};

BB66_3:
	setp.eq.f64	%p11, %fd1, 0d0000000000000000;
	@%p11 bra 	BB66_6;
	bra.uni 	BB66_4;

BB66_6:
	selp.b32	%r12, %r1, 0, %p9;
	or.b32  	%r13, %r12, 2146435072;
	setp.lt.s32	%p15, %r2, 0;
	selp.b32	%r14, %r13, %r12, %p15;
	mov.u32 	%r15, 0;
	mov.b64 	%fd93, {%r15, %r14};
	bra.uni 	BB66_7;

BB66_4:
	setp.gt.s32	%p12, %r1, -1;
	@%p12 bra 	BB66_7;

	cvt.rzi.f64.f64	%fd63, %fd61;
	setp.neu.f64	%p13, %fd63, 0d4000000000000000;
	selp.f64	%fd93, 0dFFF8000000000000, %fd93, %p13;

BB66_7:
	add.f64 	%fd94, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd94;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.ne.s32	%p16, %r17, 2146435072;
	@%p16 bra 	BB66_8;

	setp.gtu.f64	%p17, %fd2, 0d7FF0000000000000;
	@%p17 bra 	BB66_17;

	and.b32  	%r18, %r2, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB66_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd61;
	}
	setp.eq.s32	%p19, %r19, 0;
	@%p19 bra 	BB66_16;

BB66_12:
	and.b32  	%r20, %r1, 2147483647;
	setp.ne.s32	%p20, %r20, 2146435072;
	@%p20 bra 	BB66_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd1;
	}
	setp.ne.s32	%p21, %r21, 0;
	mov.f64 	%fd94, %fd93;
	@%p21 bra 	BB66_17;

	shr.s32 	%r22, %r2, 31;
	and.b32  	%r23, %r22, -2146435072;
	add.s32 	%r24, %r23, 2146435072;
	or.b32  	%r25, %r24, -2147483648;
	selp.b32	%r26, %r25, %r24, %p1;
	mov.u32 	%r27, 0;
	mov.b64 	%fd94, {%r27, %r26};
	bra.uni 	BB66_17;

BB66_8:
	mov.f64 	%fd94, %fd93;
	bra.uni 	BB66_17;

BB66_13:
	mov.f64 	%fd94, %fd93;
	bra.uni 	BB66_17;

BB66_16:
	setp.gt.f64	%p22, %fd2, 0d3FF0000000000000;
	selp.b32	%r28, 2146435072, 0, %p22;
	xor.b32  	%r29, %r28, 2146435072;
	setp.lt.s32	%p23, %r2, 0;
	selp.b32	%r30, %r29, %r28, %p23;
	setp.eq.f64	%p24, %fd1, 0dBFF0000000000000;
	selp.b32	%r31, 1072693248, %r30, %p24;
	mov.u32 	%r32, 0;
	mov.b64 	%fd94, {%r32, %r31};

BB66_17:
	mov.f64 	%fd65, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd65;
	}
	bfe.u32 	%r33, %r3, 20, 11;
	add.s32 	%r34, %r33, -1012;
	mov.u64 	%rd7, 4613937818241073152;
	shl.b64 	%rd2, %rd7, %r34;
	setp.eq.s64	%p25, %rd2, -9223372036854775808;
	// Callseq Start 171
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd65;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd96, [retval0+0];
	
	//{
	}// Callseq End 171
	and.pred  	%p2, %p10, %p25;
	@!%p2 bra 	BB66_19;
	bra.uni 	BB66_18;

BB66_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd96;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd96;
	}
	mov.b64 	%fd96, {%r37, %r36};

BB66_19:
	@%p11 bra 	BB66_22;
	bra.uni 	BB66_20;

BB66_22:
	selp.b32	%r38, %r1, 0, %p25;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p31;
	mov.u32 	%r41, 0;
	mov.b64 	%fd96, {%r41, %r40};
	bra.uni 	BB66_23;

BB66_20:
	setp.gt.s32	%p28, %r1, -1;
	@%p28 bra 	BB66_23;

	cvt.rzi.f64.f64	%fd67, %fd65;
	setp.neu.f64	%p29, %fd67, 0d4008000000000000;
	selp.f64	%fd96, 0dFFF8000000000000, %fd96, %p29;

BB66_23:
	add.f64 	%fd97, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd97;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p32, %r43, 2146435072;
	@%p32 bra 	BB66_24;

	setp.gtu.f64	%p33, %fd2, 0d7FF0000000000000;
	@%p33 bra 	BB66_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p34, %r44, 2146435072;
	@%p34 bra 	BB66_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd65;
	}
	setp.eq.s32	%p35, %r45, 0;
	@%p35 bra 	BB66_32;

BB66_28:
	and.b32  	%r46, %r1, 2147483647;
	setp.ne.s32	%p36, %r46, 2146435072;
	@%p36 bra 	BB66_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd1;
	}
	setp.ne.s32	%p37, %r47, 0;
	mov.f64 	%fd97, %fd96;
	@%p37 bra 	BB66_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd97, {%r53, %r52};
	bra.uni 	BB66_33;

BB66_24:
	mov.f64 	%fd97, %fd96;
	bra.uni 	BB66_33;

BB66_29:
	mov.f64 	%fd97, %fd96;
	bra.uni 	BB66_33;

BB66_32:
	setp.gt.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p38;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p39;
	setp.eq.f64	%p40, %fd1, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p40;
	mov.u32 	%r58, 0;
	mov.b64 	%fd97, {%r58, %r57};

BB66_33:
	mul.f64 	%fd69, %fd97, 0dC0B55B8000000000;
	setp.eq.f64	%p41, %fd1, 0d3FF0000000000000;
	selp.f64	%fd70, 0dC0B55B8000000000, %fd69, %p41;
	mul.f64 	%fd71, %fd94, 0d4089A10000000000;
	selp.f64	%fd72, 0d4089A10000000000, %fd71, %p41;
	add.f64 	%fd23, %fd72, %fd70;
	mov.f64 	%fd73, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd73;
	}
	bfe.u32 	%r59, %r4, 20, 11;
	add.s32 	%r60, %r59, -1012;
	mov.u64 	%rd8, 4616189618054758400;
	shl.b64 	%rd3, %rd8, %r60;
	setp.eq.s64	%p42, %rd3, -9223372036854775808;
	// Callseq Start 172
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd73;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd99, [retval0+0];
	
	//{
	}// Callseq End 172
	and.pred  	%p3, %p10, %p42;
	@!%p3 bra 	BB66_35;
	bra.uni 	BB66_34;

BB66_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd99;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd99;
	}
	mov.b64 	%fd99, {%r63, %r62};

BB66_35:
	@%p11 bra 	BB66_38;
	bra.uni 	BB66_36;

BB66_38:
	selp.b32	%r64, %r1, 0, %p42;
	or.b32  	%r65, %r64, 2146435072;
	setp.lt.s32	%p48, %r4, 0;
	selp.b32	%r66, %r65, %r64, %p48;
	mov.u32 	%r67, 0;
	mov.b64 	%fd99, {%r67, %r66};
	bra.uni 	BB66_39;

BB66_36:
	setp.gt.s32	%p45, %r1, -1;
	@%p45 bra 	BB66_39;

	cvt.rzi.f64.f64	%fd75, %fd73;
	setp.neu.f64	%p46, %fd75, 0d4010000000000000;
	selp.f64	%fd99, 0dFFF8000000000000, %fd99, %p46;

BB66_39:
	add.f64 	%fd100, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd100;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.ne.s32	%p49, %r69, 2146435072;
	@%p49 bra 	BB66_40;

	setp.gtu.f64	%p50, %fd2, 0d7FF0000000000000;
	@%p50 bra 	BB66_49;

	and.b32  	%r70, %r4, 2147483647;
	setp.ne.s32	%p51, %r70, 2146435072;
	@%p51 bra 	BB66_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd73;
	}
	setp.eq.s32	%p52, %r71, 0;
	@%p52 bra 	BB66_48;

BB66_44:
	and.b32  	%r72, %r1, 2147483647;
	setp.ne.s32	%p53, %r72, 2146435072;
	@%p53 bra 	BB66_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r73, 0;
	mov.f64 	%fd100, %fd99;
	@%p54 bra 	BB66_49;

	shr.s32 	%r74, %r4, 31;
	and.b32  	%r75, %r74, -2146435072;
	add.s32 	%r76, %r75, 2146435072;
	or.b32  	%r77, %r76, -2147483648;
	selp.b32	%r78, %r77, %r76, %p3;
	mov.u32 	%r79, 0;
	mov.b64 	%fd100, {%r79, %r78};
	bra.uni 	BB66_49;

BB66_40:
	mov.f64 	%fd100, %fd99;
	bra.uni 	BB66_49;

BB66_45:
	mov.f64 	%fd100, %fd99;
	bra.uni 	BB66_49;

BB66_48:
	setp.gt.f64	%p55, %fd2, 0d3FF0000000000000;
	selp.b32	%r80, 2146435072, 0, %p55;
	xor.b32  	%r81, %r80, 2146435072;
	setp.lt.s32	%p56, %r4, 0;
	selp.b32	%r82, %r81, %r80, %p56;
	setp.eq.f64	%p57, %fd1, 0dBFF0000000000000;
	selp.b32	%r83, 1072693248, %r82, %p57;
	mov.u32 	%r84, 0;
	mov.b64 	%fd100, {%r84, %r83};

BB66_49:
	mul.f64 	%fd77, %fd100, 0d40C806F000000000;
	selp.f64	%fd78, 0d40C806F000000000, %fd77, %p41;
	add.f64 	%fd34, %fd23, %fd78;
	mov.f64 	%fd79, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd79;
	}
	bfe.u32 	%r85, %r5, 20, 11;
	add.s32 	%r86, %r85, -1012;
	mov.u64 	%rd9, 4617315517961601024;
	shl.b64 	%rd4, %rd9, %r86;
	setp.eq.s64	%p59, %rd4, -9223372036854775808;
	// Callseq Start 173
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd79;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd102, [retval0+0];
	
	//{
	}// Callseq End 173
	and.pred  	%p4, %p10, %p59;
	@!%p4 bra 	BB66_51;
	bra.uni 	BB66_50;

BB66_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd102;
	}
	xor.b32  	%r88, %r87, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd102;
	}
	mov.b64 	%fd102, {%r89, %r88};

BB66_51:
	@%p11 bra 	BB66_54;
	bra.uni 	BB66_52;

BB66_54:
	selp.b32	%r90, %r1, 0, %p59;
	or.b32  	%r91, %r90, 2146435072;
	setp.lt.s32	%p65, %r5, 0;
	selp.b32	%r92, %r91, %r90, %p65;
	mov.u32 	%r93, 0;
	mov.b64 	%fd102, {%r93, %r92};
	bra.uni 	BB66_55;

BB66_52:
	setp.gt.s32	%p62, %r1, -1;
	@%p62 bra 	BB66_55;

	cvt.rzi.f64.f64	%fd81, %fd79;
	setp.neu.f64	%p63, %fd81, 0d4014000000000000;
	selp.f64	%fd102, 0dFFF8000000000000, %fd102, %p63;

BB66_55:
	add.f64 	%fd103, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd103;
	}
	and.b32  	%r95, %r94, 2146435072;
	setp.ne.s32	%p66, %r95, 2146435072;
	@%p66 bra 	BB66_56;

	setp.gtu.f64	%p67, %fd2, 0d7FF0000000000000;
	@%p67 bra 	BB66_65;

	and.b32  	%r96, %r5, 2147483647;
	setp.ne.s32	%p68, %r96, 2146435072;
	@%p68 bra 	BB66_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd79;
	}
	setp.eq.s32	%p69, %r97, 0;
	@%p69 bra 	BB66_64;

BB66_60:
	and.b32  	%r98, %r1, 2147483647;
	setp.ne.s32	%p70, %r98, 2146435072;
	@%p70 bra 	BB66_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd1;
	}
	setp.ne.s32	%p71, %r99, 0;
	mov.f64 	%fd103, %fd102;
	@%p71 bra 	BB66_65;

	shr.s32 	%r100, %r5, 31;
	and.b32  	%r101, %r100, -2146435072;
	add.s32 	%r102, %r101, 2146435072;
	or.b32  	%r103, %r102, -2147483648;
	selp.b32	%r104, %r103, %r102, %p4;
	mov.u32 	%r105, 0;
	mov.b64 	%fd103, {%r105, %r104};
	bra.uni 	BB66_65;

BB66_56:
	mov.f64 	%fd103, %fd102;
	bra.uni 	BB66_65;

BB66_61:
	mov.f64 	%fd103, %fd102;
	bra.uni 	BB66_65;

BB66_64:
	setp.gt.f64	%p72, %fd2, 0d3FF0000000000000;
	selp.b32	%r106, 2146435072, 0, %p72;
	xor.b32  	%r107, %r106, 2146435072;
	setp.lt.s32	%p73, %r5, 0;
	selp.b32	%r108, %r107, %r106, %p73;
	setp.eq.f64	%p74, %fd1, 0dBFF0000000000000;
	selp.b32	%r109, 1072693248, %r108, %p74;
	mov.u32 	%r110, 0;
	mov.b64 	%fd103, {%r110, %r109};

BB66_65:
	mul.f64 	%fd83, %fd103, 0dC0C66CE000000000;
	selp.f64	%fd84, 0dC0C66CE000000000, %fd83, %p41;
	add.f64 	%fd45, %fd34, %fd84;
	mov.f64 	%fd85, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd85;
	}
	bfe.u32 	%r111, %r6, 20, 11;
	add.s32 	%r112, %r111, -1012;
	mov.u64 	%rd10, 4618441417868443648;
	shl.b64 	%rd5, %rd10, %r112;
	setp.eq.s64	%p76, %rd5, -9223372036854775808;
	// Callseq Start 174
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd105, [retval0+0];
	
	//{
	}// Callseq End 174
	and.pred  	%p5, %p10, %p76;
	@!%p5 bra 	BB66_67;
	bra.uni 	BB66_66;

BB66_66:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd105;
	}
	xor.b32  	%r114, %r113, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd105;
	}
	mov.b64 	%fd105, {%r115, %r114};

BB66_67:
	@%p11 bra 	BB66_70;
	bra.uni 	BB66_68;

BB66_70:
	selp.b32	%r116, %r1, 0, %p76;
	or.b32  	%r117, %r116, 2146435072;
	setp.lt.s32	%p82, %r6, 0;
	selp.b32	%r118, %r117, %r116, %p82;
	mov.u32 	%r119, 0;
	mov.b64 	%fd105, {%r119, %r118};
	bra.uni 	BB66_71;

BB66_68:
	setp.gt.s32	%p79, %r1, -1;
	@%p79 bra 	BB66_71;

	cvt.rzi.f64.f64	%fd87, %fd85;
	setp.neu.f64	%p80, %fd87, 0d4018000000000000;
	selp.f64	%fd105, 0dFFF8000000000000, %fd105, %p80;

BB66_71:
	add.f64 	%fd106, %fd1, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd106;
	}
	and.b32  	%r121, %r120, 2146435072;
	setp.ne.s32	%p83, %r121, 2146435072;
	@%p83 bra 	BB66_72;

	setp.gtu.f64	%p84, %fd2, 0d7FF0000000000000;
	@%p84 bra 	BB66_81;

	and.b32  	%r122, %r6, 2147483647;
	setp.ne.s32	%p85, %r122, 2146435072;
	@%p85 bra 	BB66_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd85;
	}
	setp.eq.s32	%p86, %r123, 0;
	@%p86 bra 	BB66_80;

BB66_76:
	and.b32  	%r124, %r1, 2147483647;
	setp.ne.s32	%p87, %r124, 2146435072;
	@%p87 bra 	BB66_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd1;
	}
	setp.ne.s32	%p88, %r125, 0;
	mov.f64 	%fd106, %fd105;
	@%p88 bra 	BB66_81;

	shr.s32 	%r126, %r6, 31;
	and.b32  	%r127, %r126, -2146435072;
	add.s32 	%r128, %r127, 2146435072;
	or.b32  	%r129, %r128, -2147483648;
	selp.b32	%r130, %r129, %r128, %p5;
	mov.u32 	%r131, 0;
	mov.b64 	%fd106, {%r131, %r130};
	bra.uni 	BB66_81;

BB66_72:
	mov.f64 	%fd106, %fd105;
	bra.uni 	BB66_81;

BB66_77:
	mov.f64 	%fd106, %fd105;
	bra.uni 	BB66_81;

BB66_80:
	setp.gt.f64	%p89, %fd2, 0d3FF0000000000000;
	selp.b32	%r132, 2146435072, 0, %p89;
	xor.b32  	%r133, %r132, 2146435072;
	setp.lt.s32	%p90, %r6, 0;
	selp.b32	%r134, %r133, %r132, %p90;
	setp.eq.f64	%p91, %fd1, 0dBFF0000000000000;
	selp.b32	%r135, 1072693248, %r134, %p91;
	mov.u32 	%r136, 0;
	mov.b64 	%fd106, {%r136, %r135};

BB66_81:
	mul.f64 	%fd89, %fd106, 0d40ADE68000000000;
	selp.f64	%fd90, 0d40ADE68000000000, %fd89, %p41;
	add.f64 	%fd91, %fd45, %fd90;
	mul.f64 	%fd107, %fd91, %fd58;

BB66_82:
	st.param.f64	[func_retval0+0], %fd107;
	ret;
}

	// .globl	_Z13SmoothWave_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13SmoothWave_ttddPdiPii(
	.param .b64 _Z13SmoothWave_ttddPdiPii_param_0,
	.param .b64 _Z13SmoothWave_ttddPdiPii_param_1,
	.param .b64 _Z13SmoothWave_ttddPdiPii_param_2,
	.param .b32 _Z13SmoothWave_ttddPdiPii_param_3,
	.param .b64 _Z13SmoothWave_ttddPdiPii_param_4,
	.param .b32 _Z13SmoothWave_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<79>;
	.reg .b32 	%r<116>;
	.reg .f64 	%fd<91>;
	.reg .b64 	%rd<15>;


	ld.param.f64 	%fd48, [_Z13SmoothWave_ttddPdiPii_param_0];
	ld.param.f64 	%fd49, [_Z13SmoothWave_ttddPdiPii_param_1];
	mul.f64 	%fd1, %fd48, %fd49;
	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	setp.gt.f64	%p5, %fd1, 0d3FF0000000000000;
	or.pred  	%p6, %p4, %p5;
	mov.f64 	%fd90, 0d0000000000000000;
	@%p6 bra 	BB67_66;

	mov.f64 	%fd51, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd51;
	}
	bfe.u32 	%r6, %r1, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd4, %rd3, %r7;
	setp.eq.s64	%p7, %rd4, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 175
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd51;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd79, [retval0+0];
	
	//{
	}// Callseq End 175
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p8, %r2, 0;
	and.pred  	%p9, %p8, %p7;
	@!%p9 bra 	BB67_3;
	bra.uni 	BB67_2;

BB67_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd79;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd79;
	}
	mov.b64 	%fd79, {%r10, %r9};

BB67_3:
	setp.eq.f64	%p10, %fd1, 0d0000000000000000;
	@%p10 bra 	BB67_6;
	bra.uni 	BB67_4;

BB67_6:
	bfe.u32 	%r11, %r1, 20, 11;
	add.s32 	%r12, %r11, -1012;
	shl.b64 	%rd6, %rd3, %r12;
	setp.eq.s64	%p13, %rd6, -9223372036854775808;
	selp.b32	%r13, %r2, 0, %p13;
	or.b32  	%r14, %r13, 2146435072;
	setp.lt.s32	%p14, %r1, 0;
	selp.b32	%r15, %r14, %r13, %p14;
	mov.u32 	%r16, 0;
	mov.b64 	%fd79, {%r16, %r15};
	bra.uni 	BB67_7;

BB67_4:
	setp.gt.s32	%p11, %r2, -1;
	@%p11 bra 	BB67_7;

	cvt.rzi.f64.f64	%fd53, %fd51;
	setp.neu.f64	%p12, %fd53, 0d4000000000000000;
	selp.f64	%fd79, 0dFFF8000000000000, %fd79, %p12;

BB67_7:
	add.f64 	%fd80, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd80;
	}
	and.b32  	%r18, %r17, 2146435072;
	setp.ne.s32	%p15, %r18, 2146435072;
	@%p15 bra 	BB67_8;

	setp.gtu.f64	%p16, %fd2, 0d7FF0000000000000;
	@%p16 bra 	BB67_17;

	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p17, %r19, 2146435072;
	@%p17 bra 	BB67_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd51;
	}
	setp.eq.s32	%p18, %r20, 0;
	@%p18 bra 	BB67_16;

BB67_12:
	and.b32  	%r21, %r2, 2147483647;
	setp.ne.s32	%p19, %r21, 2146435072;
	@%p19 bra 	BB67_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd1;
	}
	setp.ne.s32	%p20, %r22, 0;
	mov.f64 	%fd80, %fd79;
	@%p20 bra 	BB67_17;

	shr.s32 	%r23, %r1, 31;
	and.b32  	%r24, %r23, -2146435072;
	add.s32 	%r25, %r24, 2146435072;
	or.b32  	%r26, %r25, -2147483648;
	bfe.u32 	%r27, %r1, 20, 11;
	add.s32 	%r28, %r27, -1012;
	shl.b64 	%rd8, %rd3, %r28;
	setp.eq.s64	%p21, %rd8, -9223372036854775808;
	and.pred  	%p23, %p8, %p21;
	selp.b32	%r29, %r26, %r25, %p23;
	mov.u32 	%r30, 0;
	mov.b64 	%fd80, {%r30, %r29};
	bra.uni 	BB67_17;

BB67_8:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB67_17;

BB67_13:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB67_17;

BB67_16:
	setp.gt.f64	%p24, %fd2, 0d3FF0000000000000;
	selp.b32	%r31, 2146435072, 0, %p24;
	xor.b32  	%r32, %r31, 2146435072;
	setp.lt.s32	%p25, %r1, 0;
	selp.b32	%r33, %r32, %r31, %p25;
	setp.eq.f64	%p26, %fd1, 0dBFF0000000000000;
	selp.b32	%r34, 1072693248, %r33, %p26;
	mov.u32 	%r35, 0;
	mov.b64 	%fd80, {%r35, %r34};

BB67_17:
	mul.f64 	%fd55, %fd80, 0dC0D004A000000000;
	setp.eq.f64	%p27, %fd1, 0d3FF0000000000000;
	selp.f64	%fd56, 0dC0D004A000000000, %fd55, %p27;
	mul.f64 	%fd57, %fd49, 0d4099A10000000000;
	fma.rn.f64 	%fd13, %fd57, %fd48, %fd56;
	mov.f64 	%fd58, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd58;
	}
	bfe.u32 	%r36, %r3, 20, 11;
	add.s32 	%r37, %r36, -1012;
	mov.u64 	%rd9, 4613937818241073152;
	shl.b64 	%rd10, %rd9, %r37;
	setp.eq.s64	%p28, %rd10, -9223372036854775808;
	// Callseq Start 176
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd58;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd82, [retval0+0];
	
	//{
	}// Callseq End 176
	and.pred  	%p1, %p8, %p28;
	@!%p1 bra 	BB67_19;
	bra.uni 	BB67_18;

BB67_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd82;
	}
	xor.b32  	%r39, %r38, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd82;
	}
	mov.b64 	%fd82, {%r40, %r39};

BB67_19:
	@%p10 bra 	BB67_22;
	bra.uni 	BB67_20;

BB67_22:
	bfe.u32 	%r41, %r3, 20, 11;
	add.s32 	%r42, %r41, -1012;
	shl.b64 	%rd12, %rd9, %r42;
	setp.eq.s64	%p33, %rd12, -9223372036854775808;
	selp.b32	%r43, %r2, 0, %p33;
	or.b32  	%r44, %r43, 2146435072;
	setp.lt.s32	%p34, %r3, 0;
	selp.b32	%r45, %r44, %r43, %p34;
	mov.u32 	%r46, 0;
	mov.b64 	%fd82, {%r46, %r45};
	bra.uni 	BB67_23;

BB67_20:
	setp.gt.s32	%p31, %r2, -1;
	@%p31 bra 	BB67_23;

	cvt.rzi.f64.f64	%fd60, %fd58;
	setp.neu.f64	%p32, %fd60, 0d4008000000000000;
	selp.f64	%fd82, 0dFFF8000000000000, %fd82, %p32;

BB67_23:
	add.f64 	%fd83, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd83;
	}
	and.b32  	%r48, %r47, 2146435072;
	setp.ne.s32	%p35, %r48, 2146435072;
	@%p35 bra 	BB67_24;

	setp.gtu.f64	%p36, %fd2, 0d7FF0000000000000;
	@%p36 bra 	BB67_33;

	and.b32  	%r49, %r3, 2147483647;
	setp.ne.s32	%p37, %r49, 2146435072;
	@%p37 bra 	BB67_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd58;
	}
	setp.eq.s32	%p38, %r50, 0;
	@%p38 bra 	BB67_32;

BB67_28:
	and.b32  	%r51, %r2, 2147483647;
	setp.ne.s32	%p39, %r51, 2146435072;
	@%p39 bra 	BB67_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r52, %temp}, %fd1;
	}
	setp.ne.s32	%p40, %r52, 0;
	mov.f64 	%fd83, %fd82;
	@%p40 bra 	BB67_33;

	shr.s32 	%r53, %r3, 31;
	and.b32  	%r54, %r53, -2146435072;
	add.s32 	%r55, %r54, 2146435072;
	or.b32  	%r56, %r55, -2147483648;
	selp.b32	%r57, %r56, %r55, %p1;
	mov.u32 	%r58, 0;
	mov.b64 	%fd83, {%r58, %r57};
	bra.uni 	BB67_33;

BB67_24:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB67_33;

BB67_29:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB67_33;

BB67_32:
	setp.gt.f64	%p41, %fd2, 0d3FF0000000000000;
	selp.b32	%r59, 2146435072, 0, %p41;
	xor.b32  	%r60, %r59, 2146435072;
	setp.lt.s32	%p42, %r3, 0;
	selp.b32	%r61, %r60, %r59, %p42;
	setp.eq.f64	%p43, %fd1, 0dBFF0000000000000;
	selp.b32	%r62, 1072693248, %r61, %p43;
	mov.u32 	%r63, 0;
	mov.b64 	%fd83, {%r63, %r62};

BB67_33:
	mul.f64 	%fd62, %fd83, 0d40E806F000000000;
	selp.f64	%fd63, 0d40E806F000000000, %fd62, %p27;
	add.f64 	%fd24, %fd13, %fd63;
	mov.f64 	%fd64, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd64;
	}
	bfe.u32 	%r64, %r4, 20, 11;
	add.s32 	%r65, %r64, -1012;
	mov.u64 	%rd13, 4616189618054758400;
	shl.b64 	%rd1, %rd13, %r65;
	setp.eq.s64	%p45, %rd1, -9223372036854775808;
	// Callseq Start 177
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd64;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd85, [retval0+0];
	
	//{
	}// Callseq End 177
	and.pred  	%p2, %p8, %p45;
	@!%p2 bra 	BB67_35;
	bra.uni 	BB67_34;

BB67_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd85;
	}
	xor.b32  	%r67, %r66, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r68, %temp}, %fd85;
	}
	mov.b64 	%fd85, {%r68, %r67};

BB67_35:
	@%p10 bra 	BB67_38;
	bra.uni 	BB67_36;

BB67_38:
	selp.b32	%r69, %r2, 0, %p45;
	or.b32  	%r70, %r69, 2146435072;
	setp.lt.s32	%p51, %r4, 0;
	selp.b32	%r71, %r70, %r69, %p51;
	mov.u32 	%r72, 0;
	mov.b64 	%fd85, {%r72, %r71};
	bra.uni 	BB67_39;

BB67_36:
	setp.gt.s32	%p48, %r2, -1;
	@%p48 bra 	BB67_39;

	cvt.rzi.f64.f64	%fd66, %fd64;
	setp.neu.f64	%p49, %fd66, 0d4010000000000000;
	selp.f64	%fd85, 0dFFF8000000000000, %fd85, %p49;

BB67_39:
	add.f64 	%fd86, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd86;
	}
	and.b32  	%r74, %r73, 2146435072;
	setp.ne.s32	%p52, %r74, 2146435072;
	@%p52 bra 	BB67_40;

	setp.gtu.f64	%p53, %fd2, 0d7FF0000000000000;
	@%p53 bra 	BB67_49;

	and.b32  	%r75, %r4, 2147483647;
	setp.ne.s32	%p54, %r75, 2146435072;
	@%p54 bra 	BB67_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r76, %temp}, %fd64;
	}
	setp.eq.s32	%p55, %r76, 0;
	@%p55 bra 	BB67_48;

BB67_44:
	and.b32  	%r77, %r2, 2147483647;
	setp.ne.s32	%p56, %r77, 2146435072;
	@%p56 bra 	BB67_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd1;
	}
	setp.ne.s32	%p57, %r78, 0;
	mov.f64 	%fd86, %fd85;
	@%p57 bra 	BB67_49;

	shr.s32 	%r79, %r4, 31;
	and.b32  	%r80, %r79, -2146435072;
	add.s32 	%r81, %r80, 2146435072;
	or.b32  	%r82, %r81, -2147483648;
	selp.b32	%r83, %r82, %r81, %p2;
	mov.u32 	%r84, 0;
	mov.b64 	%fd86, {%r84, %r83};
	bra.uni 	BB67_49;

BB67_40:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB67_49;

BB67_45:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB67_49;

BB67_48:
	setp.gt.f64	%p58, %fd2, 0d3FF0000000000000;
	selp.b32	%r85, 2146435072, 0, %p58;
	xor.b32  	%r86, %r85, 2146435072;
	setp.lt.s32	%p59, %r4, 0;
	selp.b32	%r87, %r86, %r85, %p59;
	setp.eq.f64	%p60, %fd1, 0dBFF0000000000000;
	selp.b32	%r88, 1072693248, %r87, %p60;
	mov.u32 	%r89, 0;
	mov.b64 	%fd86, {%r89, %r88};

BB67_49:
	mul.f64 	%fd68, %fd86, 0dC0EC081800000000;
	selp.f64	%fd69, 0dC0EC081800000000, %fd68, %p27;
	add.f64 	%fd35, %fd24, %fd69;
	mov.f64 	%fd70, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd70;
	}
	bfe.u32 	%r90, %r5, 20, 11;
	add.s32 	%r91, %r90, -1012;
	mov.u64 	%rd14, 4617315517961601024;
	shl.b64 	%rd2, %rd14, %r91;
	setp.eq.s64	%p62, %rd2, -9223372036854775808;
	// Callseq Start 178
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd70;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd88, [retval0+0];
	
	//{
	}// Callseq End 178
	and.pred  	%p3, %p8, %p62;
	@!%p3 bra 	BB67_51;
	bra.uni 	BB67_50;

BB67_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %fd88;
	}
	xor.b32  	%r93, %r92, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd88;
	}
	mov.b64 	%fd88, {%r94, %r93};

BB67_51:
	@%p10 bra 	BB67_54;
	bra.uni 	BB67_52;

BB67_54:
	selp.b32	%r95, %r2, 0, %p62;
	or.b32  	%r96, %r95, 2146435072;
	setp.lt.s32	%p68, %r5, 0;
	selp.b32	%r97, %r96, %r95, %p68;
	mov.u32 	%r98, 0;
	mov.b64 	%fd88, {%r98, %r97};
	bra.uni 	BB67_55;

BB67_52:
	setp.gt.s32	%p65, %r2, -1;
	@%p65 bra 	BB67_55;

	cvt.rzi.f64.f64	%fd72, %fd70;
	setp.neu.f64	%p66, %fd72, 0d4014000000000000;
	selp.f64	%fd88, 0dFFF8000000000000, %fd88, %p66;

BB67_55:
	add.f64 	%fd89, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r99}, %fd89;
	}
	and.b32  	%r100, %r99, 2146435072;
	setp.ne.s32	%p69, %r100, 2146435072;
	@%p69 bra 	BB67_56;

	setp.gtu.f64	%p70, %fd2, 0d7FF0000000000000;
	@%p70 bra 	BB67_65;

	and.b32  	%r101, %r5, 2147483647;
	setp.ne.s32	%p71, %r101, 2146435072;
	@%p71 bra 	BB67_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r102, %temp}, %fd70;
	}
	setp.eq.s32	%p72, %r102, 0;
	@%p72 bra 	BB67_64;

BB67_60:
	and.b32  	%r103, %r2, 2147483647;
	setp.ne.s32	%p73, %r103, 2146435072;
	@%p73 bra 	BB67_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r104, %temp}, %fd1;
	}
	setp.ne.s32	%p74, %r104, 0;
	mov.f64 	%fd89, %fd88;
	@%p74 bra 	BB67_65;

	shr.s32 	%r105, %r5, 31;
	and.b32  	%r106, %r105, -2146435072;
	add.s32 	%r107, %r106, 2146435072;
	or.b32  	%r108, %r107, -2147483648;
	selp.b32	%r109, %r108, %r107, %p3;
	mov.u32 	%r110, 0;
	mov.b64 	%fd89, {%r110, %r109};
	bra.uni 	BB67_65;

BB67_56:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB67_65;

BB67_61:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB67_65;

BB67_64:
	setp.gt.f64	%p75, %fd2, 0d3FF0000000000000;
	selp.b32	%r111, 2146435072, 0, %p75;
	xor.b32  	%r112, %r111, 2146435072;
	setp.lt.s32	%p76, %r5, 0;
	selp.b32	%r113, %r112, %r111, %p76;
	setp.eq.f64	%p77, %fd1, 0dBFF0000000000000;
	selp.b32	%r114, 1072693248, %r113, %p77;
	mov.u32 	%r115, 0;
	mov.b64 	%fd89, {%r115, %r114};

BB67_65:
	mul.f64 	%fd74, %fd89, 0d40D66CE000000000;
	selp.f64	%fd75, 0d40D66CE000000000, %fd74, %p27;
	add.f64 	%fd76, %fd35, %fd75;
	mul.f64 	%fd77, %fd48, %fd48;
	mul.f64 	%fd90, %fd77, %fd76;

BB67_66:
	st.param.f64	[func_retval0+0], %fd90;
	ret;
}

	// .globl	_Z14SmoothWave_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z14SmoothWave_tttddPdiPii(
	.param .b64 _Z14SmoothWave_tttddPdiPii_param_0,
	.param .b64 _Z14SmoothWave_tttddPdiPii_param_1,
	.param .b64 _Z14SmoothWave_tttddPdiPii_param_2,
	.param .b32 _Z14SmoothWave_tttddPdiPii_param_3,
	.param .b64 _Z14SmoothWave_tttddPdiPii_param_4,
	.param .b32 _Z14SmoothWave_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<58>;
	.reg .b32 	%r<85>;
	.reg .f64 	%fd<73>;
	.reg .b64 	%rd<9>;


	ld.param.f64 	%fd38, [_Z14SmoothWave_tttddPdiPii_param_0];
	ld.param.f64 	%fd39, [_Z14SmoothWave_tttddPdiPii_param_1];
	mul.f64 	%fd1, %fd38, %fd39;
	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	setp.gt.f64	%p5, %fd1, 0d3FF0000000000000;
	or.pred  	%p6, %p4, %p5;
	mov.f64 	%fd72, 0d0000000000000000;
	@%p6 bra 	BB68_50;

	mul.f64 	%fd41, %fd39, 0dC0E004A000000000;
	fma.rn.f64 	%fd2, %fd41, %fd38, 0d4099A10000000000;
	mov.f64 	%fd42, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd42;
	}
	bfe.u32 	%r5, %r1, 20, 11;
	add.s32 	%r6, %r5, -1012;
	mov.u64 	%rd3, 4611686018427387904;
	shl.b64 	%rd4, %rd3, %r6;
	setp.eq.s64	%p7, %rd4, -9223372036854775808;
	abs.f64 	%fd3, %fd1;
	// Callseq Start 179
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd64, [retval0+0];
	
	//{
	}// Callseq End 179
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p8, %r2, 0;
	and.pred  	%p1, %p8, %p7;
	@!%p1 bra 	BB68_3;
	bra.uni 	BB68_2;

BB68_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd64;
	}
	xor.b32  	%r8, %r7, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd64;
	}
	mov.b64 	%fd64, {%r9, %r8};

BB68_3:
	setp.eq.f64	%p9, %fd1, 0d0000000000000000;
	@%p9 bra 	BB68_6;
	bra.uni 	BB68_4;

BB68_6:
	bfe.u32 	%r10, %r1, 20, 11;
	add.s32 	%r11, %r10, -1012;
	shl.b64 	%rd6, %rd3, %r11;
	setp.eq.s64	%p12, %rd6, -9223372036854775808;
	selp.b32	%r12, %r2, 0, %p12;
	or.b32  	%r13, %r12, 2146435072;
	setp.lt.s32	%p13, %r1, 0;
	selp.b32	%r14, %r13, %r12, %p13;
	mov.u32 	%r15, 0;
	mov.b64 	%fd64, {%r15, %r14};
	bra.uni 	BB68_7;

BB68_4:
	setp.gt.s32	%p10, %r2, -1;
	@%p10 bra 	BB68_7;

	cvt.rzi.f64.f64	%fd44, %fd42;
	setp.neu.f64	%p11, %fd44, 0d4000000000000000;
	selp.f64	%fd64, 0dFFF8000000000000, %fd64, %p11;

BB68_7:
	add.f64 	%fd65, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd65;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.ne.s32	%p14, %r17, 2146435072;
	@%p14 bra 	BB68_8;

	setp.gtu.f64	%p15, %fd3, 0d7FF0000000000000;
	@%p15 bra 	BB68_17;

	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p16, %r18, 2146435072;
	@%p16 bra 	BB68_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd42;
	}
	setp.eq.s32	%p17, %r19, 0;
	@%p17 bra 	BB68_16;

BB68_12:
	and.b32  	%r20, %r2, 2147483647;
	setp.ne.s32	%p18, %r20, 2146435072;
	@%p18 bra 	BB68_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd1;
	}
	setp.ne.s32	%p19, %r21, 0;
	mov.f64 	%fd65, %fd64;
	@%p19 bra 	BB68_17;

	shr.s32 	%r22, %r1, 31;
	and.b32  	%r23, %r22, -2146435072;
	add.s32 	%r24, %r23, 2146435072;
	or.b32  	%r25, %r24, -2147483648;
	selp.b32	%r26, %r25, %r24, %p1;
	mov.u32 	%r27, 0;
	mov.b64 	%fd65, {%r27, %r26};
	bra.uni 	BB68_17;

BB68_8:
	mov.f64 	%fd65, %fd64;
	bra.uni 	BB68_17;

BB68_13:
	mov.f64 	%fd65, %fd64;
	bra.uni 	BB68_17;

BB68_16:
	setp.gt.f64	%p20, %fd3, 0d3FF0000000000000;
	selp.b32	%r28, 2146435072, 0, %p20;
	xor.b32  	%r29, %r28, 2146435072;
	setp.lt.s32	%p21, %r1, 0;
	selp.b32	%r30, %r29, %r28, %p21;
	setp.eq.f64	%p22, %fd1, 0dBFF0000000000000;
	selp.b32	%r31, 1072693248, %r30, %p22;
	mov.u32 	%r32, 0;
	mov.b64 	%fd65, {%r32, %r31};

BB68_17:
	mul.f64 	%fd46, %fd65, 0d4102053400000000;
	setp.eq.f64	%p23, %fd1, 0d3FF0000000000000;
	selp.f64	%fd47, 0d4102053400000000, %fd46, %p23;
	add.f64 	%fd14, %fd2, %fd47;
	mov.f64 	%fd48, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd48;
	}
	bfe.u32 	%r33, %r3, 20, 11;
	add.s32 	%r34, %r33, -1012;
	mov.u64 	%rd7, 4613937818241073152;
	shl.b64 	%rd1, %rd7, %r34;
	setp.eq.s64	%p24, %rd1, -9223372036854775808;
	// Callseq Start 180
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd48;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd67, [retval0+0];
	
	//{
	}// Callseq End 180
	and.pred  	%p2, %p8, %p24;
	@!%p2 bra 	BB68_19;
	bra.uni 	BB68_18;

BB68_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd67;
	}
	xor.b32  	%r36, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd67;
	}
	mov.b64 	%fd67, {%r37, %r36};

BB68_19:
	@%p9 bra 	BB68_22;
	bra.uni 	BB68_20;

BB68_22:
	selp.b32	%r38, %r2, 0, %p24;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p30, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p30;
	mov.u32 	%r41, 0;
	mov.b64 	%fd67, {%r41, %r40};
	bra.uni 	BB68_23;

BB68_20:
	setp.gt.s32	%p27, %r2, -1;
	@%p27 bra 	BB68_23;

	cvt.rzi.f64.f64	%fd50, %fd48;
	setp.neu.f64	%p28, %fd50, 0d4008000000000000;
	selp.f64	%fd67, 0dFFF8000000000000, %fd67, %p28;

BB68_23:
	add.f64 	%fd68, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd68;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p31, %r43, 2146435072;
	@%p31 bra 	BB68_24;

	setp.gtu.f64	%p32, %fd3, 0d7FF0000000000000;
	@%p32 bra 	BB68_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p33, %r44, 2146435072;
	@%p33 bra 	BB68_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd48;
	}
	setp.eq.s32	%p34, %r45, 0;
	@%p34 bra 	BB68_32;

BB68_28:
	and.b32  	%r46, %r2, 2147483647;
	setp.ne.s32	%p35, %r46, 2146435072;
	@%p35 bra 	BB68_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd1;
	}
	setp.ne.s32	%p36, %r47, 0;
	mov.f64 	%fd68, %fd67;
	@%p36 bra 	BB68_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd68, {%r53, %r52};
	bra.uni 	BB68_33;

BB68_24:
	mov.f64 	%fd68, %fd67;
	bra.uni 	BB68_33;

BB68_29:
	mov.f64 	%fd68, %fd67;
	bra.uni 	BB68_33;

BB68_32:
	setp.gt.f64	%p37, %fd3, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p37;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p38, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p38;
	setp.eq.f64	%p39, %fd1, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p39;
	mov.u32 	%r58, 0;
	mov.b64 	%fd68, {%r58, %r57};

BB68_33:
	mul.f64 	%fd52, %fd68, 0dC10C081800000000;
	selp.f64	%fd53, 0dC10C081800000000, %fd52, %p23;
	add.f64 	%fd25, %fd14, %fd53;
	mov.f64 	%fd54, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd54;
	}
	bfe.u32 	%r59, %r4, 20, 11;
	add.s32 	%r60, %r59, -1012;
	mov.u64 	%rd8, 4616189618054758400;
	shl.b64 	%rd2, %rd8, %r60;
	setp.eq.s64	%p41, %rd2, -9223372036854775808;
	// Callseq Start 181
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd54;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd70, [retval0+0];
	
	//{
	}// Callseq End 181
	and.pred  	%p3, %p8, %p41;
	@!%p3 bra 	BB68_35;
	bra.uni 	BB68_34;

BB68_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd70;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd70;
	}
	mov.b64 	%fd70, {%r63, %r62};

BB68_35:
	@%p9 bra 	BB68_38;
	bra.uni 	BB68_36;

BB68_38:
	selp.b32	%r64, %r2, 0, %p41;
	or.b32  	%r65, %r64, 2146435072;
	setp.lt.s32	%p47, %r4, 0;
	selp.b32	%r66, %r65, %r64, %p47;
	mov.u32 	%r67, 0;
	mov.b64 	%fd70, {%r67, %r66};
	bra.uni 	BB68_39;

BB68_36:
	setp.gt.s32	%p44, %r2, -1;
	@%p44 bra 	BB68_39;

	cvt.rzi.f64.f64	%fd56, %fd54;
	setp.neu.f64	%p45, %fd56, 0d4010000000000000;
	selp.f64	%fd70, 0dFFF8000000000000, %fd70, %p45;

BB68_39:
	add.f64 	%fd71, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd71;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.ne.s32	%p48, %r69, 2146435072;
	@%p48 bra 	BB68_40;

	setp.gtu.f64	%p49, %fd3, 0d7FF0000000000000;
	@%p49 bra 	BB68_49;

	and.b32  	%r70, %r4, 2147483647;
	setp.ne.s32	%p50, %r70, 2146435072;
	@%p50 bra 	BB68_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd54;
	}
	setp.eq.s32	%p51, %r71, 0;
	@%p51 bra 	BB68_48;

BB68_44:
	and.b32  	%r72, %r2, 2147483647;
	setp.ne.s32	%p52, %r72, 2146435072;
	@%p52 bra 	BB68_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd1;
	}
	setp.ne.s32	%p53, %r73, 0;
	mov.f64 	%fd71, %fd70;
	@%p53 bra 	BB68_49;

	shr.s32 	%r74, %r4, 31;
	and.b32  	%r75, %r74, -2146435072;
	add.s32 	%r76, %r75, 2146435072;
	or.b32  	%r77, %r76, -2147483648;
	selp.b32	%r78, %r77, %r76, %p3;
	mov.u32 	%r79, 0;
	mov.b64 	%fd71, {%r79, %r78};
	bra.uni 	BB68_49;

BB68_40:
	mov.f64 	%fd71, %fd70;
	bra.uni 	BB68_49;

BB68_45:
	mov.f64 	%fd71, %fd70;
	bra.uni 	BB68_49;

BB68_48:
	setp.gt.f64	%p54, %fd3, 0d3FF0000000000000;
	selp.b32	%r80, 2146435072, 0, %p54;
	xor.b32  	%r81, %r80, 2146435072;
	setp.lt.s32	%p55, %r4, 0;
	selp.b32	%r82, %r81, %r80, %p55;
	setp.eq.f64	%p56, %fd1, 0dBFF0000000000000;
	selp.b32	%r83, 1072693248, %r82, %p56;
	mov.u32 	%r84, 0;
	mov.b64 	%fd71, {%r84, %r83};

BB68_49:
	mul.f64 	%fd58, %fd71, 0d40FC081800000000;
	selp.f64	%fd59, 0d40FC081800000000, %fd58, %p23;
	add.f64 	%fd60, %fd25, %fd59;
	mul.f64 	%fd61, %fd38, %fd38;
	mul.f64 	%fd62, %fd61, %fd38;
	mul.f64 	%fd72, %fd62, %fd60;

BB68_50:
	st.param.f64	[func_retval0+0], %fd72;
	ret;
}

	// .globl	_Z15SmoothWave_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z15SmoothWave_omttddPdiPii(
	.param .b64 _Z15SmoothWave_omttddPdiPii_param_0,
	.param .b64 _Z15SmoothWave_omttddPdiPii_param_1,
	.param .b64 _Z15SmoothWave_omttddPdiPii_param_2,
	.param .b32 _Z15SmoothWave_omttddPdiPii_param_3,
	.param .b64 _Z15SmoothWave_omttddPdiPii_param_4,
	.param .b32 _Z15SmoothWave_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<76>;
	.reg .b32 	%r<110>;
	.reg .f64 	%fd<97>;
	.reg .b64 	%rd<9>;


	ld.param.f64 	%fd51, [_Z15SmoothWave_omttddPdiPii_param_0];
	ld.param.f64 	%fd52, [_Z15SmoothWave_omttddPdiPii_param_1];
	mul.f64 	%fd1, %fd51, %fd52;
	setp.lt.f64	%p5, %fd1, 0d0000000000000000;
	setp.gt.f64	%p6, %fd1, 0d3FF0000000000000;
	or.pred  	%p7, %p5, %p6;
	mov.f64 	%fd96, 0d0000000000000000;
	@%p7 bra 	BB69_66;

	mov.f64 	%fd54, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd54;
	}
	bfe.u32 	%r6, %r1, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd5, 4611686018427387904;
	shl.b64 	%rd1, %rd5, %r7;
	setp.eq.s64	%p8, %rd1, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 182
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd54;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd85, [retval0+0];
	
	//{
	}// Callseq End 182
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	setp.lt.s32	%p9, %r2, 0;
	and.pred  	%p1, %p9, %p8;
	@!%p1 bra 	BB69_3;
	bra.uni 	BB69_2;

BB69_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd85;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd85;
	}
	mov.b64 	%fd85, {%r10, %r9};

BB69_3:
	setp.eq.f64	%p10, %fd1, 0d0000000000000000;
	@%p10 bra 	BB69_6;
	bra.uni 	BB69_4;

BB69_6:
	selp.b32	%r11, %r2, 0, %p8;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p14, %r1, 0;
	selp.b32	%r13, %r12, %r11, %p14;
	mov.u32 	%r14, 0;
	mov.b64 	%fd85, {%r14, %r13};
	bra.uni 	BB69_7;

BB69_4:
	setp.gt.s32	%p11, %r2, -1;
	@%p11 bra 	BB69_7;

	cvt.rzi.f64.f64	%fd56, %fd54;
	setp.neu.f64	%p12, %fd56, 0d4000000000000000;
	selp.f64	%fd85, 0dFFF8000000000000, %fd85, %p12;

BB69_7:
	add.f64 	%fd86, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd86;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p15, %r16, 2146435072;
	@%p15 bra 	BB69_8;

	setp.gtu.f64	%p16, %fd2, 0d7FF0000000000000;
	@%p16 bra 	BB69_17;

	and.b32  	%r17, %r1, 2147483647;
	setp.ne.s32	%p17, %r17, 2146435072;
	@%p17 bra 	BB69_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd54;
	}
	setp.eq.s32	%p18, %r18, 0;
	@%p18 bra 	BB69_16;

BB69_12:
	and.b32  	%r19, %r2, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB69_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd1;
	}
	setp.ne.s32	%p20, %r20, 0;
	mov.f64 	%fd86, %fd85;
	@%p20 bra 	BB69_17;

	shr.s32 	%r21, %r1, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd86, {%r26, %r25};
	bra.uni 	BB69_17;

BB69_8:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB69_17;

BB69_13:
	mov.f64 	%fd86, %fd85;
	bra.uni 	BB69_17;

BB69_16:
	setp.gt.f64	%p21, %fd2, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p21;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p22, %r1, 0;
	selp.b32	%r29, %r28, %r27, %p22;
	setp.eq.f64	%p23, %fd1, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p23;
	mov.u32 	%r31, 0;
	mov.b64 	%fd86, {%r31, %r30};

BB69_17:
	setp.eq.f64	%p24, %fd1, 0d3FF0000000000000;
	selp.f64	%fd13, 0d3FF0000000000000, %fd86, %p24;
	mul.f64 	%fd58, %fd13, 0dC0D004A000000000;
	mul.f64 	%fd59, %fd52, 0d4099A10000000000;
	fma.rn.f64 	%fd14, %fd59, %fd51, %fd58;
	mov.f64 	%fd60, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd60;
	}
	bfe.u32 	%r32, %r3, 20, 11;
	add.s32 	%r33, %r32, -1012;
	mov.u64 	%rd6, 4613937818241073152;
	shl.b64 	%rd2, %rd6, %r33;
	setp.eq.s64	%p25, %rd2, -9223372036854775808;
	// Callseq Start 183
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd60;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd88, [retval0+0];
	
	//{
	}// Callseq End 183
	and.pred  	%p2, %p9, %p25;
	@!%p2 bra 	BB69_19;
	bra.uni 	BB69_18;

BB69_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd88;
	}
	xor.b32  	%r35, %r34, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd88;
	}
	mov.b64 	%fd88, {%r36, %r35};

BB69_19:
	@%p10 bra 	BB69_22;
	bra.uni 	BB69_20;

BB69_22:
	selp.b32	%r37, %r2, 0, %p25;
	or.b32  	%r38, %r37, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r39, %r38, %r37, %p31;
	mov.u32 	%r40, 0;
	mov.b64 	%fd88, {%r40, %r39};
	bra.uni 	BB69_23;

BB69_20:
	setp.gt.s32	%p28, %r2, -1;
	@%p28 bra 	BB69_23;

	cvt.rzi.f64.f64	%fd62, %fd60;
	setp.neu.f64	%p29, %fd62, 0d4008000000000000;
	selp.f64	%fd88, 0dFFF8000000000000, %fd88, %p29;

BB69_23:
	add.f64 	%fd89, %fd1, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd89;
	}
	and.b32  	%r42, %r41, 2146435072;
	setp.ne.s32	%p32, %r42, 2146435072;
	@%p32 bra 	BB69_24;

	setp.gtu.f64	%p33, %fd2, 0d7FF0000000000000;
	@%p33 bra 	BB69_33;

	and.b32  	%r43, %r3, 2147483647;
	setp.ne.s32	%p34, %r43, 2146435072;
	@%p34 bra 	BB69_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r44, %temp}, %fd60;
	}
	setp.eq.s32	%p35, %r44, 0;
	@%p35 bra 	BB69_32;

BB69_28:
	and.b32  	%r45, %r2, 2147483647;
	setp.ne.s32	%p36, %r45, 2146435072;
	@%p36 bra 	BB69_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd1;
	}
	setp.ne.s32	%p37, %r46, 0;
	mov.f64 	%fd89, %fd88;
	@%p37 bra 	BB69_33;

	shr.s32 	%r47, %r3, 31;
	and.b32  	%r48, %r47, -2146435072;
	add.s32 	%r49, %r48, 2146435072;
	or.b32  	%r50, %r49, -2147483648;
	selp.b32	%r51, %r50, %r49, %p2;
	mov.u32 	%r52, 0;
	mov.b64 	%fd89, {%r52, %r51};
	bra.uni 	BB69_33;

BB69_24:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB69_33;

BB69_29:
	mov.f64 	%fd89, %fd88;
	bra.uni 	BB69_33;

BB69_32:
	setp.gt.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.b32	%r53, 2146435072, 0, %p38;
	xor.b32  	%r54, %r53, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r55, %r54, %r53, %p39;
	setp.eq.f64	%p40, %fd1, 0dBFF0000000000000;
	selp.b32	%r56, 1072693248, %r55, %p40;
	mov.u32 	%r57, 0;
	mov.b64 	%fd89, {%r57, %r56};

BB69_33:
	selp.f64	%fd25, 0d3FF0000000000000, %fd89, %p24;
	fma.rn.f64 	%fd26, %fd25, 0d40E806F000000000, %fd14;
	mov.f64 	%fd64, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd64;
	}
	bfe.u32 	%r58, %r4, 20, 11;
	add.s32 	%r59, %r58, -1012;
	mov.u64 	%rd7, 4616189618054758400;
	shl.b64 	%rd3, %rd7, %r59;
	setp.eq.s64	%p42, %rd3, -9223372036854775808;
	// Callseq Start 184
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd64;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd91, [retval0+0];
	
	//{
	}// Callseq End 184
	and.pred  	%p3, %p9, %p42;
	@!%p3 bra 	BB69_35;
	bra.uni 	BB69_34;

BB69_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r60}, %fd91;
	}
	xor.b32  	%r61, %r60, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r62, %temp}, %fd91;
	}
	mov.b64 	%fd91, {%r62, %r61};

BB69_35:
	@%p10 bra 	BB69_38;
	bra.uni 	BB69_36;

BB69_38:
	selp.b32	%r63, %r2, 0, %p42;
	or.b32  	%r64, %r63, 2146435072;
	setp.lt.s32	%p48, %r4, 0;
	selp.b32	%r65, %r64, %r63, %p48;
	mov.u32 	%r66, 0;
	mov.b64 	%fd91, {%r66, %r65};
	bra.uni 	BB69_39;

BB69_36:
	setp.gt.s32	%p45, %r2, -1;
	@%p45 bra 	BB69_39;

	cvt.rzi.f64.f64	%fd66, %fd64;
	setp.neu.f64	%p46, %fd66, 0d4010000000000000;
	selp.f64	%fd91, 0dFFF8000000000000, %fd91, %p46;

BB69_39:
	add.f64 	%fd92, %fd1, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r67}, %fd92;
	}
	and.b32  	%r68, %r67, 2146435072;
	setp.ne.s32	%p49, %r68, 2146435072;
	@%p49 bra 	BB69_40;

	setp.gtu.f64	%p50, %fd2, 0d7FF0000000000000;
	@%p50 bra 	BB69_49;

	and.b32  	%r69, %r4, 2147483647;
	setp.ne.s32	%p51, %r69, 2146435072;
	@%p51 bra 	BB69_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r70, %temp}, %fd64;
	}
	setp.eq.s32	%p52, %r70, 0;
	@%p52 bra 	BB69_48;

BB69_44:
	and.b32  	%r71, %r2, 2147483647;
	setp.ne.s32	%p53, %r71, 2146435072;
	@%p53 bra 	BB69_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r72, 0;
	mov.f64 	%fd92, %fd91;
	@%p54 bra 	BB69_49;

	shr.s32 	%r73, %r4, 31;
	and.b32  	%r74, %r73, -2146435072;
	add.s32 	%r75, %r74, 2146435072;
	or.b32  	%r76, %r75, -2147483648;
	selp.b32	%r77, %r76, %r75, %p3;
	mov.u32 	%r78, 0;
	mov.b64 	%fd92, {%r78, %r77};
	bra.uni 	BB69_49;

BB69_40:
	mov.f64 	%fd92, %fd91;
	bra.uni 	BB69_49;

BB69_45:
	mov.f64 	%fd92, %fd91;
	bra.uni 	BB69_49;

BB69_48:
	setp.gt.f64	%p55, %fd2, 0d3FF0000000000000;
	selp.b32	%r79, 2146435072, 0, %p55;
	xor.b32  	%r80, %r79, 2146435072;
	setp.lt.s32	%p56, %r4, 0;
	selp.b32	%r81, %r80, %r79, %p56;
	setp.eq.f64	%p57, %fd1, 0dBFF0000000000000;
	selp.b32	%r82, 1072693248, %r81, %p57;
	mov.u32 	%r83, 0;
	mov.b64 	%fd92, {%r83, %r82};

BB69_49:
	selp.f64	%fd37, 0d3FF0000000000000, %fd92, %p24;
	fma.rn.f64 	%fd38, %fd37, 0dC0EC081800000000, %fd26;
	mov.f64 	%fd68, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd68;
	}
	bfe.u32 	%r84, %r5, 20, 11;
	add.s32 	%r85, %r84, -1012;
	mov.u64 	%rd8, 4617315517961601024;
	shl.b64 	%rd4, %rd8, %r85;
	setp.eq.s64	%p59, %rd4, -9223372036854775808;
	// Callseq Start 185
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd68;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd94, [retval0+0];
	
	//{
	}// Callseq End 185
	and.pred  	%p4, %p9, %p59;
	@!%p4 bra 	BB69_51;
	bra.uni 	BB69_50;

BB69_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd94;
	}
	xor.b32  	%r87, %r86, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r88, %temp}, %fd94;
	}
	mov.b64 	%fd94, {%r88, %r87};

BB69_51:
	@%p10 bra 	BB69_54;
	bra.uni 	BB69_52;

BB69_54:
	selp.b32	%r89, %r2, 0, %p59;
	or.b32  	%r90, %r89, 2146435072;
	setp.lt.s32	%p65, %r5, 0;
	selp.b32	%r91, %r90, %r89, %p65;
	mov.u32 	%r92, 0;
	mov.b64 	%fd94, {%r92, %r91};
	bra.uni 	BB69_55;

BB69_52:
	setp.gt.s32	%p62, %r2, -1;
	@%p62 bra 	BB69_55;

	cvt.rzi.f64.f64	%fd70, %fd68;
	setp.neu.f64	%p63, %fd70, 0d4014000000000000;
	selp.f64	%fd94, 0dFFF8000000000000, %fd94, %p63;

BB69_55:
	add.f64 	%fd95, %fd1, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r93}, %fd95;
	}
	and.b32  	%r94, %r93, 2146435072;
	setp.ne.s32	%p66, %r94, 2146435072;
	@%p66 bra 	BB69_56;

	setp.gtu.f64	%p67, %fd2, 0d7FF0000000000000;
	@%p67 bra 	BB69_65;

	and.b32  	%r95, %r5, 2147483647;
	setp.ne.s32	%p68, %r95, 2146435072;
	@%p68 bra 	BB69_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r96, %temp}, %fd68;
	}
	setp.eq.s32	%p69, %r96, 0;
	@%p69 bra 	BB69_64;

BB69_60:
	and.b32  	%r97, %r2, 2147483647;
	setp.ne.s32	%p70, %r97, 2146435072;
	@%p70 bra 	BB69_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd1;
	}
	setp.ne.s32	%p71, %r98, 0;
	mov.f64 	%fd95, %fd94;
	@%p71 bra 	BB69_65;

	shr.s32 	%r99, %r5, 31;
	and.b32  	%r100, %r99, -2146435072;
	add.s32 	%r101, %r100, 2146435072;
	or.b32  	%r102, %r101, -2147483648;
	selp.b32	%r103, %r102, %r101, %p4;
	mov.u32 	%r104, 0;
	mov.b64 	%fd95, {%r104, %r103};
	bra.uni 	BB69_65;

BB69_56:
	mov.f64 	%fd95, %fd94;
	bra.uni 	BB69_65;

BB69_61:
	mov.f64 	%fd95, %fd94;
	bra.uni 	BB69_65;

BB69_64:
	setp.gt.f64	%p72, %fd2, 0d3FF0000000000000;
	selp.b32	%r105, 2146435072, 0, %p72;
	xor.b32  	%r106, %r105, 2146435072;
	setp.lt.s32	%p73, %r5, 0;
	selp.b32	%r107, %r106, %r105, %p73;
	setp.eq.f64	%p74, %fd1, 0dBFF0000000000000;
	selp.b32	%r108, 1072693248, %r107, %p74;
	mov.u32 	%r109, 0;
	mov.b64 	%fd95, {%r109, %r108};

BB69_65:
	mul.f64 	%fd72, %fd95, 0d40D66CE000000000;
	selp.f64	%fd73, 0d40D66CE000000000, %fd72, %p24;
	add.f64 	%fd74, %fd38, %fd73;
	add.f64 	%fd75, %fd51, %fd51;
	mul.f64 	%fd76, %fd75, %fd74;
	mul.f64 	%fd77, %fd51, %fd51;
	mul.f64 	%fd78, %fd77, %fd52;
	mul.f64 	%fd79, %fd52, 0dC0E004A000000000;
	fma.rn.f64 	%fd80, %fd79, %fd51, 0d4099A10000000000;
	fma.rn.f64 	%fd81, %fd13, 0d4102053400000000, %fd80;
	fma.rn.f64 	%fd82, %fd25, 0dC10C081800000000, %fd81;
	fma.rn.f64 	%fd83, %fd37, 0d40FC081800000000, %fd82;
	fma.rn.f64 	%fd96, %fd78, %fd83, %fd76;

BB69_66:
	st.param.f64	[func_retval0+0], %fd96;
	ret;
}

	// .globl	_Z5BruneddPdiPii
.visible .func  (.param .b64 func_retval0) _Z5BruneddPdiPii(
	.param .b64 _Z5BruneddPdiPii_param_0,
	.param .b64 _Z5BruneddPdiPii_param_1,
	.param .b64 _Z5BruneddPdiPii_param_2,
	.param .b32 _Z5BruneddPdiPii_param_3,
	.param .b64 _Z5BruneddPdiPii_param_4,
	.param .b32 _Z5BruneddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<54>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd10, [_Z5BruneddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z5BruneddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z5BruneddPdiPii_param_2];
	mul.f64 	%fd1, %fd10, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd53, 0d0000000000000000;
	@%p1 bra 	BB70_6;

	neg.f64 	%fd2, %fd1;
	ld.f64 	%fd13, [%rd1];
	mov.f64 	%fd53, 0d3FF0000000000000;
	setp.geu.f64	%p2, %fd13, %fd2;
	@%p2 bra 	BB70_6;

	mov.f64 	%fd14, 0d4338000000000000;
	mov.f64 	%fd15, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd16, %fd2, %fd15, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd16;
	}
	mov.f64 	%fd17, 0dC338000000000000;
	add.rn.f64 	%fd18, %fd16, %fd17;
	mov.f64 	%fd19, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	mov.f64 	%fd21, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd22, %fd18, %fd21, %fd20;
	mov.f64 	%fd23, 0d3E928AF3FCA213EA;
	mov.f64 	%fd24, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F81111111122322;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FA55555555502A1;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	mov.f64 	%fd38, 0d3FC5555555555511;
	fma.rn.f64 	%fd39, %fd37, %fd22, %fd38;
	mov.f64 	%fd40, 0d3FE000000000000B;
	fma.rn.f64 	%fd41, %fd39, %fd22, %fd40;
	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd43, %fd41, %fd22, %fd42;
	fma.rn.f64 	%fd44, %fd43, %fd22, %fd42;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd44;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd52, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB70_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd45, 0d7FF0000000000000;
	sub.f64 	%fd46, %fd45, %fd1;
	selp.f64	%fd52, 0d0000000000000000, %fd46, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB70_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd47, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd48, {%r15, %r14};
	mul.f64 	%fd52, %fd47, %fd48;

BB70_5:
	add.f64 	%fd49, %fd1, 0d3FF0000000000000;
	mul.f64 	%fd50, %fd49, %fd52;
	sub.f64 	%fd53, %fd42, %fd50;

BB70_6:
	st.param.f64	[func_retval0+0], %fd53;
	ret;
}

	// .globl	_Z7Brune_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z7Brune_tddPdiPii(
	.param .b64 _Z7Brune_tddPdiPii_param_0,
	.param .b64 _Z7Brune_tddPdiPii_param_1,
	.param .b64 _Z7Brune_tddPdiPii_param_2,
	.param .b32 _Z7Brune_tddPdiPii_param_3,
	.param .b64 _Z7Brune_tddPdiPii_param_4,
	.param .b32 _Z7Brune_tddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<52>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd9, [_Z7Brune_tddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z7Brune_tddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z7Brune_tddPdiPii_param_2];
	mul.f64 	%fd1, %fd9, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd51, 0d0000000000000000;
	@%p1 bra 	BB71_6;

	neg.f64 	%fd2, %fd1;
	ld.f64 	%fd13, [%rd1];
	setp.geu.f64	%p2, %fd13, %fd2;
	@%p2 bra 	BB71_6;

	mov.f64 	%fd14, 0d4338000000000000;
	mov.f64 	%fd15, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd16, %fd2, %fd15, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd16;
	}
	mov.f64 	%fd17, 0dC338000000000000;
	add.rn.f64 	%fd18, %fd16, %fd17;
	mov.f64 	%fd19, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	mov.f64 	%fd21, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd22, %fd18, %fd21, %fd20;
	mov.f64 	%fd23, 0d3E928AF3FCA213EA;
	mov.f64 	%fd24, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F81111111122322;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FA55555555502A1;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	mov.f64 	%fd38, 0d3FC5555555555511;
	fma.rn.f64 	%fd39, %fd37, %fd22, %fd38;
	mov.f64 	%fd40, 0d3FE000000000000B;
	fma.rn.f64 	%fd41, %fd39, %fd22, %fd40;
	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd43, %fd41, %fd22, %fd42;
	fma.rn.f64 	%fd44, %fd43, %fd22, %fd42;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd44;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd50, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB71_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd45, 0d7FF0000000000000;
	sub.f64 	%fd46, %fd45, %fd1;
	selp.f64	%fd50, 0d0000000000000000, %fd46, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB71_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd47, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd48, {%r15, %r14};
	mul.f64 	%fd50, %fd47, %fd48;

BB71_5:
	mul.f64 	%fd49, %fd1, %fd9;
	mul.f64 	%fd51, %fd49, %fd50;

BB71_6:
	st.param.f64	[func_retval0+0], %fd51;
	ret;
}

	// .globl	_Z8Brune_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8Brune_omddPdiPii(
	.param .b64 _Z8Brune_omddPdiPii_param_0,
	.param .b64 _Z8Brune_omddPdiPii_param_1,
	.param .b64 _Z8Brune_omddPdiPii_param_2,
	.param .b32 _Z8Brune_omddPdiPii_param_3,
	.param .b64 _Z8Brune_omddPdiPii_param_4,
	.param .b32 _Z8Brune_omddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<52>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd11, [_Z8Brune_omddPdiPii_param_0];
	ld.param.f64 	%fd9, [_Z8Brune_omddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z8Brune_omddPdiPii_param_2];
	mul.f64 	%fd1, %fd11, %fd9;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd51, 0d0000000000000000;
	@%p1 bra 	BB72_6;

	neg.f64 	%fd2, %fd1;
	ld.f64 	%fd13, [%rd1];
	setp.geu.f64	%p2, %fd13, %fd2;
	@%p2 bra 	BB72_6;

	mov.f64 	%fd14, 0d4338000000000000;
	mov.f64 	%fd15, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd16, %fd2, %fd15, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd16;
	}
	mov.f64 	%fd17, 0dC338000000000000;
	add.rn.f64 	%fd18, %fd16, %fd17;
	mov.f64 	%fd19, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	mov.f64 	%fd21, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd22, %fd18, %fd21, %fd20;
	mov.f64 	%fd23, 0d3E928AF3FCA213EA;
	mov.f64 	%fd24, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F81111111122322;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FA55555555502A1;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	mov.f64 	%fd38, 0d3FC5555555555511;
	fma.rn.f64 	%fd39, %fd37, %fd22, %fd38;
	mov.f64 	%fd40, 0d3FE000000000000B;
	fma.rn.f64 	%fd41, %fd39, %fd22, %fd40;
	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd43, %fd41, %fd22, %fd42;
	fma.rn.f64 	%fd44, %fd43, %fd22, %fd42;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd44;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd50, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB72_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd45, 0d7FF0000000000000;
	sub.f64 	%fd46, %fd45, %fd1;
	selp.f64	%fd50, 0d0000000000000000, %fd46, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB72_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd47, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd48, {%r15, %r14};
	mul.f64 	%fd50, %fd47, %fd48;

BB72_5:
	mul.f64 	%fd49, %fd1, %fd9;
	mul.f64 	%fd51, %fd49, %fd50;

BB72_6:
	st.param.f64	[func_retval0+0], %fd51;
	ret;
}

	// .globl	_Z8Brune_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8Brune_ttddPdiPii(
	.param .b64 _Z8Brune_ttddPdiPii_param_0,
	.param .b64 _Z8Brune_ttddPdiPii_param_1,
	.param .b64 _Z8Brune_ttddPdiPii_param_2,
	.param .b32 _Z8Brune_ttddPdiPii_param_3,
	.param .b64 _Z8Brune_ttddPdiPii_param_4,
	.param .b32 _Z8Brune_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<55>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd9, [_Z8Brune_ttddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z8Brune_ttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z8Brune_ttddPdiPii_param_2];
	mul.f64 	%fd1, %fd9, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd54, 0d0000000000000000;
	@%p1 bra 	BB73_6;

	neg.f64 	%fd2, %fd1;
	ld.f64 	%fd13, [%rd1];
	setp.geu.f64	%p2, %fd13, %fd2;
	@%p2 bra 	BB73_6;

	mov.f64 	%fd14, 0d4338000000000000;
	mov.f64 	%fd15, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd16, %fd2, %fd15, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd16;
	}
	mov.f64 	%fd17, 0dC338000000000000;
	add.rn.f64 	%fd18, %fd16, %fd17;
	mov.f64 	%fd19, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	mov.f64 	%fd21, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd22, %fd18, %fd21, %fd20;
	mov.f64 	%fd23, 0d3E928AF3FCA213EA;
	mov.f64 	%fd24, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F81111111122322;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FA55555555502A1;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	mov.f64 	%fd38, 0d3FC5555555555511;
	fma.rn.f64 	%fd39, %fd37, %fd22, %fd38;
	mov.f64 	%fd40, 0d3FE000000000000B;
	fma.rn.f64 	%fd41, %fd39, %fd22, %fd40;
	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd43, %fd41, %fd22, %fd42;
	fma.rn.f64 	%fd44, %fd43, %fd22, %fd42;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd44;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd53, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB73_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd45, 0d7FF0000000000000;
	sub.f64 	%fd46, %fd45, %fd1;
	selp.f64	%fd53, 0d0000000000000000, %fd46, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB73_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd47, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd48, {%r15, %r14};
	mul.f64 	%fd53, %fd47, %fd48;

BB73_5:
	sub.f64 	%fd50, %fd42, %fd1;
	mul.f64 	%fd51, %fd9, %fd9;
	mul.f64 	%fd52, %fd51, %fd50;
	mul.f64 	%fd54, %fd52, %fd53;

BB73_6:
	st.param.f64	[func_retval0+0], %fd54;
	ret;
}

	// .globl	_Z9Brune_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z9Brune_tttddPdiPii(
	.param .b64 _Z9Brune_tttddPdiPii_param_0,
	.param .b64 _Z9Brune_tttddPdiPii_param_1,
	.param .b64 _Z9Brune_tttddPdiPii_param_2,
	.param .b32 _Z9Brune_tttddPdiPii_param_3,
	.param .b64 _Z9Brune_tttddPdiPii_param_4,
	.param .b32 _Z9Brune_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<56>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd9, [_Z9Brune_tttddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z9Brune_tttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z9Brune_tttddPdiPii_param_2];
	mul.f64 	%fd1, %fd9, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd55, 0d0000000000000000;
	@%p1 bra 	BB74_6;

	ld.f64 	%fd13, [%rd1];
	neg.f64 	%fd14, %fd13;
	setp.geu.f64	%p2, %fd1, %fd14;
	@%p2 bra 	BB74_6;

	add.f64 	%fd2, %fd1, 0dC000000000000000;
	neg.f64 	%fd15, %fd1;
	mov.f64 	%fd16, 0d4338000000000000;
	mov.f64 	%fd17, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd18, %fd15, %fd17, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd18;
	}
	mov.f64 	%fd19, 0dC338000000000000;
	add.rn.f64 	%fd20, %fd18, %fd19;
	mov.f64 	%fd21, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd22, %fd20, %fd21, %fd15;
	mov.f64 	%fd23, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd24, %fd20, %fd23, %fd22;
	mov.f64 	%fd25, 0d3E928AF3FCA213EA;
	mov.f64 	%fd26, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F81111111122322;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mov.f64 	%fd38, 0d3FA55555555502A1;
	fma.rn.f64 	%fd39, %fd37, %fd24, %fd38;
	mov.f64 	%fd40, 0d3FC5555555555511;
	fma.rn.f64 	%fd41, %fd39, %fd24, %fd40;
	mov.f64 	%fd42, 0d3FE000000000000B;
	fma.rn.f64 	%fd43, %fd41, %fd24, %fd42;
	mov.f64 	%fd44, 0d3FF0000000000000;
	fma.rn.f64 	%fd45, %fd43, %fd24, %fd44;
	fma.rn.f64 	%fd46, %fd45, %fd24, %fd44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd46;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd46;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd54, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd15;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB74_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd47, 0d7FF0000000000000;
	sub.f64 	%fd48, %fd47, %fd1;
	selp.f64	%fd54, 0d0000000000000000, %fd48, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB74_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd49, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd50, {%r15, %r14};
	mul.f64 	%fd54, %fd49, %fd50;

BB74_5:
	mul.f64 	%fd51, %fd2, %fd9;
	mul.f64 	%fd52, %fd51, %fd9;
	mul.f64 	%fd53, %fd52, %fd9;
	mul.f64 	%fd55, %fd53, %fd54;

BB74_6:
	st.param.f64	[func_retval0+0], %fd55;
	ret;
}

	// .globl	_Z10Brune_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Brune_omttddPdiPii(
	.param .b64 _Z10Brune_omttddPdiPii_param_0,
	.param .b64 _Z10Brune_omttddPdiPii_param_1,
	.param .b64 _Z10Brune_omttddPdiPii_param_2,
	.param .b32 _Z10Brune_omttddPdiPii_param_3,
	.param .b64 _Z10Brune_omttddPdiPii_param_4,
	.param .b32 _Z10Brune_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<55>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd9, [_Z10Brune_omttddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z10Brune_omttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z10Brune_omttddPdiPii_param_2];
	mul.f64 	%fd1, %fd9, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd54, 0d0000000000000000;
	@%p1 bra 	BB75_6;

	ld.f64 	%fd13, [%rd1];
	neg.f64 	%fd14, %fd13;
	setp.geu.f64	%p2, %fd1, %fd14;
	@%p2 bra 	BB75_6;

	fma.rn.f64 	%fd15, %fd1, 0dC010000000000000, 0d4000000000000000;
	fma.rn.f64 	%fd2, %fd1, %fd1, %fd15;
	neg.f64 	%fd16, %fd1;
	mov.f64 	%fd17, 0d4338000000000000;
	mov.f64 	%fd18, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd19, %fd16, %fd18, %fd17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd19;
	}
	mov.f64 	%fd20, 0dC338000000000000;
	add.rn.f64 	%fd21, %fd19, %fd20;
	mov.f64 	%fd22, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd23, %fd21, %fd22, %fd16;
	mov.f64 	%fd24, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd25, %fd21, %fd24, %fd23;
	mov.f64 	%fd26, 0d3E928AF3FCA213EA;
	mov.f64 	%fd27, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd28, %fd27, %fd25, %fd26;
	mov.f64 	%fd29, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd30, %fd28, %fd25, %fd29;
	mov.f64 	%fd31, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd32, %fd30, %fd25, %fd31;
	mov.f64 	%fd33, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd34, %fd32, %fd25, %fd33;
	mov.f64 	%fd35, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd36, %fd34, %fd25, %fd35;
	mov.f64 	%fd37, 0d3F81111111122322;
	fma.rn.f64 	%fd38, %fd36, %fd25, %fd37;
	mov.f64 	%fd39, 0d3FA55555555502A1;
	fma.rn.f64 	%fd40, %fd38, %fd25, %fd39;
	mov.f64 	%fd41, 0d3FC5555555555511;
	fma.rn.f64 	%fd42, %fd40, %fd25, %fd41;
	mov.f64 	%fd43, 0d3FE000000000000B;
	fma.rn.f64 	%fd44, %fd42, %fd25, %fd43;
	mov.f64 	%fd45, 0d3FF0000000000000;
	fma.rn.f64 	%fd46, %fd44, %fd25, %fd45;
	fma.rn.f64 	%fd47, %fd46, %fd25, %fd45;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd47;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd47;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd53, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd16;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB75_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd48, 0d7FF0000000000000;
	sub.f64 	%fd49, %fd48, %fd1;
	selp.f64	%fd53, 0d0000000000000000, %fd49, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB75_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd50, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd51, {%r15, %r14};
	mul.f64 	%fd53, %fd50, %fd51;

BB75_5:
	mul.f64 	%fd52, %fd2, %fd9;
	mul.f64 	%fd54, %fd52, %fd53;

BB75_6:
	st.param.f64	[func_retval0+0], %fd54;
	ret;
}

	// .globl	_Z6DBruneddPdiPii
.visible .func  (.param .b64 func_retval0) _Z6DBruneddPdiPii(
	.param .b64 _Z6DBruneddPdiPii_param_0,
	.param .b64 _Z6DBruneddPdiPii_param_1,
	.param .b64 _Z6DBruneddPdiPii_param_2,
	.param .b32 _Z6DBruneddPdiPii_param_3,
	.param .b64 _Z6DBruneddPdiPii_param_4,
	.param .b32 _Z6DBruneddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<53>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd8, [_Z6DBruneddPdiPii_param_0];
	ld.param.f64 	%fd10, [_Z6DBruneddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z6DBruneddPdiPii_param_2];
	mul.f64 	%fd1, %fd8, %fd10;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd52, 0d0000000000000000;
	@%p1 bra 	BB76_6;

	ld.f64 	%fd12, [%rd1];
	neg.f64 	%fd13, %fd12;
	setp.geu.f64	%p2, %fd1, %fd13;
	@%p2 bra 	BB76_6;

	neg.f64 	%fd14, %fd1;
	mov.f64 	%fd15, 0d4338000000000000;
	mov.f64 	%fd16, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd17, %fd14, %fd16, %fd15;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd17;
	}
	mov.f64 	%fd18, 0dC338000000000000;
	add.rn.f64 	%fd19, %fd17, %fd18;
	mov.f64 	%fd20, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd21, %fd19, %fd20, %fd14;
	mov.f64 	%fd22, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd23, %fd19, %fd22, %fd21;
	mov.f64 	%fd24, 0d3E928AF3FCA213EA;
	mov.f64 	%fd25, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd26, %fd25, %fd23, %fd24;
	mov.f64 	%fd27, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd28, %fd26, %fd23, %fd27;
	mov.f64 	%fd29, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd30, %fd28, %fd23, %fd29;
	mov.f64 	%fd31, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd32, %fd30, %fd23, %fd31;
	mov.f64 	%fd33, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd34, %fd32, %fd23, %fd33;
	mov.f64 	%fd35, 0d3F81111111122322;
	fma.rn.f64 	%fd36, %fd34, %fd23, %fd35;
	mov.f64 	%fd37, 0d3FA55555555502A1;
	fma.rn.f64 	%fd38, %fd36, %fd23, %fd37;
	mov.f64 	%fd39, 0d3FC5555555555511;
	fma.rn.f64 	%fd40, %fd38, %fd23, %fd39;
	mov.f64 	%fd41, 0d3FE000000000000B;
	fma.rn.f64 	%fd42, %fd40, %fd23, %fd41;
	mov.f64 	%fd43, 0d3FF0000000000000;
	fma.rn.f64 	%fd44, %fd42, %fd23, %fd43;
	fma.rn.f64 	%fd45, %fd44, %fd23, %fd43;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd45;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd51, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd14;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB76_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd46, 0d7FF0000000000000;
	sub.f64 	%fd47, %fd46, %fd1;
	selp.f64	%fd51, 0d0000000000000000, %fd47, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB76_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd48, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd49, {%r15, %r14};
	mul.f64 	%fd51, %fd48, %fd49;

BB76_5:
	mul.f64 	%fd50, %fd1, %fd8;
	mul.f64 	%fd52, %fd50, %fd51;

BB76_6:
	st.param.f64	[func_retval0+0], %fd52;
	ret;
}

	// .globl	_Z8DBrune_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8DBrune_tddPdiPii(
	.param .b64 _Z8DBrune_tddPdiPii_param_0,
	.param .b64 _Z8DBrune_tddPdiPii_param_1,
	.param .b64 _Z8DBrune_tddPdiPii_param_2,
	.param .b32 _Z8DBrune_tddPdiPii_param_3,
	.param .b64 _Z8DBrune_tddPdiPii_param_4,
	.param .b32 _Z8DBrune_tddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<55>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd9, [_Z8DBrune_tddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z8DBrune_tddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z8DBrune_tddPdiPii_param_2];
	mul.f64 	%fd1, %fd9, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd54, 0d0000000000000000;
	@%p1 bra 	BB77_6;

	neg.f64 	%fd2, %fd1;
	ld.f64 	%fd13, [%rd1];
	setp.geu.f64	%p2, %fd13, %fd2;
	@%p2 bra 	BB77_6;

	mov.f64 	%fd14, 0d4338000000000000;
	mov.f64 	%fd15, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd16, %fd2, %fd15, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd16;
	}
	mov.f64 	%fd17, 0dC338000000000000;
	add.rn.f64 	%fd18, %fd16, %fd17;
	mov.f64 	%fd19, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	mov.f64 	%fd21, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd22, %fd18, %fd21, %fd20;
	mov.f64 	%fd23, 0d3E928AF3FCA213EA;
	mov.f64 	%fd24, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F81111111122322;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FA55555555502A1;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	mov.f64 	%fd38, 0d3FC5555555555511;
	fma.rn.f64 	%fd39, %fd37, %fd22, %fd38;
	mov.f64 	%fd40, 0d3FE000000000000B;
	fma.rn.f64 	%fd41, %fd39, %fd22, %fd40;
	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd43, %fd41, %fd22, %fd42;
	fma.rn.f64 	%fd44, %fd43, %fd22, %fd42;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd44;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd53, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB77_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd45, 0d7FF0000000000000;
	sub.f64 	%fd46, %fd45, %fd1;
	selp.f64	%fd53, 0d0000000000000000, %fd46, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB77_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd47, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd48, {%r15, %r14};
	mul.f64 	%fd53, %fd47, %fd48;

BB77_5:
	sub.f64 	%fd50, %fd42, %fd1;
	mul.f64 	%fd51, %fd9, %fd9;
	mul.f64 	%fd52, %fd51, %fd50;
	mul.f64 	%fd54, %fd52, %fd53;

BB77_6:
	st.param.f64	[func_retval0+0], %fd54;
	ret;
}

	// .globl	_Z9DBrune_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z9DBrune_omddPdiPii(
	.param .b64 _Z9DBrune_omddPdiPii_param_0,
	.param .b64 _Z9DBrune_omddPdiPii_param_1,
	.param .b64 _Z9DBrune_omddPdiPii_param_2,
	.param .b32 _Z9DBrune_omddPdiPii_param_3,
	.param .b64 _Z9DBrune_omddPdiPii_param_4,
	.param .b32 _Z9DBrune_omddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<54>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd10, [_Z9DBrune_omddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z9DBrune_omddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z9DBrune_omddPdiPii_param_2];
	mul.f64 	%fd1, %fd10, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd53, 0d0000000000000000;
	@%p1 bra 	BB78_6;

	neg.f64 	%fd2, %fd1;
	ld.f64 	%fd13, [%rd1];
	setp.geu.f64	%p2, %fd13, %fd2;
	@%p2 bra 	BB78_6;

	mov.f64 	%fd14, 0d4338000000000000;
	mov.f64 	%fd15, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd16, %fd2, %fd15, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd16;
	}
	mov.f64 	%fd17, 0dC338000000000000;
	add.rn.f64 	%fd18, %fd16, %fd17;
	mov.f64 	%fd19, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd20, %fd18, %fd19, %fd2;
	mov.f64 	%fd21, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd22, %fd18, %fd21, %fd20;
	mov.f64 	%fd23, 0d3E928AF3FCA213EA;
	mov.f64 	%fd24, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F81111111122322;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FA55555555502A1;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	mov.f64 	%fd38, 0d3FC5555555555511;
	fma.rn.f64 	%fd39, %fd37, %fd22, %fd38;
	mov.f64 	%fd40, 0d3FE000000000000B;
	fma.rn.f64 	%fd41, %fd39, %fd22, %fd40;
	mov.f64 	%fd42, 0d3FF0000000000000;
	fma.rn.f64 	%fd43, %fd41, %fd22, %fd42;
	fma.rn.f64 	%fd44, %fd43, %fd22, %fd42;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd44;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd52, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB78_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd45, 0d7FF0000000000000;
	sub.f64 	%fd46, %fd45, %fd1;
	selp.f64	%fd52, 0d0000000000000000, %fd46, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB78_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd47, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd48, {%r15, %r14};
	mul.f64 	%fd52, %fd47, %fd48;

BB78_5:
	mov.f64 	%fd49, 0d4000000000000000;
	sub.f64 	%fd50, %fd49, %fd1;
	mul.f64 	%fd51, %fd1, %fd50;
	mul.f64 	%fd53, %fd51, %fd52;

BB78_6:
	st.param.f64	[func_retval0+0], %fd53;
	ret;
}

	// .globl	_Z9DBrune_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z9DBrune_ttddPdiPii(
	.param .b64 _Z9DBrune_ttddPdiPii_param_0,
	.param .b64 _Z9DBrune_ttddPdiPii_param_1,
	.param .b64 _Z9DBrune_ttddPdiPii_param_2,
	.param .b32 _Z9DBrune_ttddPdiPii_param_3,
	.param .b64 _Z9DBrune_ttddPdiPii_param_4,
	.param .b32 _Z9DBrune_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<56>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd9, [_Z9DBrune_ttddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z9DBrune_ttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z9DBrune_ttddPdiPii_param_2];
	mul.f64 	%fd1, %fd9, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd55, 0d0000000000000000;
	@%p1 bra 	BB79_6;

	ld.f64 	%fd13, [%rd1];
	neg.f64 	%fd14, %fd13;
	setp.geu.f64	%p2, %fd1, %fd14;
	@%p2 bra 	BB79_6;

	add.f64 	%fd2, %fd1, 0dC000000000000000;
	neg.f64 	%fd15, %fd1;
	mov.f64 	%fd16, 0d4338000000000000;
	mov.f64 	%fd17, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd18, %fd15, %fd17, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd18;
	}
	mov.f64 	%fd19, 0dC338000000000000;
	add.rn.f64 	%fd20, %fd18, %fd19;
	mov.f64 	%fd21, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd22, %fd20, %fd21, %fd15;
	mov.f64 	%fd23, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd24, %fd20, %fd23, %fd22;
	mov.f64 	%fd25, 0d3E928AF3FCA213EA;
	mov.f64 	%fd26, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F81111111122322;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mov.f64 	%fd38, 0d3FA55555555502A1;
	fma.rn.f64 	%fd39, %fd37, %fd24, %fd38;
	mov.f64 	%fd40, 0d3FC5555555555511;
	fma.rn.f64 	%fd41, %fd39, %fd24, %fd40;
	mov.f64 	%fd42, 0d3FE000000000000B;
	fma.rn.f64 	%fd43, %fd41, %fd24, %fd42;
	mov.f64 	%fd44, 0d3FF0000000000000;
	fma.rn.f64 	%fd45, %fd43, %fd24, %fd44;
	fma.rn.f64 	%fd46, %fd45, %fd24, %fd44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd46;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd46;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd54, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd15;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB79_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd47, 0d7FF0000000000000;
	sub.f64 	%fd48, %fd47, %fd1;
	selp.f64	%fd54, 0d0000000000000000, %fd48, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB79_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd49, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd50, {%r15, %r14};
	mul.f64 	%fd54, %fd49, %fd50;

BB79_5:
	mul.f64 	%fd51, %fd2, %fd9;
	mul.f64 	%fd52, %fd51, %fd9;
	mul.f64 	%fd53, %fd52, %fd9;
	mul.f64 	%fd55, %fd53, %fd54;

BB79_6:
	st.param.f64	[func_retval0+0], %fd55;
	ret;
}

	// .globl	_Z10DBrune_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10DBrune_tttddPdiPii(
	.param .b64 _Z10DBrune_tttddPdiPii_param_0,
	.param .b64 _Z10DBrune_tttddPdiPii_param_1,
	.param .b64 _Z10DBrune_tttddPdiPii_param_2,
	.param .b32 _Z10DBrune_tttddPdiPii_param_3,
	.param .b64 _Z10DBrune_tttddPdiPii_param_4,
	.param .b32 _Z10DBrune_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<58>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd8, [_Z10DBrune_tttddPdiPii_param_0];
	ld.param.f64 	%fd10, [_Z10DBrune_tttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z10DBrune_tttddPdiPii_param_2];
	mul.f64 	%fd1, %fd8, %fd10;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd57, 0d0000000000000000;
	@%p1 bra 	BB80_6;

	ld.f64 	%fd12, [%rd1];
	neg.f64 	%fd13, %fd12;
	setp.geu.f64	%p2, %fd1, %fd13;
	@%p2 bra 	BB80_6;

	neg.f64 	%fd14, %fd1;
	mov.f64 	%fd15, 0d4338000000000000;
	mov.f64 	%fd16, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd17, %fd14, %fd16, %fd15;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd17;
	}
	mov.f64 	%fd18, 0dC338000000000000;
	add.rn.f64 	%fd19, %fd17, %fd18;
	mov.f64 	%fd20, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd21, %fd19, %fd20, %fd14;
	mov.f64 	%fd22, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd23, %fd19, %fd22, %fd21;
	mov.f64 	%fd24, 0d3E928AF3FCA213EA;
	mov.f64 	%fd25, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd26, %fd25, %fd23, %fd24;
	mov.f64 	%fd27, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd28, %fd26, %fd23, %fd27;
	mov.f64 	%fd29, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd30, %fd28, %fd23, %fd29;
	mov.f64 	%fd31, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd32, %fd30, %fd23, %fd31;
	mov.f64 	%fd33, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd34, %fd32, %fd23, %fd33;
	mov.f64 	%fd35, 0d3F81111111122322;
	fma.rn.f64 	%fd36, %fd34, %fd23, %fd35;
	mov.f64 	%fd37, 0d3FA55555555502A1;
	fma.rn.f64 	%fd38, %fd36, %fd23, %fd37;
	mov.f64 	%fd39, 0d3FC5555555555511;
	fma.rn.f64 	%fd40, %fd38, %fd23, %fd39;
	mov.f64 	%fd41, 0d3FE000000000000B;
	fma.rn.f64 	%fd42, %fd40, %fd23, %fd41;
	mov.f64 	%fd43, 0d3FF0000000000000;
	fma.rn.f64 	%fd44, %fd42, %fd23, %fd43;
	fma.rn.f64 	%fd45, %fd44, %fd23, %fd43;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd45;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd56, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd14;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB80_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd46, 0d7FF0000000000000;
	sub.f64 	%fd47, %fd46, %fd1;
	selp.f64	%fd56, 0d0000000000000000, %fd47, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB80_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd48, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd49, {%r15, %r14};
	mul.f64 	%fd56, %fd48, %fd49;

BB80_5:
	mov.f64 	%fd50, 0d4008000000000000;
	sub.f64 	%fd51, %fd50, %fd1;
	mul.f64 	%fd52, %fd51, %fd8;
	mul.f64 	%fd53, %fd52, %fd8;
	mul.f64 	%fd54, %fd53, %fd8;
	mul.f64 	%fd55, %fd54, %fd8;
	mul.f64 	%fd57, %fd55, %fd56;

BB80_6:
	st.param.f64	[func_retval0+0], %fd57;
	ret;
}

	// .globl	_Z11DBrune_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11DBrune_omttddPdiPii(
	.param .b64 _Z11DBrune_omttddPdiPii_param_0,
	.param .b64 _Z11DBrune_omttddPdiPii_param_1,
	.param .b64 _Z11DBrune_omttddPdiPii_param_2,
	.param .b32 _Z11DBrune_omttddPdiPii_param_3,
	.param .b64 _Z11DBrune_omttddPdiPii_param_4,
	.param .b32 _Z11DBrune_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<57>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd9, [_Z11DBrune_omttddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z11DBrune_omttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z11DBrune_omttddPdiPii_param_2];
	mul.f64 	%fd1, %fd9, %fd11;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd56, 0d0000000000000000;
	@%p1 bra 	BB81_6;

	ld.f64 	%fd13, [%rd1];
	neg.f64 	%fd14, %fd13;
	setp.geu.f64	%p2, %fd1, %fd14;
	@%p2 bra 	BB81_6;

	fma.rn.f64 	%fd2, %fd1, 0d4018000000000000, 0dC018000000000000;
	neg.f64 	%fd15, %fd1;
	mov.f64 	%fd16, 0d4338000000000000;
	mov.f64 	%fd17, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd18, %fd15, %fd17, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd18;
	}
	mov.f64 	%fd19, 0dC338000000000000;
	add.rn.f64 	%fd20, %fd18, %fd19;
	mov.f64 	%fd21, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd22, %fd20, %fd21, %fd15;
	mov.f64 	%fd23, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd24, %fd20, %fd23, %fd22;
	mov.f64 	%fd25, 0d3E928AF3FCA213EA;
	mov.f64 	%fd26, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F81111111122322;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mov.f64 	%fd38, 0d3FA55555555502A1;
	fma.rn.f64 	%fd39, %fd37, %fd24, %fd38;
	mov.f64 	%fd40, 0d3FC5555555555511;
	fma.rn.f64 	%fd41, %fd39, %fd24, %fd40;
	mov.f64 	%fd42, 0d3FE000000000000B;
	fma.rn.f64 	%fd43, %fd41, %fd24, %fd42;
	mov.f64 	%fd44, 0d3FF0000000000000;
	fma.rn.f64 	%fd45, %fd43, %fd24, %fd44;
	fma.rn.f64 	%fd46, %fd45, %fd24, %fd44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd46;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd46;
	}
	shl.b32 	%r4, %r1, 20;
	add.s32 	%r5, %r3, %r4;
	mov.b64 	%fd55, {%r2, %r5};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd15;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB81_5;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd47, 0d7FF0000000000000;
	sub.f64 	%fd48, %fd47, %fd1;
	selp.f64	%fd55, 0d0000000000000000, %fd48, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB81_5;

	shr.u32 	%r7, %r1, 31;
	add.s32 	%r8, %r1, %r7;
	shr.s32 	%r9, %r8, 1;
	shl.b32 	%r10, %r9, 20;
	add.s32 	%r11, %r10, %r3;
	mov.b64 	%fd49, {%r2, %r11};
	sub.s32 	%r12, %r1, %r9;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, 1072693248;
	mov.u32 	%r15, 0;
	mov.b64 	%fd50, {%r15, %r14};
	mul.f64 	%fd55, %fd49, %fd50;

BB81_5:
	mul.f64 	%fd51, %fd1, %fd1;
	sub.f64 	%fd52, %fd2, %fd51;
	mul.f64 	%fd53, %fd52, %fd9;
	mul.f64 	%fd54, %fd53, %fd9;
	mul.f64 	%fd56, %fd54, %fd55;

BB81_6:
	st.param.f64	[func_retval0+0], %fd56;
	ret;
}

	// .globl	_Z13BruneSmoothedddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13BruneSmoothedddPdiPii(
	.param .b64 _Z13BruneSmoothedddPdiPii_param_0,
	.param .b64 _Z13BruneSmoothedddPdiPii_param_1,
	.param .b64 _Z13BruneSmoothedddPdiPii_param_2,
	.param .b32 _Z13BruneSmoothedddPdiPii_param_3,
	.param .b64 _Z13BruneSmoothedddPdiPii_param_4,
	.param .b32 _Z13BruneSmoothedddPdiPii_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<112>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd15, [_Z13BruneSmoothedddPdiPii_param_0];
	ld.param.f64 	%fd16, [_Z13BruneSmoothedddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z13BruneSmoothedddPdiPii_param_2];
	mul.f64 	%fd1, %fd15, %fd16;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd111, 0d0000000000000000;
	@%p1 bra 	BB82_11;

	setp.lt.f64	%p2, %fd1, 0d40027AE147AE147B;
	neg.f64 	%fd2, %fd1;
	@%p2 bra 	BB82_7;
	bra.uni 	BB82_2;

BB82_7:
	mov.f64 	%fd57, 0d4338000000000000;
	mov.f64 	%fd58, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd59, %fd2, %fd58, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd59;
	}
	mov.f64 	%fd60, 0dC338000000000000;
	add.rn.f64 	%fd61, %fd59, %fd60;
	mov.f64 	%fd62, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd63, %fd61, %fd62, %fd2;
	mov.f64 	%fd64, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd65, %fd61, %fd64, %fd63;
	mov.f64 	%fd66, 0d3E928AF3FCA213EA;
	mov.f64 	%fd67, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd68, %fd67, %fd65, %fd66;
	mov.f64 	%fd69, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd70, %fd68, %fd65, %fd69;
	mov.f64 	%fd71, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd72, %fd70, %fd65, %fd71;
	mov.f64 	%fd73, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd74, %fd72, %fd65, %fd73;
	mov.f64 	%fd75, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd76, %fd74, %fd65, %fd75;
	mov.f64 	%fd77, 0d3F81111111122322;
	fma.rn.f64 	%fd78, %fd76, %fd65, %fd77;
	mov.f64 	%fd79, 0d3FA55555555502A1;
	fma.rn.f64 	%fd80, %fd78, %fd65, %fd79;
	mov.f64 	%fd81, 0d3FC5555555555511;
	fma.rn.f64 	%fd82, %fd80, %fd65, %fd81;
	mov.f64 	%fd83, 0d3FE000000000000B;
	fma.rn.f64 	%fd84, %fd82, %fd65, %fd83;
	mov.f64 	%fd85, 0d3FF0000000000000;
	fma.rn.f64 	%fd86, %fd84, %fd65, %fd85;
	fma.rn.f64 	%fd87, %fd86, %fd65, %fd85;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd87;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd87;
	}
	shl.b32 	%r19, %r4, 20;
	add.s32 	%r20, %r6, %r19;
	mov.b64 	%fd110, {%r5, %r20};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd2;
	}
	mov.b32 	 %f4, %r21;
	abs.f32 	%f2, %f4;
	setp.lt.f32	%p7, %f2, 0f4086232B;
	@%p7 bra 	BB82_10;

	setp.gt.f64	%p8, %fd1, 0d8000000000000000;
	mov.f64 	%fd88, 0d7FF0000000000000;
	sub.f64 	%fd89, %fd88, %fd1;
	selp.f64	%fd110, 0d0000000000000000, %fd89, %p8;
	setp.geu.f32	%p9, %f2, 0f40874800;
	@%p9 bra 	BB82_10;

	shr.u32 	%r22, %r4, 31;
	add.s32 	%r23, %r4, %r22;
	shr.s32 	%r24, %r23, 1;
	shl.b32 	%r25, %r24, 20;
	add.s32 	%r26, %r25, %r6;
	mov.b64 	%fd90, {%r5, %r26};
	sub.s32 	%r27, %r4, %r24;
	shl.b32 	%r28, %r27, 20;
	add.s32 	%r29, %r28, 1072693248;
	mov.u32 	%r30, 0;
	mov.b64 	%fd91, {%r30, %r29};
	mul.f64 	%fd110, %fd90, %fd91;

BB82_10:
	mul.f64 	%fd92, %fd1, 0d3FE0000000000000;
	add.f64 	%fd93, %fd1, 0d3FF0000000000000;
	fma.rn.f64 	%fd94, %fd1, %fd92, %fd93;
	mul.f64 	%fd95, %fd1, 0dBFE4C77B03531DEC;
	mul.f64 	%fd96, %fd1, %fd95;
	fma.rn.f64 	%fd97, %fd1, %fd96, %fd94;
	mul.f64 	%fd98, %fd1, 0d3FD1FD9C5FF82BA3;
	mul.f64 	%fd99, %fd1, %fd98;
	mul.f64 	%fd100, %fd1, %fd99;
	fma.rn.f64 	%fd101, %fd1, %fd100, %fd97;
	mul.f64 	%fd102, %fd1, 0dBFA4C4B8F3C6331D;
	mul.f64 	%fd103, %fd1, %fd102;
	mul.f64 	%fd104, %fd1, %fd103;
	mul.f64 	%fd105, %fd1, %fd104;
	fma.rn.f64 	%fd106, %fd1, %fd105, %fd101;
	mul.f64 	%fd107, %fd106, %fd110;
	sub.f64 	%fd111, %fd85, %fd107;
	bra.uni 	BB82_11;

BB82_2:
	ld.f64 	%fd18, [%rd1];
	mov.f64 	%fd111, 0d3FF0000000000000;
	setp.geu.f64	%p3, %fd18, %fd2;
	@%p3 bra 	BB82_11;

	mov.f64 	%fd19, 0d4338000000000000;
	mov.f64 	%fd20, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd21, %fd2, %fd20, %fd19;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd21;
	}
	mov.f64 	%fd22, 0dC338000000000000;
	add.rn.f64 	%fd23, %fd21, %fd22;
	mov.f64 	%fd24, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd25, %fd23, %fd24, %fd2;
	mov.f64 	%fd26, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd27, %fd23, %fd26, %fd25;
	mov.f64 	%fd28, 0d3E928AF3FCA213EA;
	mov.f64 	%fd29, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd30, %fd29, %fd27, %fd28;
	mov.f64 	%fd31, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd32, %fd30, %fd27, %fd31;
	mov.f64 	%fd33, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd34, %fd32, %fd27, %fd33;
	mov.f64 	%fd35, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd36, %fd34, %fd27, %fd35;
	mov.f64 	%fd37, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd38, %fd36, %fd27, %fd37;
	mov.f64 	%fd39, 0d3F81111111122322;
	fma.rn.f64 	%fd40, %fd38, %fd27, %fd39;
	mov.f64 	%fd41, 0d3FA55555555502A1;
	fma.rn.f64 	%fd42, %fd40, %fd27, %fd41;
	mov.f64 	%fd43, 0d3FC5555555555511;
	fma.rn.f64 	%fd44, %fd42, %fd27, %fd43;
	mov.f64 	%fd45, 0d3FE000000000000B;
	fma.rn.f64 	%fd46, %fd44, %fd27, %fd45;
	mov.f64 	%fd47, 0d3FF0000000000000;
	fma.rn.f64 	%fd48, %fd46, %fd27, %fd47;
	fma.rn.f64 	%fd49, %fd48, %fd27, %fd47;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd49;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd49;
	}
	shl.b32 	%r7, %r1, 20;
	add.s32 	%r8, %r3, %r7;
	mov.b64 	%fd109, {%r2, %r8};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd2;
	}
	mov.b32 	 %f3, %r9;
	abs.f32 	%f1, %f3;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB82_6;

	setp.gt.f64	%p5, %fd1, 0d8000000000000000;
	mov.f64 	%fd50, 0d7FF0000000000000;
	sub.f64 	%fd51, %fd50, %fd1;
	selp.f64	%fd109, 0d0000000000000000, %fd51, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB82_6;

	shr.u32 	%r10, %r1, 31;
	add.s32 	%r11, %r1, %r10;
	shr.s32 	%r12, %r11, 1;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, %r3;
	mov.b64 	%fd52, {%r2, %r14};
	sub.s32 	%r15, %r1, %r12;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, 1072693248;
	mov.u32 	%r18, 0;
	mov.b64 	%fd53, {%r18, %r17};
	mul.f64 	%fd109, %fd52, %fd53;

BB82_6:
	add.f64 	%fd54, %fd1, 0d3FF0000000000000;
	mul.f64 	%fd55, %fd54, %fd109;
	sub.f64 	%fd111, %fd47, %fd55;

BB82_11:
	st.param.f64	[func_retval0+0], %fd111;
	ret;
}

	// .globl	_Z15BruneSmoothed_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z15BruneSmoothed_tddPdiPii(
	.param .b64 _Z15BruneSmoothed_tddPdiPii_param_0,
	.param .b64 _Z15BruneSmoothed_tddPdiPii_param_1,
	.param .b64 _Z15BruneSmoothed_tddPdiPii_param_2,
	.param .b32 _Z15BruneSmoothed_tddPdiPii_param_3,
	.param .b64 _Z15BruneSmoothed_tddPdiPii_param_4,
	.param .b32 _Z15BruneSmoothed_tddPdiPii_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<108>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd14, [_Z15BruneSmoothed_tddPdiPii_param_0];
	ld.param.f64 	%fd16, [_Z15BruneSmoothed_tddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z15BruneSmoothed_tddPdiPii_param_2];
	mul.f64 	%fd1, %fd14, %fd16;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd107, 0d0000000000000000;
	@%p1 bra 	BB83_11;

	setp.lt.f64	%p2, %fd1, 0d40027AE147AE147B;
	neg.f64 	%fd2, %fd1;
	@%p2 bra 	BB83_7;
	bra.uni 	BB83_2;

BB83_7:
	mov.f64 	%fd55, 0d4338000000000000;
	mov.f64 	%fd56, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd57, %fd2, %fd56, %fd55;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd57;
	}
	mov.f64 	%fd58, 0dC338000000000000;
	add.rn.f64 	%fd59, %fd57, %fd58;
	mov.f64 	%fd60, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd61, %fd59, %fd60, %fd2;
	mov.f64 	%fd62, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd63, %fd59, %fd62, %fd61;
	mov.f64 	%fd64, 0d3E928AF3FCA213EA;
	mov.f64 	%fd65, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd66, %fd65, %fd63, %fd64;
	mov.f64 	%fd67, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd68, %fd66, %fd63, %fd67;
	mov.f64 	%fd69, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd70, %fd68, %fd63, %fd69;
	mov.f64 	%fd71, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd72, %fd70, %fd63, %fd71;
	mov.f64 	%fd73, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd74, %fd72, %fd63, %fd73;
	mov.f64 	%fd75, 0d3F81111111122322;
	fma.rn.f64 	%fd76, %fd74, %fd63, %fd75;
	mov.f64 	%fd77, 0d3FA55555555502A1;
	fma.rn.f64 	%fd78, %fd76, %fd63, %fd77;
	mov.f64 	%fd79, 0d3FC5555555555511;
	fma.rn.f64 	%fd80, %fd78, %fd63, %fd79;
	mov.f64 	%fd81, 0d3FE000000000000B;
	fma.rn.f64 	%fd82, %fd80, %fd63, %fd81;
	mov.f64 	%fd83, 0d3FF0000000000000;
	fma.rn.f64 	%fd84, %fd82, %fd63, %fd83;
	fma.rn.f64 	%fd85, %fd84, %fd63, %fd83;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd85;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd85;
	}
	shl.b32 	%r19, %r4, 20;
	add.s32 	%r20, %r6, %r19;
	mov.b64 	%fd106, {%r5, %r20};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd2;
	}
	mov.b32 	 %f4, %r21;
	abs.f32 	%f2, %f4;
	setp.lt.f32	%p7, %f2, 0f4086232B;
	@%p7 bra 	BB83_10;

	setp.gt.f64	%p8, %fd1, 0d8000000000000000;
	mov.f64 	%fd86, 0d7FF0000000000000;
	sub.f64 	%fd87, %fd86, %fd1;
	selp.f64	%fd106, 0d0000000000000000, %fd87, %p8;
	setp.geu.f32	%p9, %f2, 0f40874800;
	@%p9 bra 	BB83_10;

	shr.u32 	%r22, %r4, 31;
	add.s32 	%r23, %r4, %r22;
	shr.s32 	%r24, %r23, 1;
	shl.b32 	%r25, %r24, 20;
	add.s32 	%r26, %r25, %r6;
	mov.b64 	%fd88, {%r5, %r26};
	sub.s32 	%r27, %r4, %r24;
	shl.b32 	%r28, %r27, 20;
	add.s32 	%r29, %r28, 1072693248;
	mov.u32 	%r30, 0;
	mov.b64 	%fd89, {%r30, %r29};
	mul.f64 	%fd106, %fd88, %fd89;

BB83_10:
	mul.f64 	%fd90, %fd1, 0d4003959C427E5671;
	mul.f64 	%fd91, %fd1, 0dBFFC6159E1A1BA99;
	mul.f64 	%fd92, %fd1, %fd91;
	mul.f64 	%fd93, %fd1, %fd92;
	fma.rn.f64 	%fd94, %fd1, %fd90, %fd93;
	mul.f64 	%fd95, %fd1, 0d3FDEF88FF8540B95;
	mul.f64 	%fd96, %fd1, %fd95;
	mul.f64 	%fd97, %fd1, %fd96;
	fma.rn.f64 	%fd98, %fd1, %fd97, %fd94;
	mul.f64 	%fd99, %fd1, 0dBFA4C4B8F3C6331D;
	mul.f64 	%fd100, %fd1, %fd99;
	mul.f64 	%fd101, %fd1, %fd100;
	mul.f64 	%fd102, %fd1, %fd101;
	fma.rn.f64 	%fd103, %fd1, %fd102, %fd98;
	mul.f64 	%fd104, %fd106, %fd14;
	mul.f64 	%fd107, %fd103, %fd104;
	bra.uni 	BB83_11;

BB83_2:
	ld.f64 	%fd18, [%rd1];
	setp.geu.f64	%p3, %fd18, %fd2;
	@%p3 bra 	BB83_11;

	mov.f64 	%fd19, 0d4338000000000000;
	mov.f64 	%fd20, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd21, %fd2, %fd20, %fd19;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd21;
	}
	mov.f64 	%fd22, 0dC338000000000000;
	add.rn.f64 	%fd23, %fd21, %fd22;
	mov.f64 	%fd24, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd25, %fd23, %fd24, %fd2;
	mov.f64 	%fd26, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd27, %fd23, %fd26, %fd25;
	mov.f64 	%fd28, 0d3E928AF3FCA213EA;
	mov.f64 	%fd29, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd30, %fd29, %fd27, %fd28;
	mov.f64 	%fd31, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd32, %fd30, %fd27, %fd31;
	mov.f64 	%fd33, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd34, %fd32, %fd27, %fd33;
	mov.f64 	%fd35, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd36, %fd34, %fd27, %fd35;
	mov.f64 	%fd37, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd38, %fd36, %fd27, %fd37;
	mov.f64 	%fd39, 0d3F81111111122322;
	fma.rn.f64 	%fd40, %fd38, %fd27, %fd39;
	mov.f64 	%fd41, 0d3FA55555555502A1;
	fma.rn.f64 	%fd42, %fd40, %fd27, %fd41;
	mov.f64 	%fd43, 0d3FC5555555555511;
	fma.rn.f64 	%fd44, %fd42, %fd27, %fd43;
	mov.f64 	%fd45, 0d3FE000000000000B;
	fma.rn.f64 	%fd46, %fd44, %fd27, %fd45;
	mov.f64 	%fd47, 0d3FF0000000000000;
	fma.rn.f64 	%fd48, %fd46, %fd27, %fd47;
	fma.rn.f64 	%fd49, %fd48, %fd27, %fd47;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd49;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd49;
	}
	shl.b32 	%r7, %r1, 20;
	add.s32 	%r8, %r3, %r7;
	mov.b64 	%fd105, {%r2, %r8};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd2;
	}
	mov.b32 	 %f3, %r9;
	abs.f32 	%f1, %f3;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB83_6;

	setp.gt.f64	%p5, %fd1, 0d8000000000000000;
	mov.f64 	%fd50, 0d7FF0000000000000;
	sub.f64 	%fd51, %fd50, %fd1;
	selp.f64	%fd105, 0d0000000000000000, %fd51, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB83_6;

	shr.u32 	%r10, %r1, 31;
	add.s32 	%r11, %r1, %r10;
	shr.s32 	%r12, %r11, 1;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, %r3;
	mov.b64 	%fd52, {%r2, %r14};
	sub.s32 	%r15, %r1, %r12;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, 1072693248;
	mov.u32 	%r18, 0;
	mov.b64 	%fd53, {%r18, %r17};
	mul.f64 	%fd105, %fd52, %fd53;

BB83_6:
	mul.f64 	%fd54, %fd1, %fd14;
	mul.f64 	%fd107, %fd54, %fd105;

BB83_11:
	st.param.f64	[func_retval0+0], %fd107;
	ret;
}

	// .globl	_Z16BruneSmoothed_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16BruneSmoothed_omddPdiPii(
	.param .b64 _Z16BruneSmoothed_omddPdiPii_param_0,
	.param .b64 _Z16BruneSmoothed_omddPdiPii_param_1,
	.param .b64 _Z16BruneSmoothed_omddPdiPii_param_2,
	.param .b32 _Z16BruneSmoothed_omddPdiPii_param_3,
	.param .b64 _Z16BruneSmoothed_omddPdiPii_param_4,
	.param .b32 _Z16BruneSmoothed_omddPdiPii_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<108>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd16, [_Z16BruneSmoothed_omddPdiPii_param_0];
	ld.param.f64 	%fd14, [_Z16BruneSmoothed_omddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z16BruneSmoothed_omddPdiPii_param_2];
	mul.f64 	%fd1, %fd16, %fd14;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd107, 0d0000000000000000;
	@%p1 bra 	BB84_11;

	setp.lt.f64	%p2, %fd1, 0d40027AE147AE147B;
	neg.f64 	%fd2, %fd1;
	@%p2 bra 	BB84_7;
	bra.uni 	BB84_2;

BB84_7:
	mov.f64 	%fd55, 0d4338000000000000;
	mov.f64 	%fd56, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd57, %fd2, %fd56, %fd55;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd57;
	}
	mov.f64 	%fd58, 0dC338000000000000;
	add.rn.f64 	%fd59, %fd57, %fd58;
	mov.f64 	%fd60, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd61, %fd59, %fd60, %fd2;
	mov.f64 	%fd62, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd63, %fd59, %fd62, %fd61;
	mov.f64 	%fd64, 0d3E928AF3FCA213EA;
	mov.f64 	%fd65, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd66, %fd65, %fd63, %fd64;
	mov.f64 	%fd67, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd68, %fd66, %fd63, %fd67;
	mov.f64 	%fd69, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd70, %fd68, %fd63, %fd69;
	mov.f64 	%fd71, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd72, %fd70, %fd63, %fd71;
	mov.f64 	%fd73, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd74, %fd72, %fd63, %fd73;
	mov.f64 	%fd75, 0d3F81111111122322;
	fma.rn.f64 	%fd76, %fd74, %fd63, %fd75;
	mov.f64 	%fd77, 0d3FA55555555502A1;
	fma.rn.f64 	%fd78, %fd76, %fd63, %fd77;
	mov.f64 	%fd79, 0d3FC5555555555511;
	fma.rn.f64 	%fd80, %fd78, %fd63, %fd79;
	mov.f64 	%fd81, 0d3FE000000000000B;
	fma.rn.f64 	%fd82, %fd80, %fd63, %fd81;
	mov.f64 	%fd83, 0d3FF0000000000000;
	fma.rn.f64 	%fd84, %fd82, %fd63, %fd83;
	fma.rn.f64 	%fd85, %fd84, %fd63, %fd83;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd85;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd85;
	}
	shl.b32 	%r19, %r4, 20;
	add.s32 	%r20, %r6, %r19;
	mov.b64 	%fd106, {%r5, %r20};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd2;
	}
	mov.b32 	 %f4, %r21;
	abs.f32 	%f2, %f4;
	setp.lt.f32	%p7, %f2, 0f4086232B;
	@%p7 bra 	BB84_10;

	setp.gt.f64	%p8, %fd1, 0d8000000000000000;
	mov.f64 	%fd86, 0d7FF0000000000000;
	sub.f64 	%fd87, %fd86, %fd1;
	selp.f64	%fd106, 0d0000000000000000, %fd87, %p8;
	setp.geu.f32	%p9, %f2, 0f40874800;
	@%p9 bra 	BB84_10;

	shr.u32 	%r22, %r4, 31;
	add.s32 	%r23, %r4, %r22;
	shr.s32 	%r24, %r23, 1;
	shl.b32 	%r25, %r24, 20;
	add.s32 	%r26, %r25, %r6;
	mov.b64 	%fd88, {%r5, %r26};
	sub.s32 	%r27, %r4, %r24;
	shl.b32 	%r28, %r27, 20;
	add.s32 	%r29, %r28, 1072693248;
	mov.u32 	%r30, 0;
	mov.b64 	%fd89, {%r30, %r29};
	mul.f64 	%fd106, %fd88, %fd89;

BB84_10:
	mul.f64 	%fd90, %fd1, 0d4003959C427E5671;
	mul.f64 	%fd91, %fd1, 0dBFFC6159E1A1BA99;
	mul.f64 	%fd92, %fd1, %fd91;
	mul.f64 	%fd93, %fd1, %fd92;
	fma.rn.f64 	%fd94, %fd1, %fd90, %fd93;
	mul.f64 	%fd95, %fd1, 0d3FDEF88FF8540B95;
	mul.f64 	%fd96, %fd1, %fd95;
	mul.f64 	%fd97, %fd1, %fd96;
	fma.rn.f64 	%fd98, %fd1, %fd97, %fd94;
	mul.f64 	%fd99, %fd1, 0dBFA4C4B8F3C6331D;
	mul.f64 	%fd100, %fd1, %fd99;
	mul.f64 	%fd101, %fd1, %fd100;
	mul.f64 	%fd102, %fd1, %fd101;
	fma.rn.f64 	%fd103, %fd1, %fd102, %fd98;
	mul.f64 	%fd104, %fd106, %fd14;
	mul.f64 	%fd107, %fd103, %fd104;
	bra.uni 	BB84_11;

BB84_2:
	ld.f64 	%fd18, [%rd1];
	setp.geu.f64	%p3, %fd18, %fd2;
	@%p3 bra 	BB84_11;

	mov.f64 	%fd19, 0d4338000000000000;
	mov.f64 	%fd20, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd21, %fd2, %fd20, %fd19;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd21;
	}
	mov.f64 	%fd22, 0dC338000000000000;
	add.rn.f64 	%fd23, %fd21, %fd22;
	mov.f64 	%fd24, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd25, %fd23, %fd24, %fd2;
	mov.f64 	%fd26, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd27, %fd23, %fd26, %fd25;
	mov.f64 	%fd28, 0d3E928AF3FCA213EA;
	mov.f64 	%fd29, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd30, %fd29, %fd27, %fd28;
	mov.f64 	%fd31, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd32, %fd30, %fd27, %fd31;
	mov.f64 	%fd33, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd34, %fd32, %fd27, %fd33;
	mov.f64 	%fd35, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd36, %fd34, %fd27, %fd35;
	mov.f64 	%fd37, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd38, %fd36, %fd27, %fd37;
	mov.f64 	%fd39, 0d3F81111111122322;
	fma.rn.f64 	%fd40, %fd38, %fd27, %fd39;
	mov.f64 	%fd41, 0d3FA55555555502A1;
	fma.rn.f64 	%fd42, %fd40, %fd27, %fd41;
	mov.f64 	%fd43, 0d3FC5555555555511;
	fma.rn.f64 	%fd44, %fd42, %fd27, %fd43;
	mov.f64 	%fd45, 0d3FE000000000000B;
	fma.rn.f64 	%fd46, %fd44, %fd27, %fd45;
	mov.f64 	%fd47, 0d3FF0000000000000;
	fma.rn.f64 	%fd48, %fd46, %fd27, %fd47;
	fma.rn.f64 	%fd49, %fd48, %fd27, %fd47;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd49;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd49;
	}
	shl.b32 	%r7, %r1, 20;
	add.s32 	%r8, %r3, %r7;
	mov.b64 	%fd105, {%r2, %r8};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd2;
	}
	mov.b32 	 %f3, %r9;
	abs.f32 	%f1, %f3;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB84_6;

	setp.gt.f64	%p5, %fd1, 0d8000000000000000;
	mov.f64 	%fd50, 0d7FF0000000000000;
	sub.f64 	%fd51, %fd50, %fd1;
	selp.f64	%fd105, 0d0000000000000000, %fd51, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB84_6;

	shr.u32 	%r10, %r1, 31;
	add.s32 	%r11, %r1, %r10;
	shr.s32 	%r12, %r11, 1;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, %r3;
	mov.b64 	%fd52, {%r2, %r14};
	sub.s32 	%r15, %r1, %r12;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, 1072693248;
	mov.u32 	%r18, 0;
	mov.b64 	%fd53, {%r18, %r17};
	mul.f64 	%fd105, %fd52, %fd53;

BB84_6:
	mul.f64 	%fd54, %fd1, %fd14;
	mul.f64 	%fd107, %fd54, %fd105;

BB84_11:
	st.param.f64	[func_retval0+0], %fd107;
	ret;
}

	// .globl	_Z16BruneSmoothed_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16BruneSmoothed_ttddPdiPii(
	.param .b64 _Z16BruneSmoothed_ttddPdiPii_param_0,
	.param .b64 _Z16BruneSmoothed_ttddPdiPii_param_1,
	.param .b64 _Z16BruneSmoothed_ttddPdiPii_param_2,
	.param .b32 _Z16BruneSmoothed_ttddPdiPii_param_3,
	.param .b64 _Z16BruneSmoothed_ttddPdiPii_param_4,
	.param .b32 _Z16BruneSmoothed_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<113>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd14, [_Z16BruneSmoothed_ttddPdiPii_param_0];
	ld.param.f64 	%fd16, [_Z16BruneSmoothed_ttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z16BruneSmoothed_ttddPdiPii_param_2];
	mul.f64 	%fd1, %fd14, %fd16;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd112, 0d0000000000000000;
	@%p1 bra 	BB85_11;

	setp.lt.f64	%p2, %fd1, 0d40027AE147AE147B;
	neg.f64 	%fd2, %fd1;
	@%p2 bra 	BB85_7;
	bra.uni 	BB85_2;

BB85_7:
	mov.f64 	%fd58, 0d4338000000000000;
	mov.f64 	%fd59, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd60, %fd2, %fd59, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	mov.f64 	%fd61, 0dC338000000000000;
	add.rn.f64 	%fd62, %fd60, %fd61;
	mov.f64 	%fd63, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd64, %fd62, %fd63, %fd2;
	mov.f64 	%fd65, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd66, %fd62, %fd65, %fd64;
	mov.f64 	%fd67, 0d3E928AF3FCA213EA;
	mov.f64 	%fd68, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd69, %fd68, %fd66, %fd67;
	mov.f64 	%fd70, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd71, %fd69, %fd66, %fd70;
	mov.f64 	%fd72, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd73, %fd71, %fd66, %fd72;
	mov.f64 	%fd74, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd75, %fd73, %fd66, %fd74;
	mov.f64 	%fd76, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd77, %fd75, %fd66, %fd76;
	mov.f64 	%fd78, 0d3F81111111122322;
	fma.rn.f64 	%fd79, %fd77, %fd66, %fd78;
	mov.f64 	%fd80, 0d3FA55555555502A1;
	fma.rn.f64 	%fd81, %fd79, %fd66, %fd80;
	mov.f64 	%fd82, 0d3FC5555555555511;
	fma.rn.f64 	%fd83, %fd81, %fd66, %fd82;
	mov.f64 	%fd84, 0d3FE000000000000B;
	fma.rn.f64 	%fd85, %fd83, %fd66, %fd84;
	mov.f64 	%fd86, 0d3FF0000000000000;
	fma.rn.f64 	%fd87, %fd85, %fd66, %fd86;
	fma.rn.f64 	%fd88, %fd87, %fd66, %fd86;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd88;
	}
	shl.b32 	%r19, %r4, 20;
	add.s32 	%r20, %r6, %r19;
	mov.b64 	%fd111, {%r5, %r20};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd2;
	}
	mov.b32 	 %f4, %r21;
	abs.f32 	%f2, %f4;
	setp.lt.f32	%p7, %f2, 0f4086232B;
	@%p7 bra 	BB85_10;

	setp.gt.f64	%p8, %fd1, 0d8000000000000000;
	mov.f64 	%fd89, 0d7FF0000000000000;
	sub.f64 	%fd90, %fd89, %fd1;
	selp.f64	%fd111, 0d0000000000000000, %fd90, %p8;
	setp.geu.f32	%p9, %f2, 0f40874800;
	@%p9 bra 	BB85_10;

	shr.u32 	%r22, %r4, 31;
	add.s32 	%r23, %r4, %r22;
	shr.s32 	%r24, %r23, 1;
	shl.b32 	%r25, %r24, 20;
	add.s32 	%r26, %r25, %r6;
	mov.b64 	%fd91, {%r5, %r26};
	sub.s32 	%r27, %r4, %r24;
	shl.b32 	%r28, %r27, 20;
	add.s32 	%r29, %r28, 1072693248;
	mov.u32 	%r30, 0;
	mov.b64 	%fd92, {%r30, %r29};
	mul.f64 	%fd111, %fd91, %fd92;

BB85_10:
	mul.f64 	%fd93, %fd1, 0dC01F13D18A78772B;
	mul.f64 	%fd94, %fd1, %fd93;
	fma.rn.f64 	%fd95, %fd1, 0d4013959C427E5671, %fd94;
	mul.f64 	%fd96, %fd1, 0d400DACF4ECFAE317;
	mul.f64 	%fd97, %fd1, %fd96;
	fma.rn.f64 	%fd98, %fd1, %fd97, %fd95;
	mul.f64 	%fd99, %fd1, 0dBFE5F9C1C857F5C4;
	mul.f64 	%fd100, %fd1, %fd99;
	mul.f64 	%fd101, %fd1, %fd100;
	fma.rn.f64 	%fd102, %fd1, %fd101, %fd98;
	mul.f64 	%fd103, %fd1, 0d3FA4C4B8F3C6331D;
	mul.f64 	%fd104, %fd1, %fd103;
	mul.f64 	%fd105, %fd1, %fd104;
	mul.f64 	%fd106, %fd1, %fd105;
	fma.rn.f64 	%fd107, %fd1, %fd106, %fd102;
	mul.f64 	%fd108, %fd14, %fd14;
	mul.f64 	%fd109, %fd108, %fd107;
	mul.f64 	%fd112, %fd109, %fd111;
	bra.uni 	BB85_11;

BB85_2:
	ld.f64 	%fd18, [%rd1];
	setp.geu.f64	%p3, %fd18, %fd2;
	@%p3 bra 	BB85_11;

	mov.f64 	%fd19, 0d4338000000000000;
	mov.f64 	%fd20, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd21, %fd2, %fd20, %fd19;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd21;
	}
	mov.f64 	%fd22, 0dC338000000000000;
	add.rn.f64 	%fd23, %fd21, %fd22;
	mov.f64 	%fd24, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd25, %fd23, %fd24, %fd2;
	mov.f64 	%fd26, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd27, %fd23, %fd26, %fd25;
	mov.f64 	%fd28, 0d3E928AF3FCA213EA;
	mov.f64 	%fd29, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd30, %fd29, %fd27, %fd28;
	mov.f64 	%fd31, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd32, %fd30, %fd27, %fd31;
	mov.f64 	%fd33, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd34, %fd32, %fd27, %fd33;
	mov.f64 	%fd35, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd36, %fd34, %fd27, %fd35;
	mov.f64 	%fd37, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd38, %fd36, %fd27, %fd37;
	mov.f64 	%fd39, 0d3F81111111122322;
	fma.rn.f64 	%fd40, %fd38, %fd27, %fd39;
	mov.f64 	%fd41, 0d3FA55555555502A1;
	fma.rn.f64 	%fd42, %fd40, %fd27, %fd41;
	mov.f64 	%fd43, 0d3FC5555555555511;
	fma.rn.f64 	%fd44, %fd42, %fd27, %fd43;
	mov.f64 	%fd45, 0d3FE000000000000B;
	fma.rn.f64 	%fd46, %fd44, %fd27, %fd45;
	mov.f64 	%fd47, 0d3FF0000000000000;
	fma.rn.f64 	%fd48, %fd46, %fd27, %fd47;
	fma.rn.f64 	%fd49, %fd48, %fd27, %fd47;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd49;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd49;
	}
	shl.b32 	%r7, %r1, 20;
	add.s32 	%r8, %r3, %r7;
	mov.b64 	%fd110, {%r2, %r8};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd2;
	}
	mov.b32 	 %f3, %r9;
	abs.f32 	%f1, %f3;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB85_6;

	setp.gt.f64	%p5, %fd1, 0d8000000000000000;
	mov.f64 	%fd50, 0d7FF0000000000000;
	sub.f64 	%fd51, %fd50, %fd1;
	selp.f64	%fd110, 0d0000000000000000, %fd51, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB85_6;

	shr.u32 	%r10, %r1, 31;
	add.s32 	%r11, %r1, %r10;
	shr.s32 	%r12, %r11, 1;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, %r3;
	mov.b64 	%fd52, {%r2, %r14};
	sub.s32 	%r15, %r1, %r12;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, 1072693248;
	mov.u32 	%r18, 0;
	mov.b64 	%fd53, {%r18, %r17};
	mul.f64 	%fd110, %fd52, %fd53;

BB85_6:
	sub.f64 	%fd55, %fd47, %fd1;
	mul.f64 	%fd56, %fd14, %fd14;
	mul.f64 	%fd57, %fd56, %fd55;
	mul.f64 	%fd112, %fd57, %fd110;

BB85_11:
	st.param.f64	[func_retval0+0], %fd112;
	ret;
}

	// .globl	_Z17BruneSmoothed_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17BruneSmoothed_tttddPdiPii(
	.param .b64 _Z17BruneSmoothed_tttddPdiPii_param_0,
	.param .b64 _Z17BruneSmoothed_tttddPdiPii_param_1,
	.param .b64 _Z17BruneSmoothed_tttddPdiPii_param_2,
	.param .b32 _Z17BruneSmoothed_tttddPdiPii_param_3,
	.param .b64 _Z17BruneSmoothed_tttddPdiPii_param_4,
	.param .b32 _Z17BruneSmoothed_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<114>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd15, [_Z17BruneSmoothed_tttddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z17BruneSmoothed_tttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z17BruneSmoothed_tttddPdiPii_param_2];
	mul.f64 	%fd1, %fd15, %fd17;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd113, 0d0000000000000000;
	@%p1 bra 	BB86_11;

	setp.lt.f64	%p2, %fd1, 0d40027AE147AE147B;
	neg.f64 	%fd2, %fd1;
	@%p2 bra 	BB86_7;
	bra.uni 	BB86_2;

BB86_7:
	mov.f64 	%fd58, 0d4338000000000000;
	mov.f64 	%fd59, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd60, %fd2, %fd59, %fd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd60;
	}
	mov.f64 	%fd61, 0dC338000000000000;
	add.rn.f64 	%fd62, %fd60, %fd61;
	mov.f64 	%fd63, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd64, %fd62, %fd63, %fd2;
	mov.f64 	%fd65, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd66, %fd62, %fd65, %fd64;
	mov.f64 	%fd67, 0d3E928AF3FCA213EA;
	mov.f64 	%fd68, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd69, %fd68, %fd66, %fd67;
	mov.f64 	%fd70, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd71, %fd69, %fd66, %fd70;
	mov.f64 	%fd72, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd73, %fd71, %fd66, %fd72;
	mov.f64 	%fd74, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd75, %fd73, %fd66, %fd74;
	mov.f64 	%fd76, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd77, %fd75, %fd66, %fd76;
	mov.f64 	%fd78, 0d3F81111111122322;
	fma.rn.f64 	%fd79, %fd77, %fd66, %fd78;
	mov.f64 	%fd80, 0d3FA55555555502A1;
	fma.rn.f64 	%fd81, %fd79, %fd66, %fd80;
	mov.f64 	%fd82, 0d3FC5555555555511;
	fma.rn.f64 	%fd83, %fd81, %fd66, %fd82;
	mov.f64 	%fd84, 0d3FE000000000000B;
	fma.rn.f64 	%fd85, %fd83, %fd66, %fd84;
	mov.f64 	%fd86, 0d3FF0000000000000;
	fma.rn.f64 	%fd87, %fd85, %fd66, %fd86;
	fma.rn.f64 	%fd88, %fd87, %fd66, %fd86;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd88;
	}
	shl.b32 	%r19, %r4, 20;
	add.s32 	%r20, %r6, %r19;
	mov.b64 	%fd112, {%r5, %r20};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd2;
	}
	mov.b32 	 %f4, %r21;
	abs.f32 	%f2, %f4;
	setp.lt.f32	%p7, %f2, 0f4086232B;
	@%p7 bra 	BB86_10;

	setp.gt.f64	%p8, %fd1, 0d8000000000000000;
	mov.f64 	%fd89, 0d7FF0000000000000;
	sub.f64 	%fd90, %fd89, %fd1;
	selp.f64	%fd112, 0d0000000000000000, %fd90, %p8;
	setp.geu.f32	%p9, %f2, 0f40874800;
	@%p9 bra 	BB86_10;

	shr.u32 	%r22, %r4, 31;
	add.s32 	%r23, %r4, %r22;
	shr.s32 	%r24, %r23, 1;
	shl.b32 	%r25, %r24, 20;
	add.s32 	%r26, %r25, %r6;
	mov.b64 	%fd91, {%r5, %r26};
	sub.s32 	%r27, %r4, %r24;
	shl.b32 	%r28, %r27, 20;
	add.s32 	%r29, %r28, 1072693248;
	mov.u32 	%r30, 0;
	mov.b64 	%fd92, {%r30, %r29};
	mul.f64 	%fd112, %fd91, %fd92;

BB86_10:
	mul.f64 	%fd93, %fd112, %fd15;
	mul.f64 	%fd94, %fd93, %fd15;
	mul.f64 	%fd95, %fd94, %fd15;
	fma.rn.f64 	%fd96, %fd1, 0dC0346F4FD5DBD132, 0d4013959C427E5671;
	mul.f64 	%fd97, %fd1, 0d4032E5D03B7C32F3;
	fma.rn.f64 	%fd98, %fd1, %fd97, %fd96;
	mul.f64 	%fd99, %fd1, 0dC019D35B5AA96C6E;
	mul.f64 	%fd100, %fd1, %fd99;
	fma.rn.f64 	%fd101, %fd1, %fd100, %fd98;
	mul.f64 	%fd102, %fd1, 0d3FEC773B9485E5BC;
	mul.f64 	%fd103, %fd1, %fd102;
	mul.f64 	%fd104, %fd1, %fd103;
	fma.rn.f64 	%fd105, %fd1, %fd104, %fd101;
	mul.f64 	%fd106, %fd1, 0dBFA4C4B8F3C6331D;
	mul.f64 	%fd107, %fd1, %fd106;
	mul.f64 	%fd108, %fd1, %fd107;
	mul.f64 	%fd109, %fd1, %fd108;
	fma.rn.f64 	%fd110, %fd1, %fd109, %fd105;
	mul.f64 	%fd113, %fd110, %fd95;
	bra.uni 	BB86_11;

BB86_2:
	ld.f64 	%fd19, [%rd1];
	setp.geu.f64	%p3, %fd19, %fd2;
	@%p3 bra 	BB86_11;

	add.f64 	%fd3, %fd1, 0dC000000000000000;
	mov.f64 	%fd20, 0d4338000000000000;
	mov.f64 	%fd21, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd22, %fd2, %fd21, %fd20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd22;
	}
	mov.f64 	%fd23, 0dC338000000000000;
	add.rn.f64 	%fd24, %fd22, %fd23;
	mov.f64 	%fd25, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd26, %fd24, %fd25, %fd2;
	mov.f64 	%fd27, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd28, %fd24, %fd27, %fd26;
	mov.f64 	%fd29, 0d3E928AF3FCA213EA;
	mov.f64 	%fd30, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd31, %fd30, %fd28, %fd29;
	mov.f64 	%fd32, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd33, %fd31, %fd28, %fd32;
	mov.f64 	%fd34, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd35, %fd33, %fd28, %fd34;
	mov.f64 	%fd36, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd37, %fd35, %fd28, %fd36;
	mov.f64 	%fd38, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd39, %fd37, %fd28, %fd38;
	mov.f64 	%fd40, 0d3F81111111122322;
	fma.rn.f64 	%fd41, %fd39, %fd28, %fd40;
	mov.f64 	%fd42, 0d3FA55555555502A1;
	fma.rn.f64 	%fd43, %fd41, %fd28, %fd42;
	mov.f64 	%fd44, 0d3FC5555555555511;
	fma.rn.f64 	%fd45, %fd43, %fd28, %fd44;
	mov.f64 	%fd46, 0d3FE000000000000B;
	fma.rn.f64 	%fd47, %fd45, %fd28, %fd46;
	mov.f64 	%fd48, 0d3FF0000000000000;
	fma.rn.f64 	%fd49, %fd47, %fd28, %fd48;
	fma.rn.f64 	%fd50, %fd49, %fd28, %fd48;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd50;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd50;
	}
	shl.b32 	%r7, %r1, 20;
	add.s32 	%r8, %r3, %r7;
	mov.b64 	%fd111, {%r2, %r8};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd2;
	}
	mov.b32 	 %f3, %r9;
	abs.f32 	%f1, %f3;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB86_6;

	setp.gt.f64	%p5, %fd1, 0d8000000000000000;
	mov.f64 	%fd51, 0d7FF0000000000000;
	sub.f64 	%fd52, %fd51, %fd1;
	selp.f64	%fd111, 0d0000000000000000, %fd52, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB86_6;

	shr.u32 	%r10, %r1, 31;
	add.s32 	%r11, %r1, %r10;
	shr.s32 	%r12, %r11, 1;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, %r3;
	mov.b64 	%fd53, {%r2, %r14};
	sub.s32 	%r15, %r1, %r12;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, 1072693248;
	mov.u32 	%r18, 0;
	mov.b64 	%fd54, {%r18, %r17};
	mul.f64 	%fd111, %fd53, %fd54;

BB86_6:
	mul.f64 	%fd55, %fd3, %fd15;
	mul.f64 	%fd56, %fd55, %fd15;
	mul.f64 	%fd57, %fd56, %fd15;
	mul.f64 	%fd113, %fd57, %fd111;

BB86_11:
	st.param.f64	[func_retval0+0], %fd113;
	ret;
}

	// .globl	_Z18BruneSmoothed_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z18BruneSmoothed_omttddPdiPii(
	.param .b64 _Z18BruneSmoothed_omttddPdiPii_param_0,
	.param .b64 _Z18BruneSmoothed_omttddPdiPii_param_1,
	.param .b64 _Z18BruneSmoothed_omttddPdiPii_param_2,
	.param .b32 _Z18BruneSmoothed_omttddPdiPii_param_3,
	.param .b64 _Z18BruneSmoothed_omttddPdiPii_param_4,
	.param .b32 _Z18BruneSmoothed_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<125>;
	.reg .b64 	%rd<2>;


	ld.param.f64 	%fd15, [_Z18BruneSmoothed_omttddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z18BruneSmoothed_omttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z18BruneSmoothed_omttddPdiPii_param_2];
	mul.f64 	%fd1, %fd15, %fd17;
	setp.lt.f64	%p1, %fd1, 0d0000000000000000;
	mov.f64 	%fd124, 0d0000000000000000;
	@%p1 bra 	BB87_11;

	setp.lt.f64	%p2, %fd1, 0d40027AE147AE147B;
	neg.f64 	%fd2, %fd1;
	@%p2 bra 	BB87_7;
	bra.uni 	BB87_2;

BB87_7:
	mov.f64 	%fd57, 0d4338000000000000;
	mov.f64 	%fd58, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd59, %fd2, %fd58, %fd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd59;
	}
	mov.f64 	%fd60, 0dC338000000000000;
	add.rn.f64 	%fd61, %fd59, %fd60;
	mov.f64 	%fd62, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd63, %fd61, %fd62, %fd2;
	mov.f64 	%fd64, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd65, %fd61, %fd64, %fd63;
	mov.f64 	%fd66, 0d3E928AF3FCA213EA;
	mov.f64 	%fd67, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd68, %fd67, %fd65, %fd66;
	mov.f64 	%fd69, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd70, %fd68, %fd65, %fd69;
	mov.f64 	%fd71, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd72, %fd70, %fd65, %fd71;
	mov.f64 	%fd73, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd74, %fd72, %fd65, %fd73;
	mov.f64 	%fd75, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd76, %fd74, %fd65, %fd75;
	mov.f64 	%fd77, 0d3F81111111122322;
	fma.rn.f64 	%fd78, %fd76, %fd65, %fd77;
	mov.f64 	%fd79, 0d3FA55555555502A1;
	fma.rn.f64 	%fd80, %fd78, %fd65, %fd79;
	mov.f64 	%fd81, 0d3FC5555555555511;
	fma.rn.f64 	%fd82, %fd80, %fd65, %fd81;
	mov.f64 	%fd83, 0d3FE000000000000B;
	fma.rn.f64 	%fd84, %fd82, %fd65, %fd83;
	mov.f64 	%fd85, 0d3FF0000000000000;
	fma.rn.f64 	%fd86, %fd84, %fd65, %fd85;
	fma.rn.f64 	%fd87, %fd86, %fd65, %fd85;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd87;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd87;
	}
	shl.b32 	%r19, %r4, 20;
	add.s32 	%r20, %r6, %r19;
	mov.b64 	%fd123, {%r5, %r20};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd2;
	}
	mov.b32 	 %f4, %r21;
	abs.f32 	%f2, %f4;
	setp.lt.f32	%p7, %f2, 0f4086232B;
	@%p7 bra 	BB87_10;

	setp.gt.f64	%p8, %fd1, 0d8000000000000000;
	mov.f64 	%fd88, 0d7FF0000000000000;
	sub.f64 	%fd89, %fd88, %fd1;
	selp.f64	%fd123, 0d0000000000000000, %fd89, %p8;
	setp.geu.f32	%p9, %f2, 0f40874800;
	@%p9 bra 	BB87_10;

	shr.u32 	%r22, %r4, 31;
	add.s32 	%r23, %r4, %r22;
	shr.s32 	%r24, %r23, 1;
	shl.b32 	%r25, %r24, 20;
	add.s32 	%r26, %r25, %r6;
	mov.b64 	%fd90, {%r5, %r26};
	sub.s32 	%r27, %r4, %r24;
	shl.b32 	%r28, %r27, 20;
	add.s32 	%r29, %r28, 1072693248;
	mov.u32 	%r30, 0;
	mov.b64 	%fd91, {%r30, %r29};
	mul.f64 	%fd123, %fd90, %fd91;

BB87_10:
	fma.rn.f64 	%fd92, %fd1, 0dC02F13D18A78772B, 0d4013959C427E5671;
	mul.f64 	%fd93, %fd1, 0d402641B7B1BC2A51;
	fma.rn.f64 	%fd94, %fd1, %fd93, %fd92;
	mul.f64 	%fd95, %fd1, 0dC005F9C1C857F5C4;
	mul.f64 	%fd96, %fd1, %fd95;
	fma.rn.f64 	%fd97, %fd1, %fd96, %fd94;
	mul.f64 	%fd98, %fd1, 0d3FC9F5E730B7BFE4;
	mul.f64 	%fd99, %fd1, %fd98;
	mul.f64 	%fd100, %fd1, %fd99;
	fma.rn.f64 	%fd101, %fd1, %fd100, %fd97;
	mul.f64 	%fd102, %fd1, 0dC01F13D18A78772B;
	mul.f64 	%fd103, %fd1, %fd102;
	fma.rn.f64 	%fd104, %fd1, 0d4013959C427E5671, %fd103;
	mul.f64 	%fd105, %fd1, 0d400DACF4ECFAE317;
	mul.f64 	%fd106, %fd1, %fd105;
	fma.rn.f64 	%fd107, %fd1, %fd106, %fd104;
	mul.f64 	%fd108, %fd1, 0dBFE5F9C1C857F5C4;
	mul.f64 	%fd109, %fd1, %fd108;
	mul.f64 	%fd110, %fd1, %fd109;
	fma.rn.f64 	%fd111, %fd1, %fd110, %fd107;
	mul.f64 	%fd112, %fd1, 0d3FA4C4B8F3C6331D;
	mul.f64 	%fd113, %fd1, %fd112;
	mul.f64 	%fd114, %fd1, %fd113;
	mul.f64 	%fd115, %fd1, %fd114;
	fma.rn.f64 	%fd116, %fd1, %fd115, %fd111;
	mov.f64 	%fd117, 0d4000000000000000;
	sub.f64 	%fd118, %fd117, %fd1;
	mul.f64 	%fd119, %fd118, %fd116;
	fma.rn.f64 	%fd120, %fd1, %fd101, %fd119;
	mul.f64 	%fd121, %fd123, %fd15;
	mul.f64 	%fd124, %fd120, %fd121;
	bra.uni 	BB87_11;

BB87_2:
	ld.f64 	%fd19, [%rd1];
	setp.geu.f64	%p3, %fd19, %fd2;
	@%p3 bra 	BB87_11;

	fma.rn.f64 	%fd20, %fd1, 0dC010000000000000, 0d4000000000000000;
	fma.rn.f64 	%fd3, %fd1, %fd1, %fd20;
	mov.f64 	%fd21, 0d4338000000000000;
	mov.f64 	%fd22, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd23, %fd2, %fd22, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd23;
	}
	mov.f64 	%fd24, 0dC338000000000000;
	add.rn.f64 	%fd25, %fd23, %fd24;
	mov.f64 	%fd26, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd27, %fd25, %fd26, %fd2;
	mov.f64 	%fd28, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd29, %fd25, %fd28, %fd27;
	mov.f64 	%fd30, 0d3E928AF3FCA213EA;
	mov.f64 	%fd31, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd32, %fd31, %fd29, %fd30;
	mov.f64 	%fd33, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd34, %fd32, %fd29, %fd33;
	mov.f64 	%fd35, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd36, %fd34, %fd29, %fd35;
	mov.f64 	%fd37, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd38, %fd36, %fd29, %fd37;
	mov.f64 	%fd39, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd40, %fd38, %fd29, %fd39;
	mov.f64 	%fd41, 0d3F81111111122322;
	fma.rn.f64 	%fd42, %fd40, %fd29, %fd41;
	mov.f64 	%fd43, 0d3FA55555555502A1;
	fma.rn.f64 	%fd44, %fd42, %fd29, %fd43;
	mov.f64 	%fd45, 0d3FC5555555555511;
	fma.rn.f64 	%fd46, %fd44, %fd29, %fd45;
	mov.f64 	%fd47, 0d3FE000000000000B;
	fma.rn.f64 	%fd48, %fd46, %fd29, %fd47;
	mov.f64 	%fd49, 0d3FF0000000000000;
	fma.rn.f64 	%fd50, %fd48, %fd29, %fd49;
	fma.rn.f64 	%fd51, %fd50, %fd29, %fd49;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd51;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd51;
	}
	shl.b32 	%r7, %r1, 20;
	add.s32 	%r8, %r3, %r7;
	mov.b64 	%fd122, {%r2, %r8};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd2;
	}
	mov.b32 	 %f3, %r9;
	abs.f32 	%f1, %f3;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB87_6;

	setp.gt.f64	%p5, %fd1, 0d8000000000000000;
	mov.f64 	%fd52, 0d7FF0000000000000;
	sub.f64 	%fd53, %fd52, %fd1;
	selp.f64	%fd122, 0d0000000000000000, %fd53, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB87_6;

	shr.u32 	%r10, %r1, 31;
	add.s32 	%r11, %r1, %r10;
	shr.s32 	%r12, %r11, 1;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, %r3;
	mov.b64 	%fd54, {%r2, %r14};
	sub.s32 	%r15, %r1, %r12;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, 1072693248;
	mov.u32 	%r18, 0;
	mov.b64 	%fd55, {%r18, %r17};
	mul.f64 	%fd122, %fd54, %fd55;

BB87_6:
	mul.f64 	%fd56, %fd3, %fd15;
	mul.f64 	%fd124, %fd56, %fd122;

BB87_11:
	st.param.f64	[func_retval0+0], %fd124;
	ret;
}

	// .globl	_Z14GaussianWindowddPdiPii
.visible .func  (.param .b64 func_retval0) _Z14GaussianWindowddPdiPii(
	.param .b64 _Z14GaussianWindowddPdiPii_param_0,
	.param .b64 _Z14GaussianWindowddPdiPii_param_1,
	.param .b64 _Z14GaussianWindowddPdiPii_param_2,
	.param .b32 _Z14GaussianWindowddPdiPii_param_3,
	.param .b64 _Z14GaussianWindowddPdiPii_param_4,
	.param .b32 _Z14GaussianWindowddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot88[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<94>;
	.reg .b64 	%rd<8>;


	mov.u64 	%SPL, __local_depot88;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd22, [_Z14GaussianWindowddPdiPii_param_0];
	ld.param.f64 	%fd23, [_Z14GaussianWindowddPdiPii_param_1];
	ld.param.u64 	%rd2, [_Z14GaussianWindowddPdiPii_param_2];
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd3;
	ld.f64 	%fd24, [%rd2+8];
	mul.f64 	%fd25, %fd24, %fd24;
	rcp.rn.f64 	%fd26, %fd25;
	mul.f64 	%fd88, %fd22, %fd23;
	mul.f64 	%fd27, %fd88, 0dBFE0000000000000;
	mul.f64 	%fd28, %fd88, %fd27;
	mul.f64 	%fd2, %fd28, %fd26;
	ld.f64 	%fd29, [%rd2];
	mov.f64 	%fd93, 0d0000000000000000;
	setp.leu.f64	%p1, %fd2, %fd29;
	@%p1 bra 	BB88_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd88;
	}
	and.b32  	%r8, %r7, 2147483647;
	setp.ne.s32	%p2, %r8, 2146435072;
	@%p2 bra 	BB88_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd88;
	}
	setp.ne.s32	%p3, %r9, 0;
	@%p3 bra 	BB88_4;

	mov.f64 	%fd30, 0d0000000000000000;
	mul.rn.f64 	%fd88, %fd88, %fd30;

BB88_4:
	mul.f64 	%fd31, %fd88, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r28, %fd31;
	st.local.u32 	[%rd1], %r28;
	cvt.rn.f64.s32	%fd32, %r28;
	neg.f64 	%fd33, %fd32;
	mov.f64 	%fd34, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd35, %fd33, %fd34, %fd88;
	mov.f64 	%fd36, 0d3C91A62633145C00;
	fma.rn.f64 	%fd37, %fd33, %fd36, %fd35;
	mov.f64 	%fd38, 0d397B839A252049C0;
	fma.rn.f64 	%fd89, %fd33, %fd38, %fd37;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd88;
	}
	and.b32  	%r11, %r10, 2145386496;
	setp.lt.u32	%p4, %r11, 1105199104;
	@%p4 bra 	BB88_6;

	// Callseq Start 186
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd88;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd89, [retval0+0];
	
	//{
	}// Callseq End 186
	ld.local.u32 	%r28, [%rd1];

BB88_6:
	and.b32  	%r12, %r28, 1;
	shl.b32 	%r13, %r12, 3;
	setp.eq.s32	%p5, %r12, 0;
	selp.f64	%fd39, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p5;
	add.s32 	%r14, %r13, 1;
	mul.wide.s32 	%rd5, %r14, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd40, [%rd7];
	mul.rn.f64 	%fd8, %fd89, %fd89;
	fma.rn.f64 	%fd41, %fd39, %fd8, %fd40;
	ld.const.f64 	%fd42, [%rd7+8];
	fma.rn.f64 	%fd43, %fd41, %fd8, %fd42;
	ld.const.f64 	%fd44, [%rd7+16];
	fma.rn.f64 	%fd45, %fd43, %fd8, %fd44;
	ld.const.f64 	%fd46, [%rd7+24];
	fma.rn.f64 	%fd47, %fd45, %fd8, %fd46;
	ld.const.f64 	%fd48, [%rd7+32];
	fma.rn.f64 	%fd49, %fd47, %fd8, %fd48;
	ld.const.f64 	%fd50, [%rd7+40];
	fma.rn.f64 	%fd9, %fd49, %fd8, %fd50;
	fma.rn.f64 	%fd90, %fd9, %fd89, %fd89;
	@%p5 bra 	BB88_8;

	mov.f64 	%fd51, 0d3FF0000000000000;
	fma.rn.f64 	%fd90, %fd9, %fd8, %fd51;

BB88_8:
	and.b32  	%r15, %r28, 2;
	setp.eq.s32	%p6, %r15, 0;
	@%p6 bra 	BB88_10;

	mov.f64 	%fd52, 0d0000000000000000;
	mov.f64 	%fd53, 0dBFF0000000000000;
	fma.rn.f64 	%fd90, %fd90, %fd53, %fd52;

BB88_10:
	mov.f64 	%fd54, 0d4338000000000000;
	mov.f64 	%fd55, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd56, %fd2, %fd55, %fd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r4, %temp}, %fd56;
	}
	mov.f64 	%fd57, 0dC338000000000000;
	add.rn.f64 	%fd58, %fd56, %fd57;
	mov.f64 	%fd59, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd60, %fd58, %fd59, %fd2;
	mov.f64 	%fd61, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd62, %fd58, %fd61, %fd60;
	mov.f64 	%fd63, 0d3E928AF3FCA213EA;
	mov.f64 	%fd64, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd65, %fd64, %fd62, %fd63;
	mov.f64 	%fd66, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd67, %fd65, %fd62, %fd66;
	mov.f64 	%fd68, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd69, %fd67, %fd62, %fd68;
	mov.f64 	%fd70, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd71, %fd69, %fd62, %fd70;
	mov.f64 	%fd72, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd73, %fd71, %fd62, %fd72;
	mov.f64 	%fd74, 0d3F81111111122322;
	fma.rn.f64 	%fd75, %fd73, %fd62, %fd74;
	mov.f64 	%fd76, 0d3FA55555555502A1;
	fma.rn.f64 	%fd77, %fd75, %fd62, %fd76;
	mov.f64 	%fd78, 0d3FC5555555555511;
	fma.rn.f64 	%fd79, %fd77, %fd62, %fd78;
	mov.f64 	%fd80, 0d3FE000000000000B;
	fma.rn.f64 	%fd81, %fd79, %fd62, %fd80;
	mov.f64 	%fd82, 0d3FF0000000000000;
	fma.rn.f64 	%fd83, %fd81, %fd62, %fd82;
	fma.rn.f64 	%fd84, %fd83, %fd62, %fd82;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r5, %temp}, %fd84;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd84;
	}
	shl.b32 	%r16, %r4, 20;
	add.s32 	%r17, %r6, %r16;
	mov.b64 	%fd92, {%r5, %r17};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r18}, %fd2;
	}
	mov.b32 	 %f2, %r18;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p7, %f1, 0f4086232B;
	@%p7 bra 	BB88_13;

	setp.lt.f64	%p8, %fd2, 0d0000000000000000;
	add.f64 	%fd85, %fd2, 0d7FF0000000000000;
	selp.f64	%fd92, 0d0000000000000000, %fd85, %p8;
	setp.geu.f32	%p9, %f1, 0f40874800;
	@%p9 bra 	BB88_13;

	shr.u32 	%r19, %r4, 31;
	add.s32 	%r20, %r4, %r19;
	shr.s32 	%r21, %r20, 1;
	shl.b32 	%r22, %r21, 20;
	add.s32 	%r23, %r22, %r6;
	mov.b64 	%fd86, {%r5, %r23};
	sub.s32 	%r24, %r4, %r21;
	shl.b32 	%r25, %r24, 20;
	add.s32 	%r26, %r25, 1072693248;
	mov.u32 	%r27, 0;
	mov.b64 	%fd87, {%r27, %r26};
	mul.f64 	%fd92, %fd86, %fd87;

BB88_13:
	mul.f64 	%fd93, %fd90, %fd92;

BB88_14:
	st.param.f64	[func_retval0+0], %fd93;
	ret;
}

	// .globl	_Z16GaussianWindow_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16GaussianWindow_tddPdiPii(
	.param .b64 _Z16GaussianWindow_tddPdiPii_param_0,
	.param .b64 _Z16GaussianWindow_tddPdiPii_param_1,
	.param .b64 _Z16GaussianWindow_tddPdiPii_param_2,
	.param .b32 _Z16GaussianWindow_tddPdiPii_param_3,
	.param .b64 _Z16GaussianWindow_tddPdiPii_param_4,
	.param .b32 _Z16GaussianWindow_tddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot89[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<139>;
	.reg .b64 	%rd<14>;


	mov.u64 	%SPL, __local_depot89;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd36, [_Z16GaussianWindow_tddPdiPii_param_0];
	ld.param.f64 	%fd38, [_Z16GaussianWindow_tddPdiPii_param_1];
	ld.param.u64 	%rd3, [_Z16GaussianWindow_tddPdiPii_param_2];
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd4;
	add.u64 	%rd5, %SP, 4;
	cvta.to.local.u64 	%rd2, %rd5;
	ld.f64 	%fd39, [%rd3+8];
	mul.f64 	%fd40, %fd39, %fd39;
	rcp.rn.f64 	%fd1, %fd40;
	mul.f64 	%fd2, %fd36, %fd38;
	mul.f64 	%fd41, %fd2, 0dBFE0000000000000;
	mul.f64 	%fd42, %fd2, %fd41;
	mul.f64 	%fd3, %fd42, %fd1;
	ld.f64 	%fd43, [%rd3];
	mov.f64 	%fd138, 0d0000000000000000;
	setp.leu.f64	%p1, %fd3, %fd43;
	@%p1 bra 	BB89_23;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd2;
	}
	and.b32  	%r1, %r12, 2147483647;
	setp.ne.s32	%p2, %r1, 2146435072;
	mov.f64 	%fd129, %fd2;
	@%p2 bra 	BB89_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd2;
	}
	setp.ne.s32	%p3, %r13, 0;
	mov.f64 	%fd129, %fd2;
	@%p3 bra 	BB89_4;

	mov.f64 	%fd44, 0d0000000000000000;
	mul.rn.f64 	%fd129, %fd2, %fd44;

BB89_4:
	mul.f64 	%fd45, %fd129, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r39, %fd45;
	st.local.u32 	[%rd2], %r39;
	cvt.rn.f64.s32	%fd46, %r39;
	neg.f64 	%fd47, %fd46;
	mov.f64 	%fd48, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd49, %fd47, %fd48, %fd129;
	mov.f64 	%fd50, 0d3C91A62633145C00;
	fma.rn.f64 	%fd51, %fd47, %fd50, %fd49;
	mov.f64 	%fd52, 0d397B839A252049C0;
	fma.rn.f64 	%fd130, %fd47, %fd52, %fd51;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd129;
	}
	and.b32  	%r15, %r14, 2145386496;
	setp.lt.u32	%p4, %r15, 1105199104;
	@%p4 bra 	BB89_6;

	// Callseq Start 187
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd129;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd130, [retval0+0];
	
	//{
	}// Callseq End 187
	ld.local.u32 	%r39, [%rd2];

BB89_6:
	add.s32 	%r5, %r39, 1;
	and.b32  	%r16, %r5, 1;
	shl.b32 	%r17, %r16, 3;
	setp.eq.s32	%p5, %r16, 0;
	selp.f64	%fd53, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p5;
	add.s32 	%r18, %r17, 1;
	mul.wide.s32 	%rd7, %r18, 8;
	mov.u64 	%rd8, __cudart_sin_cos_coeffs;
	add.s64 	%rd9, %rd8, %rd7;
	ld.const.f64 	%fd54, [%rd9];
	mul.rn.f64 	%fd9, %fd130, %fd130;
	fma.rn.f64 	%fd55, %fd53, %fd9, %fd54;
	ld.const.f64 	%fd56, [%rd9+8];
	fma.rn.f64 	%fd57, %fd55, %fd9, %fd56;
	ld.const.f64 	%fd58, [%rd9+16];
	fma.rn.f64 	%fd59, %fd57, %fd9, %fd58;
	ld.const.f64 	%fd60, [%rd9+24];
	fma.rn.f64 	%fd61, %fd59, %fd9, %fd60;
	ld.const.f64 	%fd62, [%rd9+32];
	fma.rn.f64 	%fd63, %fd61, %fd9, %fd62;
	ld.const.f64 	%fd64, [%rd9+40];
	fma.rn.f64 	%fd10, %fd63, %fd9, %fd64;
	fma.rn.f64 	%fd131, %fd10, %fd130, %fd130;
	@%p5 bra 	BB89_8;

	mov.f64 	%fd65, 0d3FF0000000000000;
	fma.rn.f64 	%fd131, %fd10, %fd9, %fd65;

BB89_8:
	and.b32  	%r19, %r5, 2;
	setp.eq.s32	%p6, %r19, 0;
	@%p6 bra 	BB89_10;

	mov.f64 	%fd66, 0d0000000000000000;
	mov.f64 	%fd67, 0dBFF0000000000000;
	fma.rn.f64 	%fd131, %fd131, %fd67, %fd66;

BB89_10:
	mov.f64 	%fd133, %fd2;
	@%p2 bra 	BB89_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd2;
	}
	setp.ne.s32	%p8, %r20, 0;
	mov.f64 	%fd133, %fd2;
	@%p8 bra 	BB89_13;

	mov.f64 	%fd68, 0d0000000000000000;
	mul.rn.f64 	%fd133, %fd2, %fd68;

BB89_13:
	mul.f64 	%fd69, %fd133, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r40, %fd69;
	st.local.u32 	[%rd1], %r40;
	cvt.rn.f64.s32	%fd70, %r40;
	neg.f64 	%fd71, %fd70;
	fma.rn.f64 	%fd73, %fd71, %fd48, %fd133;
	fma.rn.f64 	%fd75, %fd71, %fd50, %fd73;
	fma.rn.f64 	%fd134, %fd71, %fd52, %fd75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd133;
	}
	and.b32  	%r22, %r21, 2145386496;
	mul.f64 	%fd77, %fd2, %fd36;
	mul.f64 	%fd19, %fd77, %fd1;
	setp.lt.u32	%p9, %r22, 1105199104;
	@%p9 bra 	BB89_15;

	// Callseq Start 188
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd133;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd134, [retval0+0];
	
	//{
	}// Callseq End 188
	ld.local.u32 	%r40, [%rd1];

BB89_15:
	and.b32  	%r23, %r40, 1;
	shl.b32 	%r24, %r23, 3;
	setp.eq.s32	%p10, %r23, 0;
	selp.f64	%fd78, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	add.s32 	%r25, %r24, 1;
	mul.wide.s32 	%rd11, %r25, 8;
	add.s64 	%rd13, %rd8, %rd11;
	ld.const.f64 	%fd79, [%rd13];
	mul.rn.f64 	%fd22, %fd134, %fd134;
	fma.rn.f64 	%fd80, %fd78, %fd22, %fd79;
	ld.const.f64 	%fd81, [%rd13+8];
	fma.rn.f64 	%fd82, %fd80, %fd22, %fd81;
	ld.const.f64 	%fd83, [%rd13+16];
	fma.rn.f64 	%fd84, %fd82, %fd22, %fd83;
	ld.const.f64 	%fd85, [%rd13+24];
	fma.rn.f64 	%fd86, %fd84, %fd22, %fd85;
	ld.const.f64 	%fd87, [%rd13+32];
	fma.rn.f64 	%fd88, %fd86, %fd22, %fd87;
	ld.const.f64 	%fd89, [%rd13+40];
	fma.rn.f64 	%fd23, %fd88, %fd22, %fd89;
	fma.rn.f64 	%fd135, %fd23, %fd134, %fd134;
	@%p10 bra 	BB89_17;

	mov.f64 	%fd90, 0d3FF0000000000000;
	fma.rn.f64 	%fd135, %fd23, %fd22, %fd90;

BB89_17:
	and.b32  	%r26, %r40, 2;
	setp.eq.s32	%p11, %r26, 0;
	@%p11 bra 	BB89_19;

	mov.f64 	%fd91, 0d0000000000000000;
	mov.f64 	%fd92, 0dBFF0000000000000;
	fma.rn.f64 	%fd135, %fd135, %fd92, %fd91;

BB89_19:
	mul.f64 	%fd93, %fd19, %fd135;
	mul.f64 	%fd94, %fd131, %fd36;
	sub.f64 	%fd29, %fd94, %fd93;
	mov.f64 	%fd95, 0d4338000000000000;
	mov.f64 	%fd96, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd97, %fd3, %fd96, %fd95;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd97;
	}
	mov.f64 	%fd98, 0dC338000000000000;
	add.rn.f64 	%fd99, %fd97, %fd98;
	mov.f64 	%fd100, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd101, %fd99, %fd100, %fd3;
	mov.f64 	%fd102, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd103, %fd99, %fd102, %fd101;
	mov.f64 	%fd104, 0d3E928AF3FCA213EA;
	mov.f64 	%fd105, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd106, %fd105, %fd103, %fd104;
	mov.f64 	%fd107, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd108, %fd106, %fd103, %fd107;
	mov.f64 	%fd109, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd110, %fd108, %fd103, %fd109;
	mov.f64 	%fd111, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd112, %fd110, %fd103, %fd111;
	mov.f64 	%fd113, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd114, %fd112, %fd103, %fd113;
	mov.f64 	%fd115, 0d3F81111111122322;
	fma.rn.f64 	%fd116, %fd114, %fd103, %fd115;
	mov.f64 	%fd117, 0d3FA55555555502A1;
	fma.rn.f64 	%fd118, %fd116, %fd103, %fd117;
	mov.f64 	%fd119, 0d3FC5555555555511;
	fma.rn.f64 	%fd120, %fd118, %fd103, %fd119;
	mov.f64 	%fd121, 0d3FE000000000000B;
	fma.rn.f64 	%fd122, %fd120, %fd103, %fd121;
	mov.f64 	%fd123, 0d3FF0000000000000;
	fma.rn.f64 	%fd124, %fd122, %fd103, %fd123;
	fma.rn.f64 	%fd125, %fd124, %fd103, %fd123;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd125;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd125;
	}
	shl.b32 	%r27, %r9, 20;
	add.s32 	%r28, %r11, %r27;
	mov.b64 	%fd137, {%r10, %r28};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd3;
	}
	mov.b32 	 %f2, %r29;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p12, %f1, 0f4086232B;
	@%p12 bra 	BB89_22;

	setp.lt.f64	%p13, %fd3, 0d0000000000000000;
	add.f64 	%fd126, %fd3, 0d7FF0000000000000;
	selp.f64	%fd137, 0d0000000000000000, %fd126, %p13;
	setp.geu.f32	%p14, %f1, 0f40874800;
	@%p14 bra 	BB89_22;

	shr.u32 	%r30, %r9, 31;
	add.s32 	%r31, %r9, %r30;
	shr.s32 	%r32, %r31, 1;
	shl.b32 	%r33, %r32, 20;
	add.s32 	%r34, %r33, %r11;
	mov.b64 	%fd127, {%r10, %r34};
	sub.s32 	%r35, %r9, %r32;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, 1072693248;
	mov.u32 	%r38, 0;
	mov.b64 	%fd128, {%r38, %r37};
	mul.f64 	%fd137, %fd127, %fd128;

BB89_22:
	mul.f64 	%fd138, %fd29, %fd137;

BB89_23:
	st.param.f64	[func_retval0+0], %fd138;
	ret;
}

	// .globl	_Z17GaussianWindow_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17GaussianWindow_omddPdiPii(
	.param .b64 _Z17GaussianWindow_omddPdiPii_param_0,
	.param .b64 _Z17GaussianWindow_omddPdiPii_param_1,
	.param .b64 _Z17GaussianWindow_omddPdiPii_param_2,
	.param .b32 _Z17GaussianWindow_omddPdiPii_param_3,
	.param .b64 _Z17GaussianWindow_omddPdiPii_param_4,
	.param .b32 _Z17GaussianWindow_omddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot90[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<139>;
	.reg .b64 	%rd<14>;


	mov.u64 	%SPL, __local_depot90;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd38, [_Z17GaussianWindow_omddPdiPii_param_0];
	ld.param.f64 	%fd36, [_Z17GaussianWindow_omddPdiPii_param_1];
	ld.param.u64 	%rd3, [_Z17GaussianWindow_omddPdiPii_param_2];
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd4;
	add.u64 	%rd5, %SP, 4;
	cvta.to.local.u64 	%rd2, %rd5;
	ld.f64 	%fd39, [%rd3+8];
	mul.f64 	%fd40, %fd39, %fd39;
	rcp.rn.f64 	%fd1, %fd40;
	mul.f64 	%fd2, %fd38, %fd36;
	mul.f64 	%fd41, %fd2, 0dBFE0000000000000;
	mul.f64 	%fd42, %fd2, %fd41;
	mul.f64 	%fd3, %fd42, %fd1;
	ld.f64 	%fd43, [%rd3];
	mov.f64 	%fd138, 0d0000000000000000;
	setp.leu.f64	%p1, %fd3, %fd43;
	@%p1 bra 	BB90_23;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd2;
	}
	and.b32  	%r1, %r12, 2147483647;
	setp.ne.s32	%p2, %r1, 2146435072;
	mov.f64 	%fd129, %fd2;
	@%p2 bra 	BB90_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd2;
	}
	setp.ne.s32	%p3, %r13, 0;
	mov.f64 	%fd129, %fd2;
	@%p3 bra 	BB90_4;

	mov.f64 	%fd44, 0d0000000000000000;
	mul.rn.f64 	%fd129, %fd2, %fd44;

BB90_4:
	mul.f64 	%fd45, %fd129, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r39, %fd45;
	st.local.u32 	[%rd2], %r39;
	cvt.rn.f64.s32	%fd46, %r39;
	neg.f64 	%fd47, %fd46;
	mov.f64 	%fd48, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd49, %fd47, %fd48, %fd129;
	mov.f64 	%fd50, 0d3C91A62633145C00;
	fma.rn.f64 	%fd51, %fd47, %fd50, %fd49;
	mov.f64 	%fd52, 0d397B839A252049C0;
	fma.rn.f64 	%fd130, %fd47, %fd52, %fd51;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd129;
	}
	and.b32  	%r15, %r14, 2145386496;
	setp.lt.u32	%p4, %r15, 1105199104;
	@%p4 bra 	BB90_6;

	// Callseq Start 189
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd129;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd130, [retval0+0];
	
	//{
	}// Callseq End 189
	ld.local.u32 	%r39, [%rd2];

BB90_6:
	add.s32 	%r5, %r39, 1;
	and.b32  	%r16, %r5, 1;
	shl.b32 	%r17, %r16, 3;
	setp.eq.s32	%p5, %r16, 0;
	selp.f64	%fd53, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p5;
	add.s32 	%r18, %r17, 1;
	mul.wide.s32 	%rd7, %r18, 8;
	mov.u64 	%rd8, __cudart_sin_cos_coeffs;
	add.s64 	%rd9, %rd8, %rd7;
	ld.const.f64 	%fd54, [%rd9];
	mul.rn.f64 	%fd9, %fd130, %fd130;
	fma.rn.f64 	%fd55, %fd53, %fd9, %fd54;
	ld.const.f64 	%fd56, [%rd9+8];
	fma.rn.f64 	%fd57, %fd55, %fd9, %fd56;
	ld.const.f64 	%fd58, [%rd9+16];
	fma.rn.f64 	%fd59, %fd57, %fd9, %fd58;
	ld.const.f64 	%fd60, [%rd9+24];
	fma.rn.f64 	%fd61, %fd59, %fd9, %fd60;
	ld.const.f64 	%fd62, [%rd9+32];
	fma.rn.f64 	%fd63, %fd61, %fd9, %fd62;
	ld.const.f64 	%fd64, [%rd9+40];
	fma.rn.f64 	%fd10, %fd63, %fd9, %fd64;
	fma.rn.f64 	%fd131, %fd10, %fd130, %fd130;
	@%p5 bra 	BB90_8;

	mov.f64 	%fd65, 0d3FF0000000000000;
	fma.rn.f64 	%fd131, %fd10, %fd9, %fd65;

BB90_8:
	and.b32  	%r19, %r5, 2;
	setp.eq.s32	%p6, %r19, 0;
	@%p6 bra 	BB90_10;

	mov.f64 	%fd66, 0d0000000000000000;
	mov.f64 	%fd67, 0dBFF0000000000000;
	fma.rn.f64 	%fd131, %fd131, %fd67, %fd66;

BB90_10:
	mov.f64 	%fd133, %fd2;
	@%p2 bra 	BB90_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd2;
	}
	setp.ne.s32	%p8, %r20, 0;
	mov.f64 	%fd133, %fd2;
	@%p8 bra 	BB90_13;

	mov.f64 	%fd68, 0d0000000000000000;
	mul.rn.f64 	%fd133, %fd2, %fd68;

BB90_13:
	mul.f64 	%fd69, %fd133, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r40, %fd69;
	st.local.u32 	[%rd1], %r40;
	cvt.rn.f64.s32	%fd70, %r40;
	neg.f64 	%fd71, %fd70;
	fma.rn.f64 	%fd73, %fd71, %fd48, %fd133;
	fma.rn.f64 	%fd75, %fd71, %fd50, %fd73;
	fma.rn.f64 	%fd134, %fd71, %fd52, %fd75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd133;
	}
	and.b32  	%r22, %r21, 2145386496;
	mul.f64 	%fd77, %fd2, %fd36;
	mul.f64 	%fd19, %fd77, %fd1;
	setp.lt.u32	%p9, %r22, 1105199104;
	@%p9 bra 	BB90_15;

	// Callseq Start 190
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd133;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd134, [retval0+0];
	
	//{
	}// Callseq End 190
	ld.local.u32 	%r40, [%rd1];

BB90_15:
	and.b32  	%r23, %r40, 1;
	shl.b32 	%r24, %r23, 3;
	setp.eq.s32	%p10, %r23, 0;
	selp.f64	%fd78, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	add.s32 	%r25, %r24, 1;
	mul.wide.s32 	%rd11, %r25, 8;
	add.s64 	%rd13, %rd8, %rd11;
	ld.const.f64 	%fd79, [%rd13];
	mul.rn.f64 	%fd22, %fd134, %fd134;
	fma.rn.f64 	%fd80, %fd78, %fd22, %fd79;
	ld.const.f64 	%fd81, [%rd13+8];
	fma.rn.f64 	%fd82, %fd80, %fd22, %fd81;
	ld.const.f64 	%fd83, [%rd13+16];
	fma.rn.f64 	%fd84, %fd82, %fd22, %fd83;
	ld.const.f64 	%fd85, [%rd13+24];
	fma.rn.f64 	%fd86, %fd84, %fd22, %fd85;
	ld.const.f64 	%fd87, [%rd13+32];
	fma.rn.f64 	%fd88, %fd86, %fd22, %fd87;
	ld.const.f64 	%fd89, [%rd13+40];
	fma.rn.f64 	%fd23, %fd88, %fd22, %fd89;
	fma.rn.f64 	%fd135, %fd23, %fd134, %fd134;
	@%p10 bra 	BB90_17;

	mov.f64 	%fd90, 0d3FF0000000000000;
	fma.rn.f64 	%fd135, %fd23, %fd22, %fd90;

BB90_17:
	and.b32  	%r26, %r40, 2;
	setp.eq.s32	%p11, %r26, 0;
	@%p11 bra 	BB90_19;

	mov.f64 	%fd91, 0d0000000000000000;
	mov.f64 	%fd92, 0dBFF0000000000000;
	fma.rn.f64 	%fd135, %fd135, %fd92, %fd91;

BB90_19:
	mul.f64 	%fd93, %fd19, %fd135;
	mul.f64 	%fd94, %fd131, %fd36;
	sub.f64 	%fd29, %fd94, %fd93;
	mov.f64 	%fd95, 0d4338000000000000;
	mov.f64 	%fd96, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd97, %fd3, %fd96, %fd95;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd97;
	}
	mov.f64 	%fd98, 0dC338000000000000;
	add.rn.f64 	%fd99, %fd97, %fd98;
	mov.f64 	%fd100, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd101, %fd99, %fd100, %fd3;
	mov.f64 	%fd102, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd103, %fd99, %fd102, %fd101;
	mov.f64 	%fd104, 0d3E928AF3FCA213EA;
	mov.f64 	%fd105, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd106, %fd105, %fd103, %fd104;
	mov.f64 	%fd107, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd108, %fd106, %fd103, %fd107;
	mov.f64 	%fd109, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd110, %fd108, %fd103, %fd109;
	mov.f64 	%fd111, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd112, %fd110, %fd103, %fd111;
	mov.f64 	%fd113, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd114, %fd112, %fd103, %fd113;
	mov.f64 	%fd115, 0d3F81111111122322;
	fma.rn.f64 	%fd116, %fd114, %fd103, %fd115;
	mov.f64 	%fd117, 0d3FA55555555502A1;
	fma.rn.f64 	%fd118, %fd116, %fd103, %fd117;
	mov.f64 	%fd119, 0d3FC5555555555511;
	fma.rn.f64 	%fd120, %fd118, %fd103, %fd119;
	mov.f64 	%fd121, 0d3FE000000000000B;
	fma.rn.f64 	%fd122, %fd120, %fd103, %fd121;
	mov.f64 	%fd123, 0d3FF0000000000000;
	fma.rn.f64 	%fd124, %fd122, %fd103, %fd123;
	fma.rn.f64 	%fd125, %fd124, %fd103, %fd123;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd125;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd125;
	}
	shl.b32 	%r27, %r9, 20;
	add.s32 	%r28, %r11, %r27;
	mov.b64 	%fd137, {%r10, %r28};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd3;
	}
	mov.b32 	 %f2, %r29;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p12, %f1, 0f4086232B;
	@%p12 bra 	BB90_22;

	setp.lt.f64	%p13, %fd3, 0d0000000000000000;
	add.f64 	%fd126, %fd3, 0d7FF0000000000000;
	selp.f64	%fd137, 0d0000000000000000, %fd126, %p13;
	setp.geu.f32	%p14, %f1, 0f40874800;
	@%p14 bra 	BB90_22;

	shr.u32 	%r30, %r9, 31;
	add.s32 	%r31, %r9, %r30;
	shr.s32 	%r32, %r31, 1;
	shl.b32 	%r33, %r32, 20;
	add.s32 	%r34, %r33, %r11;
	mov.b64 	%fd127, {%r10, %r34};
	sub.s32 	%r35, %r9, %r32;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, 1072693248;
	mov.u32 	%r38, 0;
	mov.b64 	%fd128, {%r38, %r37};
	mul.f64 	%fd137, %fd127, %fd128;

BB90_22:
	mul.f64 	%fd138, %fd29, %fd137;

BB90_23:
	st.param.f64	[func_retval0+0], %fd138;
	ret;
}

	// .globl	_Z17GaussianWindow_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17GaussianWindow_ttddPdiPii(
	.param .b64 _Z17GaussianWindow_ttddPdiPii_param_0,
	.param .b64 _Z17GaussianWindow_ttddPdiPii_param_1,
	.param .b64 _Z17GaussianWindow_ttddPdiPii_param_2,
	.param .b32 _Z17GaussianWindow_ttddPdiPii_param_3,
	.param .b64 _Z17GaussianWindow_ttddPdiPii_param_4,
	.param .b32 _Z17GaussianWindow_ttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot91[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<149>;
	.reg .b64 	%rd<14>;


	mov.u64 	%SPL, __local_depot91;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd38, [_Z17GaussianWindow_ttddPdiPii_param_0];
	ld.param.f64 	%fd40, [_Z17GaussianWindow_ttddPdiPii_param_1];
	ld.param.u64 	%rd3, [_Z17GaussianWindow_ttddPdiPii_param_2];
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd4;
	add.u64 	%rd5, %SP, 4;
	cvta.to.local.u64 	%rd2, %rd5;
	ld.f64 	%fd41, [%rd3+8];
	mul.f64 	%fd42, %fd41, %fd41;
	rcp.rn.f64 	%fd1, %fd42;
	mul.f64 	%fd2, %fd38, %fd40;
	mul.f64 	%fd43, %fd2, 0dBFE0000000000000;
	mul.f64 	%fd44, %fd2, %fd43;
	mul.f64 	%fd3, %fd44, %fd1;
	ld.f64 	%fd45, [%rd3];
	mov.f64 	%fd148, 0d0000000000000000;
	setp.leu.f64	%p1, %fd3, %fd45;
	@%p1 bra 	BB91_23;

	mul.f64 	%fd46, %fd38, %fd38;
	neg.f64 	%fd47, %fd46;
	mul.f64 	%fd48, %fd46, %fd1;
	sub.f64 	%fd49, %fd47, %fd48;
	mul.f64 	%fd50, %fd46, %fd2;
	mul.f64 	%fd51, %fd2, %fd50;
	mul.f64 	%fd52, %fd51, %fd1;
	fma.rn.f64 	%fd4, %fd1, %fd52, %fd49;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd2;
	}
	and.b32  	%r1, %r12, 2147483647;
	setp.ne.s32	%p2, %r1, 2146435072;
	mov.f64 	%fd139, %fd2;
	@%p2 bra 	BB91_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd2;
	}
	setp.ne.s32	%p3, %r13, 0;
	mov.f64 	%fd139, %fd2;
	@%p3 bra 	BB91_4;

	mov.f64 	%fd53, 0d0000000000000000;
	mul.rn.f64 	%fd139, %fd2, %fd53;

BB91_4:
	mul.f64 	%fd54, %fd139, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r39, %fd54;
	st.local.u32 	[%rd2], %r39;
	cvt.rn.f64.s32	%fd55, %r39;
	neg.f64 	%fd56, %fd55;
	mov.f64 	%fd57, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd58, %fd56, %fd57, %fd139;
	mov.f64 	%fd59, 0d3C91A62633145C00;
	fma.rn.f64 	%fd60, %fd56, %fd59, %fd58;
	mov.f64 	%fd61, 0d397B839A252049C0;
	fma.rn.f64 	%fd140, %fd56, %fd61, %fd60;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd139;
	}
	and.b32  	%r15, %r14, 2145386496;
	setp.lt.u32	%p4, %r15, 1105199104;
	@%p4 bra 	BB91_6;

	// Callseq Start 191
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd139;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd140, [retval0+0];
	
	//{
	}// Callseq End 191
	ld.local.u32 	%r39, [%rd2];

BB91_6:
	and.b32  	%r16, %r39, 1;
	shl.b32 	%r17, %r16, 3;
	setp.eq.s32	%p5, %r16, 0;
	selp.f64	%fd62, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p5;
	add.s32 	%r18, %r17, 1;
	mul.wide.s32 	%rd7, %r18, 8;
	mov.u64 	%rd8, __cudart_sin_cos_coeffs;
	add.s64 	%rd9, %rd8, %rd7;
	ld.const.f64 	%fd63, [%rd9];
	mul.rn.f64 	%fd10, %fd140, %fd140;
	fma.rn.f64 	%fd64, %fd62, %fd10, %fd63;
	ld.const.f64 	%fd65, [%rd9+8];
	fma.rn.f64 	%fd66, %fd64, %fd10, %fd65;
	ld.const.f64 	%fd67, [%rd9+16];
	fma.rn.f64 	%fd68, %fd66, %fd10, %fd67;
	ld.const.f64 	%fd69, [%rd9+24];
	fma.rn.f64 	%fd70, %fd68, %fd10, %fd69;
	ld.const.f64 	%fd71, [%rd9+32];
	fma.rn.f64 	%fd72, %fd70, %fd10, %fd71;
	ld.const.f64 	%fd73, [%rd9+40];
	fma.rn.f64 	%fd11, %fd72, %fd10, %fd73;
	fma.rn.f64 	%fd141, %fd11, %fd140, %fd140;
	@%p5 bra 	BB91_8;

	mov.f64 	%fd74, 0d3FF0000000000000;
	fma.rn.f64 	%fd141, %fd11, %fd10, %fd74;

BB91_8:
	and.b32  	%r19, %r39, 2;
	setp.eq.s32	%p6, %r19, 0;
	@%p6 bra 	BB91_10;

	mov.f64 	%fd75, 0d0000000000000000;
	mov.f64 	%fd76, 0dBFF0000000000000;
	fma.rn.f64 	%fd141, %fd141, %fd76, %fd75;

BB91_10:
	mul.f64 	%fd17, %fd4, %fd141;
	mov.f64 	%fd143, %fd2;
	@%p2 bra 	BB91_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd2;
	}
	setp.ne.s32	%p8, %r20, 0;
	mov.f64 	%fd143, %fd2;
	@%p8 bra 	BB91_13;

	mov.f64 	%fd77, 0d0000000000000000;
	mul.rn.f64 	%fd143, %fd2, %fd77;

BB91_13:
	mul.f64 	%fd78, %fd143, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r40, %fd78;
	st.local.u32 	[%rd1], %r40;
	cvt.rn.f64.s32	%fd79, %r40;
	neg.f64 	%fd80, %fd79;
	fma.rn.f64 	%fd82, %fd80, %fd57, %fd143;
	fma.rn.f64 	%fd84, %fd80, %fd59, %fd82;
	fma.rn.f64 	%fd144, %fd80, %fd61, %fd84;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd143;
	}
	and.b32  	%r22, %r21, 2145386496;
	add.f64 	%fd86, %fd2, %fd2;
	mul.f64 	%fd87, %fd86, %fd38;
	mul.f64 	%fd88, %fd87, %fd38;
	mul.f64 	%fd21, %fd88, %fd1;
	setp.lt.u32	%p9, %r22, 1105199104;
	@%p9 bra 	BB91_15;

	// Callseq Start 192
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd143;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd144, [retval0+0];
	
	//{
	}// Callseq End 192
	ld.local.u32 	%r40, [%rd1];

BB91_15:
	add.s32 	%r8, %r40, 1;
	and.b32  	%r23, %r8, 1;
	shl.b32 	%r24, %r23, 3;
	setp.eq.s32	%p10, %r23, 0;
	selp.f64	%fd89, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	add.s32 	%r25, %r24, 1;
	mul.wide.s32 	%rd11, %r25, 8;
	add.s64 	%rd13, %rd8, %rd11;
	ld.const.f64 	%fd90, [%rd13];
	mul.rn.f64 	%fd24, %fd144, %fd144;
	fma.rn.f64 	%fd91, %fd89, %fd24, %fd90;
	ld.const.f64 	%fd92, [%rd13+8];
	fma.rn.f64 	%fd93, %fd91, %fd24, %fd92;
	ld.const.f64 	%fd94, [%rd13+16];
	fma.rn.f64 	%fd95, %fd93, %fd24, %fd94;
	ld.const.f64 	%fd96, [%rd13+24];
	fma.rn.f64 	%fd97, %fd95, %fd24, %fd96;
	ld.const.f64 	%fd98, [%rd13+32];
	fma.rn.f64 	%fd99, %fd97, %fd24, %fd98;
	ld.const.f64 	%fd100, [%rd13+40];
	fma.rn.f64 	%fd25, %fd99, %fd24, %fd100;
	fma.rn.f64 	%fd145, %fd25, %fd144, %fd144;
	@%p10 bra 	BB91_17;

	mov.f64 	%fd101, 0d3FF0000000000000;
	fma.rn.f64 	%fd145, %fd25, %fd24, %fd101;

BB91_17:
	and.b32  	%r26, %r8, 2;
	setp.eq.s32	%p11, %r26, 0;
	@%p11 bra 	BB91_19;

	mov.f64 	%fd102, 0d0000000000000000;
	mov.f64 	%fd103, 0dBFF0000000000000;
	fma.rn.f64 	%fd145, %fd145, %fd103, %fd102;

BB91_19:
	mul.f64 	%fd104, %fd21, %fd145;
	sub.f64 	%fd31, %fd17, %fd104;
	mov.f64 	%fd105, 0d4338000000000000;
	mov.f64 	%fd106, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd107, %fd3, %fd106, %fd105;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd107;
	}
	mov.f64 	%fd108, 0dC338000000000000;
	add.rn.f64 	%fd109, %fd107, %fd108;
	mov.f64 	%fd110, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd111, %fd109, %fd110, %fd3;
	mov.f64 	%fd112, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd113, %fd109, %fd112, %fd111;
	mov.f64 	%fd114, 0d3E928AF3FCA213EA;
	mov.f64 	%fd115, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd116, %fd115, %fd113, %fd114;
	mov.f64 	%fd117, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd118, %fd116, %fd113, %fd117;
	mov.f64 	%fd119, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd120, %fd118, %fd113, %fd119;
	mov.f64 	%fd121, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd122, %fd120, %fd113, %fd121;
	mov.f64 	%fd123, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd124, %fd122, %fd113, %fd123;
	mov.f64 	%fd125, 0d3F81111111122322;
	fma.rn.f64 	%fd126, %fd124, %fd113, %fd125;
	mov.f64 	%fd127, 0d3FA55555555502A1;
	fma.rn.f64 	%fd128, %fd126, %fd113, %fd127;
	mov.f64 	%fd129, 0d3FC5555555555511;
	fma.rn.f64 	%fd130, %fd128, %fd113, %fd129;
	mov.f64 	%fd131, 0d3FE000000000000B;
	fma.rn.f64 	%fd132, %fd130, %fd113, %fd131;
	mov.f64 	%fd133, 0d3FF0000000000000;
	fma.rn.f64 	%fd134, %fd132, %fd113, %fd133;
	fma.rn.f64 	%fd135, %fd134, %fd113, %fd133;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd135;
	}
	shl.b32 	%r27, %r9, 20;
	add.s32 	%r28, %r11, %r27;
	mov.b64 	%fd147, {%r10, %r28};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd3;
	}
	mov.b32 	 %f2, %r29;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p12, %f1, 0f4086232B;
	@%p12 bra 	BB91_22;

	setp.lt.f64	%p13, %fd3, 0d0000000000000000;
	add.f64 	%fd136, %fd3, 0d7FF0000000000000;
	selp.f64	%fd147, 0d0000000000000000, %fd136, %p13;
	setp.geu.f32	%p14, %f1, 0f40874800;
	@%p14 bra 	BB91_22;

	shr.u32 	%r30, %r9, 31;
	add.s32 	%r31, %r9, %r30;
	shr.s32 	%r32, %r31, 1;
	shl.b32 	%r33, %r32, 20;
	add.s32 	%r34, %r33, %r11;
	mov.b64 	%fd137, {%r10, %r34};
	sub.s32 	%r35, %r9, %r32;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, 1072693248;
	mov.u32 	%r38, 0;
	mov.b64 	%fd138, {%r38, %r37};
	mul.f64 	%fd147, %fd137, %fd138;

BB91_22:
	mul.f64 	%fd148, %fd31, %fd147;

BB91_23:
	st.param.f64	[func_retval0+0], %fd148;
	ret;
}

	// .globl	_Z18GaussianWindow_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z18GaussianWindow_tttddPdiPii(
	.param .b64 _Z18GaussianWindow_tttddPdiPii_param_0,
	.param .b64 _Z18GaussianWindow_tttddPdiPii_param_1,
	.param .b64 _Z18GaussianWindow_tttddPdiPii_param_2,
	.param .b32 _Z18GaussianWindow_tttddPdiPii_param_3,
	.param .b64 _Z18GaussianWindow_tttddPdiPii_param_4,
	.param .b32 _Z18GaussianWindow_tttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot92[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<156>;
	.reg .b64 	%rd<14>;


	mov.u64 	%SPL, __local_depot92;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd37, [_Z18GaussianWindow_tttddPdiPii_param_0];
	ld.param.f64 	%fd39, [_Z18GaussianWindow_tttddPdiPii_param_1];
	ld.param.u64 	%rd3, [_Z18GaussianWindow_tttddPdiPii_param_2];
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd4;
	add.u64 	%rd5, %SP, 4;
	cvta.to.local.u64 	%rd2, %rd5;
	ld.f64 	%fd40, [%rd3+8];
	mul.f64 	%fd41, %fd40, %fd40;
	rcp.rn.f64 	%fd1, %fd41;
	mul.f64 	%fd2, %fd37, %fd39;
	mul.f64 	%fd42, %fd2, 0dBFE0000000000000;
	mul.f64 	%fd43, %fd2, %fd42;
	mul.f64 	%fd3, %fd43, %fd1;
	ld.f64 	%fd44, [%rd3];
	mov.f64 	%fd155, 0d0000000000000000;
	setp.leu.f64	%p1, %fd3, %fd44;
	@%p1 bra 	BB92_23;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd2;
	}
	and.b32  	%r1, %r12, 2147483647;
	setp.ne.s32	%p2, %r1, 2146435072;
	mov.f64 	%fd146, %fd2;
	@%p2 bra 	BB92_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd2;
	}
	setp.ne.s32	%p3, %r13, 0;
	mov.f64 	%fd146, %fd2;
	@%p3 bra 	BB92_4;

	mov.f64 	%fd45, 0d0000000000000000;
	mul.rn.f64 	%fd146, %fd2, %fd45;

BB92_4:
	mul.f64 	%fd46, %fd146, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r39, %fd46;
	st.local.u32 	[%rd2], %r39;
	cvt.rn.f64.s32	%fd47, %r39;
	neg.f64 	%fd48, %fd47;
	mov.f64 	%fd49, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd50, %fd48, %fd49, %fd146;
	mov.f64 	%fd51, 0d3C91A62633145C00;
	fma.rn.f64 	%fd52, %fd48, %fd51, %fd50;
	mov.f64 	%fd53, 0d397B839A252049C0;
	fma.rn.f64 	%fd147, %fd48, %fd53, %fd52;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd146;
	}
	and.b32  	%r15, %r14, 2145386496;
	setp.lt.u32	%p4, %r15, 1105199104;
	@%p4 bra 	BB92_6;

	// Callseq Start 193
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd146;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd147, [retval0+0];
	
	//{
	}// Callseq End 193
	ld.local.u32 	%r39, [%rd2];

BB92_6:
	and.b32  	%r16, %r39, 1;
	shl.b32 	%r17, %r16, 3;
	setp.eq.s32	%p5, %r16, 0;
	selp.f64	%fd54, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p5;
	add.s32 	%r18, %r17, 1;
	mul.wide.s32 	%rd7, %r18, 8;
	mov.u64 	%rd8, __cudart_sin_cos_coeffs;
	add.s64 	%rd9, %rd8, %rd7;
	ld.const.f64 	%fd55, [%rd9];
	mul.rn.f64 	%fd9, %fd147, %fd147;
	fma.rn.f64 	%fd56, %fd54, %fd9, %fd55;
	ld.const.f64 	%fd57, [%rd9+8];
	fma.rn.f64 	%fd58, %fd56, %fd9, %fd57;
	ld.const.f64 	%fd59, [%rd9+16];
	fma.rn.f64 	%fd60, %fd58, %fd9, %fd59;
	ld.const.f64 	%fd61, [%rd9+24];
	fma.rn.f64 	%fd62, %fd60, %fd9, %fd61;
	ld.const.f64 	%fd63, [%rd9+32];
	fma.rn.f64 	%fd64, %fd62, %fd9, %fd63;
	ld.const.f64 	%fd65, [%rd9+40];
	fma.rn.f64 	%fd10, %fd64, %fd9, %fd65;
	fma.rn.f64 	%fd148, %fd10, %fd147, %fd147;
	@%p5 bra 	BB92_8;

	mov.f64 	%fd66, 0d3FF0000000000000;
	fma.rn.f64 	%fd148, %fd10, %fd9, %fd66;

BB92_8:
	and.b32  	%r19, %r39, 2;
	setp.eq.s32	%p6, %r19, 0;
	@%p6 bra 	BB92_10;

	mov.f64 	%fd67, 0d0000000000000000;
	mov.f64 	%fd68, 0dBFF0000000000000;
	fma.rn.f64 	%fd148, %fd148, %fd68, %fd67;

BB92_10:
	mov.f64 	%fd150, %fd2;
	@%p2 bra 	BB92_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd2;
	}
	setp.ne.s32	%p8, %r20, 0;
	mov.f64 	%fd150, %fd2;
	@%p8 bra 	BB92_13;

	mov.f64 	%fd69, 0d0000000000000000;
	mul.rn.f64 	%fd150, %fd2, %fd69;

BB92_13:
	mul.f64 	%fd70, %fd37, %fd37;
	mul.f64 	%fd71, %fd70, %fd37;
	mul.f64 	%fd72, %fd2, 0d4008000000000000;
	mul.f64 	%fd73, %fd150, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r40, %fd73;
	st.local.u32 	[%rd1], %r40;
	cvt.rn.f64.s32	%fd74, %r40;
	neg.f64 	%fd75, %fd74;
	fma.rn.f64 	%fd77, %fd75, %fd49, %fd150;
	fma.rn.f64 	%fd79, %fd75, %fd51, %fd77;
	fma.rn.f64 	%fd151, %fd75, %fd53, %fd79;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd150;
	}
	and.b32  	%r22, %r21, 2145386496;
	mul.f64 	%fd81, %fd1, 0d4008000000000000;
	mul.f64 	%fd82, %fd2, %fd72;
	mul.f64 	%fd83, %fd82, %fd1;
	mul.f64 	%fd84, %fd1, %fd83;
	sub.f64 	%fd85, %fd84, %fd81;
	add.f64 	%fd86, %fd85, 0dBFF0000000000000;
	mul.f64 	%fd19, %fd71, %fd86;
	mul.f64 	%fd87, %fd2, %fd2;
	mul.f64 	%fd88, %fd2, %fd87;
	mul.f64 	%fd89, %fd88, %fd1;
	mul.f64 	%fd90, %fd1, %fd89;
	mul.f64 	%fd91, %fd1, %fd90;
	add.f64 	%fd92, %fd1, 0d3FF0000000000000;
	mul.f64 	%fd93, %fd72, %fd1;
	mul.f64 	%fd94, %fd93, %fd92;
	sub.f64 	%fd95, %fd94, %fd91;
	mul.f64 	%fd96, %fd71, %fd95;
	mul.f64 	%fd20, %fd96, %fd148;
	setp.lt.u32	%p9, %r22, 1105199104;
	@%p9 bra 	BB92_15;

	// Callseq Start 194
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd150;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd151, [retval0+0];
	
	//{
	}// Callseq End 194
	ld.local.u32 	%r40, [%rd1];

BB92_15:
	add.s32 	%r8, %r40, 1;
	and.b32  	%r23, %r8, 1;
	shl.b32 	%r24, %r23, 3;
	setp.eq.s32	%p10, %r23, 0;
	selp.f64	%fd97, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	add.s32 	%r25, %r24, 1;
	mul.wide.s32 	%rd11, %r25, 8;
	add.s64 	%rd13, %rd8, %rd11;
	ld.const.f64 	%fd98, [%rd13];
	mul.rn.f64 	%fd23, %fd151, %fd151;
	fma.rn.f64 	%fd99, %fd97, %fd23, %fd98;
	ld.const.f64 	%fd100, [%rd13+8];
	fma.rn.f64 	%fd101, %fd99, %fd23, %fd100;
	ld.const.f64 	%fd102, [%rd13+16];
	fma.rn.f64 	%fd103, %fd101, %fd23, %fd102;
	ld.const.f64 	%fd104, [%rd13+24];
	fma.rn.f64 	%fd105, %fd103, %fd23, %fd104;
	ld.const.f64 	%fd106, [%rd13+32];
	fma.rn.f64 	%fd107, %fd105, %fd23, %fd106;
	ld.const.f64 	%fd108, [%rd13+40];
	fma.rn.f64 	%fd24, %fd107, %fd23, %fd108;
	fma.rn.f64 	%fd152, %fd24, %fd151, %fd151;
	@%p10 bra 	BB92_17;

	mov.f64 	%fd109, 0d3FF0000000000000;
	fma.rn.f64 	%fd152, %fd24, %fd23, %fd109;

BB92_17:
	and.b32  	%r26, %r8, 2;
	setp.eq.s32	%p11, %r26, 0;
	@%p11 bra 	BB92_19;

	mov.f64 	%fd110, 0d0000000000000000;
	mov.f64 	%fd111, 0dBFF0000000000000;
	fma.rn.f64 	%fd152, %fd152, %fd111, %fd110;

BB92_19:
	fma.rn.f64 	%fd30, %fd19, %fd152, %fd20;
	mov.f64 	%fd112, 0d4338000000000000;
	mov.f64 	%fd113, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd114, %fd3, %fd113, %fd112;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd114;
	}
	mov.f64 	%fd115, 0dC338000000000000;
	add.rn.f64 	%fd116, %fd114, %fd115;
	mov.f64 	%fd117, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd118, %fd116, %fd117, %fd3;
	mov.f64 	%fd119, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd120, %fd116, %fd119, %fd118;
	mov.f64 	%fd121, 0d3E928AF3FCA213EA;
	mov.f64 	%fd122, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd123, %fd122, %fd120, %fd121;
	mov.f64 	%fd124, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd125, %fd123, %fd120, %fd124;
	mov.f64 	%fd126, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd127, %fd125, %fd120, %fd126;
	mov.f64 	%fd128, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd129, %fd127, %fd120, %fd128;
	mov.f64 	%fd130, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd131, %fd129, %fd120, %fd130;
	mov.f64 	%fd132, 0d3F81111111122322;
	fma.rn.f64 	%fd133, %fd131, %fd120, %fd132;
	mov.f64 	%fd134, 0d3FA55555555502A1;
	fma.rn.f64 	%fd135, %fd133, %fd120, %fd134;
	mov.f64 	%fd136, 0d3FC5555555555511;
	fma.rn.f64 	%fd137, %fd135, %fd120, %fd136;
	mov.f64 	%fd138, 0d3FE000000000000B;
	fma.rn.f64 	%fd139, %fd137, %fd120, %fd138;
	mov.f64 	%fd140, 0d3FF0000000000000;
	fma.rn.f64 	%fd141, %fd139, %fd120, %fd140;
	fma.rn.f64 	%fd142, %fd141, %fd120, %fd140;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd142;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd142;
	}
	shl.b32 	%r27, %r9, 20;
	add.s32 	%r28, %r11, %r27;
	mov.b64 	%fd154, {%r10, %r28};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd3;
	}
	mov.b32 	 %f2, %r29;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p12, %f1, 0f4086232B;
	@%p12 bra 	BB92_22;

	setp.lt.f64	%p13, %fd3, 0d0000000000000000;
	add.f64 	%fd143, %fd3, 0d7FF0000000000000;
	selp.f64	%fd154, 0d0000000000000000, %fd143, %p13;
	setp.geu.f32	%p14, %f1, 0f40874800;
	@%p14 bra 	BB92_22;

	shr.u32 	%r30, %r9, 31;
	add.s32 	%r31, %r9, %r30;
	shr.s32 	%r32, %r31, 1;
	shl.b32 	%r33, %r32, 20;
	add.s32 	%r34, %r33, %r11;
	mov.b64 	%fd144, {%r10, %r34};
	sub.s32 	%r35, %r9, %r32;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, 1072693248;
	mov.u32 	%r38, 0;
	mov.b64 	%fd145, {%r38, %r37};
	mul.f64 	%fd154, %fd144, %fd145;

BB92_22:
	mul.f64 	%fd155, %fd30, %fd154;

BB92_23:
	st.param.f64	[func_retval0+0], %fd155;
	ret;
}

	// .globl	_Z19GaussianWindow_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z19GaussianWindow_omttddPdiPii(
	.param .b64 _Z19GaussianWindow_omttddPdiPii_param_0,
	.param .b64 _Z19GaussianWindow_omttddPdiPii_param_1,
	.param .b64 _Z19GaussianWindow_omttddPdiPii_param_2,
	.param .b32 _Z19GaussianWindow_omttddPdiPii_param_3,
	.param .b64 _Z19GaussianWindow_omttddPdiPii_param_4,
	.param .b32 _Z19GaussianWindow_omttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot93[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<160>;
	.reg .b64 	%rd<14>;


	mov.u64 	%SPL, __local_depot93;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd38, [_Z19GaussianWindow_omttddPdiPii_param_0];
	ld.param.f64 	%fd40, [_Z19GaussianWindow_omttddPdiPii_param_1];
	ld.param.u64 	%rd3, [_Z19GaussianWindow_omttddPdiPii_param_2];
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd4;
	add.u64 	%rd5, %SP, 4;
	cvta.to.local.u64 	%rd2, %rd5;
	ld.f64 	%fd41, [%rd3+8];
	mul.f64 	%fd42, %fd41, %fd41;
	rcp.rn.f64 	%fd1, %fd42;
	mul.f64 	%fd2, %fd38, %fd40;
	mul.f64 	%fd43, %fd2, 0dBFE0000000000000;
	mul.f64 	%fd44, %fd2, %fd43;
	mul.f64 	%fd3, %fd44, %fd1;
	ld.f64 	%fd45, [%rd3];
	mov.f64 	%fd159, 0d0000000000000000;
	setp.leu.f64	%p1, %fd3, %fd45;
	@%p1 bra 	BB93_23;

	fma.rn.f64 	%fd46, %fd1, 0dC000000000000000, 0dC000000000000000;
	mul.f64 	%fd47, %fd1, 0d4008000000000000;
	mul.f64 	%fd48, %fd2, %fd47;
	fma.rn.f64 	%fd49, %fd2, %fd48, %fd46;
	mul.f64 	%fd50, %fd2, 0d4014000000000000;
	mul.f64 	%fd51, %fd2, %fd50;
	mul.f64 	%fd52, %fd51, %fd1;
	fma.rn.f64 	%fd4, %fd1, %fd52, %fd49;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd2;
	}
	and.b32  	%r1, %r12, 2147483647;
	setp.ne.s32	%p2, %r1, 2146435072;
	mov.f64 	%fd150, %fd2;
	@%p2 bra 	BB93_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd2;
	}
	setp.ne.s32	%p3, %r13, 0;
	mov.f64 	%fd150, %fd2;
	@%p3 bra 	BB93_4;

	mov.f64 	%fd53, 0d0000000000000000;
	mul.rn.f64 	%fd150, %fd2, %fd53;

BB93_4:
	mul.f64 	%fd54, %fd150, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r39, %fd54;
	st.local.u32 	[%rd2], %r39;
	cvt.rn.f64.s32	%fd55, %r39;
	neg.f64 	%fd56, %fd55;
	mov.f64 	%fd57, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd58, %fd56, %fd57, %fd150;
	mov.f64 	%fd59, 0d3C91A62633145C00;
	fma.rn.f64 	%fd60, %fd56, %fd59, %fd58;
	mov.f64 	%fd61, 0d397B839A252049C0;
	fma.rn.f64 	%fd151, %fd56, %fd61, %fd60;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd150;
	}
	and.b32  	%r15, %r14, 2145386496;
	setp.lt.u32	%p4, %r15, 1105199104;
	@%p4 bra 	BB93_6;

	// Callseq Start 195
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd150;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd151, [retval0+0];
	
	//{
	}// Callseq End 195
	ld.local.u32 	%r39, [%rd2];

BB93_6:
	and.b32  	%r16, %r39, 1;
	shl.b32 	%r17, %r16, 3;
	setp.eq.s32	%p5, %r16, 0;
	selp.f64	%fd62, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p5;
	add.s32 	%r18, %r17, 1;
	mul.wide.s32 	%rd7, %r18, 8;
	mov.u64 	%rd8, __cudart_sin_cos_coeffs;
	add.s64 	%rd9, %rd8, %rd7;
	ld.const.f64 	%fd63, [%rd9];
	mul.rn.f64 	%fd10, %fd151, %fd151;
	fma.rn.f64 	%fd64, %fd62, %fd10, %fd63;
	ld.const.f64 	%fd65, [%rd9+8];
	fma.rn.f64 	%fd66, %fd64, %fd10, %fd65;
	ld.const.f64 	%fd67, [%rd9+16];
	fma.rn.f64 	%fd68, %fd66, %fd10, %fd67;
	ld.const.f64 	%fd69, [%rd9+24];
	fma.rn.f64 	%fd70, %fd68, %fd10, %fd69;
	ld.const.f64 	%fd71, [%rd9+32];
	fma.rn.f64 	%fd72, %fd70, %fd10, %fd71;
	ld.const.f64 	%fd73, [%rd9+40];
	fma.rn.f64 	%fd11, %fd72, %fd10, %fd73;
	fma.rn.f64 	%fd152, %fd11, %fd151, %fd151;
	@%p5 bra 	BB93_8;

	mov.f64 	%fd74, 0d3FF0000000000000;
	fma.rn.f64 	%fd152, %fd11, %fd10, %fd74;

BB93_8:
	and.b32  	%r19, %r39, 2;
	setp.eq.s32	%p6, %r19, 0;
	@%p6 bra 	BB93_10;

	mov.f64 	%fd75, 0d0000000000000000;
	mov.f64 	%fd76, 0dBFF0000000000000;
	fma.rn.f64 	%fd152, %fd152, %fd76, %fd75;

BB93_10:
	mul.f64 	%fd77, %fd2, %fd2;
	mul.f64 	%fd78, %fd2, %fd77;
	mul.f64 	%fd79, %fd2, %fd78;
	mul.f64 	%fd80, %fd79, %fd1;
	mul.f64 	%fd81, %fd1, %fd80;
	mul.f64 	%fd82, %fd1, %fd81;
	sub.f64 	%fd83, %fd4, %fd82;
	mul.f64 	%fd84, %fd83, %fd38;
	mul.f64 	%fd17, %fd84, %fd152;
	mov.f64 	%fd154, %fd2;
	@%p2 bra 	BB93_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd2;
	}
	setp.ne.s32	%p8, %r20, 0;
	mov.f64 	%fd154, %fd2;
	@%p8 bra 	BB93_13;

	mov.f64 	%fd85, 0d0000000000000000;
	mul.rn.f64 	%fd154, %fd2, %fd85;

BB93_13:
	mul.f64 	%fd86, %fd154, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r40, %fd86;
	st.local.u32 	[%rd1], %r40;
	cvt.rn.f64.s32	%fd87, %r40;
	neg.f64 	%fd88, %fd87;
	fma.rn.f64 	%fd90, %fd88, %fd57, %fd154;
	fma.rn.f64 	%fd92, %fd88, %fd59, %fd90;
	fma.rn.f64 	%fd155, %fd88, %fd61, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd154;
	}
	and.b32  	%r22, %r21, 2145386496;
	mul.f64 	%fd94, %fd2, %fd38;
	mul.f64 	%fd95, %fd1, 0dC01C000000000000;
	mul.f64 	%fd96, %fd2, 0d4008000000000000;
	mul.f64 	%fd97, %fd2, %fd96;
	mul.f64 	%fd98, %fd97, %fd1;
	fma.rn.f64 	%fd99, %fd1, %fd98, %fd95;
	add.f64 	%fd100, %fd99, 0dBFF0000000000000;
	mul.f64 	%fd21, %fd94, %fd100;
	setp.lt.u32	%p9, %r22, 1105199104;
	@%p9 bra 	BB93_15;

	// Callseq Start 196
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd154;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd155, [retval0+0];
	
	//{
	}// Callseq End 196
	ld.local.u32 	%r40, [%rd1];

BB93_15:
	add.s32 	%r8, %r40, 1;
	and.b32  	%r23, %r8, 1;
	shl.b32 	%r24, %r23, 3;
	setp.eq.s32	%p10, %r23, 0;
	selp.f64	%fd101, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	add.s32 	%r25, %r24, 1;
	mul.wide.s32 	%rd11, %r25, 8;
	add.s64 	%rd13, %rd8, %rd11;
	ld.const.f64 	%fd102, [%rd13];
	mul.rn.f64 	%fd24, %fd155, %fd155;
	fma.rn.f64 	%fd103, %fd101, %fd24, %fd102;
	ld.const.f64 	%fd104, [%rd13+8];
	fma.rn.f64 	%fd105, %fd103, %fd24, %fd104;
	ld.const.f64 	%fd106, [%rd13+16];
	fma.rn.f64 	%fd107, %fd105, %fd24, %fd106;
	ld.const.f64 	%fd108, [%rd13+24];
	fma.rn.f64 	%fd109, %fd107, %fd24, %fd108;
	ld.const.f64 	%fd110, [%rd13+32];
	fma.rn.f64 	%fd111, %fd109, %fd24, %fd110;
	ld.const.f64 	%fd112, [%rd13+40];
	fma.rn.f64 	%fd25, %fd111, %fd24, %fd112;
	fma.rn.f64 	%fd156, %fd25, %fd155, %fd155;
	@%p10 bra 	BB93_17;

	mov.f64 	%fd113, 0d3FF0000000000000;
	fma.rn.f64 	%fd156, %fd25, %fd24, %fd113;

BB93_17:
	and.b32  	%r26, %r8, 2;
	setp.eq.s32	%p11, %r26, 0;
	@%p11 bra 	BB93_19;

	mov.f64 	%fd114, 0d0000000000000000;
	mov.f64 	%fd115, 0dBFF0000000000000;
	fma.rn.f64 	%fd156, %fd156, %fd115, %fd114;

BB93_19:
	fma.rn.f64 	%fd31, %fd21, %fd156, %fd17;
	mov.f64 	%fd116, 0d4338000000000000;
	mov.f64 	%fd117, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd118, %fd3, %fd117, %fd116;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd118;
	}
	mov.f64 	%fd119, 0dC338000000000000;
	add.rn.f64 	%fd120, %fd118, %fd119;
	mov.f64 	%fd121, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd122, %fd120, %fd121, %fd3;
	mov.f64 	%fd123, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd124, %fd120, %fd123, %fd122;
	mov.f64 	%fd125, 0d3E928AF3FCA213EA;
	mov.f64 	%fd126, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd127, %fd126, %fd124, %fd125;
	mov.f64 	%fd128, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd129, %fd127, %fd124, %fd128;
	mov.f64 	%fd130, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd131, %fd129, %fd124, %fd130;
	mov.f64 	%fd132, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd133, %fd131, %fd124, %fd132;
	mov.f64 	%fd134, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd135, %fd133, %fd124, %fd134;
	mov.f64 	%fd136, 0d3F81111111122322;
	fma.rn.f64 	%fd137, %fd135, %fd124, %fd136;
	mov.f64 	%fd138, 0d3FA55555555502A1;
	fma.rn.f64 	%fd139, %fd137, %fd124, %fd138;
	mov.f64 	%fd140, 0d3FC5555555555511;
	fma.rn.f64 	%fd141, %fd139, %fd124, %fd140;
	mov.f64 	%fd142, 0d3FE000000000000B;
	fma.rn.f64 	%fd143, %fd141, %fd124, %fd142;
	mov.f64 	%fd144, 0d3FF0000000000000;
	fma.rn.f64 	%fd145, %fd143, %fd124, %fd144;
	fma.rn.f64 	%fd146, %fd145, %fd124, %fd144;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd146;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd146;
	}
	shl.b32 	%r27, %r9, 20;
	add.s32 	%r28, %r11, %r27;
	mov.b64 	%fd158, {%r10, %r28};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd3;
	}
	mov.b32 	 %f2, %r29;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p12, %f1, 0f4086232B;
	@%p12 bra 	BB93_22;

	setp.lt.f64	%p13, %fd3, 0d0000000000000000;
	add.f64 	%fd147, %fd3, 0d7FF0000000000000;
	selp.f64	%fd158, 0d0000000000000000, %fd147, %p13;
	setp.geu.f32	%p14, %f1, 0f40874800;
	@%p14 bra 	BB93_22;

	shr.u32 	%r30, %r9, 31;
	add.s32 	%r31, %r9, %r30;
	shr.s32 	%r32, %r31, 1;
	shl.b32 	%r33, %r32, 20;
	add.s32 	%r34, %r33, %r11;
	mov.b64 	%fd148, {%r10, %r34};
	sub.s32 	%r35, %r9, %r32;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, 1072693248;
	mov.u32 	%r38, 0;
	mov.b64 	%fd149, {%r38, %r37};
	mul.f64 	%fd158, %fd148, %fd149;

BB93_22:
	mul.f64 	%fd159, %fd31, %fd158;

BB93_23:
	st.param.f64	[func_retval0+0], %fd159;
	ret;
}

	// .globl	_Z3LiuddPdiPii
.visible .func  (.param .b64 func_retval0) _Z3LiuddPdiPii(
	.param .b64 _Z3LiuddPdiPii_param_0,
	.param .b64 _Z3LiuddPdiPii_param_1,
	.param .b64 _Z3LiuddPdiPii_param_2,
	.param .b32 _Z3LiuddPdiPii_param_3,
	.param .b64 _Z3LiuddPdiPii_param_4,
	.param .b32 _Z3LiuddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot94[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<31>;
	.reg .b32 	%r<67>;
	.reg .f64 	%fd<254>;
	.reg .b64 	%rd<31>;


	mov.u64 	%SPL, __local_depot94;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd82, [_Z3LiuddPdiPii_param_0];
	ld.param.f64 	%fd80, [_Z3LiuddPdiPii_param_1];
	add.u64 	%rd6, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd6;
	mov.f64 	%fd83, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd83, %fd82;
	mul.f64 	%fd2, %fd1, 0d3FC0A3D70A3D70A4;
	sub.f64 	%fd3, %fd1, %fd2;
	setp.lt.f64	%p1, %fd80, 0d0000000000000000;
	mov.f64 	%fd81, 0d0000000000000000;
	@%p1 bra 	BB94_1;
	bra.uni 	BB94_2;

BB94_1:
	mov.f64 	%fd253, %fd81;
	bra.uni 	BB94_54;

BB94_2:
	mov.f64 	%fd253, 0d3FF0000000000000;
	setp.le.f64	%p2, %fd1, %fd80;
	@%p2 bra 	BB94_54;

	mul.f64 	%fd85, %fd2, 0d3FF3333333333333;
	mul.f64 	%fd4, %fd85, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd86, %fd2, 0d3FF6666666666666, %fd4;
	mul.f64 	%fd5, %fd3, 0d3FD3333333333333;
	add.f64 	%fd87, %fd5, %fd86;
	rcp.rn.f64 	%fd6, %fd87;
	setp.ltu.f64	%p3, %fd2, %fd80;
	@%p3 bra 	BB94_23;
	bra.uni 	BB94_4;

BB94_23:
	add.f64 	%fd145, %fd2, %fd2;
	setp.ltu.f64	%p14, %fd145, %fd80;
	@%p14 bra 	BB94_43;
	bra.uni 	BB94_24;

BB94_43:
	setp.ltu.f64	%p25, %fd1, %fd80;
	mov.f64 	%fd253, %fd81;
	@%p25 bra 	BB94_54;

	mul.f64 	%fd203, %fd2, 0d3FF199999999999A;
	fma.rn.f64 	%fd204, %fd80, 0d3FD3333333333333, %fd203;
	add.f64 	%fd64, %fd204, %fd4;
	sub.f64 	%fd205, %fd80, %fd2;
	mul.f64 	%fd206, %fd205, 0d400921FB54442D18;
	div.rn.f64 	%fd249, %fd206, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd249;
	}
	and.b32  	%r54, %r53, 2147483647;
	setp.ne.s32	%p26, %r54, 2146435072;
	@%p26 bra 	BB94_47;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r55, %temp}, %fd249;
	}
	setp.ne.s32	%p27, %r55, 0;
	@%p27 bra 	BB94_47;

	mov.f64 	%fd207, 0d0000000000000000;
	mul.rn.f64 	%fd249, %fd249, %fd207;

BB94_47:
	mul.f64 	%fd208, %fd249, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r66, %fd208;
	st.local.u32 	[%rd1], %r66;
	cvt.rn.f64.s32	%fd209, %r66;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd249;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd250, %fd210, %fd215, %fd214;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd249;
	}
	and.b32  	%r57, %r56, 2145386496;
	setp.lt.u32	%p28, %r57, 1105199104;
	@%p28 bra 	BB94_49;

	// Callseq Start 201
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd249;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd250, [retval0+0];
	
	//{
	}// Callseq End 201
	ld.local.u32 	%r66, [%rd1];

BB94_49:
	and.b32  	%r58, %r66, 1;
	shl.b32 	%r59, %r58, 3;
	setp.eq.s32	%p29, %r58, 0;
	selp.f64	%fd216, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p29;
	add.s32 	%r60, %r59, 1;
	mul.wide.s32 	%rd28, %r60, 8;
	mov.u64 	%rd29, __cudart_sin_cos_coeffs;
	add.s64 	%rd30, %rd29, %rd28;
	ld.const.f64 	%fd217, [%rd30];
	mul.rn.f64 	%fd71, %fd250, %fd250;
	fma.rn.f64 	%fd218, %fd216, %fd71, %fd217;
	ld.const.f64 	%fd219, [%rd30+8];
	fma.rn.f64 	%fd220, %fd218, %fd71, %fd219;
	ld.const.f64 	%fd221, [%rd30+16];
	fma.rn.f64 	%fd222, %fd220, %fd71, %fd221;
	ld.const.f64 	%fd223, [%rd30+24];
	fma.rn.f64 	%fd224, %fd222, %fd71, %fd223;
	ld.const.f64 	%fd225, [%rd30+32];
	fma.rn.f64 	%fd226, %fd224, %fd71, %fd225;
	ld.const.f64 	%fd227, [%rd30+40];
	fma.rn.f64 	%fd72, %fd226, %fd71, %fd227;
	fma.rn.f64 	%fd251, %fd72, %fd250, %fd250;
	@%p29 bra 	BB94_51;

	mov.f64 	%fd228, 0d3FF0000000000000;
	fma.rn.f64 	%fd251, %fd72, %fd71, %fd228;

BB94_51:
	and.b32  	%r61, %r66, 2;
	setp.eq.s32	%p30, %r61, 0;
	@%p30 bra 	BB94_53;

	mov.f64 	%fd229, 0d0000000000000000;
	mov.f64 	%fd230, 0dBFF0000000000000;
	fma.rn.f64 	%fd251, %fd251, %fd230, %fd229;

BB94_53:
	mul.f64 	%fd231, %fd5, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd232, %fd231, %fd251, %fd64;
	mul.f64 	%fd253, %fd6, %fd232;
	bra.uni 	BB94_54;

BB94_4:
	mul.f64 	%fd88, %fd80, 0d400921FB54442D18;
	div.rn.f64 	%fd233, %fd88, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd233;
	}
	and.b32  	%r18, %r17, 2147483647;
	setp.ne.s32	%p4, %r18, 2146435072;
	@%p4 bra 	BB94_7;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd233;
	}
	setp.ne.s32	%p5, %r19, 0;
	@%p5 bra 	BB94_7;

	mov.f64 	%fd89, 0d0000000000000000;
	mul.rn.f64 	%fd233, %fd233, %fd89;

BB94_7:
	mul.f64 	%fd90, %fd233, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r62, %fd90;
	st.local.u32 	[%rd1], %r62;
	cvt.rn.f64.s32	%fd91, %r62;
	neg.f64 	%fd92, %fd91;
	mov.f64 	%fd93, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd94, %fd92, %fd93, %fd233;
	mov.f64 	%fd95, 0d3C91A62633145C00;
	fma.rn.f64 	%fd96, %fd92, %fd95, %fd94;
	mov.f64 	%fd97, 0d397B839A252049C0;
	fma.rn.f64 	%fd234, %fd92, %fd97, %fd96;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd233;
	}
	and.b32  	%r21, %r20, 2145386496;
	setp.lt.u32	%p6, %r21, 1105199104;
	@%p6 bra 	BB94_9;

	// Callseq Start 197
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd233;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd234, [retval0+0];
	
	//{
	}// Callseq End 197
	ld.local.u32 	%r62, [%rd1];

BB94_9:
	and.b32  	%r22, %r62, 1;
	shl.b32 	%r23, %r22, 3;
	setp.eq.s32	%p7, %r22, 0;
	selp.f64	%fd98, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p7;
	add.s32 	%r24, %r23, 1;
	mul.wide.s32 	%rd12, %r24, 8;
	mov.u64 	%rd13, __cudart_sin_cos_coeffs;
	add.s64 	%rd14, %rd13, %rd12;
	ld.const.f64 	%fd99, [%rd14];
	mul.rn.f64 	%fd13, %fd234, %fd234;
	fma.rn.f64 	%fd100, %fd98, %fd13, %fd99;
	ld.const.f64 	%fd101, [%rd14+8];
	fma.rn.f64 	%fd102, %fd100, %fd13, %fd101;
	ld.const.f64 	%fd103, [%rd14+16];
	fma.rn.f64 	%fd104, %fd102, %fd13, %fd103;
	ld.const.f64 	%fd105, [%rd14+24];
	fma.rn.f64 	%fd106, %fd104, %fd13, %fd105;
	ld.const.f64 	%fd107, [%rd14+32];
	fma.rn.f64 	%fd108, %fd106, %fd13, %fd107;
	ld.const.f64 	%fd109, [%rd14+40];
	fma.rn.f64 	%fd14, %fd108, %fd13, %fd109;
	fma.rn.f64 	%fd235, %fd14, %fd234, %fd234;
	@%p7 bra 	BB94_11;

	mov.f64 	%fd110, 0d3FF0000000000000;
	fma.rn.f64 	%fd235, %fd14, %fd13, %fd110;

BB94_11:
	and.b32  	%r25, %r62, 2;
	setp.eq.s32	%p8, %r25, 0;
	@%p8 bra 	BB94_13;

	mov.f64 	%fd111, 0d0000000000000000;
	mov.f64 	%fd112, 0dBFF0000000000000;
	fma.rn.f64 	%fd235, %fd235, %fd112, %fd111;

BB94_13:
	mul.f64 	%fd113, %fd2, 0d3FE6666666666666;
	mul.f64 	%fd114, %fd113, 0d3FD45F306DC9C883;
	mul.f64 	%fd20, %fd114, %fd235;
	mul.f64 	%fd115, %fd80, 0d3FF921FB54442D18;
	div.rn.f64 	%fd237, %fd115, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd237;
	}
	and.b32  	%r27, %r26, 2147483647;
	setp.ne.s32	%p9, %r27, 2146435072;
	@%p9 bra 	BB94_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd237;
	}
	setp.ne.s32	%p10, %r28, 0;
	@%p10 bra 	BB94_16;

	mov.f64 	%fd116, 0d0000000000000000;
	mul.rn.f64 	%fd237, %fd237, %fd116;

BB94_16:
	mul.f64 	%fd117, %fd237, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r63, %fd117;
	st.local.u32 	[%rd1], %r63;
	cvt.rn.f64.s32	%fd118, %r63;
	neg.f64 	%fd119, %fd118;
	fma.rn.f64 	%fd121, %fd119, %fd93, %fd237;
	fma.rn.f64 	%fd123, %fd119, %fd95, %fd121;
	fma.rn.f64 	%fd238, %fd119, %fd97, %fd123;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd237;
	}
	and.b32  	%r30, %r29, 2145386496;
	setp.lt.u32	%p11, %r30, 1105199104;
	@%p11 bra 	BB94_18;

	// Callseq Start 198
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd237;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd238, [retval0+0];
	
	//{
	}// Callseq End 198
	ld.local.u32 	%r63, [%rd1];

BB94_18:
	add.s32 	%r7, %r63, 1;
	and.b32  	%r31, %r7, 1;
	shl.b32 	%r32, %r31, 3;
	setp.eq.s32	%p12, %r31, 0;
	selp.f64	%fd125, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	add.s32 	%r33, %r32, 1;
	mul.wide.s32 	%rd16, %r33, 8;
	add.s64 	%rd18, %rd13, %rd16;
	ld.const.f64 	%fd126, [%rd18];
	mul.rn.f64 	%fd27, %fd238, %fd238;
	fma.rn.f64 	%fd127, %fd125, %fd27, %fd126;
	ld.const.f64 	%fd128, [%rd18+8];
	fma.rn.f64 	%fd129, %fd127, %fd27, %fd128;
	ld.const.f64 	%fd130, [%rd18+16];
	fma.rn.f64 	%fd131, %fd129, %fd27, %fd130;
	ld.const.f64 	%fd132, [%rd18+24];
	fma.rn.f64 	%fd133, %fd131, %fd27, %fd132;
	ld.const.f64 	%fd134, [%rd18+32];
	fma.rn.f64 	%fd135, %fd133, %fd27, %fd134;
	ld.const.f64 	%fd136, [%rd18+40];
	fma.rn.f64 	%fd28, %fd135, %fd27, %fd136;
	fma.rn.f64 	%fd239, %fd28, %fd238, %fd238;
	@%p12 bra 	BB94_20;

	mov.f64 	%fd137, 0d3FF0000000000000;
	fma.rn.f64 	%fd239, %fd28, %fd27, %fd137;

BB94_20:
	and.b32  	%r34, %r7, 2;
	setp.eq.s32	%p13, %r34, 0;
	@%p13 bra 	BB94_22;

	mov.f64 	%fd138, 0d0000000000000000;
	mov.f64 	%fd139, 0dBFF0000000000000;
	fma.rn.f64 	%fd239, %fd239, %fd139, %fd138;

BB94_22:
	add.f64 	%fd140, %fd239, 0dBFF0000000000000;
	mul.f64 	%fd141, %fd4, %fd140;
	mul.f64 	%fd142, %fd80, 0d3FE6666666666666;
	sub.f64 	%fd143, %fd142, %fd20;
	sub.f64 	%fd144, %fd143, %fd141;
	mul.f64 	%fd253, %fd6, %fd144;
	bra.uni 	BB94_54;

BB94_24:
	fma.rn.f64 	%fd146, %fd2, 0dBFD3333333333333, %fd80;
	add.f64 	%fd35, %fd146, %fd4;
	mul.f64 	%fd147, %fd80, 0d400921FB54442D18;
	div.rn.f64 	%fd241, %fd147, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd241;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p15, %r36, 2146435072;
	@%p15 bra 	BB94_27;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd241;
	}
	setp.ne.s32	%p16, %r37, 0;
	@%p16 bra 	BB94_27;

	mov.f64 	%fd148, 0d0000000000000000;
	mul.rn.f64 	%fd241, %fd241, %fd148;

BB94_27:
	mul.f64 	%fd149, %fd241, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r64, %fd149;
	st.local.u32 	[%rd1], %r64;
	cvt.rn.f64.s32	%fd150, %r64;
	neg.f64 	%fd151, %fd150;
	mov.f64 	%fd152, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd153, %fd151, %fd152, %fd241;
	mov.f64 	%fd154, 0d3C91A62633145C00;
	fma.rn.f64 	%fd155, %fd151, %fd154, %fd153;
	mov.f64 	%fd156, 0d397B839A252049C0;
	fma.rn.f64 	%fd242, %fd151, %fd156, %fd155;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd241;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p17, %r39, 1105199104;
	@%p17 bra 	BB94_29;

	// Callseq Start 199
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd241;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd242, [retval0+0];
	
	//{
	}// Callseq End 199
	ld.local.u32 	%r64, [%rd1];

BB94_29:
	and.b32  	%r40, %r64, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p18, %r40, 0;
	selp.f64	%fd157, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p18;
	add.s32 	%r42, %r41, 1;
	mul.wide.s32 	%rd20, %r42, 8;
	mov.u64 	%rd21, __cudart_sin_cos_coeffs;
	add.s64 	%rd22, %rd21, %rd20;
	ld.const.f64 	%fd158, [%rd22];
	mul.rn.f64 	%fd42, %fd242, %fd242;
	fma.rn.f64 	%fd159, %fd157, %fd42, %fd158;
	ld.const.f64 	%fd160, [%rd22+8];
	fma.rn.f64 	%fd161, %fd159, %fd42, %fd160;
	ld.const.f64 	%fd162, [%rd22+16];
	fma.rn.f64 	%fd163, %fd161, %fd42, %fd162;
	ld.const.f64 	%fd164, [%rd22+24];
	fma.rn.f64 	%fd165, %fd163, %fd42, %fd164;
	ld.const.f64 	%fd166, [%rd22+32];
	fma.rn.f64 	%fd167, %fd165, %fd42, %fd166;
	ld.const.f64 	%fd168, [%rd22+40];
	fma.rn.f64 	%fd43, %fd167, %fd42, %fd168;
	fma.rn.f64 	%fd243, %fd43, %fd242, %fd242;
	@%p18 bra 	BB94_31;

	mov.f64 	%fd169, 0d3FF0000000000000;
	fma.rn.f64 	%fd243, %fd43, %fd42, %fd169;

BB94_31:
	and.b32  	%r43, %r64, 2;
	setp.eq.s32	%p19, %r43, 0;
	@%p19 bra 	BB94_33;

	mov.f64 	%fd170, 0d0000000000000000;
	mov.f64 	%fd171, 0dBFF0000000000000;
	fma.rn.f64 	%fd243, %fd243, %fd171, %fd170;

BB94_33:
	mul.f64 	%fd172, %fd2, 0dBFE6666666666666;
	mul.f64 	%fd173, %fd172, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd49, %fd173, %fd243, %fd35;
	sub.f64 	%fd174, %fd80, %fd2;
	mul.f64 	%fd175, %fd174, 0d400921FB54442D18;
	div.rn.f64 	%fd245, %fd175, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd245;
	}
	and.b32  	%r45, %r44, 2147483647;
	setp.ne.s32	%p20, %r45, 2146435072;
	@%p20 bra 	BB94_36;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd245;
	}
	setp.ne.s32	%p21, %r46, 0;
	@%p21 bra 	BB94_36;

	mov.f64 	%fd176, 0d0000000000000000;
	mul.rn.f64 	%fd245, %fd245, %fd176;

BB94_36:
	mul.f64 	%fd177, %fd245, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r65, %fd177;
	st.local.u32 	[%rd1], %r65;
	cvt.rn.f64.s32	%fd178, %r65;
	neg.f64 	%fd179, %fd178;
	fma.rn.f64 	%fd181, %fd179, %fd152, %fd245;
	fma.rn.f64 	%fd183, %fd179, %fd154, %fd181;
	fma.rn.f64 	%fd246, %fd179, %fd156, %fd183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd245;
	}
	and.b32  	%r48, %r47, 2145386496;
	setp.lt.u32	%p22, %r48, 1105199104;
	@%p22 bra 	BB94_38;

	// Callseq Start 200
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd245;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd246, [retval0+0];
	
	//{
	}// Callseq End 200
	ld.local.u32 	%r65, [%rd1];

BB94_38:
	and.b32  	%r49, %r65, 1;
	shl.b32 	%r50, %r49, 3;
	setp.eq.s32	%p23, %r49, 0;
	selp.f64	%fd185, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p23;
	add.s32 	%r51, %r50, 1;
	mul.wide.s32 	%rd24, %r51, 8;
	add.s64 	%rd26, %rd21, %rd24;
	ld.const.f64 	%fd186, [%rd26];
	mul.rn.f64 	%fd56, %fd246, %fd246;
	fma.rn.f64 	%fd187, %fd185, %fd56, %fd186;
	ld.const.f64 	%fd188, [%rd26+8];
	fma.rn.f64 	%fd189, %fd187, %fd56, %fd188;
	ld.const.f64 	%fd190, [%rd26+16];
	fma.rn.f64 	%fd191, %fd189, %fd56, %fd190;
	ld.const.f64 	%fd192, [%rd26+24];
	fma.rn.f64 	%fd193, %fd191, %fd56, %fd192;
	ld.const.f64 	%fd194, [%rd26+32];
	fma.rn.f64 	%fd195, %fd193, %fd56, %fd194;
	ld.const.f64 	%fd196, [%rd26+40];
	fma.rn.f64 	%fd57, %fd195, %fd56, %fd196;
	fma.rn.f64 	%fd247, %fd57, %fd246, %fd246;
	@%p23 bra 	BB94_40;

	mov.f64 	%fd197, 0d3FF0000000000000;
	fma.rn.f64 	%fd247, %fd57, %fd56, %fd197;

BB94_40:
	and.b32  	%r52, %r65, 2;
	setp.eq.s32	%p24, %r52, 0;
	@%p24 bra 	BB94_42;

	mov.f64 	%fd198, 0d0000000000000000;
	mov.f64 	%fd199, 0dBFF0000000000000;
	fma.rn.f64 	%fd247, %fd247, %fd199, %fd198;

BB94_42:
	mul.f64 	%fd200, %fd5, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd201, %fd200, %fd247, %fd49;
	mul.f64 	%fd253, %fd6, %fd201;

BB94_54:
	st.param.f64	[func_retval0+0], %fd253;
	ret;
}

	// .globl	_Z5Liu_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z5Liu_tddPdiPii(
	.param .b64 _Z5Liu_tddPdiPii_param_0,
	.param .b64 _Z5Liu_tddPdiPii_param_1,
	.param .b64 _Z5Liu_tddPdiPii_param_2,
	.param .b32 _Z5Liu_tddPdiPii_param_3,
	.param .b64 _Z5Liu_tddPdiPii_param_4,
	.param .b32 _Z5Liu_tddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot95[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<32>;
	.reg .b32 	%r<70>;
	.reg .f64 	%fd<239>;
	.reg .b64 	%rd<36>;


	mov.u64 	%SPL, __local_depot95;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd76, [_Z5Liu_tddPdiPii_param_0];
	ld.param.f64 	%fd74, [_Z5Liu_tddPdiPii_param_1];
	mov.f64 	%fd77, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd77, %fd76;
	mul.f64 	%fd2, %fd1, 0d3FC0A3D70A3D70A4;
	sub.f64 	%fd3, %fd1, %fd2;
	setp.gtu.f64	%p1, %fd1, %fd74;
	setp.geu.f64	%p2, %fd74, 0d0000000000000000;
	and.pred  	%p3, %p2, %p1;
	mov.f64 	%fd238, 0d0000000000000000;
	@!%p3 bra 	BB95_52;
	bra.uni 	BB95_1;

BB95_1:
	mul.f64 	%fd78, %fd2, 0d3FF3333333333333;
	mul.f64 	%fd79, %fd78, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd80, %fd2, 0d3FF6666666666666, %fd79;
	fma.rn.f64 	%fd81, %fd3, 0d3FD3333333333333, %fd80;
	rcp.rn.f64 	%fd4, %fd81;
	setp.ltu.f64	%p4, %fd2, %fd74;
	@%p4 bra 	BB95_21;
	bra.uni 	BB95_2;

BB95_21:
	add.f64 	%fd136, %fd2, %fd2;
	setp.ltu.f64	%p15, %fd136, %fd74;
	@%p15 bra 	BB95_41;
	bra.uni 	BB95_22;

BB95_41:
	setp.ltu.f64	%p26, %fd1, %fd74;
	@%p26 bra 	BB95_52;

	sub.f64 	%fd191, %fd74, %fd2;
	mul.f64 	%fd192, %fd191, 0d400921FB54442D18;
	div.rn.f64 	%fd234, %fd192, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd234;
	}
	and.b32  	%r57, %r56, 2147483647;
	setp.ne.s32	%p27, %r57, 2146435072;
	@%p27 bra 	BB95_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd234;
	}
	setp.ne.s32	%p28, %r58, 0;
	@%p28 bra 	BB95_45;

	mov.f64 	%fd193, 0d0000000000000000;
	mul.rn.f64 	%fd234, %fd234, %fd193;

BB95_45:
	mul.f64 	%fd194, %fd234, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r69, %fd194;
	add.u64 	%rd29, %SP, 0;
	cvta.to.local.u64 	%rd30, %rd29;
	st.local.u32 	[%rd30], %r69;
	cvt.rn.f64.s32	%fd195, %r69;
	neg.f64 	%fd196, %fd195;
	mov.f64 	%fd197, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd198, %fd196, %fd197, %fd234;
	mov.f64 	%fd199, 0d3C91A62633145C00;
	fma.rn.f64 	%fd200, %fd196, %fd199, %fd198;
	mov.f64 	%fd201, 0d397B839A252049C0;
	fma.rn.f64 	%fd235, %fd196, %fd201, %fd200;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd234;
	}
	and.b32  	%r60, %r59, 2145386496;
	setp.lt.u32	%p29, %r60, 1105199104;
	@%p29 bra 	BB95_47;

	// Callseq Start 206
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd234;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd235, [retval0+0];
	
	//{
	}// Callseq End 206
	ld.local.u32 	%r69, [%rd30];

BB95_47:
	add.s32 	%r19, %r69, 1;
	and.b32  	%r61, %r19, 1;
	shl.b32 	%r62, %r61, 3;
	setp.eq.s32	%p30, %r61, 0;
	selp.f64	%fd202, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p30;
	add.s32 	%r63, %r62, 1;
	mul.wide.s32 	%rd33, %r63, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.const.f64 	%fd203, [%rd35];
	mul.rn.f64 	%fd65, %fd235, %fd235;
	fma.rn.f64 	%fd204, %fd202, %fd65, %fd203;
	ld.const.f64 	%fd205, [%rd35+8];
	fma.rn.f64 	%fd206, %fd204, %fd65, %fd205;
	ld.const.f64 	%fd207, [%rd35+16];
	fma.rn.f64 	%fd208, %fd206, %fd65, %fd207;
	ld.const.f64 	%fd209, [%rd35+24];
	fma.rn.f64 	%fd210, %fd208, %fd65, %fd209;
	ld.const.f64 	%fd211, [%rd35+32];
	fma.rn.f64 	%fd212, %fd210, %fd65, %fd211;
	ld.const.f64 	%fd213, [%rd35+40];
	fma.rn.f64 	%fd66, %fd212, %fd65, %fd213;
	fma.rn.f64 	%fd236, %fd66, %fd235, %fd235;
	@%p30 bra 	BB95_49;

	mov.f64 	%fd214, 0d3FF0000000000000;
	fma.rn.f64 	%fd236, %fd66, %fd65, %fd214;

BB95_49:
	and.b32  	%r64, %r19, 2;
	setp.eq.s32	%p31, %r64, 0;
	@%p31 bra 	BB95_51;

	mov.f64 	%fd215, 0d0000000000000000;
	mov.f64 	%fd216, 0dBFF0000000000000;
	fma.rn.f64 	%fd236, %fd236, %fd216, %fd215;

BB95_51:
	fma.rn.f64 	%fd217, %fd236, 0d3FD3333333333333, 0d3FD3333333333333;
	mul.f64 	%fd238, %fd4, %fd217;
	bra.uni 	BB95_52;

BB95_2:
	mul.f64 	%fd82, %fd74, 0d400921FB54442D18;
	div.rn.f64 	%fd218, %fd82, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd218;
	}
	and.b32  	%r21, %r20, 2147483647;
	setp.ne.s32	%p5, %r21, 2146435072;
	@%p5 bra 	BB95_5;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd218;
	}
	setp.ne.s32	%p6, %r22, 0;
	@%p6 bra 	BB95_5;

	mov.f64 	%fd83, 0d0000000000000000;
	mul.rn.f64 	%fd218, %fd218, %fd83;

BB95_5:
	mul.f64 	%fd84, %fd218, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r65, %fd84;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r65;
	cvt.rn.f64.s32	%fd85, %r65;
	neg.f64 	%fd86, %fd85;
	mov.f64 	%fd87, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd88, %fd86, %fd87, %fd218;
	mov.f64 	%fd89, 0d3C91A62633145C00;
	fma.rn.f64 	%fd90, %fd86, %fd89, %fd88;
	mov.f64 	%fd91, 0d397B839A252049C0;
	fma.rn.f64 	%fd219, %fd86, %fd91, %fd90;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd218;
	}
	and.b32  	%r24, %r23, 2145386496;
	setp.lt.u32	%p7, %r24, 1105199104;
	@%p7 bra 	BB95_7;

	// Callseq Start 202
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd218;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd219, [retval0+0];
	
	//{
	}// Callseq End 202
	ld.local.u32 	%r65, [%rd2];

BB95_7:
	add.s32 	%r4, %r65, 1;
	and.b32  	%r25, %r4, 1;
	shl.b32 	%r26, %r25, 3;
	setp.eq.s32	%p8, %r25, 0;
	selp.f64	%fd92, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	add.s32 	%r27, %r26, 1;
	mul.wide.s32 	%rd5, %r27, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd93, [%rd7];
	mul.rn.f64 	%fd11, %fd219, %fd219;
	fma.rn.f64 	%fd94, %fd92, %fd11, %fd93;
	ld.const.f64 	%fd95, [%rd7+8];
	fma.rn.f64 	%fd96, %fd94, %fd11, %fd95;
	ld.const.f64 	%fd97, [%rd7+16];
	fma.rn.f64 	%fd98, %fd96, %fd11, %fd97;
	ld.const.f64 	%fd99, [%rd7+24];
	fma.rn.f64 	%fd100, %fd98, %fd11, %fd99;
	ld.const.f64 	%fd101, [%rd7+32];
	fma.rn.f64 	%fd102, %fd100, %fd11, %fd101;
	ld.const.f64 	%fd103, [%rd7+40];
	fma.rn.f64 	%fd12, %fd102, %fd11, %fd103;
	fma.rn.f64 	%fd220, %fd12, %fd219, %fd219;
	@%p8 bra 	BB95_9;

	mov.f64 	%fd104, 0d3FF0000000000000;
	fma.rn.f64 	%fd220, %fd12, %fd11, %fd104;

BB95_9:
	and.b32  	%r28, %r4, 2;
	setp.eq.s32	%p9, %r28, 0;
	@%p9 bra 	BB95_11;

	mov.f64 	%fd105, 0d0000000000000000;
	mov.f64 	%fd106, 0dBFF0000000000000;
	fma.rn.f64 	%fd220, %fd220, %fd106, %fd105;

BB95_11:
	mul.f64 	%fd107, %fd74, 0d3FF921FB54442D18;
	div.rn.f64 	%fd222, %fd107, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd222;
	}
	and.b32  	%r30, %r29, 2147483647;
	setp.ne.s32	%p10, %r30, 2146435072;
	@%p10 bra 	BB95_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd222;
	}
	setp.ne.s32	%p11, %r31, 0;
	@%p11 bra 	BB95_14;

	mov.f64 	%fd108, 0d0000000000000000;
	mul.rn.f64 	%fd222, %fd222, %fd108;

BB95_14:
	mul.f64 	%fd109, %fd222, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r66, %fd109;
	st.local.u32 	[%rd2], %r66;
	cvt.rn.f64.s32	%fd110, %r66;
	neg.f64 	%fd111, %fd110;
	fma.rn.f64 	%fd113, %fd111, %fd87, %fd222;
	fma.rn.f64 	%fd115, %fd111, %fd89, %fd113;
	fma.rn.f64 	%fd223, %fd111, %fd91, %fd115;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd222;
	}
	and.b32  	%r33, %r32, 2145386496;
	setp.lt.u32	%p12, %r33, 1105199104;
	@%p12 bra 	BB95_16;

	// Callseq Start 203
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd222;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd223, [retval0+0];
	
	//{
	}// Callseq End 203
	ld.local.u32 	%r66, [%rd2];

BB95_16:
	and.b32  	%r34, %r66, 1;
	shl.b32 	%r35, %r34, 3;
	setp.eq.s32	%p13, %r34, 0;
	selp.f64	%fd117, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p13;
	add.s32 	%r36, %r35, 1;
	mul.wide.s32 	%rd12, %r36, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd118, [%rd14];
	mul.rn.f64 	%fd24, %fd223, %fd223;
	fma.rn.f64 	%fd119, %fd117, %fd24, %fd118;
	ld.const.f64 	%fd120, [%rd14+8];
	fma.rn.f64 	%fd121, %fd119, %fd24, %fd120;
	ld.const.f64 	%fd122, [%rd14+16];
	fma.rn.f64 	%fd123, %fd121, %fd24, %fd122;
	ld.const.f64 	%fd124, [%rd14+24];
	fma.rn.f64 	%fd125, %fd123, %fd24, %fd124;
	ld.const.f64 	%fd126, [%rd14+32];
	fma.rn.f64 	%fd127, %fd125, %fd24, %fd126;
	ld.const.f64 	%fd128, [%rd14+40];
	fma.rn.f64 	%fd25, %fd127, %fd24, %fd128;
	fma.rn.f64 	%fd224, %fd25, %fd223, %fd223;
	@%p13 bra 	BB95_18;

	mov.f64 	%fd129, 0d3FF0000000000000;
	fma.rn.f64 	%fd224, %fd25, %fd24, %fd129;

BB95_18:
	and.b32  	%r37, %r66, 2;
	setp.eq.s32	%p14, %r37, 0;
	@%p14 bra 	BB95_20;

	mov.f64 	%fd130, 0d0000000000000000;
	mov.f64 	%fd131, 0dBFF0000000000000;
	fma.rn.f64 	%fd224, %fd224, %fd131, %fd130;

BB95_20:
	mul.f64 	%fd132, %fd220, 0d3FE6666666666666;
	mov.f64 	%fd133, 0d3FE6666666666666;
	sub.f64 	%fd134, %fd133, %fd132;
	fma.rn.f64 	%fd135, %fd224, 0d3FE3333333333333, %fd134;
	mul.f64 	%fd238, %fd4, %fd135;
	bra.uni 	BB95_52;

BB95_22:
	mul.f64 	%fd137, %fd74, 0d400921FB54442D18;
	div.rn.f64 	%fd226, %fd137, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd226;
	}
	and.b32  	%r39, %r38, 2147483647;
	setp.ne.s32	%p16, %r39, 2146435072;
	@%p16 bra 	BB95_25;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd226;
	}
	setp.ne.s32	%p17, %r40, 0;
	@%p17 bra 	BB95_25;

	mov.f64 	%fd138, 0d0000000000000000;
	mul.rn.f64 	%fd226, %fd226, %fd138;

BB95_25:
	mul.f64 	%fd139, %fd226, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r67, %fd139;
	add.u64 	%rd15, %SP, 0;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.u32 	[%rd16], %r67;
	cvt.rn.f64.s32	%fd140, %r67;
	neg.f64 	%fd141, %fd140;
	mov.f64 	%fd142, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd143, %fd141, %fd142, %fd226;
	mov.f64 	%fd144, 0d3C91A62633145C00;
	fma.rn.f64 	%fd145, %fd141, %fd144, %fd143;
	mov.f64 	%fd146, 0d397B839A252049C0;
	fma.rn.f64 	%fd227, %fd141, %fd146, %fd145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd226;
	}
	and.b32  	%r42, %r41, 2145386496;
	setp.lt.u32	%p18, %r42, 1105199104;
	@%p18 bra 	BB95_27;

	// Callseq Start 204
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd226;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd227, [retval0+0];
	
	//{
	}// Callseq End 204
	ld.local.u32 	%r67, [%rd16];

BB95_27:
	add.s32 	%r11, %r67, 1;
	and.b32  	%r43, %r11, 1;
	shl.b32 	%r44, %r43, 3;
	setp.eq.s32	%p19, %r43, 0;
	selp.f64	%fd147, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p19;
	add.s32 	%r45, %r44, 1;
	mul.wide.s32 	%rd19, %r45, 8;
	mov.u64 	%rd20, __cudart_sin_cos_coeffs;
	add.s64 	%rd21, %rd20, %rd19;
	ld.const.f64 	%fd148, [%rd21];
	mul.rn.f64 	%fd38, %fd227, %fd227;
	fma.rn.f64 	%fd149, %fd147, %fd38, %fd148;
	ld.const.f64 	%fd150, [%rd21+8];
	fma.rn.f64 	%fd151, %fd149, %fd38, %fd150;
	ld.const.f64 	%fd152, [%rd21+16];
	fma.rn.f64 	%fd153, %fd151, %fd38, %fd152;
	ld.const.f64 	%fd154, [%rd21+24];
	fma.rn.f64 	%fd155, %fd153, %fd38, %fd154;
	ld.const.f64 	%fd156, [%rd21+32];
	fma.rn.f64 	%fd157, %fd155, %fd38, %fd156;
	ld.const.f64 	%fd158, [%rd21+40];
	fma.rn.f64 	%fd39, %fd157, %fd38, %fd158;
	fma.rn.f64 	%fd228, %fd39, %fd227, %fd227;
	@%p19 bra 	BB95_29;

	mov.f64 	%fd159, 0d3FF0000000000000;
	fma.rn.f64 	%fd228, %fd39, %fd38, %fd159;

BB95_29:
	and.b32  	%r46, %r11, 2;
	setp.eq.s32	%p20, %r46, 0;
	@%p20 bra 	BB95_31;

	mov.f64 	%fd160, 0d0000000000000000;
	mov.f64 	%fd161, 0dBFF0000000000000;
	fma.rn.f64 	%fd228, %fd228, %fd161, %fd160;

BB95_31:
	sub.f64 	%fd162, %fd74, %fd2;
	mul.f64 	%fd163, %fd162, 0d400921FB54442D18;
	div.rn.f64 	%fd230, %fd163, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd230;
	}
	and.b32  	%r48, %r47, 2147483647;
	setp.ne.s32	%p21, %r48, 2146435072;
	@%p21 bra 	BB95_34;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd230;
	}
	setp.ne.s32	%p22, %r49, 0;
	@%p22 bra 	BB95_34;

	mov.f64 	%fd164, 0d0000000000000000;
	mul.rn.f64 	%fd230, %fd230, %fd164;

BB95_34:
	mul.f64 	%fd165, %fd230, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r68, %fd165;
	st.local.u32 	[%rd16], %r68;
	cvt.rn.f64.s32	%fd166, %r68;
	neg.f64 	%fd167, %fd166;
	fma.rn.f64 	%fd169, %fd167, %fd142, %fd230;
	fma.rn.f64 	%fd171, %fd167, %fd144, %fd169;
	fma.rn.f64 	%fd231, %fd167, %fd146, %fd171;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd230;
	}
	and.b32  	%r51, %r50, 2145386496;
	setp.lt.u32	%p23, %r51, 1105199104;
	@%p23 bra 	BB95_36;

	// Callseq Start 205
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd230;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd231, [retval0+0];
	
	//{
	}// Callseq End 205
	ld.local.u32 	%r68, [%rd16];

BB95_36:
	add.s32 	%r15, %r68, 1;
	and.b32  	%r52, %r15, 1;
	shl.b32 	%r53, %r52, 3;
	setp.eq.s32	%p24, %r52, 0;
	selp.f64	%fd173, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p24;
	add.s32 	%r54, %r53, 1;
	mul.wide.s32 	%rd26, %r54, 8;
	add.s64 	%rd28, %rd20, %rd26;
	ld.const.f64 	%fd174, [%rd28];
	mul.rn.f64 	%fd51, %fd231, %fd231;
	fma.rn.f64 	%fd175, %fd173, %fd51, %fd174;
	ld.const.f64 	%fd176, [%rd28+8];
	fma.rn.f64 	%fd177, %fd175, %fd51, %fd176;
	ld.const.f64 	%fd178, [%rd28+16];
	fma.rn.f64 	%fd179, %fd177, %fd51, %fd178;
	ld.const.f64 	%fd180, [%rd28+24];
	fma.rn.f64 	%fd181, %fd179, %fd51, %fd180;
	ld.const.f64 	%fd182, [%rd28+32];
	fma.rn.f64 	%fd183, %fd181, %fd51, %fd182;
	ld.const.f64 	%fd184, [%rd28+40];
	fma.rn.f64 	%fd52, %fd183, %fd51, %fd184;
	fma.rn.f64 	%fd232, %fd52, %fd231, %fd231;
	@%p24 bra 	BB95_38;

	mov.f64 	%fd185, 0d3FF0000000000000;
	fma.rn.f64 	%fd232, %fd52, %fd51, %fd185;

BB95_38:
	and.b32  	%r55, %r15, 2;
	setp.eq.s32	%p25, %r55, 0;
	@%p25 bra 	BB95_40;

	mov.f64 	%fd186, 0d0000000000000000;
	mov.f64 	%fd187, 0dBFF0000000000000;
	fma.rn.f64 	%fd232, %fd232, %fd187, %fd186;

BB95_40:
	fma.rn.f64 	%fd188, %fd228, 0dBFE6666666666666, 0d3FF0000000000000;
	fma.rn.f64 	%fd189, %fd232, 0d3FD3333333333333, %fd188;
	mul.f64 	%fd238, %fd4, %fd189;

BB95_52:
	st.param.f64	[func_retval0+0], %fd238;
	ret;
}

	// .globl	_Z6Liu_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z6Liu_omddPdiPii(
	.param .b64 _Z6Liu_omddPdiPii_param_0,
	.param .b64 _Z6Liu_omddPdiPii_param_1,
	.param .b64 _Z6Liu_omddPdiPii_param_2,
	.param .b32 _Z6Liu_omddPdiPii_param_3,
	.param .b64 _Z6Liu_omddPdiPii_param_4,
	.param .b32 _Z6Liu_omddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot96[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<32>;
	.reg .b32 	%r<70>;
	.reg .f64 	%fd<240>;
	.reg .b64 	%rd<36>;


	mov.u64 	%SPL, __local_depot96;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd74, [_Z6Liu_omddPdiPii_param_0];
	ld.param.f64 	%fd75, [_Z6Liu_omddPdiPii_param_1];
	mov.f64 	%fd77, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd77, %fd74;
	mul.f64 	%fd2, %fd1, 0d3FC0A3D70A3D70A4;
	sub.f64 	%fd3, %fd1, %fd2;
	setp.gtu.f64	%p1, %fd1, %fd75;
	setp.geu.f64	%p2, %fd75, 0d0000000000000000;
	and.pred  	%p3, %p2, %p1;
	mov.f64 	%fd239, 0d0000000000000000;
	@!%p3 bra 	BB96_52;
	bra.uni 	BB96_1;

BB96_1:
	mul.f64 	%fd78, %fd2, 0d3FF3333333333333;
	mul.f64 	%fd79, %fd78, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd80, %fd2, 0d3FF6666666666666, %fd79;
	fma.rn.f64 	%fd81, %fd3, 0d3FD3333333333333, %fd80;
	div.rn.f64 	%fd82, %fd75, %fd81;
	div.rn.f64 	%fd4, %fd82, %fd74;
	setp.ltu.f64	%p4, %fd2, %fd75;
	@%p4 bra 	BB96_21;
	bra.uni 	BB96_2;

BB96_21:
	add.f64 	%fd137, %fd2, %fd2;
	setp.ltu.f64	%p15, %fd137, %fd75;
	@%p15 bra 	BB96_41;
	bra.uni 	BB96_22;

BB96_41:
	setp.ltu.f64	%p26, %fd1, %fd75;
	@%p26 bra 	BB96_52;

	sub.f64 	%fd192, %fd75, %fd2;
	mul.f64 	%fd193, %fd192, 0d400921FB54442D18;
	div.rn.f64 	%fd235, %fd193, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd235;
	}
	and.b32  	%r57, %r56, 2147483647;
	setp.ne.s32	%p27, %r57, 2146435072;
	@%p27 bra 	BB96_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd235;
	}
	setp.ne.s32	%p28, %r58, 0;
	@%p28 bra 	BB96_45;

	mov.f64 	%fd194, 0d0000000000000000;
	mul.rn.f64 	%fd235, %fd235, %fd194;

BB96_45:
	mul.f64 	%fd195, %fd235, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r69, %fd195;
	add.u64 	%rd29, %SP, 0;
	cvta.to.local.u64 	%rd30, %rd29;
	st.local.u32 	[%rd30], %r69;
	cvt.rn.f64.s32	%fd196, %r69;
	neg.f64 	%fd197, %fd196;
	mov.f64 	%fd198, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd199, %fd197, %fd198, %fd235;
	mov.f64 	%fd200, 0d3C91A62633145C00;
	fma.rn.f64 	%fd201, %fd197, %fd200, %fd199;
	mov.f64 	%fd202, 0d397B839A252049C0;
	fma.rn.f64 	%fd236, %fd197, %fd202, %fd201;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd235;
	}
	and.b32  	%r60, %r59, 2145386496;
	setp.lt.u32	%p29, %r60, 1105199104;
	@%p29 bra 	BB96_47;

	// Callseq Start 211
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd235;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd236, [retval0+0];
	
	//{
	}// Callseq End 211
	ld.local.u32 	%r69, [%rd30];

BB96_47:
	add.s32 	%r19, %r69, 1;
	and.b32  	%r61, %r19, 1;
	shl.b32 	%r62, %r61, 3;
	setp.eq.s32	%p30, %r61, 0;
	selp.f64	%fd203, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p30;
	add.s32 	%r63, %r62, 1;
	mul.wide.s32 	%rd33, %r63, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.const.f64 	%fd204, [%rd35];
	mul.rn.f64 	%fd65, %fd236, %fd236;
	fma.rn.f64 	%fd205, %fd203, %fd65, %fd204;
	ld.const.f64 	%fd206, [%rd35+8];
	fma.rn.f64 	%fd207, %fd205, %fd65, %fd206;
	ld.const.f64 	%fd208, [%rd35+16];
	fma.rn.f64 	%fd209, %fd207, %fd65, %fd208;
	ld.const.f64 	%fd210, [%rd35+24];
	fma.rn.f64 	%fd211, %fd209, %fd65, %fd210;
	ld.const.f64 	%fd212, [%rd35+32];
	fma.rn.f64 	%fd213, %fd211, %fd65, %fd212;
	ld.const.f64 	%fd214, [%rd35+40];
	fma.rn.f64 	%fd66, %fd213, %fd65, %fd214;
	fma.rn.f64 	%fd237, %fd66, %fd236, %fd236;
	@%p30 bra 	BB96_49;

	mov.f64 	%fd215, 0d3FF0000000000000;
	fma.rn.f64 	%fd237, %fd66, %fd65, %fd215;

BB96_49:
	and.b32  	%r64, %r19, 2;
	setp.eq.s32	%p31, %r64, 0;
	@%p31 bra 	BB96_51;

	mov.f64 	%fd216, 0d0000000000000000;
	mov.f64 	%fd217, 0dBFF0000000000000;
	fma.rn.f64 	%fd237, %fd237, %fd217, %fd216;

BB96_51:
	fma.rn.f64 	%fd218, %fd237, 0d3FD3333333333333, 0d3FD3333333333333;
	mul.f64 	%fd239, %fd4, %fd218;
	bra.uni 	BB96_52;

BB96_2:
	mul.f64 	%fd83, %fd75, 0d400921FB54442D18;
	div.rn.f64 	%fd219, %fd83, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd219;
	}
	and.b32  	%r21, %r20, 2147483647;
	setp.ne.s32	%p5, %r21, 2146435072;
	@%p5 bra 	BB96_5;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd219;
	}
	setp.ne.s32	%p6, %r22, 0;
	@%p6 bra 	BB96_5;

	mov.f64 	%fd84, 0d0000000000000000;
	mul.rn.f64 	%fd219, %fd219, %fd84;

BB96_5:
	mul.f64 	%fd85, %fd219, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r65, %fd85;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r65;
	cvt.rn.f64.s32	%fd86, %r65;
	neg.f64 	%fd87, %fd86;
	mov.f64 	%fd88, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd89, %fd87, %fd88, %fd219;
	mov.f64 	%fd90, 0d3C91A62633145C00;
	fma.rn.f64 	%fd91, %fd87, %fd90, %fd89;
	mov.f64 	%fd92, 0d397B839A252049C0;
	fma.rn.f64 	%fd220, %fd87, %fd92, %fd91;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd219;
	}
	and.b32  	%r24, %r23, 2145386496;
	setp.lt.u32	%p7, %r24, 1105199104;
	@%p7 bra 	BB96_7;

	// Callseq Start 207
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd219;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd220, [retval0+0];
	
	//{
	}// Callseq End 207
	ld.local.u32 	%r65, [%rd2];

BB96_7:
	add.s32 	%r4, %r65, 1;
	and.b32  	%r25, %r4, 1;
	shl.b32 	%r26, %r25, 3;
	setp.eq.s32	%p8, %r25, 0;
	selp.f64	%fd93, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	add.s32 	%r27, %r26, 1;
	mul.wide.s32 	%rd5, %r27, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd94, [%rd7];
	mul.rn.f64 	%fd11, %fd220, %fd220;
	fma.rn.f64 	%fd95, %fd93, %fd11, %fd94;
	ld.const.f64 	%fd96, [%rd7+8];
	fma.rn.f64 	%fd97, %fd95, %fd11, %fd96;
	ld.const.f64 	%fd98, [%rd7+16];
	fma.rn.f64 	%fd99, %fd97, %fd11, %fd98;
	ld.const.f64 	%fd100, [%rd7+24];
	fma.rn.f64 	%fd101, %fd99, %fd11, %fd100;
	ld.const.f64 	%fd102, [%rd7+32];
	fma.rn.f64 	%fd103, %fd101, %fd11, %fd102;
	ld.const.f64 	%fd104, [%rd7+40];
	fma.rn.f64 	%fd12, %fd103, %fd11, %fd104;
	fma.rn.f64 	%fd221, %fd12, %fd220, %fd220;
	@%p8 bra 	BB96_9;

	mov.f64 	%fd105, 0d3FF0000000000000;
	fma.rn.f64 	%fd221, %fd12, %fd11, %fd105;

BB96_9:
	and.b32  	%r28, %r4, 2;
	setp.eq.s32	%p9, %r28, 0;
	@%p9 bra 	BB96_11;

	mov.f64 	%fd106, 0d0000000000000000;
	mov.f64 	%fd107, 0dBFF0000000000000;
	fma.rn.f64 	%fd221, %fd221, %fd107, %fd106;

BB96_11:
	mul.f64 	%fd108, %fd75, 0d3FF921FB54442D18;
	div.rn.f64 	%fd223, %fd108, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd223;
	}
	and.b32  	%r30, %r29, 2147483647;
	setp.ne.s32	%p10, %r30, 2146435072;
	@%p10 bra 	BB96_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd223;
	}
	setp.ne.s32	%p11, %r31, 0;
	@%p11 bra 	BB96_14;

	mov.f64 	%fd109, 0d0000000000000000;
	mul.rn.f64 	%fd223, %fd223, %fd109;

BB96_14:
	mul.f64 	%fd110, %fd223, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r66, %fd110;
	st.local.u32 	[%rd2], %r66;
	cvt.rn.f64.s32	%fd111, %r66;
	neg.f64 	%fd112, %fd111;
	fma.rn.f64 	%fd114, %fd112, %fd88, %fd223;
	fma.rn.f64 	%fd116, %fd112, %fd90, %fd114;
	fma.rn.f64 	%fd224, %fd112, %fd92, %fd116;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd223;
	}
	and.b32  	%r33, %r32, 2145386496;
	setp.lt.u32	%p12, %r33, 1105199104;
	@%p12 bra 	BB96_16;

	// Callseq Start 208
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd223;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd224, [retval0+0];
	
	//{
	}// Callseq End 208
	ld.local.u32 	%r66, [%rd2];

BB96_16:
	and.b32  	%r34, %r66, 1;
	shl.b32 	%r35, %r34, 3;
	setp.eq.s32	%p13, %r34, 0;
	selp.f64	%fd118, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p13;
	add.s32 	%r36, %r35, 1;
	mul.wide.s32 	%rd12, %r36, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd119, [%rd14];
	mul.rn.f64 	%fd24, %fd224, %fd224;
	fma.rn.f64 	%fd120, %fd118, %fd24, %fd119;
	ld.const.f64 	%fd121, [%rd14+8];
	fma.rn.f64 	%fd122, %fd120, %fd24, %fd121;
	ld.const.f64 	%fd123, [%rd14+16];
	fma.rn.f64 	%fd124, %fd122, %fd24, %fd123;
	ld.const.f64 	%fd125, [%rd14+24];
	fma.rn.f64 	%fd126, %fd124, %fd24, %fd125;
	ld.const.f64 	%fd127, [%rd14+32];
	fma.rn.f64 	%fd128, %fd126, %fd24, %fd127;
	ld.const.f64 	%fd129, [%rd14+40];
	fma.rn.f64 	%fd25, %fd128, %fd24, %fd129;
	fma.rn.f64 	%fd225, %fd25, %fd224, %fd224;
	@%p13 bra 	BB96_18;

	mov.f64 	%fd130, 0d3FF0000000000000;
	fma.rn.f64 	%fd225, %fd25, %fd24, %fd130;

BB96_18:
	and.b32  	%r37, %r66, 2;
	setp.eq.s32	%p14, %r37, 0;
	@%p14 bra 	BB96_20;

	mov.f64 	%fd131, 0d0000000000000000;
	mov.f64 	%fd132, 0dBFF0000000000000;
	fma.rn.f64 	%fd225, %fd225, %fd132, %fd131;

BB96_20:
	mul.f64 	%fd133, %fd221, 0d3FE6666666666666;
	mov.f64 	%fd134, 0d3FE6666666666666;
	sub.f64 	%fd135, %fd134, %fd133;
	fma.rn.f64 	%fd136, %fd225, 0d3FE3333333333333, %fd135;
	mul.f64 	%fd239, %fd4, %fd136;
	bra.uni 	BB96_52;

BB96_22:
	mul.f64 	%fd138, %fd75, 0d400921FB54442D18;
	div.rn.f64 	%fd227, %fd138, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd227;
	}
	and.b32  	%r39, %r38, 2147483647;
	setp.ne.s32	%p16, %r39, 2146435072;
	@%p16 bra 	BB96_25;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd227;
	}
	setp.ne.s32	%p17, %r40, 0;
	@%p17 bra 	BB96_25;

	mov.f64 	%fd139, 0d0000000000000000;
	mul.rn.f64 	%fd227, %fd227, %fd139;

BB96_25:
	mul.f64 	%fd140, %fd227, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r67, %fd140;
	add.u64 	%rd15, %SP, 0;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.u32 	[%rd16], %r67;
	cvt.rn.f64.s32	%fd141, %r67;
	neg.f64 	%fd142, %fd141;
	mov.f64 	%fd143, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd144, %fd142, %fd143, %fd227;
	mov.f64 	%fd145, 0d3C91A62633145C00;
	fma.rn.f64 	%fd146, %fd142, %fd145, %fd144;
	mov.f64 	%fd147, 0d397B839A252049C0;
	fma.rn.f64 	%fd228, %fd142, %fd147, %fd146;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd227;
	}
	and.b32  	%r42, %r41, 2145386496;
	setp.lt.u32	%p18, %r42, 1105199104;
	@%p18 bra 	BB96_27;

	// Callseq Start 209
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd227;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd228, [retval0+0];
	
	//{
	}// Callseq End 209
	ld.local.u32 	%r67, [%rd16];

BB96_27:
	add.s32 	%r11, %r67, 1;
	and.b32  	%r43, %r11, 1;
	shl.b32 	%r44, %r43, 3;
	setp.eq.s32	%p19, %r43, 0;
	selp.f64	%fd148, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p19;
	add.s32 	%r45, %r44, 1;
	mul.wide.s32 	%rd19, %r45, 8;
	mov.u64 	%rd20, __cudart_sin_cos_coeffs;
	add.s64 	%rd21, %rd20, %rd19;
	ld.const.f64 	%fd149, [%rd21];
	mul.rn.f64 	%fd38, %fd228, %fd228;
	fma.rn.f64 	%fd150, %fd148, %fd38, %fd149;
	ld.const.f64 	%fd151, [%rd21+8];
	fma.rn.f64 	%fd152, %fd150, %fd38, %fd151;
	ld.const.f64 	%fd153, [%rd21+16];
	fma.rn.f64 	%fd154, %fd152, %fd38, %fd153;
	ld.const.f64 	%fd155, [%rd21+24];
	fma.rn.f64 	%fd156, %fd154, %fd38, %fd155;
	ld.const.f64 	%fd157, [%rd21+32];
	fma.rn.f64 	%fd158, %fd156, %fd38, %fd157;
	ld.const.f64 	%fd159, [%rd21+40];
	fma.rn.f64 	%fd39, %fd158, %fd38, %fd159;
	fma.rn.f64 	%fd229, %fd39, %fd228, %fd228;
	@%p19 bra 	BB96_29;

	mov.f64 	%fd160, 0d3FF0000000000000;
	fma.rn.f64 	%fd229, %fd39, %fd38, %fd160;

BB96_29:
	and.b32  	%r46, %r11, 2;
	setp.eq.s32	%p20, %r46, 0;
	@%p20 bra 	BB96_31;

	mov.f64 	%fd161, 0d0000000000000000;
	mov.f64 	%fd162, 0dBFF0000000000000;
	fma.rn.f64 	%fd229, %fd229, %fd162, %fd161;

BB96_31:
	sub.f64 	%fd163, %fd75, %fd2;
	mul.f64 	%fd164, %fd163, 0d400921FB54442D18;
	div.rn.f64 	%fd231, %fd164, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd231;
	}
	and.b32  	%r48, %r47, 2147483647;
	setp.ne.s32	%p21, %r48, 2146435072;
	@%p21 bra 	BB96_34;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd231;
	}
	setp.ne.s32	%p22, %r49, 0;
	@%p22 bra 	BB96_34;

	mov.f64 	%fd165, 0d0000000000000000;
	mul.rn.f64 	%fd231, %fd231, %fd165;

BB96_34:
	mul.f64 	%fd166, %fd231, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r68, %fd166;
	st.local.u32 	[%rd16], %r68;
	cvt.rn.f64.s32	%fd167, %r68;
	neg.f64 	%fd168, %fd167;
	fma.rn.f64 	%fd170, %fd168, %fd143, %fd231;
	fma.rn.f64 	%fd172, %fd168, %fd145, %fd170;
	fma.rn.f64 	%fd232, %fd168, %fd147, %fd172;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd231;
	}
	and.b32  	%r51, %r50, 2145386496;
	setp.lt.u32	%p23, %r51, 1105199104;
	@%p23 bra 	BB96_36;

	// Callseq Start 210
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd231;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd232, [retval0+0];
	
	//{
	}// Callseq End 210
	ld.local.u32 	%r68, [%rd16];

BB96_36:
	add.s32 	%r15, %r68, 1;
	and.b32  	%r52, %r15, 1;
	shl.b32 	%r53, %r52, 3;
	setp.eq.s32	%p24, %r52, 0;
	selp.f64	%fd174, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p24;
	add.s32 	%r54, %r53, 1;
	mul.wide.s32 	%rd26, %r54, 8;
	add.s64 	%rd28, %rd20, %rd26;
	ld.const.f64 	%fd175, [%rd28];
	mul.rn.f64 	%fd51, %fd232, %fd232;
	fma.rn.f64 	%fd176, %fd174, %fd51, %fd175;
	ld.const.f64 	%fd177, [%rd28+8];
	fma.rn.f64 	%fd178, %fd176, %fd51, %fd177;
	ld.const.f64 	%fd179, [%rd28+16];
	fma.rn.f64 	%fd180, %fd178, %fd51, %fd179;
	ld.const.f64 	%fd181, [%rd28+24];
	fma.rn.f64 	%fd182, %fd180, %fd51, %fd181;
	ld.const.f64 	%fd183, [%rd28+32];
	fma.rn.f64 	%fd184, %fd182, %fd51, %fd183;
	ld.const.f64 	%fd185, [%rd28+40];
	fma.rn.f64 	%fd52, %fd184, %fd51, %fd185;
	fma.rn.f64 	%fd233, %fd52, %fd232, %fd232;
	@%p24 bra 	BB96_38;

	mov.f64 	%fd186, 0d3FF0000000000000;
	fma.rn.f64 	%fd233, %fd52, %fd51, %fd186;

BB96_38:
	and.b32  	%r55, %r15, 2;
	setp.eq.s32	%p25, %r55, 0;
	@%p25 bra 	BB96_40;

	mov.f64 	%fd187, 0d0000000000000000;
	mov.f64 	%fd188, 0dBFF0000000000000;
	fma.rn.f64 	%fd233, %fd233, %fd188, %fd187;

BB96_40:
	fma.rn.f64 	%fd189, %fd229, 0dBFE6666666666666, 0d3FF0000000000000;
	fma.rn.f64 	%fd190, %fd233, 0d3FD3333333333333, %fd189;
	mul.f64 	%fd239, %fd4, %fd190;

BB96_52:
	st.param.f64	[func_retval0+0], %fd239;
	ret;
}

	// .globl	_Z6Liu_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z6Liu_ttddPdiPii(
	.param .b64 _Z6Liu_ttddPdiPii_param_0,
	.param .b64 _Z6Liu_ttddPdiPii_param_1,
	.param .b64 _Z6Liu_ttddPdiPii_param_2,
	.param .b32 _Z6Liu_ttddPdiPii_param_3,
	.param .b64 _Z6Liu_ttddPdiPii_param_4,
	.param .b32 _Z6Liu_ttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot97[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<32>;
	.reg .b32 	%r<67>;
	.reg .f64 	%fd<242>;
	.reg .b64 	%rd<36>;


	mov.u64 	%SPL, __local_depot97;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd77, [_Z6Liu_ttddPdiPii_param_0];
	ld.param.f64 	%fd75, [_Z6Liu_ttddPdiPii_param_1];
	mov.f64 	%fd78, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd78, %fd77;
	mul.f64 	%fd2, %fd1, 0d3FC0A3D70A3D70A4;
	sub.f64 	%fd3, %fd1, %fd2;
	setp.gtu.f64	%p1, %fd1, %fd75;
	setp.geu.f64	%p2, %fd75, 0d0000000000000000;
	and.pred  	%p3, %p2, %p1;
	mov.f64 	%fd241, 0d0000000000000000;
	@!%p3 bra 	BB97_52;
	bra.uni 	BB97_1;

BB97_1:
	mul.f64 	%fd79, %fd2, 0d3FF3333333333333;
	mul.f64 	%fd80, %fd79, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd81, %fd2, 0d3FF6666666666666, %fd80;
	fma.rn.f64 	%fd82, %fd3, 0d3FD3333333333333, %fd81;
	rcp.rn.f64 	%fd4, %fd82;
	setp.ltu.f64	%p4, %fd2, %fd75;
	@%p4 bra 	BB97_21;
	bra.uni 	BB97_2;

BB97_21:
	add.f64 	%fd136, %fd2, %fd2;
	setp.ltu.f64	%p15, %fd136, %fd75;
	@%p15 bra 	BB97_41;
	bra.uni 	BB97_22;

BB97_41:
	setp.ltu.f64	%p26, %fd1, %fd75;
	@%p26 bra 	BB97_52;

	sub.f64 	%fd193, %fd75, %fd2;
	mul.f64 	%fd194, %fd193, 0d400921FB54442D18;
	div.rn.f64 	%fd237, %fd194, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd237;
	}
	and.b32  	%r54, %r53, 2147483647;
	setp.ne.s32	%p27, %r54, 2146435072;
	@%p27 bra 	BB97_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r55, %temp}, %fd237;
	}
	setp.ne.s32	%p28, %r55, 0;
	@%p28 bra 	BB97_45;

	mov.f64 	%fd195, 0d0000000000000000;
	mul.rn.f64 	%fd237, %fd237, %fd195;

BB97_45:
	mul.f64 	%fd196, %fd237, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r66, %fd196;
	add.u64 	%rd29, %SP, 0;
	cvta.to.local.u64 	%rd30, %rd29;
	st.local.u32 	[%rd30], %r66;
	cvt.rn.f64.s32	%fd197, %r66;
	neg.f64 	%fd198, %fd197;
	mov.f64 	%fd199, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd200, %fd198, %fd199, %fd237;
	mov.f64 	%fd201, 0d3C91A62633145C00;
	fma.rn.f64 	%fd202, %fd198, %fd201, %fd200;
	mov.f64 	%fd203, 0d397B839A252049C0;
	fma.rn.f64 	%fd238, %fd198, %fd203, %fd202;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd237;
	}
	and.b32  	%r57, %r56, 2145386496;
	setp.lt.u32	%p29, %r57, 1105199104;
	@%p29 bra 	BB97_47;

	// Callseq Start 216
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd237;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd238, [retval0+0];
	
	//{
	}// Callseq End 216
	ld.local.u32 	%r66, [%rd30];

BB97_47:
	and.b32  	%r58, %r66, 1;
	shl.b32 	%r59, %r58, 3;
	setp.eq.s32	%p30, %r58, 0;
	selp.f64	%fd204, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p30;
	add.s32 	%r60, %r59, 1;
	mul.wide.s32 	%rd33, %r60, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.const.f64 	%fd205, [%rd35];
	mul.rn.f64 	%fd66, %fd238, %fd238;
	fma.rn.f64 	%fd206, %fd204, %fd66, %fd205;
	ld.const.f64 	%fd207, [%rd35+8];
	fma.rn.f64 	%fd208, %fd206, %fd66, %fd207;
	ld.const.f64 	%fd209, [%rd35+16];
	fma.rn.f64 	%fd210, %fd208, %fd66, %fd209;
	ld.const.f64 	%fd211, [%rd35+24];
	fma.rn.f64 	%fd212, %fd210, %fd66, %fd211;
	ld.const.f64 	%fd213, [%rd35+32];
	fma.rn.f64 	%fd214, %fd212, %fd66, %fd213;
	ld.const.f64 	%fd215, [%rd35+40];
	fma.rn.f64 	%fd67, %fd214, %fd66, %fd215;
	fma.rn.f64 	%fd239, %fd67, %fd238, %fd238;
	@%p30 bra 	BB97_49;

	mov.f64 	%fd216, 0d3FF0000000000000;
	fma.rn.f64 	%fd239, %fd67, %fd66, %fd216;

BB97_49:
	and.b32  	%r61, %r66, 2;
	setp.eq.s32	%p31, %r61, 0;
	@%p31 bra 	BB97_51;

	mov.f64 	%fd217, 0d0000000000000000;
	mov.f64 	%fd218, 0dBFF0000000000000;
	fma.rn.f64 	%fd239, %fd239, %fd218, %fd217;

BB97_51:
	mul.f64 	%fd219, %fd239, 0dBFEE28C731EB6950;
	mul.f64 	%fd220, %fd4, %fd219;
	div.rn.f64 	%fd241, %fd220, %fd3;
	bra.uni 	BB97_52;

BB97_2:
	mul.f64 	%fd83, %fd75, 0d400921FB54442D18;
	div.rn.f64 	%fd221, %fd83, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd221;
	}
	and.b32  	%r18, %r17, 2147483647;
	setp.ne.s32	%p5, %r18, 2146435072;
	@%p5 bra 	BB97_5;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd221;
	}
	setp.ne.s32	%p6, %r19, 0;
	@%p6 bra 	BB97_5;

	mov.f64 	%fd84, 0d0000000000000000;
	mul.rn.f64 	%fd221, %fd221, %fd84;

BB97_5:
	mul.f64 	%fd85, %fd221, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r62, %fd85;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r62;
	cvt.rn.f64.s32	%fd86, %r62;
	neg.f64 	%fd87, %fd86;
	mov.f64 	%fd88, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd89, %fd87, %fd88, %fd221;
	mov.f64 	%fd90, 0d3C91A62633145C00;
	fma.rn.f64 	%fd91, %fd87, %fd90, %fd89;
	mov.f64 	%fd92, 0d397B839A252049C0;
	fma.rn.f64 	%fd222, %fd87, %fd92, %fd91;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd221;
	}
	and.b32  	%r21, %r20, 2145386496;
	setp.lt.u32	%p7, %r21, 1105199104;
	@%p7 bra 	BB97_7;

	// Callseq Start 212
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd221;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd222, [retval0+0];
	
	//{
	}// Callseq End 212
	ld.local.u32 	%r62, [%rd2];

BB97_7:
	and.b32  	%r22, %r62, 1;
	shl.b32 	%r23, %r22, 3;
	setp.eq.s32	%p8, %r22, 0;
	selp.f64	%fd93, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	add.s32 	%r24, %r23, 1;
	mul.wide.s32 	%rd5, %r24, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd94, [%rd7];
	mul.rn.f64 	%fd11, %fd222, %fd222;
	fma.rn.f64 	%fd95, %fd93, %fd11, %fd94;
	ld.const.f64 	%fd96, [%rd7+8];
	fma.rn.f64 	%fd97, %fd95, %fd11, %fd96;
	ld.const.f64 	%fd98, [%rd7+16];
	fma.rn.f64 	%fd99, %fd97, %fd11, %fd98;
	ld.const.f64 	%fd100, [%rd7+24];
	fma.rn.f64 	%fd101, %fd99, %fd11, %fd100;
	ld.const.f64 	%fd102, [%rd7+32];
	fma.rn.f64 	%fd103, %fd101, %fd11, %fd102;
	ld.const.f64 	%fd104, [%rd7+40];
	fma.rn.f64 	%fd12, %fd103, %fd11, %fd104;
	fma.rn.f64 	%fd223, %fd12, %fd222, %fd222;
	@%p8 bra 	BB97_9;

	mov.f64 	%fd105, 0d3FF0000000000000;
	fma.rn.f64 	%fd223, %fd12, %fd11, %fd105;

BB97_9:
	and.b32  	%r25, %r62, 2;
	setp.eq.s32	%p9, %r25, 0;
	@%p9 bra 	BB97_11;

	mov.f64 	%fd106, 0d0000000000000000;
	mov.f64 	%fd107, 0dBFF0000000000000;
	fma.rn.f64 	%fd223, %fd223, %fd107, %fd106;

BB97_11:
	mul.f64 	%fd108, %fd75, 0d3FF921FB54442D18;
	div.rn.f64 	%fd225, %fd108, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd225;
	}
	and.b32  	%r27, %r26, 2147483647;
	setp.ne.s32	%p10, %r27, 2146435072;
	@%p10 bra 	BB97_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd225;
	}
	setp.ne.s32	%p11, %r28, 0;
	@%p11 bra 	BB97_14;

	mov.f64 	%fd109, 0d0000000000000000;
	mul.rn.f64 	%fd225, %fd225, %fd109;

BB97_14:
	mul.f64 	%fd110, %fd225, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r63, %fd110;
	st.local.u32 	[%rd2], %r63;
	cvt.rn.f64.s32	%fd111, %r63;
	neg.f64 	%fd112, %fd111;
	fma.rn.f64 	%fd114, %fd112, %fd88, %fd225;
	fma.rn.f64 	%fd116, %fd112, %fd90, %fd114;
	fma.rn.f64 	%fd226, %fd112, %fd92, %fd116;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd225;
	}
	and.b32  	%r30, %r29, 2145386496;
	setp.lt.u32	%p12, %r30, 1105199104;
	@%p12 bra 	BB97_16;

	// Callseq Start 213
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd225;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd226, [retval0+0];
	
	//{
	}// Callseq End 213
	ld.local.u32 	%r63, [%rd2];

BB97_16:
	add.s32 	%r7, %r63, 1;
	and.b32  	%r31, %r7, 1;
	shl.b32 	%r32, %r31, 3;
	setp.eq.s32	%p13, %r31, 0;
	selp.f64	%fd118, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p13;
	add.s32 	%r33, %r32, 1;
	mul.wide.s32 	%rd12, %r33, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd119, [%rd14];
	mul.rn.f64 	%fd24, %fd226, %fd226;
	fma.rn.f64 	%fd120, %fd118, %fd24, %fd119;
	ld.const.f64 	%fd121, [%rd14+8];
	fma.rn.f64 	%fd122, %fd120, %fd24, %fd121;
	ld.const.f64 	%fd123, [%rd14+16];
	fma.rn.f64 	%fd124, %fd122, %fd24, %fd123;
	ld.const.f64 	%fd125, [%rd14+24];
	fma.rn.f64 	%fd126, %fd124, %fd24, %fd125;
	ld.const.f64 	%fd127, [%rd14+32];
	fma.rn.f64 	%fd128, %fd126, %fd24, %fd127;
	ld.const.f64 	%fd129, [%rd14+40];
	fma.rn.f64 	%fd25, %fd128, %fd24, %fd129;
	fma.rn.f64 	%fd227, %fd25, %fd226, %fd226;
	@%p13 bra 	BB97_18;

	mov.f64 	%fd130, 0d3FF0000000000000;
	fma.rn.f64 	%fd227, %fd25, %fd24, %fd130;

BB97_18:
	and.b32  	%r34, %r7, 2;
	setp.eq.s32	%p14, %r34, 0;
	@%p14 bra 	BB97_20;

	mov.f64 	%fd131, 0d0000000000000000;
	mov.f64 	%fd132, 0dBFF0000000000000;
	fma.rn.f64 	%fd227, %fd227, %fd132, %fd131;

BB97_20:
	mul.f64 	%fd133, %fd227, 0d3FEE28C731EB6950;
	fma.rn.f64 	%fd134, %fd223, 0d400197C987C952C4, %fd133;
	mul.f64 	%fd135, %fd4, %fd134;
	div.rn.f64 	%fd241, %fd135, %fd2;
	bra.uni 	BB97_52;

BB97_22:
	mul.f64 	%fd137, %fd75, 0d400921FB54442D18;
	div.rn.f64 	%fd229, %fd137, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd229;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p16, %r36, 2146435072;
	@%p16 bra 	BB97_25;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd229;
	}
	setp.ne.s32	%p17, %r37, 0;
	@%p17 bra 	BB97_25;

	mov.f64 	%fd138, 0d0000000000000000;
	mul.rn.f64 	%fd229, %fd229, %fd138;

BB97_25:
	mul.f64 	%fd139, %fd229, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r64, %fd139;
	add.u64 	%rd15, %SP, 0;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.u32 	[%rd16], %r64;
	cvt.rn.f64.s32	%fd140, %r64;
	neg.f64 	%fd141, %fd140;
	mov.f64 	%fd142, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd143, %fd141, %fd142, %fd229;
	mov.f64 	%fd144, 0d3C91A62633145C00;
	fma.rn.f64 	%fd145, %fd141, %fd144, %fd143;
	mov.f64 	%fd146, 0d397B839A252049C0;
	fma.rn.f64 	%fd230, %fd141, %fd146, %fd145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd229;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p18, %r39, 1105199104;
	@%p18 bra 	BB97_27;

	// Callseq Start 214
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd229;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd230, [retval0+0];
	
	//{
	}// Callseq End 214
	ld.local.u32 	%r64, [%rd16];

BB97_27:
	and.b32  	%r40, %r64, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p19, %r40, 0;
	selp.f64	%fd147, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p19;
	add.s32 	%r42, %r41, 1;
	mul.wide.s32 	%rd19, %r42, 8;
	mov.u64 	%rd20, __cudart_sin_cos_coeffs;
	add.s64 	%rd21, %rd20, %rd19;
	ld.const.f64 	%fd148, [%rd21];
	mul.rn.f64 	%fd38, %fd230, %fd230;
	fma.rn.f64 	%fd149, %fd147, %fd38, %fd148;
	ld.const.f64 	%fd150, [%rd21+8];
	fma.rn.f64 	%fd151, %fd149, %fd38, %fd150;
	ld.const.f64 	%fd152, [%rd21+16];
	fma.rn.f64 	%fd153, %fd151, %fd38, %fd152;
	ld.const.f64 	%fd154, [%rd21+24];
	fma.rn.f64 	%fd155, %fd153, %fd38, %fd154;
	ld.const.f64 	%fd156, [%rd21+32];
	fma.rn.f64 	%fd157, %fd155, %fd38, %fd156;
	ld.const.f64 	%fd158, [%rd21+40];
	fma.rn.f64 	%fd39, %fd157, %fd38, %fd158;
	fma.rn.f64 	%fd231, %fd39, %fd230, %fd230;
	@%p19 bra 	BB97_29;

	mov.f64 	%fd159, 0d3FF0000000000000;
	fma.rn.f64 	%fd231, %fd39, %fd38, %fd159;

BB97_29:
	and.b32  	%r43, %r64, 2;
	setp.eq.s32	%p20, %r43, 0;
	@%p20 bra 	BB97_31;

	mov.f64 	%fd160, 0d0000000000000000;
	mov.f64 	%fd161, 0dBFF0000000000000;
	fma.rn.f64 	%fd231, %fd231, %fd161, %fd160;

BB97_31:
	mul.f64 	%fd162, %fd231, 0d400197C987C952C4;
	div.rn.f64 	%fd45, %fd162, %fd2;
	sub.f64 	%fd163, %fd75, %fd2;
	mul.f64 	%fd164, %fd163, 0d400921FB54442D18;
	div.rn.f64 	%fd233, %fd164, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd233;
	}
	and.b32  	%r45, %r44, 2147483647;
	setp.ne.s32	%p21, %r45, 2146435072;
	@%p21 bra 	BB97_34;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd233;
	}
	setp.ne.s32	%p22, %r46, 0;
	@%p22 bra 	BB97_34;

	mov.f64 	%fd165, 0d0000000000000000;
	mul.rn.f64 	%fd233, %fd233, %fd165;

BB97_34:
	mul.f64 	%fd166, %fd233, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r65, %fd166;
	st.local.u32 	[%rd16], %r65;
	cvt.rn.f64.s32	%fd167, %r65;
	neg.f64 	%fd168, %fd167;
	fma.rn.f64 	%fd170, %fd168, %fd142, %fd233;
	fma.rn.f64 	%fd172, %fd168, %fd144, %fd170;
	fma.rn.f64 	%fd234, %fd168, %fd146, %fd172;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd233;
	}
	and.b32  	%r48, %r47, 2145386496;
	setp.lt.u32	%p23, %r48, 1105199104;
	@%p23 bra 	BB97_36;

	// Callseq Start 215
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd233;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd234, [retval0+0];
	
	//{
	}// Callseq End 215
	ld.local.u32 	%r65, [%rd16];

BB97_36:
	and.b32  	%r49, %r65, 1;
	shl.b32 	%r50, %r49, 3;
	setp.eq.s32	%p24, %r49, 0;
	selp.f64	%fd174, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p24;
	add.s32 	%r51, %r50, 1;
	mul.wide.s32 	%rd26, %r51, 8;
	add.s64 	%rd28, %rd20, %rd26;
	ld.const.f64 	%fd175, [%rd28];
	mul.rn.f64 	%fd52, %fd234, %fd234;
	fma.rn.f64 	%fd176, %fd174, %fd52, %fd175;
	ld.const.f64 	%fd177, [%rd28+8];
	fma.rn.f64 	%fd178, %fd176, %fd52, %fd177;
	ld.const.f64 	%fd179, [%rd28+16];
	fma.rn.f64 	%fd180, %fd178, %fd52, %fd179;
	ld.const.f64 	%fd181, [%rd28+24];
	fma.rn.f64 	%fd182, %fd180, %fd52, %fd181;
	ld.const.f64 	%fd183, [%rd28+32];
	fma.rn.f64 	%fd184, %fd182, %fd52, %fd183;
	ld.const.f64 	%fd185, [%rd28+40];
	fma.rn.f64 	%fd53, %fd184, %fd52, %fd185;
	fma.rn.f64 	%fd235, %fd53, %fd234, %fd234;
	@%p24 bra 	BB97_38;

	mov.f64 	%fd186, 0d3FF0000000000000;
	fma.rn.f64 	%fd235, %fd53, %fd52, %fd186;

BB97_38:
	and.b32  	%r52, %r65, 2;
	setp.eq.s32	%p25, %r52, 0;
	@%p25 bra 	BB97_40;

	mov.f64 	%fd187, 0d0000000000000000;
	mov.f64 	%fd188, 0dBFF0000000000000;
	fma.rn.f64 	%fd235, %fd235, %fd188, %fd187;

BB97_40:
	mul.f64 	%fd189, %fd235, 0dBFEE28C731EB6950;
	div.rn.f64 	%fd190, %fd189, %fd3;
	add.f64 	%fd191, %fd45, %fd190;
	mul.f64 	%fd241, %fd4, %fd191;

BB97_52:
	st.param.f64	[func_retval0+0], %fd241;
	ret;
}

	// .globl	_Z7Liu_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z7Liu_tttddPdiPii(
	.param .b64 _Z7Liu_tttddPdiPii_param_0,
	.param .b64 _Z7Liu_tttddPdiPii_param_1,
	.param .b64 _Z7Liu_tttddPdiPii_param_2,
	.param .b32 _Z7Liu_tttddPdiPii_param_3,
	.param .b64 _Z7Liu_tttddPdiPii_param_4,
	.param .b32 _Z7Liu_tttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot98[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<32>;
	.reg .b32 	%r<70>;
	.reg .f64 	%fd<248>;
	.reg .b64 	%rd<36>;


	mov.u64 	%SPL, __local_depot98;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd77, [_Z7Liu_tttddPdiPii_param_0];
	ld.param.f64 	%fd75, [_Z7Liu_tttddPdiPii_param_1];
	mov.f64 	%fd78, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd78, %fd77;
	mul.f64 	%fd2, %fd1, 0d3FC0A3D70A3D70A4;
	sub.f64 	%fd3, %fd1, %fd2;
	setp.gtu.f64	%p1, %fd1, %fd75;
	setp.geu.f64	%p2, %fd75, 0d0000000000000000;
	and.pred  	%p3, %p2, %p1;
	mov.f64 	%fd247, 0d0000000000000000;
	@!%p3 bra 	BB98_52;
	bra.uni 	BB98_1;

BB98_1:
	mul.f64 	%fd79, %fd2, 0d3FF3333333333333;
	mul.f64 	%fd80, %fd79, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd81, %fd2, 0d3FF6666666666666, %fd80;
	fma.rn.f64 	%fd82, %fd3, 0d3FD3333333333333, %fd81;
	rcp.rn.f64 	%fd4, %fd82;
	setp.ltu.f64	%p4, %fd2, %fd75;
	@%p4 bra 	BB98_21;
	bra.uni 	BB98_2;

BB98_21:
	add.f64 	%fd139, %fd2, %fd2;
	setp.ltu.f64	%p15, %fd139, %fd75;
	@%p15 bra 	BB98_41;
	bra.uni 	BB98_22;

BB98_41:
	setp.ltu.f64	%p26, %fd1, %fd75;
	@%p26 bra 	BB98_52;

	sub.f64 	%fd198, %fd75, %fd2;
	mul.f64 	%fd199, %fd198, 0d400921FB54442D18;
	div.rn.f64 	%fd243, %fd199, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd243;
	}
	and.b32  	%r57, %r56, 2147483647;
	setp.ne.s32	%p27, %r57, 2146435072;
	@%p27 bra 	BB98_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd243;
	}
	setp.ne.s32	%p28, %r58, 0;
	@%p28 bra 	BB98_45;

	mov.f64 	%fd200, 0d0000000000000000;
	mul.rn.f64 	%fd243, %fd243, %fd200;

BB98_45:
	mul.f64 	%fd201, %fd243, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r69, %fd201;
	add.u64 	%rd29, %SP, 0;
	cvta.to.local.u64 	%rd30, %rd29;
	st.local.u32 	[%rd30], %r69;
	cvt.rn.f64.s32	%fd202, %r69;
	neg.f64 	%fd203, %fd202;
	mov.f64 	%fd204, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd205, %fd203, %fd204, %fd243;
	mov.f64 	%fd206, 0d3C91A62633145C00;
	fma.rn.f64 	%fd207, %fd203, %fd206, %fd205;
	mov.f64 	%fd208, 0d397B839A252049C0;
	fma.rn.f64 	%fd244, %fd203, %fd208, %fd207;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd243;
	}
	and.b32  	%r60, %r59, 2145386496;
	setp.lt.u32	%p29, %r60, 1105199104;
	@%p29 bra 	BB98_47;

	// Callseq Start 221
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd243;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd244, [retval0+0];
	
	//{
	}// Callseq End 221
	ld.local.u32 	%r69, [%rd30];

BB98_47:
	add.s32 	%r19, %r69, 1;
	and.b32  	%r61, %r19, 1;
	shl.b32 	%r62, %r61, 3;
	setp.eq.s32	%p30, %r61, 0;
	selp.f64	%fd209, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p30;
	add.s32 	%r63, %r62, 1;
	mul.wide.s32 	%rd33, %r63, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.const.f64 	%fd210, [%rd35];
	mul.rn.f64 	%fd66, %fd244, %fd244;
	fma.rn.f64 	%fd211, %fd209, %fd66, %fd210;
	ld.const.f64 	%fd212, [%rd35+8];
	fma.rn.f64 	%fd213, %fd211, %fd66, %fd212;
	ld.const.f64 	%fd214, [%rd35+16];
	fma.rn.f64 	%fd215, %fd213, %fd66, %fd214;
	ld.const.f64 	%fd216, [%rd35+24];
	fma.rn.f64 	%fd217, %fd215, %fd66, %fd216;
	ld.const.f64 	%fd218, [%rd35+32];
	fma.rn.f64 	%fd219, %fd217, %fd66, %fd218;
	ld.const.f64 	%fd220, [%rd35+40];
	fma.rn.f64 	%fd67, %fd219, %fd66, %fd220;
	fma.rn.f64 	%fd245, %fd67, %fd244, %fd244;
	@%p30 bra 	BB98_49;

	mov.f64 	%fd221, 0d3FF0000000000000;
	fma.rn.f64 	%fd245, %fd67, %fd66, %fd221;

BB98_49:
	and.b32  	%r64, %r19, 2;
	setp.eq.s32	%p31, %r64, 0;
	@%p31 bra 	BB98_51;

	mov.f64 	%fd222, 0d0000000000000000;
	mov.f64 	%fd223, 0dBFF0000000000000;
	fma.rn.f64 	%fd245, %fd245, %fd223, %fd222;

BB98_51:
	mul.f64 	%fd224, %fd245, 0dC007AFE28BB120A4;
	mul.f64 	%fd225, %fd4, %fd224;
	mul.f64 	%fd226, %fd3, %fd3;
	div.rn.f64 	%fd247, %fd225, %fd226;
	bra.uni 	BB98_52;

BB98_2:
	mov.f64 	%fd83, 0d400921FB54442D18;
	div.rn.f64 	%fd84, %fd83, %fd2;
	mul.f64 	%fd227, %fd84, %fd75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd227;
	}
	and.b32  	%r21, %r20, 2147483647;
	setp.ne.s32	%p5, %r21, 2146435072;
	@%p5 bra 	BB98_5;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd227;
	}
	setp.ne.s32	%p6, %r22, 0;
	@%p6 bra 	BB98_5;

	mov.f64 	%fd85, 0d0000000000000000;
	mul.rn.f64 	%fd227, %fd227, %fd85;

BB98_5:
	mul.f64 	%fd86, %fd227, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r65, %fd86;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r65;
	cvt.rn.f64.s32	%fd87, %r65;
	neg.f64 	%fd88, %fd87;
	mov.f64 	%fd89, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd90, %fd88, %fd89, %fd227;
	mov.f64 	%fd91, 0d3C91A62633145C00;
	fma.rn.f64 	%fd92, %fd88, %fd91, %fd90;
	mov.f64 	%fd93, 0d397B839A252049C0;
	fma.rn.f64 	%fd228, %fd88, %fd93, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd227;
	}
	and.b32  	%r24, %r23, 2145386496;
	setp.lt.u32	%p7, %r24, 1105199104;
	@%p7 bra 	BB98_7;

	// Callseq Start 217
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd227;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd228, [retval0+0];
	
	//{
	}// Callseq End 217
	ld.local.u32 	%r65, [%rd2];

BB98_7:
	add.s32 	%r4, %r65, 1;
	and.b32  	%r25, %r4, 1;
	shl.b32 	%r26, %r25, 3;
	setp.eq.s32	%p8, %r25, 0;
	selp.f64	%fd94, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	add.s32 	%r27, %r26, 1;
	mul.wide.s32 	%rd5, %r27, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd6, %rd5;
	ld.const.f64 	%fd95, [%rd7];
	mul.rn.f64 	%fd11, %fd228, %fd228;
	fma.rn.f64 	%fd96, %fd94, %fd11, %fd95;
	ld.const.f64 	%fd97, [%rd7+8];
	fma.rn.f64 	%fd98, %fd96, %fd11, %fd97;
	ld.const.f64 	%fd99, [%rd7+16];
	fma.rn.f64 	%fd100, %fd98, %fd11, %fd99;
	ld.const.f64 	%fd101, [%rd7+24];
	fma.rn.f64 	%fd102, %fd100, %fd11, %fd101;
	ld.const.f64 	%fd103, [%rd7+32];
	fma.rn.f64 	%fd104, %fd102, %fd11, %fd103;
	ld.const.f64 	%fd105, [%rd7+40];
	fma.rn.f64 	%fd12, %fd104, %fd11, %fd105;
	fma.rn.f64 	%fd229, %fd12, %fd228, %fd228;
	@%p8 bra 	BB98_9;

	mov.f64 	%fd106, 0d3FF0000000000000;
	fma.rn.f64 	%fd229, %fd12, %fd11, %fd106;

BB98_9:
	and.b32  	%r28, %r4, 2;
	setp.eq.s32	%p9, %r28, 0;
	@%p9 bra 	BB98_11;

	mov.f64 	%fd107, 0d0000000000000000;
	mov.f64 	%fd108, 0dBFF0000000000000;
	fma.rn.f64 	%fd229, %fd229, %fd108, %fd107;

BB98_11:
	div.rn.f64 	%fd110, %fd89, %fd2;
	mul.f64 	%fd231, %fd110, %fd75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd231;
	}
	and.b32  	%r30, %r29, 2147483647;
	setp.ne.s32	%p10, %r30, 2146435072;
	@%p10 bra 	BB98_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd231;
	}
	setp.ne.s32	%p11, %r31, 0;
	@%p11 bra 	BB98_14;

	mov.f64 	%fd111, 0d0000000000000000;
	mul.rn.f64 	%fd231, %fd231, %fd111;

BB98_14:
	mul.f64 	%fd112, %fd231, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r66, %fd112;
	st.local.u32 	[%rd2], %r66;
	cvt.rn.f64.s32	%fd113, %r66;
	neg.f64 	%fd114, %fd113;
	fma.rn.f64 	%fd116, %fd114, %fd89, %fd231;
	fma.rn.f64 	%fd118, %fd114, %fd91, %fd116;
	fma.rn.f64 	%fd232, %fd114, %fd93, %fd118;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd231;
	}
	and.b32  	%r33, %r32, 2145386496;
	setp.lt.u32	%p12, %r33, 1105199104;
	@%p12 bra 	BB98_16;

	// Callseq Start 218
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd231;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd232, [retval0+0];
	
	//{
	}// Callseq End 218
	ld.local.u32 	%r66, [%rd2];

BB98_16:
	and.b32  	%r34, %r66, 1;
	shl.b32 	%r35, %r34, 3;
	setp.eq.s32	%p13, %r34, 0;
	selp.f64	%fd120, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p13;
	add.s32 	%r36, %r35, 1;
	mul.wide.s32 	%rd12, %r36, 8;
	add.s64 	%rd14, %rd6, %rd12;
	ld.const.f64 	%fd121, [%rd14];
	mul.rn.f64 	%fd24, %fd232, %fd232;
	fma.rn.f64 	%fd122, %fd120, %fd24, %fd121;
	ld.const.f64 	%fd123, [%rd14+8];
	fma.rn.f64 	%fd124, %fd122, %fd24, %fd123;
	ld.const.f64 	%fd125, [%rd14+16];
	fma.rn.f64 	%fd126, %fd124, %fd24, %fd125;
	ld.const.f64 	%fd127, [%rd14+24];
	fma.rn.f64 	%fd128, %fd126, %fd24, %fd127;
	ld.const.f64 	%fd129, [%rd14+32];
	fma.rn.f64 	%fd130, %fd128, %fd24, %fd129;
	ld.const.f64 	%fd131, [%rd14+40];
	fma.rn.f64 	%fd25, %fd130, %fd24, %fd131;
	fma.rn.f64 	%fd233, %fd25, %fd232, %fd232;
	@%p13 bra 	BB98_18;

	mov.f64 	%fd132, 0d3FF0000000000000;
	fma.rn.f64 	%fd233, %fd25, %fd24, %fd132;

BB98_18:
	and.b32  	%r37, %r66, 2;
	setp.eq.s32	%p14, %r37, 0;
	@%p14 bra 	BB98_20;

	mov.f64 	%fd133, 0d0000000000000000;
	mov.f64 	%fd134, 0dBFF0000000000000;
	fma.rn.f64 	%fd233, %fd233, %fd134, %fd133;

BB98_20:
	mul.f64 	%fd135, %fd233, 0dBFF7AFE28BB120A4;
	fma.rn.f64 	%fd136, %fd229, 0d401BA2884DA3FB6A, %fd135;
	mul.f64 	%fd137, %fd4, %fd136;
	mul.f64 	%fd138, %fd2, %fd2;
	div.rn.f64 	%fd247, %fd137, %fd138;
	bra.uni 	BB98_52;

BB98_22:
	mul.f64 	%fd140, %fd75, 0d400921FB54442D18;
	div.rn.f64 	%fd235, %fd140, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd235;
	}
	and.b32  	%r39, %r38, 2147483647;
	setp.ne.s32	%p16, %r39, 2146435072;
	@%p16 bra 	BB98_25;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd235;
	}
	setp.ne.s32	%p17, %r40, 0;
	@%p17 bra 	BB98_25;

	mov.f64 	%fd141, 0d0000000000000000;
	mul.rn.f64 	%fd235, %fd235, %fd141;

BB98_25:
	mul.f64 	%fd142, %fd235, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r67, %fd142;
	add.u64 	%rd15, %SP, 0;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.u32 	[%rd16], %r67;
	cvt.rn.f64.s32	%fd143, %r67;
	neg.f64 	%fd144, %fd143;
	mov.f64 	%fd145, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd146, %fd144, %fd145, %fd235;
	mov.f64 	%fd147, 0d3C91A62633145C00;
	fma.rn.f64 	%fd148, %fd144, %fd147, %fd146;
	mov.f64 	%fd149, 0d397B839A252049C0;
	fma.rn.f64 	%fd236, %fd144, %fd149, %fd148;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd235;
	}
	and.b32  	%r42, %r41, 2145386496;
	setp.lt.u32	%p18, %r42, 1105199104;
	@%p18 bra 	BB98_27;

	// Callseq Start 219
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd235;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd236, [retval0+0];
	
	//{
	}// Callseq End 219
	ld.local.u32 	%r67, [%rd16];

BB98_27:
	add.s32 	%r11, %r67, 1;
	and.b32  	%r43, %r11, 1;
	shl.b32 	%r44, %r43, 3;
	setp.eq.s32	%p19, %r43, 0;
	selp.f64	%fd150, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p19;
	add.s32 	%r45, %r44, 1;
	mul.wide.s32 	%rd19, %r45, 8;
	mov.u64 	%rd20, __cudart_sin_cos_coeffs;
	add.s64 	%rd21, %rd20, %rd19;
	ld.const.f64 	%fd151, [%rd21];
	mul.rn.f64 	%fd38, %fd236, %fd236;
	fma.rn.f64 	%fd152, %fd150, %fd38, %fd151;
	ld.const.f64 	%fd153, [%rd21+8];
	fma.rn.f64 	%fd154, %fd152, %fd38, %fd153;
	ld.const.f64 	%fd155, [%rd21+16];
	fma.rn.f64 	%fd156, %fd154, %fd38, %fd155;
	ld.const.f64 	%fd157, [%rd21+24];
	fma.rn.f64 	%fd158, %fd156, %fd38, %fd157;
	ld.const.f64 	%fd159, [%rd21+32];
	fma.rn.f64 	%fd160, %fd158, %fd38, %fd159;
	ld.const.f64 	%fd161, [%rd21+40];
	fma.rn.f64 	%fd39, %fd160, %fd38, %fd161;
	fma.rn.f64 	%fd237, %fd39, %fd236, %fd236;
	@%p19 bra 	BB98_29;

	mov.f64 	%fd162, 0d3FF0000000000000;
	fma.rn.f64 	%fd237, %fd39, %fd38, %fd162;

BB98_29:
	and.b32  	%r46, %r11, 2;
	setp.eq.s32	%p20, %r46, 0;
	@%p20 bra 	BB98_31;

	mov.f64 	%fd163, 0d0000000000000000;
	mov.f64 	%fd164, 0dBFF0000000000000;
	fma.rn.f64 	%fd237, %fd237, %fd164, %fd163;

BB98_31:
	mul.f64 	%fd165, %fd2, %fd2;
	mul.f64 	%fd166, %fd237, 0d401BA2884DA3FB6A;
	div.rn.f64 	%fd45, %fd166, %fd165;
	sub.f64 	%fd167, %fd75, %fd2;
	mul.f64 	%fd168, %fd167, 0d400921FB54442D18;
	div.rn.f64 	%fd239, %fd168, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd239;
	}
	and.b32  	%r48, %r47, 2147483647;
	setp.ne.s32	%p21, %r48, 2146435072;
	@%p21 bra 	BB98_34;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd239;
	}
	setp.ne.s32	%p22, %r49, 0;
	@%p22 bra 	BB98_34;

	mov.f64 	%fd169, 0d0000000000000000;
	mul.rn.f64 	%fd239, %fd239, %fd169;

BB98_34:
	mul.f64 	%fd170, %fd239, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r68, %fd170;
	st.local.u32 	[%rd16], %r68;
	cvt.rn.f64.s32	%fd171, %r68;
	neg.f64 	%fd172, %fd171;
	fma.rn.f64 	%fd174, %fd172, %fd145, %fd239;
	fma.rn.f64 	%fd176, %fd172, %fd147, %fd174;
	fma.rn.f64 	%fd240, %fd172, %fd149, %fd176;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd239;
	}
	and.b32  	%r51, %r50, 2145386496;
	setp.lt.u32	%p23, %r51, 1105199104;
	@%p23 bra 	BB98_36;

	// Callseq Start 220
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd239;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd240, [retval0+0];
	
	//{
	}// Callseq End 220
	ld.local.u32 	%r68, [%rd16];

BB98_36:
	add.s32 	%r15, %r68, 1;
	and.b32  	%r52, %r15, 1;
	shl.b32 	%r53, %r52, 3;
	setp.eq.s32	%p24, %r52, 0;
	selp.f64	%fd178, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p24;
	add.s32 	%r54, %r53, 1;
	mul.wide.s32 	%rd26, %r54, 8;
	add.s64 	%rd28, %rd20, %rd26;
	ld.const.f64 	%fd179, [%rd28];
	mul.rn.f64 	%fd52, %fd240, %fd240;
	fma.rn.f64 	%fd180, %fd178, %fd52, %fd179;
	ld.const.f64 	%fd181, [%rd28+8];
	fma.rn.f64 	%fd182, %fd180, %fd52, %fd181;
	ld.const.f64 	%fd183, [%rd28+16];
	fma.rn.f64 	%fd184, %fd182, %fd52, %fd183;
	ld.const.f64 	%fd185, [%rd28+24];
	fma.rn.f64 	%fd186, %fd184, %fd52, %fd185;
	ld.const.f64 	%fd187, [%rd28+32];
	fma.rn.f64 	%fd188, %fd186, %fd52, %fd187;
	ld.const.f64 	%fd189, [%rd28+40];
	fma.rn.f64 	%fd53, %fd188, %fd52, %fd189;
	fma.rn.f64 	%fd241, %fd53, %fd240, %fd240;
	@%p24 bra 	BB98_38;

	mov.f64 	%fd190, 0d3FF0000000000000;
	fma.rn.f64 	%fd241, %fd53, %fd52, %fd190;

BB98_38:
	and.b32  	%r55, %r15, 2;
	setp.eq.s32	%p25, %r55, 0;
	@%p25 bra 	BB98_40;

	mov.f64 	%fd191, 0d0000000000000000;
	mov.f64 	%fd192, 0dBFF0000000000000;
	fma.rn.f64 	%fd241, %fd241, %fd192, %fd191;

BB98_40:
	mul.f64 	%fd193, %fd3, %fd3;
	mul.f64 	%fd194, %fd241, 0dC007AFE28BB120A4;
	div.rn.f64 	%fd195, %fd194, %fd193;
	add.f64 	%fd196, %fd45, %fd195;
	mul.f64 	%fd247, %fd4, %fd196;

BB98_52:
	st.param.f64	[func_retval0+0], %fd247;
	ret;
}

	// .globl	_Z8Liu_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8Liu_omttddPdiPii(
	.param .b64 _Z8Liu_omttddPdiPii_param_0,
	.param .b64 _Z8Liu_omttddPdiPii_param_1,
	.param .b64 _Z8Liu_omttddPdiPii_param_2,
	.param .b32 _Z8Liu_omttddPdiPii_param_3,
	.param .b64 _Z8Liu_omttddPdiPii_param_4,
	.param .b32 _Z8Liu_omttddPdiPii_param_5
)
{
	.local .align 4 .b8 	__local_depot99[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<57>;
	.reg .b32 	%r<126>;
	.reg .f64 	%fd<467>;
	.reg .b64 	%rd<61>;


	mov.u64 	%SPL, __local_depot99;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd137, [_Z8Liu_omttddPdiPii_param_0];
	ld.param.f64 	%fd138, [_Z8Liu_omttddPdiPii_param_1];
	add.u64 	%rd11, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd11;
	mov.f64 	%fd140, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd140, %fd137;
	mul.f64 	%fd2, %fd1, 0d3FC0A3D70A3D70A4;
	sub.f64 	%fd3, %fd1, %fd2;
	setp.gtu.f64	%p1, %fd1, %fd138;
	setp.geu.f64	%p2, %fd138, 0d0000000000000000;
	and.pred  	%p3, %p2, %p1;
	mov.f64 	%fd466, 0d0000000000000000;
	@!%p3 bra 	BB99_97;
	bra.uni 	BB99_1;

BB99_1:
	mul.f64 	%fd141, %fd2, 0d3FF3333333333333;
	mul.f64 	%fd142, %fd141, 0d3FD45F306DC9C883;
	fma.rn.f64 	%fd143, %fd2, 0d3FF6666666666666, %fd142;
	fma.rn.f64 	%fd144, %fd3, 0d3FD3333333333333, %fd143;
	rcp.rn.f64 	%fd145, %fd144;
	div.rn.f64 	%fd4, %fd145, %fd137;
	setp.ltu.f64	%p4, %fd2, %fd138;
	@%p4 bra 	BB99_39;
	bra.uni 	BB99_2;

BB99_39:
	add.f64 	%fd255, %fd2, %fd2;
	setp.ltu.f64	%p25, %fd255, %fd138;
	@%p25 bra 	BB99_77;
	bra.uni 	BB99_40;

BB99_77:
	setp.ltu.f64	%p46, %fd1, %fd138;
	@%p46 bra 	BB99_97;

	sub.f64 	%fd368, %fd138, %fd2;
	mul.f64 	%fd369, %fd368, 0d400921FB54442D18;
	div.rn.f64 	%fd462, %fd369, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r101}, %fd462;
	}
	and.b32  	%r33, %r101, 2147483647;
	setp.ne.s32	%p47, %r33, 2146435072;
	mov.f64 	%fd458, %fd462;
	@%p47 bra 	BB99_81;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r102, %temp}, %fd462;
	}
	setp.ne.s32	%p48, %r102, 0;
	mov.f64 	%fd458, %fd462;
	@%p48 bra 	BB99_81;

	mov.f64 	%fd370, 0d0000000000000000;
	mul.rn.f64 	%fd458, %fd462, %fd370;

BB99_81:
	mul.f64 	%fd371, %fd458, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r124, %fd371;
	st.local.u32 	[%rd1], %r124;
	cvt.rn.f64.s32	%fd372, %r124;
	neg.f64 	%fd373, %fd372;
	mov.f64 	%fd374, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd375, %fd373, %fd374, %fd458;
	mov.f64 	%fd376, 0d3C91A62633145C00;
	fma.rn.f64 	%fd377, %fd373, %fd376, %fd375;
	mov.f64 	%fd378, 0d397B839A252049C0;
	fma.rn.f64 	%fd459, %fd373, %fd378, %fd377;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r103}, %fd458;
	}
	and.b32  	%r104, %r103, 2145386496;
	setp.lt.u32	%p49, %r104, 1105199104;
	@%p49 bra 	BB99_83;

	// Callseq Start 230
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd458;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd459, [retval0+0];
	
	//{
	}// Callseq End 230
	ld.local.u32 	%r124, [%rd1];

BB99_83:
	and.b32  	%r105, %r124, 1;
	shl.b32 	%r106, %r105, 3;
	setp.eq.s32	%p50, %r105, 0;
	selp.f64	%fd379, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p50;
	add.s32 	%r107, %r106, 1;
	mul.wide.s32 	%rd54, %r107, 8;
	mov.u64 	%rd55, __cudart_sin_cos_coeffs;
	add.s64 	%rd56, %rd55, %rd54;
	ld.const.f64 	%fd380, [%rd56];
	mul.rn.f64 	%fd116, %fd459, %fd459;
	fma.rn.f64 	%fd381, %fd379, %fd116, %fd380;
	ld.const.f64 	%fd382, [%rd56+8];
	fma.rn.f64 	%fd383, %fd381, %fd116, %fd382;
	ld.const.f64 	%fd384, [%rd56+16];
	fma.rn.f64 	%fd385, %fd383, %fd116, %fd384;
	ld.const.f64 	%fd386, [%rd56+24];
	fma.rn.f64 	%fd387, %fd385, %fd116, %fd386;
	ld.const.f64 	%fd388, [%rd56+32];
	fma.rn.f64 	%fd389, %fd387, %fd116, %fd388;
	ld.const.f64 	%fd390, [%rd56+40];
	fma.rn.f64 	%fd117, %fd389, %fd116, %fd390;
	fma.rn.f64 	%fd460, %fd117, %fd459, %fd459;
	@%p50 bra 	BB99_85;

	mov.f64 	%fd391, 0d3FF0000000000000;
	fma.rn.f64 	%fd460, %fd117, %fd116, %fd391;

BB99_85:
	and.b32  	%r108, %r124, 2;
	setp.eq.s32	%p51, %r108, 0;
	@%p51 bra 	BB99_87;

	mov.f64 	%fd392, 0d0000000000000000;
	mov.f64 	%fd393, 0dBFF0000000000000;
	fma.rn.f64 	%fd460, %fd460, %fd393, %fd392;

BB99_87:
	@%p47 bra 	BB99_90;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r109, %temp}, %fd462;
	}
	setp.ne.s32	%p53, %r109, 0;
	@%p53 bra 	BB99_90;

	mov.f64 	%fd394, 0d0000000000000000;
	mul.rn.f64 	%fd462, %fd462, %fd394;

BB99_90:
	mul.f64 	%fd395, %fd462, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r125, %fd395;
	st.local.u32 	[%rd1], %r125;
	cvt.rn.f64.s32	%fd396, %r125;
	neg.f64 	%fd397, %fd396;
	fma.rn.f64 	%fd399, %fd397, %fd374, %fd462;
	fma.rn.f64 	%fd401, %fd397, %fd376, %fd399;
	fma.rn.f64 	%fd463, %fd397, %fd378, %fd401;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd462;
	}
	and.b32  	%r111, %r110, 2145386496;
	setp.lt.u32	%p54, %r111, 1105199104;
	@%p54 bra 	BB99_92;

	// Callseq Start 231
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd462;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd463, [retval0+0];
	
	//{
	}// Callseq End 231
	ld.local.u32 	%r125, [%rd1];

BB99_92:
	add.s32 	%r40, %r125, 1;
	and.b32  	%r112, %r40, 1;
	shl.b32 	%r113, %r112, 3;
	setp.eq.s32	%p55, %r112, 0;
	selp.f64	%fd403, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p55;
	add.s32 	%r114, %r113, 1;
	mul.wide.s32 	%rd58, %r114, 8;
	add.s64 	%rd60, %rd55, %rd58;
	ld.const.f64 	%fd404, [%rd60];
	mul.rn.f64 	%fd128, %fd463, %fd463;
	fma.rn.f64 	%fd405, %fd403, %fd128, %fd404;
	ld.const.f64 	%fd406, [%rd60+8];
	fma.rn.f64 	%fd407, %fd405, %fd128, %fd406;
	ld.const.f64 	%fd408, [%rd60+16];
	fma.rn.f64 	%fd409, %fd407, %fd128, %fd408;
	ld.const.f64 	%fd410, [%rd60+24];
	fma.rn.f64 	%fd411, %fd409, %fd128, %fd410;
	ld.const.f64 	%fd412, [%rd60+32];
	fma.rn.f64 	%fd413, %fd411, %fd128, %fd412;
	ld.const.f64 	%fd414, [%rd60+40];
	fma.rn.f64 	%fd129, %fd413, %fd128, %fd414;
	fma.rn.f64 	%fd464, %fd129, %fd463, %fd463;
	@%p55 bra 	BB99_94;

	mov.f64 	%fd415, 0d3FF0000000000000;
	fma.rn.f64 	%fd464, %fd129, %fd128, %fd415;

BB99_94:
	and.b32  	%r115, %r40, 2;
	setp.eq.s32	%p56, %r115, 0;
	@%p56 bra 	BB99_96;

	mov.f64 	%fd416, 0d0000000000000000;
	mov.f64 	%fd417, 0dBFF0000000000000;
	fma.rn.f64 	%fd464, %fd464, %fd417, %fd416;

BB99_96:
	mul.f64 	%fd418, %fd3, %fd3;
	mul.f64 	%fd419, %fd138, 0d400921FB54442D18;
	mul.f64 	%fd420, %fd419, %fd464;
	div.rn.f64 	%fd421, %fd420, %fd418;
	add.f64 	%fd422, %fd460, %fd460;
	div.rn.f64 	%fd423, %fd422, %fd3;
	add.f64 	%fd424, %fd423, %fd421;
	mul.f64 	%fd425, %fd4, 0dBFEE28C731EB6950;
	mul.f64 	%fd466, %fd425, %fd424;
	bra.uni 	BB99_97;

BB99_2:
	mov.f64 	%fd146, 0d400921FB54442D18;
	div.rn.f64 	%fd147, %fd146, %fd2;
	mul.f64 	%fd434, %fd147, %fd138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd434;
	}
	and.b32  	%r1, %r41, 2147483647;
	setp.ne.s32	%p5, %r1, 2146435072;
	mov.f64 	%fd426, %fd434;
	@%p5 bra 	BB99_5;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd434;
	}
	setp.ne.s32	%p6, %r42, 0;
	mov.f64 	%fd426, %fd434;
	@%p6 bra 	BB99_5;

	mov.f64 	%fd148, 0d0000000000000000;
	mul.rn.f64 	%fd426, %fd434, %fd148;

BB99_5:
	mul.f64 	%fd149, %fd426, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r116, %fd149;
	st.local.u32 	[%rd1], %r116;
	cvt.rn.f64.s32	%fd150, %r116;
	neg.f64 	%fd151, %fd150;
	mov.f64 	%fd152, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd153, %fd151, %fd152, %fd426;
	mov.f64 	%fd154, 0d3C91A62633145C00;
	fma.rn.f64 	%fd155, %fd151, %fd154, %fd153;
	mov.f64 	%fd156, 0d397B839A252049C0;
	fma.rn.f64 	%fd427, %fd151, %fd156, %fd155;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd426;
	}
	and.b32  	%r44, %r43, 2145386496;
	setp.lt.u32	%p7, %r44, 1105199104;
	@%p7 bra 	BB99_7;

	// Callseq Start 222
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd426;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd427, [retval0+0];
	
	//{
	}// Callseq End 222
	ld.local.u32 	%r116, [%rd1];

BB99_7:
	and.b32  	%r45, %r116, 1;
	shl.b32 	%r46, %r45, 3;
	setp.eq.s32	%p8, %r45, 0;
	selp.f64	%fd157, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	add.s32 	%r47, %r46, 1;
	mul.wide.s32 	%rd22, %r47, 8;
	mov.u64 	%rd23, __cudart_sin_cos_coeffs;
	add.s64 	%rd24, %rd23, %rd22;
	ld.const.f64 	%fd158, [%rd24];
	mul.rn.f64 	%fd11, %fd427, %fd427;
	fma.rn.f64 	%fd159, %fd157, %fd11, %fd158;
	ld.const.f64 	%fd160, [%rd24+8];
	fma.rn.f64 	%fd161, %fd159, %fd11, %fd160;
	ld.const.f64 	%fd162, [%rd24+16];
	fma.rn.f64 	%fd163, %fd161, %fd11, %fd162;
	ld.const.f64 	%fd164, [%rd24+24];
	fma.rn.f64 	%fd165, %fd163, %fd11, %fd164;
	ld.const.f64 	%fd166, [%rd24+32];
	fma.rn.f64 	%fd167, %fd165, %fd11, %fd166;
	ld.const.f64 	%fd168, [%rd24+40];
	fma.rn.f64 	%fd12, %fd167, %fd11, %fd168;
	fma.rn.f64 	%fd428, %fd12, %fd427, %fd427;
	@%p8 bra 	BB99_9;

	mov.f64 	%fd169, 0d3FF0000000000000;
	fma.rn.f64 	%fd428, %fd12, %fd11, %fd169;

BB99_9:
	and.b32  	%r48, %r116, 2;
	setp.eq.s32	%p9, %r48, 0;
	@%p9 bra 	BB99_11;

	mov.f64 	%fd170, 0d0000000000000000;
	mov.f64 	%fd171, 0dBFF0000000000000;
	fma.rn.f64 	%fd428, %fd428, %fd171, %fd170;

BB99_11:
	div.rn.f64 	%fd173, %fd152, %fd2;
	mul.f64 	%fd438, %fd173, %fd138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd438;
	}
	and.b32  	%r5, %r49, 2147483647;
	setp.ne.s32	%p10, %r5, 2146435072;
	mov.f64 	%fd430, %fd438;
	@%p10 bra 	BB99_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd438;
	}
	setp.ne.s32	%p11, %r50, 0;
	mov.f64 	%fd430, %fd438;
	@%p11 bra 	BB99_14;

	mov.f64 	%fd174, 0d0000000000000000;
	mul.rn.f64 	%fd430, %fd438, %fd174;

BB99_14:
	mul.f64 	%fd175, %fd430, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r117, %fd175;
	st.local.u32 	[%rd1], %r117;
	cvt.rn.f64.s32	%fd176, %r117;
	neg.f64 	%fd177, %fd176;
	fma.rn.f64 	%fd179, %fd177, %fd152, %fd430;
	fma.rn.f64 	%fd181, %fd177, %fd154, %fd179;
	fma.rn.f64 	%fd431, %fd177, %fd156, %fd181;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd430;
	}
	and.b32  	%r52, %r51, 2145386496;
	setp.lt.u32	%p12, %r52, 1105199104;
	@%p12 bra 	BB99_16;

	// Callseq Start 223
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd430;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd431, [retval0+0];
	
	//{
	}// Callseq End 223
	ld.local.u32 	%r117, [%rd1];

BB99_16:
	add.s32 	%r9, %r117, 1;
	and.b32  	%r53, %r9, 1;
	shl.b32 	%r54, %r53, 3;
	setp.eq.s32	%p13, %r53, 0;
	selp.f64	%fd183, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p13;
	add.s32 	%r55, %r54, 1;
	mul.wide.s32 	%rd26, %r55, 8;
	add.s64 	%rd28, %rd23, %rd26;
	ld.const.f64 	%fd184, [%rd28];
	mul.rn.f64 	%fd24, %fd431, %fd431;
	fma.rn.f64 	%fd185, %fd183, %fd24, %fd184;
	ld.const.f64 	%fd186, [%rd28+8];
	fma.rn.f64 	%fd187, %fd185, %fd24, %fd186;
	ld.const.f64 	%fd188, [%rd28+16];
	fma.rn.f64 	%fd189, %fd187, %fd24, %fd188;
	ld.const.f64 	%fd190, [%rd28+24];
	fma.rn.f64 	%fd191, %fd189, %fd24, %fd190;
	ld.const.f64 	%fd192, [%rd28+32];
	fma.rn.f64 	%fd193, %fd191, %fd24, %fd192;
	ld.const.f64 	%fd194, [%rd28+40];
	fma.rn.f64 	%fd25, %fd193, %fd24, %fd194;
	fma.rn.f64 	%fd432, %fd25, %fd431, %fd431;
	@%p13 bra 	BB99_18;

	mov.f64 	%fd195, 0d3FF0000000000000;
	fma.rn.f64 	%fd432, %fd25, %fd24, %fd195;

BB99_18:
	and.b32  	%r56, %r9, 2;
	setp.eq.s32	%p14, %r56, 0;
	@%p14 bra 	BB99_20;

	mov.f64 	%fd196, 0d0000000000000000;
	mov.f64 	%fd197, 0dBFF0000000000000;
	fma.rn.f64 	%fd432, %fd432, %fd197, %fd196;

BB99_20:
	mul.f64 	%fd198, %fd432, 0d3FEE28C731EB6950;
	fma.rn.f64 	%fd31, %fd428, 0d400197C987C952C4, %fd198;
	@%p5 bra 	BB99_23;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd434;
	}
	setp.ne.s32	%p16, %r57, 0;
	@%p16 bra 	BB99_23;

	mov.f64 	%fd199, 0d0000000000000000;
	mul.rn.f64 	%fd434, %fd434, %fd199;

BB99_23:
	mul.f64 	%fd200, %fd434, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r118, %fd200;
	st.local.u32 	[%rd1], %r118;
	cvt.rn.f64.s32	%fd201, %r118;
	neg.f64 	%fd202, %fd201;
	fma.rn.f64 	%fd204, %fd202, %fd152, %fd434;
	fma.rn.f64 	%fd206, %fd202, %fd154, %fd204;
	fma.rn.f64 	%fd435, %fd202, %fd156, %fd206;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd434;
	}
	and.b32  	%r59, %r58, 2145386496;
	setp.lt.u32	%p17, %r59, 1105199104;
	@%p17 bra 	BB99_25;

	// Callseq Start 224
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd434;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd435, [retval0+0];
	
	//{
	}// Callseq End 224
	ld.local.u32 	%r118, [%rd1];

BB99_25:
	add.s32 	%r13, %r118, 1;
	and.b32  	%r60, %r13, 1;
	shl.b32 	%r61, %r60, 3;
	setp.eq.s32	%p18, %r60, 0;
	selp.f64	%fd208, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p18;
	add.s32 	%r62, %r61, 1;
	mul.wide.s32 	%rd30, %r62, 8;
	add.s64 	%rd32, %rd23, %rd30;
	ld.const.f64 	%fd209, [%rd32];
	mul.rn.f64 	%fd37, %fd435, %fd435;
	fma.rn.f64 	%fd210, %fd208, %fd37, %fd209;
	ld.const.f64 	%fd211, [%rd32+8];
	fma.rn.f64 	%fd212, %fd210, %fd37, %fd211;
	ld.const.f64 	%fd213, [%rd32+16];
	fma.rn.f64 	%fd214, %fd212, %fd37, %fd213;
	ld.const.f64 	%fd215, [%rd32+24];
	fma.rn.f64 	%fd216, %fd214, %fd37, %fd215;
	ld.const.f64 	%fd217, [%rd32+32];
	fma.rn.f64 	%fd218, %fd216, %fd37, %fd217;
	ld.const.f64 	%fd219, [%rd32+40];
	fma.rn.f64 	%fd38, %fd218, %fd37, %fd219;
	fma.rn.f64 	%fd436, %fd38, %fd435, %fd435;
	@%p18 bra 	BB99_27;

	mov.f64 	%fd220, 0d3FF0000000000000;
	fma.rn.f64 	%fd436, %fd38, %fd37, %fd220;

BB99_27:
	and.b32  	%r63, %r13, 2;
	setp.eq.s32	%p19, %r63, 0;
	@%p19 bra 	BB99_29;

	mov.f64 	%fd221, 0d0000000000000000;
	mov.f64 	%fd222, 0dBFF0000000000000;
	fma.rn.f64 	%fd436, %fd436, %fd222, %fd221;

BB99_29:
	@%p10 bra 	BB99_32;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd438;
	}
	setp.ne.s32	%p21, %r64, 0;
	@%p21 bra 	BB99_32;

	mov.f64 	%fd223, 0d0000000000000000;
	mul.rn.f64 	%fd438, %fd438, %fd223;

BB99_32:
	mul.f64 	%fd224, %fd438, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r119, %fd224;
	st.local.u32 	[%rd1], %r119;
	cvt.rn.f64.s32	%fd225, %r119;
	neg.f64 	%fd226, %fd225;
	fma.rn.f64 	%fd228, %fd226, %fd152, %fd438;
	fma.rn.f64 	%fd230, %fd226, %fd154, %fd228;
	fma.rn.f64 	%fd439, %fd226, %fd156, %fd230;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd438;
	}
	and.b32  	%r66, %r65, 2145386496;
	setp.lt.u32	%p22, %r66, 1105199104;
	@%p22 bra 	BB99_34;

	// Callseq Start 225
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd438;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd439, [retval0+0];
	
	//{
	}// Callseq End 225
	ld.local.u32 	%r119, [%rd1];

BB99_34:
	and.b32  	%r67, %r119, 1;
	shl.b32 	%r68, %r67, 3;
	setp.eq.s32	%p23, %r67, 0;
	selp.f64	%fd232, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p23;
	add.s32 	%r69, %r68, 1;
	mul.wide.s32 	%rd34, %r69, 8;
	add.s64 	%rd36, %rd23, %rd34;
	ld.const.f64 	%fd233, [%rd36];
	mul.rn.f64 	%fd49, %fd439, %fd439;
	fma.rn.f64 	%fd234, %fd232, %fd49, %fd233;
	ld.const.f64 	%fd235, [%rd36+8];
	fma.rn.f64 	%fd236, %fd234, %fd49, %fd235;
	ld.const.f64 	%fd237, [%rd36+16];
	fma.rn.f64 	%fd238, %fd236, %fd49, %fd237;
	ld.const.f64 	%fd239, [%rd36+24];
	fma.rn.f64 	%fd240, %fd238, %fd49, %fd239;
	ld.const.f64 	%fd241, [%rd36+32];
	fma.rn.f64 	%fd242, %fd240, %fd49, %fd241;
	ld.const.f64 	%fd243, [%rd36+40];
	fma.rn.f64 	%fd50, %fd242, %fd49, %fd243;
	fma.rn.f64 	%fd440, %fd50, %fd439, %fd439;
	@%p23 bra 	BB99_36;

	mov.f64 	%fd244, 0d3FF0000000000000;
	fma.rn.f64 	%fd440, %fd50, %fd49, %fd244;

BB99_36:
	and.b32  	%r70, %r119, 2;
	setp.eq.s32	%p24, %r70, 0;
	@%p24 bra 	BB99_38;

	mov.f64 	%fd245, 0d0000000000000000;
	mov.f64 	%fd246, 0dBFF0000000000000;
	fma.rn.f64 	%fd440, %fd440, %fd246, %fd245;

BB99_38:
	mul.f64 	%fd247, %fd138, 0dBFF7AFE28BB120A4;
	div.rn.f64 	%fd248, %fd247, %fd2;
	mul.f64 	%fd249, %fd248, %fd440;
	mul.f64 	%fd250, %fd138, 0d401BA2884DA3FB6A;
	div.rn.f64 	%fd251, %fd250, %fd2;
	fma.rn.f64 	%fd252, %fd251, %fd436, %fd249;
	fma.rn.f64 	%fd253, %fd31, 0d4000000000000000, %fd252;
	mul.f64 	%fd254, %fd4, %fd253;
	div.rn.f64 	%fd466, %fd254, %fd2;
	bra.uni 	BB99_97;

BB99_40:
	mul.f64 	%fd256, %fd138, 0d400921FB54442D18;
	div.rn.f64 	%fd450, %fd256, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd450;
	}
	and.b32  	%r17, %r71, 2147483647;
	setp.ne.s32	%p26, %r17, 2146435072;
	mov.f64 	%fd442, %fd450;
	@%p26 bra 	BB99_43;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd450;
	}
	setp.ne.s32	%p27, %r72, 0;
	mov.f64 	%fd442, %fd450;
	@%p27 bra 	BB99_43;

	mov.f64 	%fd257, 0d0000000000000000;
	mul.rn.f64 	%fd442, %fd450, %fd257;

BB99_43:
	mul.f64 	%fd258, %fd442, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r120, %fd258;
	st.local.u32 	[%rd1], %r120;
	cvt.rn.f64.s32	%fd259, %r120;
	neg.f64 	%fd260, %fd259;
	mov.f64 	%fd261, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd262, %fd260, %fd261, %fd442;
	mov.f64 	%fd263, 0d3C91A62633145C00;
	fma.rn.f64 	%fd264, %fd260, %fd263, %fd262;
	mov.f64 	%fd265, 0d397B839A252049C0;
	fma.rn.f64 	%fd443, %fd260, %fd265, %fd264;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd442;
	}
	and.b32  	%r74, %r73, 2145386496;
	setp.lt.u32	%p28, %r74, 1105199104;
	@%p28 bra 	BB99_45;

	// Callseq Start 226
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd442;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd443, [retval0+0];
	
	//{
	}// Callseq End 226
	ld.local.u32 	%r120, [%rd1];

BB99_45:
	and.b32  	%r75, %r120, 1;
	shl.b32 	%r76, %r75, 3;
	setp.eq.s32	%p29, %r75, 0;
	selp.f64	%fd266, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p29;
	add.s32 	%r77, %r76, 1;
	mul.wide.s32 	%rd38, %r77, 8;
	mov.u64 	%rd39, __cudart_sin_cos_coeffs;
	add.s64 	%rd40, %rd39, %rd38;
	ld.const.f64 	%fd267, [%rd40];
	mul.rn.f64 	%fd63, %fd443, %fd443;
	fma.rn.f64 	%fd268, %fd266, %fd63, %fd267;
	ld.const.f64 	%fd269, [%rd40+8];
	fma.rn.f64 	%fd270, %fd268, %fd63, %fd269;
	ld.const.f64 	%fd271, [%rd40+16];
	fma.rn.f64 	%fd272, %fd270, %fd63, %fd271;
	ld.const.f64 	%fd273, [%rd40+24];
	fma.rn.f64 	%fd274, %fd272, %fd63, %fd273;
	ld.const.f64 	%fd275, [%rd40+32];
	fma.rn.f64 	%fd276, %fd274, %fd63, %fd275;
	ld.const.f64 	%fd277, [%rd40+40];
	fma.rn.f64 	%fd64, %fd276, %fd63, %fd277;
	fma.rn.f64 	%fd444, %fd64, %fd443, %fd443;
	@%p29 bra 	BB99_47;

	mov.f64 	%fd278, 0d3FF0000000000000;
	fma.rn.f64 	%fd444, %fd64, %fd63, %fd278;

BB99_47:
	and.b32  	%r78, %r120, 2;
	setp.eq.s32	%p30, %r78, 0;
	@%p30 bra 	BB99_49;

	mov.f64 	%fd279, 0d0000000000000000;
	mov.f64 	%fd280, 0dBFF0000000000000;
	fma.rn.f64 	%fd444, %fd444, %fd280, %fd279;

BB99_49:
	sub.f64 	%fd281, %fd138, %fd2;
	mul.f64 	%fd282, %fd281, 0d400921FB54442D18;
	div.rn.f64 	%fd454, %fd282, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd454;
	}
	and.b32  	%r21, %r79, 2147483647;
	setp.ne.s32	%p31, %r21, 2146435072;
	mov.f64 	%fd446, %fd454;
	@%p31 bra 	BB99_52;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r80, %temp}, %fd454;
	}
	setp.ne.s32	%p32, %r80, 0;
	mov.f64 	%fd446, %fd454;
	@%p32 bra 	BB99_52;

	mov.f64 	%fd283, 0d0000000000000000;
	mul.rn.f64 	%fd446, %fd454, %fd283;

BB99_52:
	mul.f64 	%fd284, %fd446, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r121, %fd284;
	st.local.u32 	[%rd1], %r121;
	cvt.rn.f64.s32	%fd285, %r121;
	neg.f64 	%fd286, %fd285;
	fma.rn.f64 	%fd288, %fd286, %fd261, %fd446;
	fma.rn.f64 	%fd290, %fd286, %fd263, %fd288;
	fma.rn.f64 	%fd447, %fd286, %fd265, %fd290;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r81}, %fd446;
	}
	and.b32  	%r82, %r81, 2145386496;
	setp.lt.u32	%p33, %r82, 1105199104;
	@%p33 bra 	BB99_54;

	// Callseq Start 227
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd446;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd447, [retval0+0];
	
	//{
	}// Callseq End 227
	ld.local.u32 	%r121, [%rd1];

BB99_54:
	and.b32  	%r83, %r121, 1;
	shl.b32 	%r84, %r83, 3;
	setp.eq.s32	%p34, %r83, 0;
	selp.f64	%fd292, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p34;
	add.s32 	%r85, %r84, 1;
	mul.wide.s32 	%rd42, %r85, 8;
	add.s64 	%rd44, %rd39, %rd42;
	ld.const.f64 	%fd293, [%rd44];
	mul.rn.f64 	%fd76, %fd447, %fd447;
	fma.rn.f64 	%fd294, %fd292, %fd76, %fd293;
	ld.const.f64 	%fd295, [%rd44+8];
	fma.rn.f64 	%fd296, %fd294, %fd76, %fd295;
	ld.const.f64 	%fd297, [%rd44+16];
	fma.rn.f64 	%fd298, %fd296, %fd76, %fd297;
	ld.const.f64 	%fd299, [%rd44+24];
	fma.rn.f64 	%fd300, %fd298, %fd76, %fd299;
	ld.const.f64 	%fd301, [%rd44+32];
	fma.rn.f64 	%fd302, %fd300, %fd76, %fd301;
	ld.const.f64 	%fd303, [%rd44+40];
	fma.rn.f64 	%fd77, %fd302, %fd76, %fd303;
	fma.rn.f64 	%fd448, %fd77, %fd447, %fd447;
	@%p34 bra 	BB99_56;

	mov.f64 	%fd304, 0d3FF0000000000000;
	fma.rn.f64 	%fd448, %fd77, %fd76, %fd304;

BB99_56:
	and.b32  	%r86, %r121, 2;
	setp.eq.s32	%p35, %r86, 0;
	@%p35 bra 	BB99_58;

	mov.f64 	%fd305, 0d0000000000000000;
	mov.f64 	%fd306, 0dBFF0000000000000;
	fma.rn.f64 	%fd448, %fd448, %fd306, %fd305;

BB99_58:
	mul.f64 	%fd307, %fd448, 0dBFEE28C731EB6950;
	div.rn.f64 	%fd308, %fd307, %fd3;
	mul.f64 	%fd309, %fd444, 0d400197C987C952C4;
	div.rn.f64 	%fd310, %fd309, %fd2;
	add.f64 	%fd83, %fd310, %fd308;
	@%p26 bra 	BB99_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r87, %temp}, %fd450;
	}
	setp.ne.s32	%p37, %r87, 0;
	@%p37 bra 	BB99_61;

	mov.f64 	%fd311, 0d0000000000000000;
	mul.rn.f64 	%fd450, %fd450, %fd311;

BB99_61:
	mul.f64 	%fd312, %fd450, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r122, %fd312;
	st.local.u32 	[%rd1], %r122;
	cvt.rn.f64.s32	%fd313, %r122;
	neg.f64 	%fd314, %fd313;
	fma.rn.f64 	%fd316, %fd314, %fd261, %fd450;
	fma.rn.f64 	%fd318, %fd314, %fd263, %fd316;
	fma.rn.f64 	%fd451, %fd314, %fd265, %fd318;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd450;
	}
	and.b32  	%r89, %r88, 2145386496;
	setp.lt.u32	%p38, %r89, 1105199104;
	@%p38 bra 	BB99_63;

	// Callseq Start 228
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd450;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd451, [retval0+0];
	
	//{
	}// Callseq End 228
	ld.local.u32 	%r122, [%rd1];

BB99_63:
	add.s32 	%r28, %r122, 1;
	and.b32  	%r90, %r28, 1;
	shl.b32 	%r91, %r90, 3;
	setp.eq.s32	%p39, %r90, 0;
	selp.f64	%fd320, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p39;
	add.s32 	%r92, %r91, 1;
	mul.wide.s32 	%rd46, %r92, 8;
	add.s64 	%rd48, %rd39, %rd46;
	ld.const.f64 	%fd321, [%rd48];
	mul.rn.f64 	%fd89, %fd451, %fd451;
	fma.rn.f64 	%fd322, %fd320, %fd89, %fd321;
	ld.const.f64 	%fd323, [%rd48+8];
	fma.rn.f64 	%fd324, %fd322, %fd89, %fd323;
	ld.const.f64 	%fd325, [%rd48+16];
	fma.rn.f64 	%fd326, %fd324, %fd89, %fd325;
	ld.const.f64 	%fd327, [%rd48+24];
	fma.rn.f64 	%fd328, %fd326, %fd89, %fd327;
	ld.const.f64 	%fd329, [%rd48+32];
	fma.rn.f64 	%fd330, %fd328, %fd89, %fd329;
	ld.const.f64 	%fd331, [%rd48+40];
	fma.rn.f64 	%fd90, %fd330, %fd89, %fd331;
	fma.rn.f64 	%fd452, %fd90, %fd451, %fd451;
	@%p39 bra 	BB99_65;

	mov.f64 	%fd332, 0d3FF0000000000000;
	fma.rn.f64 	%fd452, %fd90, %fd89, %fd332;

BB99_65:
	and.b32  	%r93, %r28, 2;
	setp.eq.s32	%p40, %r93, 0;
	@%p40 bra 	BB99_67;

	mov.f64 	%fd333, 0d0000000000000000;
	mov.f64 	%fd334, 0dBFF0000000000000;
	fma.rn.f64 	%fd452, %fd452, %fd334, %fd333;

BB99_67:
	mul.f64 	%fd335, %fd2, %fd2;
	mul.f64 	%fd336, %fd452, 0d401BA2884DA3FB6A;
	div.rn.f64 	%fd96, %fd336, %fd335;
	@%p31 bra 	BB99_70;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd454;
	}
	setp.ne.s32	%p42, %r94, 0;
	@%p42 bra 	BB99_70;

	mov.f64 	%fd337, 0d0000000000000000;
	mul.rn.f64 	%fd454, %fd454, %fd337;

BB99_70:
	mul.f64 	%fd338, %fd454, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r123, %fd338;
	st.local.u32 	[%rd1], %r123;
	cvt.rn.f64.s32	%fd339, %r123;
	neg.f64 	%fd340, %fd339;
	fma.rn.f64 	%fd342, %fd340, %fd261, %fd454;
	fma.rn.f64 	%fd344, %fd340, %fd263, %fd342;
	fma.rn.f64 	%fd455, %fd340, %fd265, %fd344;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd454;
	}
	and.b32  	%r96, %r95, 2145386496;
	setp.lt.u32	%p43, %r96, 1105199104;
	@%p43 bra 	BB99_72;

	// Callseq Start 229
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd454;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd11;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd455, [retval0+0];
	
	//{
	}// Callseq End 229
	ld.local.u32 	%r123, [%rd1];

BB99_72:
	add.s32 	%r32, %r123, 1;
	and.b32  	%r97, %r32, 1;
	shl.b32 	%r98, %r97, 3;
	setp.eq.s32	%p44, %r97, 0;
	selp.f64	%fd346, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p44;
	add.s32 	%r99, %r98, 1;
	mul.wide.s32 	%rd50, %r99, 8;
	add.s64 	%rd52, %rd39, %rd50;
	ld.const.f64 	%fd347, [%rd52];
	mul.rn.f64 	%fd102, %fd455, %fd455;
	fma.rn.f64 	%fd348, %fd346, %fd102, %fd347;
	ld.const.f64 	%fd349, [%rd52+8];
	fma.rn.f64 	%fd350, %fd348, %fd102, %fd349;
	ld.const.f64 	%fd351, [%rd52+16];
	fma.rn.f64 	%fd352, %fd350, %fd102, %fd351;
	ld.const.f64 	%fd353, [%rd52+24];
	fma.rn.f64 	%fd354, %fd352, %fd102, %fd353;
	ld.const.f64 	%fd355, [%rd52+32];
	fma.rn.f64 	%fd356, %fd354, %fd102, %fd355;
	ld.const.f64 	%fd357, [%rd52+40];
	fma.rn.f64 	%fd103, %fd356, %fd102, %fd357;
	fma.rn.f64 	%fd456, %fd103, %fd455, %fd455;
	@%p44 bra 	BB99_74;

	mov.f64 	%fd358, 0d3FF0000000000000;
	fma.rn.f64 	%fd456, %fd103, %fd102, %fd358;

BB99_74:
	and.b32  	%r100, %r32, 2;
	setp.eq.s32	%p45, %r100, 0;
	@%p45 bra 	BB99_76;

	mov.f64 	%fd359, 0d0000000000000000;
	mov.f64 	%fd360, 0dBFF0000000000000;
	fma.rn.f64 	%fd456, %fd456, %fd360, %fd359;

BB99_76:
	mul.f64 	%fd361, %fd3, %fd3;
	mul.f64 	%fd362, %fd456, 0dC007AFE28BB120A4;
	div.rn.f64 	%fd363, %fd362, %fd361;
	add.f64 	%fd364, %fd96, %fd363;
	mul.f64 	%fd365, %fd364, %fd138;
	fma.rn.f64 	%fd366, %fd83, 0d4000000000000000, %fd365;
	mul.f64 	%fd466, %fd4, %fd366;

BB99_97:
	st.param.f64	[func_retval0+0], %fd466;
	ret;
}

	// .globl	_Z5DiracddPdiPii
.visible .func  (.param .b64 func_retval0) _Z5DiracddPdiPii(
	.param .b64 _Z5DiracddPdiPii_param_0,
	.param .b64 _Z5DiracddPdiPii_param_1,
	.param .b64 _Z5DiracddPdiPii_param_2,
	.param .b32 _Z5DiracddPdiPii_param_3,
	.param .b64 _Z5DiracddPdiPii_param_4,
	.param .b32 _Z5DiracddPdiPii_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<3>;
	.reg .f64 	%fd<55>;


	ld.param.f64 	%fd13, [_Z5DiracddPdiPii_param_0];
	ld.param.f64 	%fd15, [_Z5DiracddPdiPii_param_1];
	mul.f64 	%fd1, %fd13, %fd15;
	mov.f64 	%fd16, 0d3FE0000000000000;
	sub.f64 	%fd17, %fd16, %fd1;
	cvt.rmi.f64.f64	%fd18, %fd17;
	cvt.rzi.s32.f64	%r1, %fd18;
	add.s32 	%r2, %r1, 2;
	setp.gt.u32	%p1, %r2, 4;
	mov.f64 	%fd54, 0d0000000000000000;
	@%p1 bra 	BB100_12;

	neg.f64 	%fd19, %fd1;
	cvt.rn.f64.s32	%fd20, %r1;
	sub.f64 	%fd2, %fd19, %fd20;
	mul.f64 	%fd3, %fd2, %fd2;
	mul.f64 	%fd21, %fd3, %fd3;
	fma.rn.f64 	%fd22, %fd3, 0dC024200000000000, 0d4004C80000000000;
	mul.f64 	%fd23, %fd3, 0d4036E00000000000;
	fma.rn.f64 	%fd24, %fd3, %fd23, %fd22;
	mul.f64 	%fd25, %fd3, 0dC03AAAAAAAAAAAB4;
	mul.f64 	%fd26, %fd3, %fd25;
	fma.rn.f64 	%fd27, %fd3, %fd26, %fd24;
	mul.f64 	%fd28, %fd3, 0d4027555555555568;
	mul.f64 	%fd29, %fd3, %fd28;
	mul.f64 	%fd30, %fd3, %fd29;
	fma.rn.f64 	%fd31, %fd3, %fd30, %fd27;
	mul.f64 	%fd4, %fd21, %fd31;
	setp.eq.s32	%p2, %r1, 2;
	@%p2 bra 	BB100_10;
	bra.uni 	BB100_2;

BB100_10:
	mul.f64 	%fd48, %fd2, 0d3FB5555555555553;
	mov.f64 	%fd49, 0d3FF0000000000000;
	sub.f64 	%fd50, %fd49, %fd3;
	mul.f64 	%fd51, %fd3, 0dBFDA400000000000;
	fma.rn.f64 	%fd52, %fd48, %fd50, %fd51;
	add.f64 	%fd53, %fd52, %fd4;
	bra.uni 	BB100_11;

BB100_2:
	setp.eq.s32	%p3, %r1, 1;
	@%p3 bra 	BB100_9;
	bra.uni 	BB100_3;

BB100_9:
	mul.f64 	%fd44, %fd2, 0d3FC5555555555561;
	add.f64 	%fd45, %fd3, 0dC010000000000000;
	mul.f64 	%fd46, %fd44, %fd45;
	fma.rn.f64 	%fd47, %fd3, 0d4001200000000000, %fd46;
	fma.rn.f64 	%fd53, %fd4, 0dC010000000000000, %fd47;
	bra.uni 	BB100_11;

BB100_3:
	setp.eq.s32	%p4, %r1, 0;
	@%p4 bra 	BB100_8;

	setp.eq.s32	%p5, %r1, -1;
	@%p5 bra 	BB100_7;

	setp.ne.s32	%p6, %r1, -2;
	@%p6 bra 	BB100_11;

	mul.f64 	%fd33, %fd2, 0d3FB5555555555553;
	add.f64 	%fd34, %fd3, 0dBFF0000000000000;
	mul.f64 	%fd35, %fd3, 0dBFDA400000000000;
	fma.rn.f64 	%fd36, %fd33, %fd34, %fd35;
	add.f64 	%fd53, %fd36, %fd4;
	bra.uni 	BB100_11;

BB100_8:
	fma.rn.f64 	%fd43, %fd3, 0dC00BB00000000000, 0d3FF0000000000000;
	fma.rn.f64 	%fd53, %fd4, 0d4018000000000000, %fd43;
	bra.uni 	BB100_11;

BB100_7:
	mul.f64 	%fd37, %fd2, 0d3FC5555555555561;
	mov.f64 	%fd38, 0d4010000000000000;
	sub.f64 	%fd39, %fd38, %fd3;
	mul.f64 	%fd40, %fd37, %fd39;
	fma.rn.f64 	%fd41, %fd3, 0d4001200000000000, %fd40;
	mul.f64 	%fd42, %fd4, 0d4010000000000000;
	sub.f64 	%fd53, %fd41, %fd42;

BB100_11:
	mul.f64 	%fd54, %fd53, %fd13;

BB100_12:
	st.param.f64	[func_retval0+0], %fd54;
	ret;
}

	// .globl	_Z7Dirac_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z7Dirac_tddPdiPii(
	.param .b64 _Z7Dirac_tddPdiPii_param_0,
	.param .b64 _Z7Dirac_tddPdiPii_param_1,
	.param .b64 _Z7Dirac_tddPdiPii_param_2,
	.param .b32 _Z7Dirac_tddPdiPii_param_3,
	.param .b64 _Z7Dirac_tddPdiPii_param_4,
	.param .b32 _Z7Dirac_tddPdiPii_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<3>;
	.reg .f64 	%fd<50>;


	ld.param.f64 	%fd13, [_Z7Dirac_tddPdiPii_param_0];
	ld.param.f64 	%fd15, [_Z7Dirac_tddPdiPii_param_1];
	mul.f64 	%fd1, %fd13, %fd15;
	mov.f64 	%fd16, 0d3FE0000000000000;
	sub.f64 	%fd17, %fd16, %fd1;
	cvt.rmi.f64.f64	%fd18, %fd17;
	cvt.rzi.s32.f64	%r1, %fd18;
	add.s32 	%r2, %r1, 2;
	setp.gt.u32	%p1, %r2, 4;
	mov.f64 	%fd49, 0d0000000000000000;
	@%p1 bra 	BB101_12;

	neg.f64 	%fd19, %fd1;
	cvt.rn.f64.s32	%fd20, %r1;
	sub.f64 	%fd2, %fd19, %fd20;
	mul.f64 	%fd3, %fd2, %fd2;
	mul.f64 	%fd21, %fd2, %fd3;
	fma.rn.f64 	%fd22, %fd3, 0dC04E300000000000, 0d4024C80000000000;
	mul.f64 	%fd23, %fd3, 0d4066E00000000000;
	fma.rn.f64 	%fd24, %fd3, %fd23, %fd22;
	mul.f64 	%fd25, %fd3, 0dC070AAAAAAAAAAB1;
	mul.f64 	%fd26, %fd3, %fd25;
	fma.rn.f64 	%fd27, %fd3, %fd26, %fd24;
	mul.f64 	%fd28, %fd3, 0d4061800000000000;
	mul.f64 	%fd29, %fd3, %fd28;
	mul.f64 	%fd30, %fd3, %fd29;
	fma.rn.f64 	%fd31, %fd3, %fd30, %fd27;
	mul.f64 	%fd4, %fd21, %fd31;
	setp.eq.s32	%p2, %r1, 2;
	@%p2 bra 	BB101_10;
	bra.uni 	BB101_2;

BB101_10:
	fma.rn.f64 	%fd44, %fd3, 0dC008000000000000, 0d3FF0000000000000;
	mul.f64 	%fd45, %fd2, 0dBFEA400000000000;
	fma.rn.f64 	%fd46, %fd44, 0d3FB5555555555553, %fd45;
	add.f64 	%fd48, %fd46, %fd4;
	bra.uni 	BB101_11;

BB101_2:
	setp.eq.s32	%p3, %r1, 1;
	@%p3 bra 	BB101_9;
	bra.uni 	BB101_3;

BB101_9:
	fma.rn.f64 	%fd41, %fd3, 0d4008000000000000, 0dC010000000000000;
	mul.f64 	%fd42, %fd41, 0d3FC5555555555561;
	fma.rn.f64 	%fd43, %fd2, 0d4011200000000000, %fd42;
	fma.rn.f64 	%fd48, %fd4, 0dC010000000000000, %fd43;
	bra.uni 	BB101_11;

BB101_3:
	setp.eq.s32	%p4, %r1, 0;
	@%p4 bra 	BB101_8;

	setp.eq.s32	%p5, %r1, -1;
	@%p5 bra 	BB101_7;

	setp.ne.s32	%p6, %r1, -2;
	@%p6 bra 	BB101_11;

	fma.rn.f64 	%fd33, %fd3, 0d4008000000000000, 0dBFF0000000000000;
	mul.f64 	%fd34, %fd2, 0dBFEA400000000000;
	fma.rn.f64 	%fd35, %fd33, 0d3FB5555555555553, %fd34;
	add.f64 	%fd48, %fd35, %fd4;
	bra.uni 	BB101_11;

BB101_8:
	mul.f64 	%fd40, %fd4, 0d4018000000000000;
	fma.rn.f64 	%fd48, %fd2, 0dC01BB00000000000, %fd40;
	bra.uni 	BB101_11;

BB101_7:
	fma.rn.f64 	%fd36, %fd3, 0dC008000000000000, 0d4010000000000000;
	mul.f64 	%fd37, %fd36, 0d3FC5555555555561;
	fma.rn.f64 	%fd38, %fd2, 0d4011200000000000, %fd37;
	mul.f64 	%fd39, %fd4, 0d4010000000000000;
	sub.f64 	%fd48, %fd38, %fd39;

BB101_11:
	mul.f64 	%fd47, %fd13, %fd13;
	mul.f64 	%fd49, %fd47, %fd48;

BB101_12:
	st.param.f64	[func_retval0+0], %fd49;
	ret;
}

	// .globl	_Z8Dirac_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8Dirac_ttddPdiPii(
	.param .b64 _Z8Dirac_ttddPdiPii_param_0,
	.param .b64 _Z8Dirac_ttddPdiPii_param_1,
	.param .b64 _Z8Dirac_ttddPdiPii_param_2,
	.param .b32 _Z8Dirac_ttddPdiPii_param_3,
	.param .b64 _Z8Dirac_ttddPdiPii_param_4,
	.param .b32 _Z8Dirac_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<3>;
	.reg .f64 	%fd<40>;


	ld.param.f64 	%fd12, [_Z8Dirac_ttddPdiPii_param_0];
	ld.param.f64 	%fd14, [_Z8Dirac_ttddPdiPii_param_1];
	mul.f64 	%fd1, %fd12, %fd14;
	mov.f64 	%fd15, 0d3FE0000000000000;
	sub.f64 	%fd16, %fd15, %fd1;
	cvt.rmi.f64.f64	%fd17, %fd16;
	cvt.rzi.s32.f64	%r1, %fd17;
	add.s32 	%r2, %r1, 2;
	setp.gt.u32	%p1, %r2, 4;
	mov.f64 	%fd39, 0d0000000000000000;
	@%p1 bra 	BB102_11;

	neg.f64 	%fd18, %fd1;
	cvt.rn.f64.s32	%fd19, %r1;
	sub.f64 	%fd2, %fd18, %fd19;
	mul.f64 	%fd20, %fd2, %fd2;
	fma.rn.f64 	%fd21, %fd20, 0dC072DE0000000000, 0d403F2C0000000000;
	mul.f64 	%fd22, %fd20, 0d4094040000000000;
	fma.rn.f64 	%fd23, %fd20, %fd22, %fd21;
	mul.f64 	%fd24, %fd20, 0dC0A2C00000000000;
	mul.f64 	%fd25, %fd20, %fd24;
	fma.rn.f64 	%fd26, %fd20, %fd25, %fd23;
	mul.f64 	%fd27, %fd20, 0d4098100000000000;
	mul.f64 	%fd28, %fd20, %fd27;
	mul.f64 	%fd29, %fd20, %fd28;
	fma.rn.f64 	%fd30, %fd20, %fd29, %fd26;
	mul.f64 	%fd3, %fd20, %fd30;
	setp.eq.s32	%p2, %r1, 2;
	@%p2 bra 	BB102_9;
	bra.uni 	BB102_2;

BB102_9:
	fma.rn.f64 	%fd35, %fd2, 0dBFE0000000000000, 0dBFEA400000000000;
	add.f64 	%fd38, %fd35, %fd3;
	bra.uni 	BB102_10;

BB102_2:
	setp.eq.s32	%p3, %r1, 1;
	@%p3 bra 	BB102_8;
	bra.uni 	BB102_3;

BB102_8:
	add.f64 	%fd34, %fd2, 0d4011200000000000;
	fma.rn.f64 	%fd38, %fd3, 0dC010000000000000, %fd34;
	bra.uni 	BB102_10;

BB102_3:
	setp.eq.s32	%p4, %r1, 0;
	@%p4 bra 	BB102_7;

	setp.eq.s32	%p5, %r1, -1;
	@%p5 bra 	BB102_6;

	fma.rn.f64 	%fd31, %fd2, 0d3FE0000000000000, 0dBFEA400000000000;
	add.f64 	%fd38, %fd31, %fd3;
	bra.uni 	BB102_10;

BB102_7:
	fma.rn.f64 	%fd38, %fd3, 0d4018000000000000, 0dC01BB00000000000;
	bra.uni 	BB102_10;

BB102_6:
	mov.f64 	%fd32, 0d4011200000000000;
	sub.f64 	%fd33, %fd32, %fd2;
	fma.rn.f64 	%fd38, %fd3, 0dC010000000000000, %fd33;

BB102_10:
	mul.f64 	%fd36, %fd12, %fd12;
	mul.f64 	%fd37, %fd36, %fd12;
	mul.f64 	%fd39, %fd37, %fd38;

BB102_11:
	st.param.f64	[func_retval0+0], %fd39;
	ret;
}

	// .globl	_Z9Dirac_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z9Dirac_tttddPdiPii(
	.param .b64 _Z9Dirac_tttddPdiPii_param_0,
	.param .b64 _Z9Dirac_tttddPdiPii_param_1,
	.param .b64 _Z9Dirac_tttddPdiPii_param_2,
	.param .b32 _Z9Dirac_tttddPdiPii_param_3,
	.param .b64 _Z9Dirac_tttddPdiPii_param_4,
	.param .b32 _Z9Dirac_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<3>;
	.reg .f64 	%fd<37>;


	ld.param.f64 	%fd10, [_Z9Dirac_tttddPdiPii_param_0];
	ld.param.f64 	%fd12, [_Z9Dirac_tttddPdiPii_param_1];
	mul.f64 	%fd1, %fd10, %fd12;
	mov.f64 	%fd13, 0d3FE0000000000000;
	sub.f64 	%fd14, %fd13, %fd1;
	cvt.rmi.f64.f64	%fd15, %fd14;
	cvt.rzi.s32.f64	%r1, %fd15;
	add.s32 	%r2, %r1, 2;
	setp.gt.u32	%p1, %r2, 4;
	mov.f64 	%fd36, 0d0000000000000000;
	@%p1 bra 	BB103_9;

	neg.f64 	%fd16, %fd1;
	cvt.rn.f64.s32	%fd17, %r1;
	sub.f64 	%fd18, %fd16, %fd17;
	mul.f64 	%fd19, %fd18, %fd18;
	fma.rn.f64 	%fd20, %fd19, 0dC092DE0000000000, 0d404F2C0000000000;
	mul.f64 	%fd21, %fd19, 0d40BE060000000000;
	fma.rn.f64 	%fd22, %fd19, %fd21, %fd20;
	mul.f64 	%fd23, %fd19, 0dC0D2C00000000000;
	mul.f64 	%fd24, %fd19, %fd23;
	fma.rn.f64 	%fd25, %fd19, %fd24, %fd22;
	mul.f64 	%fd26, %fd19, 0d40CE140000000000;
	mul.f64 	%fd27, %fd19, %fd26;
	mul.f64 	%fd28, %fd19, %fd27;
	fma.rn.f64 	%fd29, %fd19, %fd28, %fd25;
	mul.f64 	%fd2, %fd18, %fd29;
	setp.eq.s32	%p2, %r1, 2;
	@%p2 bra 	BB103_7;
	bra.uni 	BB103_2;

BB103_7:
	add.f64 	%fd35, %fd2, 0dBFE0000000000000;
	bra.uni 	BB103_8;

BB103_2:
	setp.eq.s32	%p3, %r1, 1;
	@%p3 bra 	BB103_6;
	bra.uni 	BB103_3;

BB103_6:
	fma.rn.f64 	%fd35, %fd2, 0dC010000000000000, 0d3FF0000000000000;
	bra.uni 	BB103_8;

BB103_3:
	setp.eq.s32	%p4, %r1, 0;
	@%p4 bra 	BB103_5;

	setp.eq.s32	%p5, %r1, -1;
	fma.rn.f64 	%fd30, %fd2, 0dC010000000000000, 0dBFF0000000000000;
	add.f64 	%fd31, %fd2, 0d3FE0000000000000;
	selp.f64	%fd35, %fd30, %fd31, %p5;
	bra.uni 	BB103_8;

BB103_5:
	mul.f64 	%fd35, %fd2, 0d4018000000000000;

BB103_8:
	mul.f64 	%fd32, %fd10, %fd10;
	mul.f64 	%fd33, %fd32, %fd10;
	mul.f64 	%fd34, %fd33, %fd10;
	mul.f64 	%fd36, %fd34, %fd35;

BB103_9:
	st.param.f64	[func_retval0+0], %fd36;
	ret;
}

	// .globl	_Z10Dirac_ttttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Dirac_ttttddPdiPii(
	.param .b64 _Z10Dirac_ttttddPdiPii_param_0,
	.param .b64 _Z10Dirac_ttttddPdiPii_param_1,
	.param .b64 _Z10Dirac_ttttddPdiPii_param_2,
	.param .b32 _Z10Dirac_ttttddPdiPii_param_3,
	.param .b64 _Z10Dirac_ttttddPdiPii_param_4,
	.param .b32 _Z10Dirac_ttttddPdiPii_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<3>;
	.reg .f64 	%fd<35>;


	ld.param.f64 	%fd9, [_Z10Dirac_ttttddPdiPii_param_0];
	ld.param.f64 	%fd11, [_Z10Dirac_ttttddPdiPii_param_1];
	mul.f64 	%fd1, %fd9, %fd11;
	mov.f64 	%fd12, 0d3FE0000000000000;
	sub.f64 	%fd13, %fd12, %fd1;
	cvt.rmi.f64.f64	%fd14, %fd13;
	cvt.rzi.s32.f64	%r1, %fd14;
	add.s32 	%r2, %r1, 2;
	setp.gt.u32	%p1, %r2, 4;
	mov.f64 	%fd34, 0d0000000000000000;
	@%p1 bra 	BB104_8;

	neg.f64 	%fd15, %fd1;
	cvt.rn.f64.s32	%fd16, %r1;
	sub.f64 	%fd17, %fd15, %fd16;
	mul.f64 	%fd18, %fd17, %fd17;
	fma.rn.f64 	%fd19, %fd18, 0dC0AC4D0000000000, 0d404F2C0000000000;
	mul.f64 	%fd20, %fd18, 0d40E2C3C000000000;
	fma.rn.f64 	%fd21, %fd18, %fd20, %fd19;
	mul.f64 	%fd22, %fd18, 0dC100680000000000;
	mul.f64 	%fd23, %fd18, %fd22;
	fma.rn.f64 	%fd24, %fd18, %fd23, %fd21;
	mul.f64 	%fd25, %fd18, 0d4100EB4000000000;
	mul.f64 	%fd26, %fd18, %fd25;
	mul.f64 	%fd27, %fd18, %fd26;
	fma.rn.f64 	%fd33, %fd18, %fd27, %fd24;
	setp.eq.s32	%p2, %r1, 2;
	@%p2 bra 	BB104_7;

	setp.eq.s32	%p3, %r1, 1;
	@%p3 bra 	BB104_6;
	bra.uni 	BB104_3;

BB104_6:
	mul.f64 	%fd33, %fd33, 0dC010000000000000;
	bra.uni 	BB104_7;

BB104_3:
	setp.eq.s32	%p4, %r1, 0;
	@%p4 bra 	BB104_5;

	setp.eq.s32	%p5, %r1, -1;
	mul.f64 	%fd28, %fd33, 0dC010000000000000;
	selp.f64	%fd33, %fd28, %fd33, %p5;
	bra.uni 	BB104_7;

BB104_5:
	mul.f64 	%fd33, %fd33, 0d4018000000000000;

BB104_7:
	mul.f64 	%fd29, %fd9, %fd9;
	mul.f64 	%fd30, %fd29, %fd9;
	mul.f64 	%fd31, %fd30, %fd9;
	mul.f64 	%fd32, %fd31, %fd9;
	mul.f64 	%fd34, %fd32, %fd33;

BB104_8:
	st.param.f64	[func_retval0+0], %fd34;
	ret;
}

	// .globl	_Z8Dirac_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8Dirac_omddPdiPii(
	.param .b64 _Z8Dirac_omddPdiPii_param_0,
	.param .b64 _Z8Dirac_omddPdiPii_param_1,
	.param .b64 _Z8Dirac_omddPdiPii_param_2,
	.param .b32 _Z8Dirac_omddPdiPii_param_3,
	.param .b64 _Z8Dirac_omddPdiPii_param_4,
	.param .b32 _Z8Dirac_omddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z9Dirac_tomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z9Dirac_tomddPdiPii(
	.param .b64 _Z9Dirac_tomddPdiPii_param_0,
	.param .b64 _Z9Dirac_tomddPdiPii_param_1,
	.param .b64 _Z9Dirac_tomddPdiPii_param_2,
	.param .b32 _Z9Dirac_tomddPdiPii_param_3,
	.param .b64 _Z9Dirac_tomddPdiPii_param_4,
	.param .b32 _Z9Dirac_tomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z10Dirac_omomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Dirac_omomddPdiPii(
	.param .b64 _Z10Dirac_omomddPdiPii_param_0,
	.param .b64 _Z10Dirac_omomddPdiPii_param_1,
	.param .b64 _Z10Dirac_omomddPdiPii_param_2,
	.param .b32 _Z10Dirac_omomddPdiPii_param_3,
	.param .b64 _Z10Dirac_omomddPdiPii_param_4,
	.param .b32 _Z10Dirac_omomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z10Dirac_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Dirac_omttddPdiPii(
	.param .b64 _Z10Dirac_omttddPdiPii_param_0,
	.param .b64 _Z10Dirac_omttddPdiPii_param_1,
	.param .b64 _Z10Dirac_omttddPdiPii_param_2,
	.param .b32 _Z10Dirac_omttddPdiPii_param_3,
	.param .b64 _Z10Dirac_omttddPdiPii_param_4,
	.param .b32 _Z10Dirac_omttddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z11Dirac_tttomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Dirac_tttomddPdiPii(
	.param .b64 _Z11Dirac_tttomddPdiPii_param_0,
	.param .b64 _Z11Dirac_tttomddPdiPii_param_1,
	.param .b64 _Z11Dirac_tttomddPdiPii_param_2,
	.param .b32 _Z11Dirac_tttomddPdiPii_param_3,
	.param .b64 _Z11Dirac_tttomddPdiPii_param_4,
	.param .b32 _Z11Dirac_tttomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z12Dirac_ttomomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12Dirac_ttomomddPdiPii(
	.param .b64 _Z12Dirac_ttomomddPdiPii_param_0,
	.param .b64 _Z12Dirac_ttomomddPdiPii_param_1,
	.param .b64 _Z12Dirac_ttomomddPdiPii_param_2,
	.param .b32 _Z12Dirac_ttomomddPdiPii_param_3,
	.param .b64 _Z12Dirac_ttomomddPdiPii_param_4,
	.param .b32 _Z12Dirac_ttomomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z8DiscreteddPdiPii
.visible .func  (.param .b64 func_retval0) _Z8DiscreteddPdiPii(
	.param .b64 _Z8DiscreteddPdiPii_param_0,
	.param .b64 _Z8DiscreteddPdiPii_param_1,
	.param .b64 _Z8DiscreteddPdiPii_param_2,
	.param .b32 _Z8DiscreteddPdiPii_param_3,
	.param .b64 _Z8DiscreteddPdiPii_param_4,
	.param .b32 _Z8DiscreteddPdiPii_param_5
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<38>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd5, [_Z8DiscreteddPdiPii_param_0];
	ld.param.f64 	%fd6, [_Z8DiscreteddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z8DiscreteddPdiPii_param_2];
	ld.param.u64 	%rd2, [_Z8DiscreteddPdiPii_param_4];
	ld.f64 	%fd1, [%rd1];
	sub.f64 	%fd7, %fd6, %fd1;
	mul.f64 	%fd8, %fd7, %fd5;
	cvt.rmi.f64.f64	%fd9, %fd8;
	cvt.rzi.s32.f64	%r5, %fd9;
	setp.lt.s32	%p1, %r5, 0;
	selp.f64	%fd37, %fd1, %fd6, %p1;
	mov.u32 	%r6, 0;
	max.s32 	%r9, %r6, %r5;
	ld.u32 	%r2, [%rd2];
	add.s32 	%r3, %r2, -2;
	setp.le.s32	%p2, %r9, %r3;
	@%p2 bra 	BB111_2;

	add.s32 	%r7, %r2, -1;
	cvt.rn.f64.s32	%fd10, %r7;
	div.rn.f64 	%fd11, %fd10, %fd5;
	add.f64 	%fd37, %fd1, %fd11;
	mov.u32 	%r9, %r3;

BB111_2:
	sub.f64 	%fd12, %fd37, %fd1;
	mul.f64 	%fd13, %fd12, %fd5;
	cvt.rn.f64.s32	%fd14, %r9;
	sub.f64 	%fd15, %fd13, %fd14;
	mad.lo.s32 	%r8, %r9, 6, 1;
	mul.wide.s32 	%rd3, %r8, 8;
	add.s64 	%rd4, %rd1, %rd3;
	ld.f64 	%fd16, [%rd4+8];
	ld.f64 	%fd17, [%rd4];
	fma.rn.f64 	%fd18, %fd16, %fd15, %fd17;
	ld.f64 	%fd19, [%rd4+16];
	mul.f64 	%fd20, %fd15, %fd19;
	fma.rn.f64 	%fd21, %fd15, %fd20, %fd18;
	ld.f64 	%fd22, [%rd4+24];
	mul.f64 	%fd23, %fd15, %fd22;
	mul.f64 	%fd24, %fd15, %fd23;
	fma.rn.f64 	%fd25, %fd15, %fd24, %fd21;
	ld.f64 	%fd26, [%rd4+32];
	mul.f64 	%fd27, %fd15, %fd26;
	mul.f64 	%fd28, %fd15, %fd27;
	mul.f64 	%fd29, %fd15, %fd28;
	fma.rn.f64 	%fd30, %fd15, %fd29, %fd25;
	ld.f64 	%fd31, [%rd4+40];
	mul.f64 	%fd32, %fd15, %fd31;
	mul.f64 	%fd33, %fd15, %fd32;
	mul.f64 	%fd34, %fd15, %fd33;
	mul.f64 	%fd35, %fd15, %fd34;
	fma.rn.f64 	%fd36, %fd15, %fd35, %fd30;
	st.param.f64	[func_retval0+0], %fd36;
	ret;
}

	// .globl	_Z10Discrete_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z10Discrete_tddPdiPii(
	.param .b64 _Z10Discrete_tddPdiPii_param_0,
	.param .b64 _Z10Discrete_tddPdiPii_param_1,
	.param .b64 _Z10Discrete_tddPdiPii_param_2,
	.param .b32 _Z10Discrete_tddPdiPii_param_3,
	.param .b64 _Z10Discrete_tddPdiPii_param_4,
	.param .b32 _Z10Discrete_tddPdiPii_param_5
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<37>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd5, [_Z10Discrete_tddPdiPii_param_0];
	ld.param.f64 	%fd6, [_Z10Discrete_tddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z10Discrete_tddPdiPii_param_2];
	ld.param.u64 	%rd2, [_Z10Discrete_tddPdiPii_param_4];
	ld.f64 	%fd1, [%rd1];
	sub.f64 	%fd7, %fd6, %fd1;
	mul.f64 	%fd8, %fd7, %fd5;
	cvt.rmi.f64.f64	%fd9, %fd8;
	cvt.rzi.s32.f64	%r5, %fd9;
	setp.lt.s32	%p1, %r5, 0;
	selp.f64	%fd36, %fd1, %fd6, %p1;
	mov.u32 	%r6, 0;
	max.s32 	%r9, %r6, %r5;
	ld.u32 	%r2, [%rd2];
	add.s32 	%r3, %r2, -2;
	setp.le.s32	%p2, %r9, %r3;
	@%p2 bra 	BB112_2;

	add.s32 	%r7, %r2, -1;
	cvt.rn.f64.s32	%fd10, %r7;
	div.rn.f64 	%fd11, %fd10, %fd5;
	add.f64 	%fd36, %fd1, %fd11;
	mov.u32 	%r9, %r3;

BB112_2:
	sub.f64 	%fd12, %fd36, %fd1;
	mul.f64 	%fd13, %fd12, %fd5;
	cvt.rn.f64.s32	%fd14, %r9;
	sub.f64 	%fd15, %fd13, %fd14;
	mad.lo.s32 	%r8, %r9, 6, 2;
	mul.wide.s32 	%rd3, %r8, 8;
	add.s64 	%rd4, %rd1, %rd3;
	ld.f64 	%fd16, [%rd4+8];
	add.f64 	%fd17, %fd16, %fd16;
	ld.f64 	%fd18, [%rd4];
	fma.rn.f64 	%fd19, %fd15, %fd17, %fd18;
	ld.f64 	%fd20, [%rd4+16];
	mul.f64 	%fd21, %fd20, 0d4008000000000000;
	mul.f64 	%fd22, %fd15, %fd21;
	fma.rn.f64 	%fd23, %fd15, %fd22, %fd19;
	ld.f64 	%fd24, [%rd4+24];
	mul.f64 	%fd25, %fd24, 0d4010000000000000;
	mul.f64 	%fd26, %fd15, %fd25;
	mul.f64 	%fd27, %fd15, %fd26;
	fma.rn.f64 	%fd28, %fd15, %fd27, %fd23;
	ld.f64 	%fd29, [%rd4+32];
	mul.f64 	%fd30, %fd29, 0d4014000000000000;
	mul.f64 	%fd31, %fd15, %fd30;
	mul.f64 	%fd32, %fd15, %fd31;
	mul.f64 	%fd33, %fd15, %fd32;
	fma.rn.f64 	%fd34, %fd15, %fd33, %fd28;
	mul.f64 	%fd35, %fd34, %fd5;
	st.param.f64	[func_retval0+0], %fd35;
	ret;
}

	// .globl	_Z11Discrete_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Discrete_ttddPdiPii(
	.param .b64 _Z11Discrete_ttddPdiPii_param_0,
	.param .b64 _Z11Discrete_ttddPdiPii_param_1,
	.param .b64 _Z11Discrete_ttddPdiPii_param_2,
	.param .b32 _Z11Discrete_ttddPdiPii_param_3,
	.param .b64 _Z11Discrete_ttddPdiPii_param_4,
	.param .b32 _Z11Discrete_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<33>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd5, [_Z11Discrete_ttddPdiPii_param_0];
	ld.param.f64 	%fd6, [_Z11Discrete_ttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z11Discrete_ttddPdiPii_param_2];
	ld.param.u64 	%rd2, [_Z11Discrete_ttddPdiPii_param_4];
	ld.f64 	%fd1, [%rd1];
	sub.f64 	%fd7, %fd6, %fd1;
	mul.f64 	%fd8, %fd7, %fd5;
	cvt.rmi.f64.f64	%fd9, %fd8;
	cvt.rzi.s32.f64	%r5, %fd9;
	setp.lt.s32	%p1, %r5, 0;
	selp.f64	%fd32, %fd1, %fd6, %p1;
	mov.u32 	%r6, 0;
	max.s32 	%r9, %r6, %r5;
	ld.u32 	%r2, [%rd2];
	add.s32 	%r3, %r2, -2;
	setp.le.s32	%p2, %r9, %r3;
	@%p2 bra 	BB113_2;

	add.s32 	%r7, %r2, -1;
	cvt.rn.f64.s32	%fd10, %r7;
	div.rn.f64 	%fd11, %fd10, %fd5;
	add.f64 	%fd32, %fd1, %fd11;
	mov.u32 	%r9, %r3;

BB113_2:
	sub.f64 	%fd12, %fd32, %fd1;
	mul.f64 	%fd13, %fd12, %fd5;
	cvt.rn.f64.s32	%fd14, %r9;
	sub.f64 	%fd15, %fd13, %fd14;
	mad.lo.s32 	%r8, %r9, 6, 3;
	mul.wide.s32 	%rd3, %r8, 8;
	add.s64 	%rd4, %rd1, %rd3;
	ld.f64 	%fd16, [%rd4];
	ld.f64 	%fd17, [%rd4+8];
	mul.f64 	%fd18, %fd17, 0d4018000000000000;
	mul.f64 	%fd19, %fd15, %fd18;
	fma.rn.f64 	%fd20, %fd16, 0d4000000000000000, %fd19;
	ld.f64 	%fd21, [%rd4+16];
	mul.f64 	%fd22, %fd21, 0d4028000000000000;
	mul.f64 	%fd23, %fd15, %fd22;
	fma.rn.f64 	%fd24, %fd15, %fd23, %fd20;
	ld.f64 	%fd25, [%rd4+24];
	mul.f64 	%fd26, %fd25, 0d4034000000000000;
	mul.f64 	%fd27, %fd15, %fd26;
	mul.f64 	%fd28, %fd15, %fd27;
	fma.rn.f64 	%fd29, %fd15, %fd28, %fd24;
	mul.f64 	%fd30, %fd29, %fd5;
	mul.f64 	%fd31, %fd30, %fd5;
	st.param.f64	[func_retval0+0], %fd31;
	ret;
}

	// .globl	_Z12Discrete_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12Discrete_tttddPdiPii(
	.param .b64 _Z12Discrete_tttddPdiPii_param_0,
	.param .b64 _Z12Discrete_tttddPdiPii_param_1,
	.param .b64 _Z12Discrete_tttddPdiPii_param_2,
	.param .b32 _Z12Discrete_tttddPdiPii_param_3,
	.param .b64 _Z12Discrete_tttddPdiPii_param_4,
	.param .b32 _Z12Discrete_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<29>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd5, [_Z12Discrete_tttddPdiPii_param_0];
	ld.param.f64 	%fd6, [_Z12Discrete_tttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z12Discrete_tttddPdiPii_param_2];
	ld.param.u64 	%rd2, [_Z12Discrete_tttddPdiPii_param_4];
	ld.f64 	%fd1, [%rd1];
	sub.f64 	%fd7, %fd6, %fd1;
	mul.f64 	%fd8, %fd7, %fd5;
	cvt.rmi.f64.f64	%fd9, %fd8;
	cvt.rzi.s32.f64	%r5, %fd9;
	setp.lt.s32	%p1, %r5, 0;
	selp.f64	%fd28, %fd1, %fd6, %p1;
	mov.u32 	%r6, 0;
	max.s32 	%r9, %r6, %r5;
	ld.u32 	%r2, [%rd2];
	add.s32 	%r3, %r2, -2;
	setp.le.s32	%p2, %r9, %r3;
	@%p2 bra 	BB114_2;

	add.s32 	%r7, %r2, -1;
	cvt.rn.f64.s32	%fd10, %r7;
	div.rn.f64 	%fd11, %fd10, %fd5;
	add.f64 	%fd28, %fd1, %fd11;
	mov.u32 	%r9, %r3;

BB114_2:
	sub.f64 	%fd12, %fd28, %fd1;
	mul.f64 	%fd13, %fd12, %fd5;
	cvt.rn.f64.s32	%fd14, %r9;
	sub.f64 	%fd15, %fd13, %fd14;
	mad.lo.s32 	%r8, %r9, 6, 4;
	mul.wide.s32 	%rd3, %r8, 8;
	add.s64 	%rd4, %rd1, %rd3;
	ld.f64 	%fd16, [%rd4];
	ld.f64 	%fd17, [%rd4+8];
	mul.f64 	%fd18, %fd17, 0d4038000000000000;
	mul.f64 	%fd19, %fd15, %fd18;
	fma.rn.f64 	%fd20, %fd16, 0d4018000000000000, %fd19;
	ld.f64 	%fd21, [%rd4+16];
	mul.f64 	%fd22, %fd21, 0d404E000000000000;
	mul.f64 	%fd23, %fd15, %fd22;
	fma.rn.f64 	%fd24, %fd15, %fd23, %fd20;
	mul.f64 	%fd25, %fd24, %fd5;
	mul.f64 	%fd26, %fd25, %fd5;
	mul.f64 	%fd27, %fd26, %fd5;
	st.param.f64	[func_retval0+0], %fd27;
	ret;
}

	// .globl	_Z13Discrete_ttttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Discrete_ttttddPdiPii(
	.param .b64 _Z13Discrete_ttttddPdiPii_param_0,
	.param .b64 _Z13Discrete_ttttddPdiPii_param_1,
	.param .b64 _Z13Discrete_ttttddPdiPii_param_2,
	.param .b32 _Z13Discrete_ttttddPdiPii_param_3,
	.param .b64 _Z13Discrete_ttttddPdiPii_param_4,
	.param .b32 _Z13Discrete_ttttddPdiPii_param_5
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<26>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd5, [_Z13Discrete_ttttddPdiPii_param_0];
	ld.param.f64 	%fd6, [_Z13Discrete_ttttddPdiPii_param_1];
	ld.param.u64 	%rd1, [_Z13Discrete_ttttddPdiPii_param_2];
	ld.param.u64 	%rd2, [_Z13Discrete_ttttddPdiPii_param_4];
	ld.f64 	%fd1, [%rd1];
	sub.f64 	%fd7, %fd6, %fd1;
	mul.f64 	%fd8, %fd7, %fd5;
	cvt.rmi.f64.f64	%fd9, %fd8;
	cvt.rzi.s32.f64	%r5, %fd9;
	setp.lt.s32	%p1, %r5, 0;
	selp.f64	%fd25, %fd1, %fd6, %p1;
	mov.u32 	%r6, 0;
	max.s32 	%r9, %r6, %r5;
	ld.u32 	%r2, [%rd2];
	add.s32 	%r3, %r2, -2;
	setp.le.s32	%p2, %r9, %r3;
	@%p2 bra 	BB115_2;

	add.s32 	%r7, %r2, -1;
	cvt.rn.f64.s32	%fd10, %r7;
	div.rn.f64 	%fd11, %fd10, %fd5;
	add.f64 	%fd25, %fd1, %fd11;
	mov.u32 	%r9, %r3;

BB115_2:
	sub.f64 	%fd12, %fd25, %fd1;
	mul.f64 	%fd13, %fd12, %fd5;
	cvt.rn.f64.s32	%fd14, %r9;
	sub.f64 	%fd15, %fd13, %fd14;
	mad.lo.s32 	%r8, %r9, 6, 5;
	mul.wide.s32 	%rd3, %r8, 8;
	add.s64 	%rd4, %rd1, %rd3;
	ld.f64 	%fd16, [%rd4];
	ld.f64 	%fd17, [%rd4+8];
	mul.f64 	%fd18, %fd17, 0d405E000000000000;
	mul.f64 	%fd19, %fd15, %fd18;
	fma.rn.f64 	%fd20, %fd16, 0d4038000000000000, %fd19;
	mul.f64 	%fd21, %fd20, %fd5;
	mul.f64 	%fd22, %fd21, %fd5;
	mul.f64 	%fd23, %fd22, %fd5;
	mul.f64 	%fd24, %fd23, %fd5;
	st.param.f64	[func_retval0+0], %fd24;
	ret;
}

	// .globl	_Z11Discrete_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z11Discrete_omddPdiPii(
	.param .b64 _Z11Discrete_omddPdiPii_param_0,
	.param .b64 _Z11Discrete_omddPdiPii_param_1,
	.param .b64 _Z11Discrete_omddPdiPii_param_2,
	.param .b32 _Z11Discrete_omddPdiPii_param_3,
	.param .b64 _Z11Discrete_omddPdiPii_param_4,
	.param .b32 _Z11Discrete_omddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z12Discrete_tomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12Discrete_tomddPdiPii(
	.param .b64 _Z12Discrete_tomddPdiPii_param_0,
	.param .b64 _Z12Discrete_tomddPdiPii_param_1,
	.param .b64 _Z12Discrete_tomddPdiPii_param_2,
	.param .b32 _Z12Discrete_tomddPdiPii_param_3,
	.param .b64 _Z12Discrete_tomddPdiPii_param_4,
	.param .b32 _Z12Discrete_tomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z13Discrete_omomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Discrete_omomddPdiPii(
	.param .b64 _Z13Discrete_omomddPdiPii_param_0,
	.param .b64 _Z13Discrete_omomddPdiPii_param_1,
	.param .b64 _Z13Discrete_omomddPdiPii_param_2,
	.param .b32 _Z13Discrete_omomddPdiPii_param_3,
	.param .b64 _Z13Discrete_omomddPdiPii_param_4,
	.param .b32 _Z13Discrete_omomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z13Discrete_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z13Discrete_omttddPdiPii(
	.param .b64 _Z13Discrete_omttddPdiPii_param_0,
	.param .b64 _Z13Discrete_omttddPdiPii_param_1,
	.param .b64 _Z13Discrete_omttddPdiPii_param_2,
	.param .b32 _Z13Discrete_omttddPdiPii_param_3,
	.param .b64 _Z13Discrete_omttddPdiPii_param_4,
	.param .b32 _Z13Discrete_omttddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z14Discrete_tttomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z14Discrete_tttomddPdiPii(
	.param .b64 _Z14Discrete_tttomddPdiPii_param_0,
	.param .b64 _Z14Discrete_tttomddPdiPii_param_1,
	.param .b64 _Z14Discrete_tttomddPdiPii_param_2,
	.param .b32 _Z14Discrete_tttomddPdiPii_param_3,
	.param .b64 _Z14Discrete_tttomddPdiPii_param_4,
	.param .b32 _Z14Discrete_tttomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z15Discrete_ttomomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z15Discrete_ttomomddPdiPii(
	.param .b64 _Z15Discrete_ttomomddPdiPii_param_0,
	.param .b64 _Z15Discrete_ttomomddPdiPii_param_1,
	.param .b64 _Z15Discrete_ttomomddPdiPii_param_2,
	.param .b32 _Z15Discrete_ttomomddPdiPii_param_3,
	.param .b64 _Z15Discrete_ttomomddPdiPii_param_4,
	.param .b32 _Z15Discrete_ttomomddPdiPii_param_5
)
{
	.reg .f64 	%fd<2>;


	mov.f64 	%fd1, 0d0000000000000000;
	st.param.f64	[func_retval0+0], %fd1;
	ret;
}

	// .globl	_Z12C6SmoothBumpddPdiPii
.visible .func  (.param .b64 func_retval0) _Z12C6SmoothBumpddPdiPii(
	.param .b64 _Z12C6SmoothBumpddPdiPii_param_0,
	.param .b64 _Z12C6SmoothBumpddPdiPii_param_1,
	.param .b64 _Z12C6SmoothBumpddPdiPii_param_2,
	.param .b32 _Z12C6SmoothBumpddPdiPii_param_3,
	.param .b64 _Z12C6SmoothBumpddPdiPii_param_4,
	.param .b32 _Z12C6SmoothBumpddPdiPii_param_5
)
{
	.reg .pred 	%p<22>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<30>;
	.reg .b64 	%rd<3>;


	ld.param.f64 	%fd17, [_Z12C6SmoothBumpddPdiPii_param_0];
	ld.param.f64 	%fd18, [_Z12C6SmoothBumpddPdiPii_param_1];
	mul.f64 	%fd1, %fd17, %fd18;
	setp.lt.f64	%p2, %fd1, 0d0000000000000000;
	setp.gt.f64	%p3, %fd1, 0d3FF0000000000000;
	or.pred  	%p4, %p2, %p3;
	mov.f64 	%fd29, 0d0000000000000000;
	@%p4 bra 	BB122_18;

	mov.f64 	%fd19, 0d3FF0000000000000;
	sub.f64 	%fd20, %fd19, %fd1;
	mul.f64 	%fd2, %fd1, %fd20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd21, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd21;
	}
	bfe.u32 	%r3, %r2, 20, 11;
	add.s32 	%r4, %r3, -1012;
	mov.u64 	%rd2, 4619567317775286272;
	shl.b64 	%rd1, %rd2, %r4;
	setp.eq.s64	%p5, %rd1, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 232
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd21;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd27, [retval0+0];
	
	//{
	}// Callseq End 232
	setp.lt.s32	%p6, %r1, 0;
	and.pred  	%p1, %p6, %p5;
	@!%p1 bra 	BB122_3;
	bra.uni 	BB122_2;

BB122_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd27;
	}
	xor.b32  	%r6, %r5, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd27;
	}
	mov.b64 	%fd27, {%r7, %r6};

BB122_3:
	setp.eq.f64	%p7, %fd2, 0d0000000000000000;
	@%p7 bra 	BB122_6;
	bra.uni 	BB122_4;

BB122_6:
	selp.b32	%r8, %r1, 0, %p5;
	or.b32  	%r9, %r8, 2146435072;
	setp.lt.s32	%p11, %r2, 0;
	selp.b32	%r10, %r9, %r8, %p11;
	mov.u32 	%r11, 0;
	mov.b64 	%fd27, {%r11, %r10};
	bra.uni 	BB122_7;

BB122_4:
	setp.gt.s32	%p8, %r1, -1;
	@%p8 bra 	BB122_7;

	cvt.rzi.f64.f64	%fd23, %fd21;
	setp.neu.f64	%p9, %fd23, 0d401C000000000000;
	selp.f64	%fd27, 0dFFF8000000000000, %fd27, %p9;

BB122_7:
	add.f64 	%fd28, %fd2, 0d401C000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd28;
	}
	and.b32  	%r13, %r12, 2146435072;
	setp.ne.s32	%p12, %r13, 2146435072;
	@%p12 bra 	BB122_8;

	setp.gtu.f64	%p13, %fd3, 0d7FF0000000000000;
	@%p13 bra 	BB122_17;

	and.b32  	%r14, %r2, 2147483647;
	setp.ne.s32	%p14, %r14, 2146435072;
	@%p14 bra 	BB122_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r15, %temp}, %fd21;
	}
	setp.eq.s32	%p15, %r15, 0;
	@%p15 bra 	BB122_16;

BB122_12:
	and.b32  	%r16, %r1, 2147483647;
	setp.ne.s32	%p16, %r16, 2146435072;
	@%p16 bra 	BB122_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd2;
	}
	setp.ne.s32	%p17, %r17, 0;
	mov.f64 	%fd28, %fd27;
	@%p17 bra 	BB122_17;

	shr.s32 	%r18, %r2, 31;
	and.b32  	%r19, %r18, -2146435072;
	add.s32 	%r20, %r19, 2146435072;
	or.b32  	%r21, %r20, -2147483648;
	selp.b32	%r22, %r21, %r20, %p1;
	mov.u32 	%r23, 0;
	mov.b64 	%fd28, {%r23, %r22};
	bra.uni 	BB122_17;

BB122_8:
	mov.f64 	%fd28, %fd27;
	bra.uni 	BB122_17;

BB122_13:
	mov.f64 	%fd28, %fd27;
	bra.uni 	BB122_17;

BB122_16:
	setp.gt.f64	%p18, %fd3, 0d3FF0000000000000;
	selp.b32	%r24, 2146435072, 0, %p18;
	xor.b32  	%r25, %r24, 2146435072;
	setp.lt.s32	%p19, %r2, 0;
	selp.b32	%r26, %r25, %r24, %p19;
	setp.eq.f64	%p20, %fd2, 0dBFF0000000000000;
	selp.b32	%r27, 1072693248, %r26, %p20;
	mov.u32 	%r28, 0;
	mov.b64 	%fd28, {%r28, %r27};

BB122_17:
	mul.f64 	%fd25, %fd28, 0d40E9230000000000;
	setp.eq.f64	%p21, %fd2, 0d3FF0000000000000;
	selp.f64	%fd29, 0d40E9230000000000, %fd25, %p21;

BB122_18:
	st.param.f64	[func_retval0+0], %fd29;
	ret;
}

	// .globl	_Z14C6SmoothBump_tddPdiPii
.visible .func  (.param .b64 func_retval0) _Z14C6SmoothBump_tddPdiPii(
	.param .b64 _Z14C6SmoothBump_tddPdiPii_param_0,
	.param .b64 _Z14C6SmoothBump_tddPdiPii_param_1,
	.param .b64 _Z14C6SmoothBump_tddPdiPii_param_2,
	.param .b32 _Z14C6SmoothBump_tddPdiPii_param_3,
	.param .b64 _Z14C6SmoothBump_tddPdiPii_param_4,
	.param .b32 _Z14C6SmoothBump_tddPdiPii_param_5
)
{
	.reg .pred 	%p<22>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<35>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd16, [_Z14C6SmoothBump_tddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z14C6SmoothBump_tddPdiPii_param_1];
	mul.f64 	%fd1, %fd16, %fd17;
	setp.lt.f64	%p2, %fd1, 0d0000000000000000;
	setp.gt.f64	%p3, %fd1, 0d3FF0000000000000;
	or.pred  	%p4, %p2, %p3;
	mov.f64 	%fd34, 0d0000000000000000;
	@%p4 bra 	BB123_18;

	mov.f64 	%fd19, 0d3FF0000000000000;
	sub.f64 	%fd20, %fd19, %fd1;
	mul.f64 	%fd2, %fd1, %fd20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd21, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd21;
	}
	bfe.u32 	%r3, %r2, 20, 11;
	add.s32 	%r4, %r3, -1012;
	mov.u64 	%rd1, 4618441417868443648;
	shl.b64 	%rd2, %rd1, %r4;
	setp.eq.s64	%p5, %rd2, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 233
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd21;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd32, [retval0+0];
	
	//{
	}// Callseq End 233
	setp.lt.s32	%p6, %r1, 0;
	and.pred  	%p1, %p6, %p5;
	@!%p1 bra 	BB123_3;
	bra.uni 	BB123_2;

BB123_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd32;
	}
	xor.b32  	%r6, %r5, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd32;
	}
	mov.b64 	%fd32, {%r7, %r6};

BB123_3:
	setp.eq.f64	%p7, %fd2, 0d0000000000000000;
	@%p7 bra 	BB123_6;
	bra.uni 	BB123_4;

BB123_6:
	bfe.u32 	%r8, %r2, 20, 11;
	add.s32 	%r9, %r8, -1012;
	shl.b64 	%rd4, %rd1, %r9;
	setp.eq.s64	%p10, %rd4, -9223372036854775808;
	selp.b32	%r10, %r1, 0, %p10;
	or.b32  	%r11, %r10, 2146435072;
	setp.lt.s32	%p11, %r2, 0;
	selp.b32	%r12, %r11, %r10, %p11;
	mov.u32 	%r13, 0;
	mov.b64 	%fd32, {%r13, %r12};
	bra.uni 	BB123_7;

BB123_4:
	setp.gt.s32	%p8, %r1, -1;
	@%p8 bra 	BB123_7;

	cvt.rzi.f64.f64	%fd23, %fd21;
	setp.neu.f64	%p9, %fd23, 0d4018000000000000;
	selp.f64	%fd32, 0dFFF8000000000000, %fd32, %p9;

BB123_7:
	add.f64 	%fd33, %fd2, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd33;
	}
	and.b32  	%r15, %r14, 2146435072;
	setp.ne.s32	%p12, %r15, 2146435072;
	@%p12 bra 	BB123_8;

	setp.gtu.f64	%p13, %fd3, 0d7FF0000000000000;
	@%p13 bra 	BB123_17;

	and.b32  	%r16, %r2, 2147483647;
	setp.ne.s32	%p14, %r16, 2146435072;
	@%p14 bra 	BB123_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd21;
	}
	setp.eq.s32	%p15, %r17, 0;
	@%p15 bra 	BB123_16;

BB123_12:
	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p16, %r18, 2146435072;
	@%p16 bra 	BB123_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd2;
	}
	setp.ne.s32	%p17, %r19, 0;
	mov.f64 	%fd33, %fd32;
	@%p17 bra 	BB123_17;

	shr.s32 	%r20, %r2, 31;
	and.b32  	%r21, %r20, -2146435072;
	add.s32 	%r22, %r21, 2146435072;
	or.b32  	%r23, %r22, -2147483648;
	selp.b32	%r24, %r23, %r22, %p1;
	mov.u32 	%r25, 0;
	mov.b64 	%fd33, {%r25, %r24};
	bra.uni 	BB123_17;

BB123_8:
	mov.f64 	%fd33, %fd32;
	bra.uni 	BB123_17;

BB123_13:
	mov.f64 	%fd33, %fd32;
	bra.uni 	BB123_17;

BB123_16:
	setp.gt.f64	%p18, %fd3, 0d3FF0000000000000;
	selp.b32	%r26, 2146435072, 0, %p18;
	xor.b32  	%r27, %r26, 2146435072;
	setp.lt.s32	%p19, %r2, 0;
	selp.b32	%r28, %r27, %r26, %p19;
	setp.eq.f64	%p20, %fd2, 0dBFF0000000000000;
	selp.b32	%r29, 1072693248, %r28, %p20;
	mov.u32 	%r30, 0;
	mov.b64 	%fd33, {%r30, %r29};

BB123_17:
	setp.eq.f64	%p21, %fd2, 0d3FF0000000000000;
	selp.f64	%fd25, 0d3FF0000000000000, %fd33, %p21;
	mul.f64 	%fd26, %fd17, 0dC000000000000000;
	fma.rn.f64 	%fd27, %fd26, %fd16, 0d3FF0000000000000;
	mul.f64 	%fd28, %fd16, 0d40E9230000000000;
	mul.f64 	%fd29, %fd28, 0d401C000000000000;
	mul.f64 	%fd30, %fd29, %fd27;
	mul.f64 	%fd34, %fd30, %fd25;

BB123_18:
	st.param.f64	[func_retval0+0], %fd34;
	ret;
}

	// .globl	_Z15C6SmoothBump_omddPdiPii
.visible .func  (.param .b64 func_retval0) _Z15C6SmoothBump_omddPdiPii(
	.param .b64 _Z15C6SmoothBump_omddPdiPii_param_0,
	.param .b64 _Z15C6SmoothBump_omddPdiPii_param_1,
	.param .b64 _Z15C6SmoothBump_omddPdiPii_param_2,
	.param .b32 _Z15C6SmoothBump_omddPdiPii_param_3,
	.param .b64 _Z15C6SmoothBump_omddPdiPii_param_4,
	.param .b32 _Z15C6SmoothBump_omddPdiPii_param_5
)
{
	.reg .pred 	%p<22>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<35>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd16, [_Z15C6SmoothBump_omddPdiPii_param_0];
	ld.param.f64 	%fd17, [_Z15C6SmoothBump_omddPdiPii_param_1];
	mul.f64 	%fd1, %fd16, %fd17;
	setp.lt.f64	%p2, %fd1, 0d0000000000000000;
	setp.gt.f64	%p3, %fd1, 0d3FF0000000000000;
	or.pred  	%p4, %p2, %p3;
	mov.f64 	%fd34, 0d0000000000000000;
	@%p4 bra 	BB124_18;

	mov.f64 	%fd19, 0d3FF0000000000000;
	sub.f64 	%fd20, %fd19, %fd1;
	mul.f64 	%fd2, %fd1, %fd20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd21, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd21;
	}
	bfe.u32 	%r3, %r2, 20, 11;
	add.s32 	%r4, %r3, -1012;
	mov.u64 	%rd1, 4618441417868443648;
	shl.b64 	%rd2, %rd1, %r4;
	setp.eq.s64	%p5, %rd2, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 234
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd21;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd32, [retval0+0];
	
	//{
	}// Callseq End 234
	setp.lt.s32	%p6, %r1, 0;
	and.pred  	%p1, %p6, %p5;
	@!%p1 bra 	BB124_3;
	bra.uni 	BB124_2;

BB124_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd32;
	}
	xor.b32  	%r6, %r5, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd32;
	}
	mov.b64 	%fd32, {%r7, %r6};

BB124_3:
	setp.eq.f64	%p7, %fd2, 0d0000000000000000;
	@%p7 bra 	BB124_6;
	bra.uni 	BB124_4;

BB124_6:
	bfe.u32 	%r8, %r2, 20, 11;
	add.s32 	%r9, %r8, -1012;
	shl.b64 	%rd4, %rd1, %r9;
	setp.eq.s64	%p10, %rd4, -9223372036854775808;
	selp.b32	%r10, %r1, 0, %p10;
	or.b32  	%r11, %r10, 2146435072;
	setp.lt.s32	%p11, %r2, 0;
	selp.b32	%r12, %r11, %r10, %p11;
	mov.u32 	%r13, 0;
	mov.b64 	%fd32, {%r13, %r12};
	bra.uni 	BB124_7;

BB124_4:
	setp.gt.s32	%p8, %r1, -1;
	@%p8 bra 	BB124_7;

	cvt.rzi.f64.f64	%fd23, %fd21;
	setp.neu.f64	%p9, %fd23, 0d4018000000000000;
	selp.f64	%fd32, 0dFFF8000000000000, %fd32, %p9;

BB124_7:
	add.f64 	%fd33, %fd2, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd33;
	}
	and.b32  	%r15, %r14, 2146435072;
	setp.ne.s32	%p12, %r15, 2146435072;
	@%p12 bra 	BB124_8;

	setp.gtu.f64	%p13, %fd3, 0d7FF0000000000000;
	@%p13 bra 	BB124_17;

	and.b32  	%r16, %r2, 2147483647;
	setp.ne.s32	%p14, %r16, 2146435072;
	@%p14 bra 	BB124_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd21;
	}
	setp.eq.s32	%p15, %r17, 0;
	@%p15 bra 	BB124_16;

BB124_12:
	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p16, %r18, 2146435072;
	@%p16 bra 	BB124_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd2;
	}
	setp.ne.s32	%p17, %r19, 0;
	mov.f64 	%fd33, %fd32;
	@%p17 bra 	BB124_17;

	shr.s32 	%r20, %r2, 31;
	and.b32  	%r21, %r20, -2146435072;
	add.s32 	%r22, %r21, 2146435072;
	or.b32  	%r23, %r22, -2147483648;
	selp.b32	%r24, %r23, %r22, %p1;
	mov.u32 	%r25, 0;
	mov.b64 	%fd33, {%r25, %r24};
	bra.uni 	BB124_17;

BB124_8:
	mov.f64 	%fd33, %fd32;
	bra.uni 	BB124_17;

BB124_13:
	mov.f64 	%fd33, %fd32;
	bra.uni 	BB124_17;

BB124_16:
	setp.gt.f64	%p18, %fd3, 0d3FF0000000000000;
	selp.b32	%r26, 2146435072, 0, %p18;
	xor.b32  	%r27, %r26, 2146435072;
	setp.lt.s32	%p19, %r2, 0;
	selp.b32	%r28, %r27, %r26, %p19;
	setp.eq.f64	%p20, %fd2, 0dBFF0000000000000;
	selp.b32	%r29, 1072693248, %r28, %p20;
	mov.u32 	%r30, 0;
	mov.b64 	%fd33, {%r30, %r29};

BB124_17:
	setp.eq.f64	%p21, %fd2, 0d3FF0000000000000;
	selp.f64	%fd25, 0d3FF0000000000000, %fd33, %p21;
	mul.f64 	%fd26, %fd17, 0dC000000000000000;
	fma.rn.f64 	%fd27, %fd26, %fd16, 0d3FF0000000000000;
	mul.f64 	%fd28, %fd17, 0d40E9230000000000;
	mul.f64 	%fd29, %fd28, 0d401C000000000000;
	mul.f64 	%fd30, %fd29, %fd27;
	mul.f64 	%fd34, %fd30, %fd25;

BB124_18:
	st.param.f64	[func_retval0+0], %fd34;
	ret;
}

	// .globl	_Z15C6SmoothBump_ttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z15C6SmoothBump_ttddPdiPii(
	.param .b64 _Z15C6SmoothBump_ttddPdiPii_param_0,
	.param .b64 _Z15C6SmoothBump_ttddPdiPii_param_1,
	.param .b64 _Z15C6SmoothBump_ttddPdiPii_param_2,
	.param .b32 _Z15C6SmoothBump_ttddPdiPii_param_3,
	.param .b64 _Z15C6SmoothBump_ttddPdiPii_param_4,
	.param .b32 _Z15C6SmoothBump_ttddPdiPii_param_5
)
{
	.reg .pred 	%p<42>;
	.reg .b32 	%r<62>;
	.reg .f64 	%fd<60>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd26, [_Z15C6SmoothBump_ttddPdiPii_param_0];
	ld.param.f64 	%fd27, [_Z15C6SmoothBump_ttddPdiPii_param_1];
	mul.f64 	%fd1, %fd26, %fd27;
	setp.lt.f64	%p2, %fd1, 0d0000000000000000;
	setp.gt.f64	%p3, %fd1, 0d3FF0000000000000;
	or.pred  	%p4, %p2, %p3;
	mov.f64 	%fd59, 0d0000000000000000;
	@%p4 bra 	BB125_34;

	mov.f64 	%fd29, 0d3FF0000000000000;
	sub.f64 	%fd30, %fd29, %fd1;
	mul.f64 	%fd2, %fd1, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd31, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd31;
	}
	bfe.u32 	%r4, %r2, 20, 11;
	add.s32 	%r5, %r4, -1012;
	mov.u64 	%rd1, 4617315517961601024;
	shl.b64 	%rd2, %rd1, %r5;
	setp.eq.s64	%p5, %rd2, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 235
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd31;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd54, [retval0+0];
	
	//{
	}// Callseq End 235
	setp.lt.s32	%p6, %r1, 0;
	and.pred  	%p7, %p6, %p5;
	@!%p7 bra 	BB125_3;
	bra.uni 	BB125_2;

BB125_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd54;
	}
	xor.b32  	%r7, %r6, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd54;
	}
	mov.b64 	%fd54, {%r8, %r7};

BB125_3:
	setp.eq.f64	%p8, %fd2, 0d0000000000000000;
	@%p8 bra 	BB125_6;
	bra.uni 	BB125_4;

BB125_6:
	bfe.u32 	%r9, %r2, 20, 11;
	add.s32 	%r10, %r9, -1012;
	shl.b64 	%rd4, %rd1, %r10;
	setp.eq.s64	%p11, %rd4, -9223372036854775808;
	selp.b32	%r11, %r1, 0, %p11;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p12, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p12;
	mov.u32 	%r14, 0;
	mov.b64 	%fd54, {%r14, %r13};
	bra.uni 	BB125_7;

BB125_4:
	setp.gt.s32	%p9, %r1, -1;
	@%p9 bra 	BB125_7;

	cvt.rzi.f64.f64	%fd33, %fd31;
	setp.neu.f64	%p10, %fd33, 0d4014000000000000;
	selp.f64	%fd54, 0dFFF8000000000000, %fd54, %p10;

BB125_7:
	add.f64 	%fd55, %fd2, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd55;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p13, %r16, 2146435072;
	@%p13 bra 	BB125_8;

	setp.gtu.f64	%p14, %fd3, 0d7FF0000000000000;
	@%p14 bra 	BB125_17;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p15, %r17, 2146435072;
	@%p15 bra 	BB125_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd31;
	}
	setp.eq.s32	%p16, %r18, 0;
	@%p16 bra 	BB125_16;

BB125_12:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p17, %r19, 2146435072;
	@%p17 bra 	BB125_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd2;
	}
	setp.ne.s32	%p18, %r20, 0;
	mov.f64 	%fd55, %fd54;
	@%p18 bra 	BB125_17;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	bfe.u32 	%r25, %r2, 20, 11;
	add.s32 	%r26, %r25, -1012;
	shl.b64 	%rd6, %rd1, %r26;
	setp.eq.s64	%p19, %rd6, -9223372036854775808;
	and.pred  	%p21, %p6, %p19;
	selp.b32	%r27, %r24, %r23, %p21;
	mov.u32 	%r28, 0;
	mov.b64 	%fd55, {%r28, %r27};
	bra.uni 	BB125_17;

BB125_8:
	mov.f64 	%fd55, %fd54;
	bra.uni 	BB125_17;

BB125_13:
	mov.f64 	%fd55, %fd54;
	bra.uni 	BB125_17;

BB125_16:
	setp.gt.f64	%p22, %fd3, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p22;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p23, %r2, 0;
	selp.b32	%r31, %r30, %r29, %p23;
	setp.eq.f64	%p24, %fd2, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p24;
	mov.u32 	%r33, 0;
	mov.b64 	%fd55, {%r33, %r32};

BB125_17:
	mov.f64 	%fd35, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd35;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd7, 4618441417868443648;
	shl.b64 	%rd8, %rd7, %r35;
	setp.eq.s64	%p25, %rd8, -9223372036854775808;
	// Callseq Start 236
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd57, [retval0+0];
	
	//{
	}// Callseq End 236
	and.pred  	%p1, %p6, %p25;
	@!%p1 bra 	BB125_19;
	bra.uni 	BB125_18;

BB125_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd57;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd57;
	}
	mov.b64 	%fd57, {%r38, %r37};

BB125_19:
	@%p8 bra 	BB125_22;
	bra.uni 	BB125_20;

BB125_22:
	bfe.u32 	%r39, %r3, 20, 11;
	add.s32 	%r40, %r39, -1012;
	shl.b64 	%rd10, %rd7, %r40;
	setp.eq.s64	%p30, %rd10, -9223372036854775808;
	selp.b32	%r41, %r1, 0, %p30;
	or.b32  	%r42, %r41, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r43, %r42, %r41, %p31;
	mov.u32 	%r44, 0;
	mov.b64 	%fd57, {%r44, %r43};
	bra.uni 	BB125_23;

BB125_20:
	setp.gt.s32	%p28, %r1, -1;
	@%p28 bra 	BB125_23;

	cvt.rzi.f64.f64	%fd37, %fd35;
	setp.neu.f64	%p29, %fd37, 0d4018000000000000;
	selp.f64	%fd57, 0dFFF8000000000000, %fd57, %p29;

BB125_23:
	add.f64 	%fd58, %fd2, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd58;
	}
	and.b32  	%r46, %r45, 2146435072;
	setp.ne.s32	%p32, %r46, 2146435072;
	@%p32 bra 	BB125_24;

	setp.gtu.f64	%p33, %fd3, 0d7FF0000000000000;
	@%p33 bra 	BB125_33;

	and.b32  	%r47, %r3, 2147483647;
	setp.ne.s32	%p34, %r47, 2146435072;
	@%p34 bra 	BB125_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd35;
	}
	setp.eq.s32	%p35, %r48, 0;
	@%p35 bra 	BB125_32;

BB125_28:
	and.b32  	%r49, %r1, 2147483647;
	setp.ne.s32	%p36, %r49, 2146435072;
	@%p36 bra 	BB125_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd2;
	}
	setp.ne.s32	%p37, %r50, 0;
	mov.f64 	%fd58, %fd57;
	@%p37 bra 	BB125_33;

	shr.s32 	%r51, %r3, 31;
	and.b32  	%r52, %r51, -2146435072;
	add.s32 	%r53, %r52, 2146435072;
	or.b32  	%r54, %r53, -2147483648;
	selp.b32	%r55, %r54, %r53, %p1;
	mov.u32 	%r56, 0;
	mov.b64 	%fd58, {%r56, %r55};
	bra.uni 	BB125_33;

BB125_24:
	mov.f64 	%fd58, %fd57;
	bra.uni 	BB125_33;

BB125_29:
	mov.f64 	%fd58, %fd57;
	bra.uni 	BB125_33;

BB125_32:
	setp.gt.f64	%p38, %fd3, 0d3FF0000000000000;
	selp.b32	%r57, 2146435072, 0, %p38;
	xor.b32  	%r58, %r57, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r59, %r58, %r57, %p39;
	setp.eq.f64	%p40, %fd2, 0dBFF0000000000000;
	selp.b32	%r60, 1072693248, %r59, %p40;
	mov.u32 	%r61, 0;
	mov.b64 	%fd58, {%r61, %r60};

BB125_33:
	add.f64 	%fd39, %fd27, %fd27;
	mul.f64 	%fd40, %fd39, %fd26;
	sub.f64 	%fd42, %fd29, %fd40;
	add.f64 	%fd43, %fd58, %fd58;
	setp.eq.f64	%p41, %fd2, 0d3FF0000000000000;
	selp.f64	%fd44, 0d4000000000000000, %fd43, %p41;
	mul.f64 	%fd45, %fd42, 0d4018000000000000;
	mul.f64 	%fd46, %fd42, %fd45;
	selp.f64	%fd47, 0d3FF0000000000000, %fd55, %p41;
	mul.f64 	%fd48, %fd46, %fd47;
	sub.f64 	%fd49, %fd48, %fd44;
	mul.f64 	%fd50, %fd26, 0d40E9230000000000;
	mul.f64 	%fd51, %fd50, %fd26;
	mul.f64 	%fd52, %fd51, 0d401C000000000000;
	mul.f64 	%fd59, %fd52, %fd49;

BB125_34:
	st.param.f64	[func_retval0+0], %fd59;
	ret;
}

	// .globl	_Z16C6SmoothBump_tomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16C6SmoothBump_tomddPdiPii(
	.param .b64 _Z16C6SmoothBump_tomddPdiPii_param_0,
	.param .b64 _Z16C6SmoothBump_tomddPdiPii_param_1,
	.param .b64 _Z16C6SmoothBump_tomddPdiPii_param_2,
	.param .b32 _Z16C6SmoothBump_tomddPdiPii_param_3,
	.param .b64 _Z16C6SmoothBump_tomddPdiPii_param_4,
	.param .b32 _Z16C6SmoothBump_tomddPdiPii_param_5
)
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<56>;
	.reg .f64 	%fd<59>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd26, [_Z16C6SmoothBump_tomddPdiPii_param_0];
	ld.param.f64 	%fd27, [_Z16C6SmoothBump_tomddPdiPii_param_1];
	mul.f64 	%fd1, %fd26, %fd27;
	setp.lt.f64	%p3, %fd1, 0d0000000000000000;
	setp.gt.f64	%p4, %fd1, 0d3FF0000000000000;
	or.pred  	%p5, %p3, %p4;
	mov.f64 	%fd58, 0d0000000000000000;
	@%p5 bra 	BB126_34;

	mov.f64 	%fd29, 0d3FF0000000000000;
	sub.f64 	%fd30, %fd29, %fd1;
	mul.f64 	%fd2, %fd1, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd31, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd31;
	}
	bfe.u32 	%r4, %r2, 20, 11;
	add.s32 	%r5, %r4, -1012;
	mov.u64 	%rd3, 4618441417868443648;
	shl.b64 	%rd1, %rd3, %r5;
	setp.eq.s64	%p6, %rd1, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 237
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd31;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd53, [retval0+0];
	
	//{
	}// Callseq End 237
	setp.lt.s32	%p7, %r1, 0;
	and.pred  	%p1, %p7, %p6;
	@!%p1 bra 	BB126_3;
	bra.uni 	BB126_2;

BB126_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd53;
	}
	xor.b32  	%r7, %r6, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd53;
	}
	mov.b64 	%fd53, {%r8, %r7};

BB126_3:
	setp.eq.f64	%p8, %fd2, 0d0000000000000000;
	@%p8 bra 	BB126_6;
	bra.uni 	BB126_4;

BB126_6:
	selp.b32	%r9, %r1, 0, %p6;
	or.b32  	%r10, %r9, 2146435072;
	setp.lt.s32	%p12, %r2, 0;
	selp.b32	%r11, %r10, %r9, %p12;
	mov.u32 	%r12, 0;
	mov.b64 	%fd53, {%r12, %r11};
	bra.uni 	BB126_7;

BB126_4:
	setp.gt.s32	%p9, %r1, -1;
	@%p9 bra 	BB126_7;

	cvt.rzi.f64.f64	%fd33, %fd31;
	setp.neu.f64	%p10, %fd33, 0d4018000000000000;
	selp.f64	%fd53, 0dFFF8000000000000, %fd53, %p10;

BB126_7:
	add.f64 	%fd54, %fd2, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd54;
	}
	and.b32  	%r14, %r13, 2146435072;
	setp.ne.s32	%p13, %r14, 2146435072;
	@%p13 bra 	BB126_8;

	setp.gtu.f64	%p14, %fd3, 0d7FF0000000000000;
	@%p14 bra 	BB126_17;

	and.b32  	%r15, %r2, 2147483647;
	setp.ne.s32	%p15, %r15, 2146435072;
	@%p15 bra 	BB126_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r16, %temp}, %fd31;
	}
	setp.eq.s32	%p16, %r16, 0;
	@%p16 bra 	BB126_16;

BB126_12:
	and.b32  	%r17, %r1, 2147483647;
	setp.ne.s32	%p17, %r17, 2146435072;
	@%p17 bra 	BB126_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd2;
	}
	setp.ne.s32	%p18, %r18, 0;
	mov.f64 	%fd54, %fd53;
	@%p18 bra 	BB126_17;

	shr.s32 	%r19, %r2, 31;
	and.b32  	%r20, %r19, -2146435072;
	add.s32 	%r21, %r20, 2146435072;
	or.b32  	%r22, %r21, -2147483648;
	selp.b32	%r23, %r22, %r21, %p1;
	mov.u32 	%r24, 0;
	mov.b64 	%fd54, {%r24, %r23};
	bra.uni 	BB126_17;

BB126_8:
	mov.f64 	%fd54, %fd53;
	bra.uni 	BB126_17;

BB126_13:
	mov.f64 	%fd54, %fd53;
	bra.uni 	BB126_17;

BB126_16:
	setp.gt.f64	%p19, %fd3, 0d3FF0000000000000;
	selp.b32	%r25, 2146435072, 0, %p19;
	xor.b32  	%r26, %r25, 2146435072;
	setp.lt.s32	%p20, %r2, 0;
	selp.b32	%r27, %r26, %r25, %p20;
	setp.eq.f64	%p21, %fd2, 0dBFF0000000000000;
	selp.b32	%r28, 1072693248, %r27, %p21;
	mov.u32 	%r29, 0;
	mov.b64 	%fd54, {%r29, %r28};

BB126_17:
	mov.f64 	%fd35, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd35;
	}
	bfe.u32 	%r30, %r3, 20, 11;
	add.s32 	%r31, %r30, -1012;
	mov.u64 	%rd4, 4617315517961601024;
	shl.b64 	%rd2, %rd4, %r31;
	setp.eq.s64	%p22, %rd2, -9223372036854775808;
	// Callseq Start 238
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd56, [retval0+0];
	
	//{
	}// Callseq End 238
	and.pred  	%p2, %p7, %p22;
	@!%p2 bra 	BB126_19;
	bra.uni 	BB126_18;

BB126_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd56;
	}
	xor.b32  	%r33, %r32, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd56;
	}
	mov.b64 	%fd56, {%r34, %r33};

BB126_19:
	@%p8 bra 	BB126_22;
	bra.uni 	BB126_20;

BB126_22:
	selp.b32	%r35, %r1, 0, %p22;
	or.b32  	%r36, %r35, 2146435072;
	setp.lt.s32	%p28, %r3, 0;
	selp.b32	%r37, %r36, %r35, %p28;
	mov.u32 	%r38, 0;
	mov.b64 	%fd56, {%r38, %r37};
	bra.uni 	BB126_23;

BB126_20:
	setp.gt.s32	%p25, %r1, -1;
	@%p25 bra 	BB126_23;

	cvt.rzi.f64.f64	%fd37, %fd35;
	setp.neu.f64	%p26, %fd37, 0d4014000000000000;
	selp.f64	%fd56, 0dFFF8000000000000, %fd56, %p26;

BB126_23:
	add.f64 	%fd57, %fd2, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd57;
	}
	and.b32  	%r40, %r39, 2146435072;
	setp.ne.s32	%p29, %r40, 2146435072;
	@%p29 bra 	BB126_24;

	setp.gtu.f64	%p30, %fd3, 0d7FF0000000000000;
	@%p30 bra 	BB126_33;

	and.b32  	%r41, %r3, 2147483647;
	setp.ne.s32	%p31, %r41, 2146435072;
	@%p31 bra 	BB126_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd35;
	}
	setp.eq.s32	%p32, %r42, 0;
	@%p32 bra 	BB126_32;

BB126_28:
	and.b32  	%r43, %r1, 2147483647;
	setp.ne.s32	%p33, %r43, 2146435072;
	@%p33 bra 	BB126_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r44, %temp}, %fd2;
	}
	setp.ne.s32	%p34, %r44, 0;
	mov.f64 	%fd57, %fd56;
	@%p34 bra 	BB126_33;

	shr.s32 	%r45, %r3, 31;
	and.b32  	%r46, %r45, -2146435072;
	add.s32 	%r47, %r46, 2146435072;
	or.b32  	%r48, %r47, -2147483648;
	selp.b32	%r49, %r48, %r47, %p2;
	mov.u32 	%r50, 0;
	mov.b64 	%fd57, {%r50, %r49};
	bra.uni 	BB126_33;

BB126_24:
	mov.f64 	%fd57, %fd56;
	bra.uni 	BB126_33;

BB126_29:
	mov.f64 	%fd57, %fd56;
	bra.uni 	BB126_33;

BB126_32:
	setp.gt.f64	%p35, %fd3, 0d3FF0000000000000;
	selp.b32	%r51, 2146435072, 0, %p35;
	xor.b32  	%r52, %r51, 2146435072;
	setp.lt.s32	%p36, %r3, 0;
	selp.b32	%r53, %r52, %r51, %p36;
	setp.eq.f64	%p37, %fd2, 0dBFF0000000000000;
	selp.b32	%r54, 1072693248, %r53, %p37;
	mov.u32 	%r55, 0;
	mov.b64 	%fd57, {%r55, %r54};

BB126_33:
	mul.f64 	%fd39, %fd27, 0dC000000000000000;
	fma.rn.f64 	%fd40, %fd39, %fd26, 0d3FF0000000000000;
	setp.eq.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.f64	%fd41, 0d3FF0000000000000, %fd54, %p38;
	selp.f64	%fd42, 0d3FF0000000000000, %fd57, %p38;
	mul.f64 	%fd43, %fd40, 0d4018000000000000;
	mul.f64 	%fd44, %fd40, %fd43;
	mul.f64 	%fd45, %fd44, %fd42;
	add.f64 	%fd46, %fd41, %fd41;
	sub.f64 	%fd47, %fd45, %fd46;
	mul.f64 	%fd48, %fd1, 0d401C000000000000;
	mul.f64 	%fd49, %fd48, %fd47;
	mul.f64 	%fd50, %fd40, 0d401C000000000000;
	fma.rn.f64 	%fd51, %fd50, %fd41, %fd49;
	mul.f64 	%fd58, %fd51, 0d40E9230000000000;

BB126_34:
	st.param.f64	[func_retval0+0], %fd58;
	ret;
}

	// .globl	_Z17C6SmoothBump_omomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17C6SmoothBump_omomddPdiPii(
	.param .b64 _Z17C6SmoothBump_omomddPdiPii_param_0,
	.param .b64 _Z17C6SmoothBump_omomddPdiPii_param_1,
	.param .b64 _Z17C6SmoothBump_omomddPdiPii_param_2,
	.param .b32 _Z17C6SmoothBump_omomddPdiPii_param_3,
	.param .b64 _Z17C6SmoothBump_omomddPdiPii_param_4,
	.param .b32 _Z17C6SmoothBump_omomddPdiPii_param_5
)
{
	.reg .pred 	%p<42>;
	.reg .b32 	%r<62>;
	.reg .f64 	%fd<60>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd26, [_Z17C6SmoothBump_omomddPdiPii_param_0];
	ld.param.f64 	%fd27, [_Z17C6SmoothBump_omomddPdiPii_param_1];
	mul.f64 	%fd1, %fd26, %fd27;
	setp.lt.f64	%p2, %fd1, 0d0000000000000000;
	setp.gt.f64	%p3, %fd1, 0d3FF0000000000000;
	or.pred  	%p4, %p2, %p3;
	mov.f64 	%fd59, 0d0000000000000000;
	@%p4 bra 	BB127_34;

	mov.f64 	%fd29, 0d3FF0000000000000;
	sub.f64 	%fd30, %fd29, %fd1;
	mul.f64 	%fd2, %fd1, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd31, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd31;
	}
	bfe.u32 	%r4, %r2, 20, 11;
	add.s32 	%r5, %r4, -1012;
	mov.u64 	%rd1, 4617315517961601024;
	shl.b64 	%rd2, %rd1, %r5;
	setp.eq.s64	%p5, %rd2, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 239
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd31;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd54, [retval0+0];
	
	//{
	}// Callseq End 239
	setp.lt.s32	%p6, %r1, 0;
	and.pred  	%p7, %p6, %p5;
	@!%p7 bra 	BB127_3;
	bra.uni 	BB127_2;

BB127_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd54;
	}
	xor.b32  	%r7, %r6, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd54;
	}
	mov.b64 	%fd54, {%r8, %r7};

BB127_3:
	setp.eq.f64	%p8, %fd2, 0d0000000000000000;
	@%p8 bra 	BB127_6;
	bra.uni 	BB127_4;

BB127_6:
	bfe.u32 	%r9, %r2, 20, 11;
	add.s32 	%r10, %r9, -1012;
	shl.b64 	%rd4, %rd1, %r10;
	setp.eq.s64	%p11, %rd4, -9223372036854775808;
	selp.b32	%r11, %r1, 0, %p11;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p12, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p12;
	mov.u32 	%r14, 0;
	mov.b64 	%fd54, {%r14, %r13};
	bra.uni 	BB127_7;

BB127_4:
	setp.gt.s32	%p9, %r1, -1;
	@%p9 bra 	BB127_7;

	cvt.rzi.f64.f64	%fd33, %fd31;
	setp.neu.f64	%p10, %fd33, 0d4014000000000000;
	selp.f64	%fd54, 0dFFF8000000000000, %fd54, %p10;

BB127_7:
	add.f64 	%fd55, %fd2, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd55;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p13, %r16, 2146435072;
	@%p13 bra 	BB127_8;

	setp.gtu.f64	%p14, %fd3, 0d7FF0000000000000;
	@%p14 bra 	BB127_17;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p15, %r17, 2146435072;
	@%p15 bra 	BB127_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd31;
	}
	setp.eq.s32	%p16, %r18, 0;
	@%p16 bra 	BB127_16;

BB127_12:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p17, %r19, 2146435072;
	@%p17 bra 	BB127_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd2;
	}
	setp.ne.s32	%p18, %r20, 0;
	mov.f64 	%fd55, %fd54;
	@%p18 bra 	BB127_17;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	bfe.u32 	%r25, %r2, 20, 11;
	add.s32 	%r26, %r25, -1012;
	shl.b64 	%rd6, %rd1, %r26;
	setp.eq.s64	%p19, %rd6, -9223372036854775808;
	and.pred  	%p21, %p6, %p19;
	selp.b32	%r27, %r24, %r23, %p21;
	mov.u32 	%r28, 0;
	mov.b64 	%fd55, {%r28, %r27};
	bra.uni 	BB127_17;

BB127_8:
	mov.f64 	%fd55, %fd54;
	bra.uni 	BB127_17;

BB127_13:
	mov.f64 	%fd55, %fd54;
	bra.uni 	BB127_17;

BB127_16:
	setp.gt.f64	%p22, %fd3, 0d3FF0000000000000;
	selp.b32	%r29, 2146435072, 0, %p22;
	xor.b32  	%r30, %r29, 2146435072;
	setp.lt.s32	%p23, %r2, 0;
	selp.b32	%r31, %r30, %r29, %p23;
	setp.eq.f64	%p24, %fd2, 0dBFF0000000000000;
	selp.b32	%r32, 1072693248, %r31, %p24;
	mov.u32 	%r33, 0;
	mov.b64 	%fd55, {%r33, %r32};

BB127_17:
	mov.f64 	%fd35, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd35;
	}
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd7, 4618441417868443648;
	shl.b64 	%rd8, %rd7, %r35;
	setp.eq.s64	%p25, %rd8, -9223372036854775808;
	// Callseq Start 240
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd57, [retval0+0];
	
	//{
	}// Callseq End 240
	and.pred  	%p1, %p6, %p25;
	@!%p1 bra 	BB127_19;
	bra.uni 	BB127_18;

BB127_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd57;
	}
	xor.b32  	%r37, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd57;
	}
	mov.b64 	%fd57, {%r38, %r37};

BB127_19:
	@%p8 bra 	BB127_22;
	bra.uni 	BB127_20;

BB127_22:
	bfe.u32 	%r39, %r3, 20, 11;
	add.s32 	%r40, %r39, -1012;
	shl.b64 	%rd10, %rd7, %r40;
	setp.eq.s64	%p30, %rd10, -9223372036854775808;
	selp.b32	%r41, %r1, 0, %p30;
	or.b32  	%r42, %r41, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r43, %r42, %r41, %p31;
	mov.u32 	%r44, 0;
	mov.b64 	%fd57, {%r44, %r43};
	bra.uni 	BB127_23;

BB127_20:
	setp.gt.s32	%p28, %r1, -1;
	@%p28 bra 	BB127_23;

	cvt.rzi.f64.f64	%fd37, %fd35;
	setp.neu.f64	%p29, %fd37, 0d4018000000000000;
	selp.f64	%fd57, 0dFFF8000000000000, %fd57, %p29;

BB127_23:
	add.f64 	%fd58, %fd2, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd58;
	}
	and.b32  	%r46, %r45, 2146435072;
	setp.ne.s32	%p32, %r46, 2146435072;
	@%p32 bra 	BB127_24;

	setp.gtu.f64	%p33, %fd3, 0d7FF0000000000000;
	@%p33 bra 	BB127_33;

	and.b32  	%r47, %r3, 2147483647;
	setp.ne.s32	%p34, %r47, 2146435072;
	@%p34 bra 	BB127_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd35;
	}
	setp.eq.s32	%p35, %r48, 0;
	@%p35 bra 	BB127_32;

BB127_28:
	and.b32  	%r49, %r1, 2147483647;
	setp.ne.s32	%p36, %r49, 2146435072;
	@%p36 bra 	BB127_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd2;
	}
	setp.ne.s32	%p37, %r50, 0;
	mov.f64 	%fd58, %fd57;
	@%p37 bra 	BB127_33;

	shr.s32 	%r51, %r3, 31;
	and.b32  	%r52, %r51, -2146435072;
	add.s32 	%r53, %r52, 2146435072;
	or.b32  	%r54, %r53, -2147483648;
	selp.b32	%r55, %r54, %r53, %p1;
	mov.u32 	%r56, 0;
	mov.b64 	%fd58, {%r56, %r55};
	bra.uni 	BB127_33;

BB127_24:
	mov.f64 	%fd58, %fd57;
	bra.uni 	BB127_33;

BB127_29:
	mov.f64 	%fd58, %fd57;
	bra.uni 	BB127_33;

BB127_32:
	setp.gt.f64	%p38, %fd3, 0d3FF0000000000000;
	selp.b32	%r57, 2146435072, 0, %p38;
	xor.b32  	%r58, %r57, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r59, %r58, %r57, %p39;
	setp.eq.f64	%p40, %fd2, 0dBFF0000000000000;
	selp.b32	%r60, 1072693248, %r59, %p40;
	mov.u32 	%r61, 0;
	mov.b64 	%fd58, {%r61, %r60};

BB127_33:
	add.f64 	%fd39, %fd27, %fd27;
	mul.f64 	%fd40, %fd39, %fd26;
	sub.f64 	%fd42, %fd29, %fd40;
	add.f64 	%fd43, %fd58, %fd58;
	setp.eq.f64	%p41, %fd2, 0d3FF0000000000000;
	selp.f64	%fd44, 0d4000000000000000, %fd43, %p41;
	mul.f64 	%fd45, %fd42, 0d4018000000000000;
	mul.f64 	%fd46, %fd42, %fd45;
	selp.f64	%fd47, 0d3FF0000000000000, %fd55, %p41;
	mul.f64 	%fd48, %fd46, %fd47;
	sub.f64 	%fd49, %fd48, %fd44;
	mul.f64 	%fd50, %fd27, 0d40E9230000000000;
	mul.f64 	%fd51, %fd50, %fd27;
	mul.f64 	%fd52, %fd51, 0d401C000000000000;
	mul.f64 	%fd59, %fd52, %fd49;

BB127_34:
	st.param.f64	[func_retval0+0], %fd59;
	ret;
}

	// .globl	_Z16C6SmoothBump_tttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z16C6SmoothBump_tttddPdiPii(
	.param .b64 _Z16C6SmoothBump_tttddPdiPii_param_0,
	.param .b64 _Z16C6SmoothBump_tttddPdiPii_param_1,
	.param .b64 _Z16C6SmoothBump_tttddPdiPii_param_2,
	.param .b32 _Z16C6SmoothBump_tttddPdiPii_param_3,
	.param .b64 _Z16C6SmoothBump_tttddPdiPii_param_4,
	.param .b32 _Z16C6SmoothBump_tttddPdiPii_param_5
)
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<56>;
	.reg .f64 	%fd<59>;
	.reg .b64 	%rd<5>;


	ld.param.f64 	%fd26, [_Z16C6SmoothBump_tttddPdiPii_param_0];
	ld.param.f64 	%fd27, [_Z16C6SmoothBump_tttddPdiPii_param_1];
	mul.f64 	%fd1, %fd26, %fd27;
	setp.lt.f64	%p3, %fd1, 0d0000000000000000;
	setp.gt.f64	%p4, %fd1, 0d3FF0000000000000;
	or.pred  	%p5, %p3, %p4;
	mov.f64 	%fd58, 0d0000000000000000;
	@%p5 bra 	BB128_34;

	mov.f64 	%fd29, 0d3FF0000000000000;
	sub.f64 	%fd30, %fd29, %fd1;
	mul.f64 	%fd2, %fd1, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd31, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd31;
	}
	bfe.u32 	%r4, %r2, 20, 11;
	add.s32 	%r5, %r4, -1012;
	mov.u64 	%rd3, 4617315517961601024;
	shl.b64 	%rd1, %rd3, %r5;
	setp.eq.s64	%p6, %rd1, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 241
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd31;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd53, [retval0+0];
	
	//{
	}// Callseq End 241
	setp.lt.s32	%p7, %r1, 0;
	and.pred  	%p1, %p7, %p6;
	@!%p1 bra 	BB128_3;
	bra.uni 	BB128_2;

BB128_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd53;
	}
	xor.b32  	%r7, %r6, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd53;
	}
	mov.b64 	%fd53, {%r8, %r7};

BB128_3:
	setp.eq.f64	%p8, %fd2, 0d0000000000000000;
	@%p8 bra 	BB128_6;
	bra.uni 	BB128_4;

BB128_6:
	selp.b32	%r9, %r1, 0, %p6;
	or.b32  	%r10, %r9, 2146435072;
	setp.lt.s32	%p12, %r2, 0;
	selp.b32	%r11, %r10, %r9, %p12;
	mov.u32 	%r12, 0;
	mov.b64 	%fd53, {%r12, %r11};
	bra.uni 	BB128_7;

BB128_4:
	setp.gt.s32	%p9, %r1, -1;
	@%p9 bra 	BB128_7;

	cvt.rzi.f64.f64	%fd33, %fd31;
	setp.neu.f64	%p10, %fd33, 0d4014000000000000;
	selp.f64	%fd53, 0dFFF8000000000000, %fd53, %p10;

BB128_7:
	add.f64 	%fd54, %fd2, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd54;
	}
	and.b32  	%r14, %r13, 2146435072;
	setp.ne.s32	%p13, %r14, 2146435072;
	@%p13 bra 	BB128_8;

	setp.gtu.f64	%p14, %fd3, 0d7FF0000000000000;
	@%p14 bra 	BB128_17;

	and.b32  	%r15, %r2, 2147483647;
	setp.ne.s32	%p15, %r15, 2146435072;
	@%p15 bra 	BB128_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r16, %temp}, %fd31;
	}
	setp.eq.s32	%p16, %r16, 0;
	@%p16 bra 	BB128_16;

BB128_12:
	and.b32  	%r17, %r1, 2147483647;
	setp.ne.s32	%p17, %r17, 2146435072;
	@%p17 bra 	BB128_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd2;
	}
	setp.ne.s32	%p18, %r18, 0;
	mov.f64 	%fd54, %fd53;
	@%p18 bra 	BB128_17;

	shr.s32 	%r19, %r2, 31;
	and.b32  	%r20, %r19, -2146435072;
	add.s32 	%r21, %r20, 2146435072;
	or.b32  	%r22, %r21, -2147483648;
	selp.b32	%r23, %r22, %r21, %p1;
	mov.u32 	%r24, 0;
	mov.b64 	%fd54, {%r24, %r23};
	bra.uni 	BB128_17;

BB128_8:
	mov.f64 	%fd54, %fd53;
	bra.uni 	BB128_17;

BB128_13:
	mov.f64 	%fd54, %fd53;
	bra.uni 	BB128_17;

BB128_16:
	setp.gt.f64	%p19, %fd3, 0d3FF0000000000000;
	selp.b32	%r25, 2146435072, 0, %p19;
	xor.b32  	%r26, %r25, 2146435072;
	setp.lt.s32	%p20, %r2, 0;
	selp.b32	%r27, %r26, %r25, %p20;
	setp.eq.f64	%p21, %fd2, 0dBFF0000000000000;
	selp.b32	%r28, 1072693248, %r27, %p21;
	mov.u32 	%r29, 0;
	mov.b64 	%fd54, {%r29, %r28};

BB128_17:
	mov.f64 	%fd35, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd35;
	}
	bfe.u32 	%r30, %r3, 20, 11;
	add.s32 	%r31, %r30, -1012;
	mov.u64 	%rd4, 4616189618054758400;
	shl.b64 	%rd2, %rd4, %r31;
	setp.eq.s64	%p22, %rd2, -9223372036854775808;
	// Callseq Start 242
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd56, [retval0+0];
	
	//{
	}// Callseq End 242
	and.pred  	%p2, %p7, %p22;
	@!%p2 bra 	BB128_19;
	bra.uni 	BB128_18;

BB128_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd56;
	}
	xor.b32  	%r33, %r32, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd56;
	}
	mov.b64 	%fd56, {%r34, %r33};

BB128_19:
	@%p8 bra 	BB128_22;
	bra.uni 	BB128_20;

BB128_22:
	selp.b32	%r35, %r1, 0, %p22;
	or.b32  	%r36, %r35, 2146435072;
	setp.lt.s32	%p28, %r3, 0;
	selp.b32	%r37, %r36, %r35, %p28;
	mov.u32 	%r38, 0;
	mov.b64 	%fd56, {%r38, %r37};
	bra.uni 	BB128_23;

BB128_20:
	setp.gt.s32	%p25, %r1, -1;
	@%p25 bra 	BB128_23;

	cvt.rzi.f64.f64	%fd37, %fd35;
	setp.neu.f64	%p26, %fd37, 0d4010000000000000;
	selp.f64	%fd56, 0dFFF8000000000000, %fd56, %p26;

BB128_23:
	add.f64 	%fd57, %fd2, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd57;
	}
	and.b32  	%r40, %r39, 2146435072;
	setp.ne.s32	%p29, %r40, 2146435072;
	@%p29 bra 	BB128_24;

	setp.gtu.f64	%p30, %fd3, 0d7FF0000000000000;
	@%p30 bra 	BB128_33;

	and.b32  	%r41, %r3, 2147483647;
	setp.ne.s32	%p31, %r41, 2146435072;
	@%p31 bra 	BB128_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd35;
	}
	setp.eq.s32	%p32, %r42, 0;
	@%p32 bra 	BB128_32;

BB128_28:
	and.b32  	%r43, %r1, 2147483647;
	setp.ne.s32	%p33, %r43, 2146435072;
	@%p33 bra 	BB128_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r44, %temp}, %fd2;
	}
	setp.ne.s32	%p34, %r44, 0;
	mov.f64 	%fd57, %fd56;
	@%p34 bra 	BB128_33;

	shr.s32 	%r45, %r3, 31;
	and.b32  	%r46, %r45, -2146435072;
	add.s32 	%r47, %r46, 2146435072;
	or.b32  	%r48, %r47, -2147483648;
	selp.b32	%r49, %r48, %r47, %p2;
	mov.u32 	%r50, 0;
	mov.b64 	%fd57, {%r50, %r49};
	bra.uni 	BB128_33;

BB128_24:
	mov.f64 	%fd57, %fd56;
	bra.uni 	BB128_33;

BB128_29:
	mov.f64 	%fd57, %fd56;
	bra.uni 	BB128_33;

BB128_32:
	setp.gt.f64	%p35, %fd3, 0d3FF0000000000000;
	selp.b32	%r51, 2146435072, 0, %p35;
	xor.b32  	%r52, %r51, 2146435072;
	setp.lt.s32	%p36, %r3, 0;
	selp.b32	%r53, %r52, %r51, %p36;
	setp.eq.f64	%p37, %fd2, 0dBFF0000000000000;
	selp.b32	%r54, 1072693248, %r53, %p37;
	mov.u32 	%r55, 0;
	mov.b64 	%fd57, {%r55, %r54};

BB128_33:
	mul.f64 	%fd39, %fd27, 0dC000000000000000;
	fma.rn.f64 	%fd40, %fd39, %fd26, 0d3FF0000000000000;
	setp.eq.f64	%p38, %fd2, 0d3FF0000000000000;
	selp.f64	%fd41, 0d3FF0000000000000, %fd57, %p38;
	mul.f64 	%fd42, %fd40, 0d4014000000000000;
	mul.f64 	%fd43, %fd40, %fd42;
	mul.f64 	%fd44, %fd54, 0dC018000000000000;
	selp.f64	%fd45, 0dC018000000000000, %fd44, %p38;
	fma.rn.f64 	%fd46, %fd43, %fd41, %fd45;
	mul.f64 	%fd47, %fd26, 0d40E9230000000000;
	mul.f64 	%fd48, %fd47, %fd26;
	mul.f64 	%fd49, %fd48, %fd26;
	mul.f64 	%fd50, %fd49, 0d4045000000000000;
	mul.f64 	%fd51, %fd50, %fd40;
	mul.f64 	%fd58, %fd51, %fd46;

BB128_34:
	st.param.f64	[func_retval0+0], %fd58;
	ret;
}

	// .globl	_Z17C6SmoothBump_omttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17C6SmoothBump_omttddPdiPii(
	.param .b64 _Z17C6SmoothBump_omttddPdiPii_param_0,
	.param .b64 _Z17C6SmoothBump_omttddPdiPii_param_1,
	.param .b64 _Z17C6SmoothBump_omttddPdiPii_param_2,
	.param .b32 _Z17C6SmoothBump_omttddPdiPii_param_3,
	.param .b64 _Z17C6SmoothBump_omttddPdiPii_param_4,
	.param .b32 _Z17C6SmoothBump_omttddPdiPii_param_5
)
{
	.reg .pred 	%p<58>;
	.reg .b32 	%r<83>;
	.reg .f64 	%fd<85>;
	.reg .b64 	%rd<7>;


	ld.param.f64 	%fd39, [_Z17C6SmoothBump_omttddPdiPii_param_0];
	ld.param.f64 	%fd40, [_Z17C6SmoothBump_omttddPdiPii_param_1];
	mul.f64 	%fd1, %fd39, %fd40;
	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	setp.gt.f64	%p5, %fd1, 0d3FF0000000000000;
	or.pred  	%p6, %p4, %p5;
	mov.f64 	%fd84, 0d0000000000000000;
	@%p6 bra 	BB129_50;

	mul.f64 	%fd42, %fd40, 0dC000000000000000;
	fma.rn.f64 	%fd2, %fd42, %fd39, 0d3FF0000000000000;
	mov.f64 	%fd43, 0d3FF0000000000000;
	sub.f64 	%fd44, %fd43, %fd1;
	mul.f64 	%fd3, %fd1, %fd44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd3;
	}
	mov.f64 	%fd45, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd45;
	}
	bfe.u32 	%r5, %r2, 20, 11;
	add.s32 	%r6, %r5, -1012;
	mov.u64 	%rd4, 4617315517961601024;
	shl.b64 	%rd1, %rd4, %r6;
	setp.eq.s64	%p7, %rd1, -9223372036854775808;
	abs.f64 	%fd4, %fd3;
	// Callseq Start 243
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd45;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd76, [retval0+0];
	
	//{
	}// Callseq End 243
	setp.lt.s32	%p8, %r1, 0;
	and.pred  	%p1, %p8, %p7;
	@!%p1 bra 	BB129_3;
	bra.uni 	BB129_2;

BB129_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd76;
	}
	xor.b32  	%r8, %r7, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd76;
	}
	mov.b64 	%fd76, {%r9, %r8};

BB129_3:
	setp.eq.f64	%p9, %fd3, 0d0000000000000000;
	@%p9 bra 	BB129_6;
	bra.uni 	BB129_4;

BB129_6:
	selp.b32	%r10, %r1, 0, %p7;
	or.b32  	%r11, %r10, 2146435072;
	setp.lt.s32	%p13, %r2, 0;
	selp.b32	%r12, %r11, %r10, %p13;
	mov.u32 	%r13, 0;
	mov.b64 	%fd76, {%r13, %r12};
	bra.uni 	BB129_7;

BB129_4:
	setp.gt.s32	%p10, %r1, -1;
	@%p10 bra 	BB129_7;

	cvt.rzi.f64.f64	%fd47, %fd45;
	setp.neu.f64	%p11, %fd47, 0d4014000000000000;
	selp.f64	%fd76, 0dFFF8000000000000, %fd76, %p11;

BB129_7:
	add.f64 	%fd77, %fd3, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd77;
	}
	and.b32  	%r15, %r14, 2146435072;
	setp.ne.s32	%p14, %r15, 2146435072;
	@%p14 bra 	BB129_8;

	setp.gtu.f64	%p15, %fd4, 0d7FF0000000000000;
	@%p15 bra 	BB129_17;

	and.b32  	%r16, %r2, 2147483647;
	setp.ne.s32	%p16, %r16, 2146435072;
	@%p16 bra 	BB129_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd45;
	}
	setp.eq.s32	%p17, %r17, 0;
	@%p17 bra 	BB129_16;

BB129_12:
	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB129_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd3;
	}
	setp.ne.s32	%p19, %r19, 0;
	mov.f64 	%fd77, %fd76;
	@%p19 bra 	BB129_17;

	shr.s32 	%r20, %r2, 31;
	and.b32  	%r21, %r20, -2146435072;
	add.s32 	%r22, %r21, 2146435072;
	or.b32  	%r23, %r22, -2147483648;
	selp.b32	%r24, %r23, %r22, %p1;
	mov.u32 	%r25, 0;
	mov.b64 	%fd77, {%r25, %r24};
	bra.uni 	BB129_17;

BB129_8:
	mov.f64 	%fd77, %fd76;
	bra.uni 	BB129_17;

BB129_13:
	mov.f64 	%fd77, %fd76;
	bra.uni 	BB129_17;

BB129_16:
	setp.gt.f64	%p20, %fd4, 0d3FF0000000000000;
	selp.b32	%r26, 2146435072, 0, %p20;
	xor.b32  	%r27, %r26, 2146435072;
	setp.lt.s32	%p21, %r2, 0;
	selp.b32	%r28, %r27, %r26, %p21;
	setp.eq.f64	%p22, %fd3, 0dBFF0000000000000;
	selp.b32	%r29, 1072693248, %r28, %p22;
	mov.u32 	%r30, 0;
	mov.b64 	%fd77, {%r30, %r29};

BB129_17:
	setp.eq.f64	%p23, %fd3, 0d3FF0000000000000;
	selp.f64	%fd15, 0d3FF0000000000000, %fd77, %p23;
	mov.f64 	%fd49, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd49;
	}
	bfe.u32 	%r31, %r3, 20, 11;
	add.s32 	%r32, %r31, -1012;
	mov.u64 	%rd5, 4618441417868443648;
	shl.b64 	%rd2, %rd5, %r32;
	setp.eq.s64	%p24, %rd2, -9223372036854775808;
	// Callseq Start 244
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd49;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd79, [retval0+0];
	
	//{
	}// Callseq End 244
	and.pred  	%p2, %p8, %p24;
	@!%p2 bra 	BB129_19;
	bra.uni 	BB129_18;

BB129_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd79;
	}
	xor.b32  	%r34, %r33, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd79;
	}
	mov.b64 	%fd79, {%r35, %r34};

BB129_19:
	@%p9 bra 	BB129_22;
	bra.uni 	BB129_20;

BB129_22:
	selp.b32	%r36, %r1, 0, %p24;
	or.b32  	%r37, %r36, 2146435072;
	setp.lt.s32	%p30, %r3, 0;
	selp.b32	%r38, %r37, %r36, %p30;
	mov.u32 	%r39, 0;
	mov.b64 	%fd79, {%r39, %r38};
	bra.uni 	BB129_23;

BB129_20:
	setp.gt.s32	%p27, %r1, -1;
	@%p27 bra 	BB129_23;

	cvt.rzi.f64.f64	%fd51, %fd49;
	setp.neu.f64	%p28, %fd51, 0d4018000000000000;
	selp.f64	%fd79, 0dFFF8000000000000, %fd79, %p28;

BB129_23:
	add.f64 	%fd80, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd80;
	}
	and.b32  	%r41, %r40, 2146435072;
	setp.ne.s32	%p31, %r41, 2146435072;
	@%p31 bra 	BB129_24;

	setp.gtu.f64	%p32, %fd4, 0d7FF0000000000000;
	@%p32 bra 	BB129_33;

	and.b32  	%r42, %r3, 2147483647;
	setp.ne.s32	%p33, %r42, 2146435072;
	@%p33 bra 	BB129_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r43, %temp}, %fd49;
	}
	setp.eq.s32	%p34, %r43, 0;
	@%p34 bra 	BB129_32;

BB129_28:
	and.b32  	%r44, %r1, 2147483647;
	setp.ne.s32	%p35, %r44, 2146435072;
	@%p35 bra 	BB129_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd3;
	}
	setp.ne.s32	%p36, %r45, 0;
	mov.f64 	%fd80, %fd79;
	@%p36 bra 	BB129_33;

	shr.s32 	%r46, %r3, 31;
	and.b32  	%r47, %r46, -2146435072;
	add.s32 	%r48, %r47, 2146435072;
	or.b32  	%r49, %r48, -2147483648;
	selp.b32	%r50, %r49, %r48, %p2;
	mov.u32 	%r51, 0;
	mov.b64 	%fd80, {%r51, %r50};
	bra.uni 	BB129_33;

BB129_24:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB129_33;

BB129_29:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB129_33;

BB129_32:
	setp.gt.f64	%p37, %fd4, 0d3FF0000000000000;
	selp.b32	%r52, 2146435072, 0, %p37;
	xor.b32  	%r53, %r52, 2146435072;
	setp.lt.s32	%p38, %r3, 0;
	selp.b32	%r54, %r53, %r52, %p38;
	setp.eq.f64	%p39, %fd3, 0dBFF0000000000000;
	selp.b32	%r55, 1072693248, %r54, %p39;
	mov.u32 	%r56, 0;
	mov.b64 	%fd80, {%r56, %r55};

BB129_33:
	mov.f64 	%fd53, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd53;
	}
	bfe.u32 	%r57, %r4, 20, 11;
	add.s32 	%r58, %r57, -1012;
	mov.u64 	%rd6, 4616189618054758400;
	shl.b64 	%rd3, %rd6, %r58;
	setp.eq.s64	%p40, %rd3, -9223372036854775808;
	// Callseq Start 245
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd53;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd82, [retval0+0];
	
	//{
	}// Callseq End 245
	and.pred  	%p3, %p8, %p40;
	@!%p3 bra 	BB129_35;
	bra.uni 	BB129_34;

BB129_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd82;
	}
	xor.b32  	%r60, %r59, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r61, %temp}, %fd82;
	}
	mov.b64 	%fd82, {%r61, %r60};

BB129_35:
	add.f64 	%fd54, %fd39, %fd39;
	mul.f64 	%fd55, %fd2, 0d4018000000000000;
	mul.f64 	%fd56, %fd2, %fd55;
	mul.f64 	%fd57, %fd56, %fd15;
	add.f64 	%fd58, %fd80, %fd80;
	selp.f64	%fd59, 0d4000000000000000, %fd58, %p23;
	sub.f64 	%fd60, %fd57, %fd59;
	mul.f64 	%fd61, %fd60, 0d401C000000000000;
	mul.f64 	%fd29, %fd54, %fd61;
	@%p9 bra 	BB129_38;
	bra.uni 	BB129_36;

BB129_38:
	selp.b32	%r62, %r1, 0, %p40;
	or.b32  	%r63, %r62, 2146435072;
	setp.lt.s32	%p47, %r4, 0;
	selp.b32	%r64, %r63, %r62, %p47;
	mov.u32 	%r65, 0;
	mov.b64 	%fd82, {%r65, %r64};
	bra.uni 	BB129_39;

BB129_36:
	setp.gt.s32	%p44, %r1, -1;
	@%p44 bra 	BB129_39;

	cvt.rzi.f64.f64	%fd63, %fd53;
	setp.neu.f64	%p45, %fd63, 0d4010000000000000;
	selp.f64	%fd82, 0dFFF8000000000000, %fd82, %p45;

BB129_39:
	add.f64 	%fd83, %fd3, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd83;
	}
	and.b32  	%r67, %r66, 2146435072;
	setp.ne.s32	%p48, %r67, 2146435072;
	@%p48 bra 	BB129_40;

	setp.gtu.f64	%p49, %fd4, 0d7FF0000000000000;
	@%p49 bra 	BB129_49;

	and.b32  	%r68, %r4, 2147483647;
	setp.ne.s32	%p50, %r68, 2146435072;
	@%p50 bra 	BB129_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd53;
	}
	setp.eq.s32	%p51, %r69, 0;
	@%p51 bra 	BB129_48;

BB129_44:
	and.b32  	%r70, %r1, 2147483647;
	setp.ne.s32	%p52, %r70, 2146435072;
	@%p52 bra 	BB129_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd3;
	}
	setp.ne.s32	%p53, %r71, 0;
	mov.f64 	%fd83, %fd82;
	@%p53 bra 	BB129_49;

	shr.s32 	%r72, %r4, 31;
	and.b32  	%r73, %r72, -2146435072;
	add.s32 	%r74, %r73, 2146435072;
	or.b32  	%r75, %r74, -2147483648;
	selp.b32	%r76, %r75, %r74, %p3;
	mov.u32 	%r77, 0;
	mov.b64 	%fd83, {%r77, %r76};
	bra.uni 	BB129_49;

BB129_40:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB129_49;

BB129_45:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB129_49;

BB129_48:
	setp.gt.f64	%p54, %fd4, 0d3FF0000000000000;
	selp.b32	%r78, 2146435072, 0, %p54;
	xor.b32  	%r79, %r78, 2146435072;
	setp.lt.s32	%p55, %r4, 0;
	selp.b32	%r80, %r79, %r78, %p55;
	setp.eq.f64	%p56, %fd3, 0dBFF0000000000000;
	selp.b32	%r81, 1072693248, %r80, %p56;
	mov.u32 	%r82, 0;
	mov.b64 	%fd83, {%r82, %r81};

BB129_49:
	selp.f64	%fd65, 0d3FF0000000000000, %fd83, %p23;
	mul.f64 	%fd66, %fd2, 0d4014000000000000;
	mul.f64 	%fd67, %fd2, %fd66;
	mul.f64 	%fd68, %fd67, %fd65;
	fma.rn.f64 	%fd69, %fd15, 0dC018000000000000, %fd68;
	mul.f64 	%fd70, %fd2, 0d4045000000000000;
	mul.f64 	%fd71, %fd70, %fd69;
	mul.f64 	%fd72, %fd39, %fd39;
	mul.f64 	%fd73, %fd72, %fd40;
	fma.rn.f64 	%fd74, %fd73, %fd71, %fd29;
	mul.f64 	%fd84, %fd74, 0d40E9230000000000;

BB129_50:
	st.param.f64	[func_retval0+0], %fd84;
	ret;
}

	// .globl	_Z17C6SmoothBump_ttttddPdiPii
.visible .func  (.param .b64 func_retval0) _Z17C6SmoothBump_ttttddPdiPii(
	.param .b64 _Z17C6SmoothBump_ttttddPdiPii_param_0,
	.param .b64 _Z17C6SmoothBump_ttttddPdiPii_param_1,
	.param .b64 _Z17C6SmoothBump_ttttddPdiPii_param_2,
	.param .b32 _Z17C6SmoothBump_ttttddPdiPii_param_3,
	.param .b64 _Z17C6SmoothBump_ttttddPdiPii_param_4,
	.param .b32 _Z17C6SmoothBump_ttttddPdiPii_param_5
)
{
	.reg .pred 	%p<57>;
	.reg .b32 	%r<87>;
	.reg .f64 	%fd<85>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd40, [_Z17C6SmoothBump_ttttddPdiPii_param_0];
	ld.param.f64 	%fd41, [_Z17C6SmoothBump_ttttddPdiPii_param_1];
	mul.f64 	%fd1, %fd40, %fd41;
	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	setp.gt.f64	%p5, %fd1, 0d3FF0000000000000;
	or.pred  	%p6, %p4, %p5;
	mov.f64 	%fd84, 0d0000000000000000;
	@%p6 bra 	BB130_50;

	mov.f64 	%fd43, 0d3FF0000000000000;
	sub.f64 	%fd2, %fd43, %fd1;
	mul.f64 	%fd3, %fd1, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd3;
	}
	mov.f64 	%fd44, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd44;
	}
	bfe.u32 	%r5, %r2, 20, 11;
	add.s32 	%r6, %r5, -1012;
	mov.u64 	%rd2, 4617315517961601024;
	shl.b64 	%rd1, %rd2, %r6;
	setp.eq.s64	%p7, %rd1, -9223372036854775808;
	abs.f64 	%fd4, %fd3;
	// Callseq Start 246
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd44;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd76, [retval0+0];
	
	//{
	}// Callseq End 246
	setp.lt.s32	%p8, %r1, 0;
	and.pred  	%p1, %p8, %p7;
	@!%p1 bra 	BB130_3;
	bra.uni 	BB130_2;

BB130_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd76;
	}
	xor.b32  	%r8, %r7, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd76;
	}
	mov.b64 	%fd76, {%r9, %r8};

BB130_3:
	setp.eq.f64	%p9, %fd3, 0d0000000000000000;
	@%p9 bra 	BB130_6;
	bra.uni 	BB130_4;

BB130_6:
	selp.b32	%r10, %r1, 0, %p7;
	or.b32  	%r11, %r10, 2146435072;
	setp.lt.s32	%p13, %r2, 0;
	selp.b32	%r12, %r11, %r10, %p13;
	mov.u32 	%r13, 0;
	mov.b64 	%fd76, {%r13, %r12};
	bra.uni 	BB130_7;

BB130_4:
	setp.gt.s32	%p10, %r1, -1;
	@%p10 bra 	BB130_7;

	cvt.rzi.f64.f64	%fd46, %fd44;
	setp.neu.f64	%p11, %fd46, 0d4014000000000000;
	selp.f64	%fd76, 0dFFF8000000000000, %fd76, %p11;

BB130_7:
	add.f64 	%fd77, %fd3, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd77;
	}
	and.b32  	%r15, %r14, 2146435072;
	setp.ne.s32	%p14, %r15, 2146435072;
	@%p14 bra 	BB130_8;

	setp.gtu.f64	%p15, %fd4, 0d7FF0000000000000;
	@%p15 bra 	BB130_17;

	and.b32  	%r16, %r2, 2147483647;
	setp.ne.s32	%p16, %r16, 2146435072;
	@%p16 bra 	BB130_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd44;
	}
	setp.eq.s32	%p17, %r17, 0;
	@%p17 bra 	BB130_16;

BB130_12:
	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB130_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd3;
	}
	setp.ne.s32	%p19, %r19, 0;
	mov.f64 	%fd77, %fd76;
	@%p19 bra 	BB130_17;

	shr.s32 	%r20, %r2, 31;
	and.b32  	%r21, %r20, -2146435072;
	add.s32 	%r22, %r21, 2146435072;
	or.b32  	%r23, %r22, -2147483648;
	selp.b32	%r24, %r23, %r22, %p1;
	mov.u32 	%r25, 0;
	mov.b64 	%fd77, {%r25, %r24};
	bra.uni 	BB130_17;

BB130_8:
	mov.f64 	%fd77, %fd76;
	bra.uni 	BB130_17;

BB130_13:
	mov.f64 	%fd77, %fd76;
	bra.uni 	BB130_17;

BB130_16:
	setp.gt.f64	%p20, %fd4, 0d3FF0000000000000;
	selp.b32	%r26, 2146435072, 0, %p20;
	xor.b32  	%r27, %r26, 2146435072;
	setp.lt.s32	%p21, %r2, 0;
	selp.b32	%r28, %r27, %r26, %p21;
	setp.eq.f64	%p22, %fd3, 0dBFF0000000000000;
	selp.b32	%r29, 1072693248, %r28, %p22;
	mov.u32 	%r30, 0;
	mov.b64 	%fd77, {%r30, %r29};

BB130_17:
	mov.f64 	%fd48, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd48;
	}
	bfe.u32 	%r31, %r3, 20, 11;
	add.s32 	%r32, %r31, -1012;
	mov.u64 	%rd3, 4616189618054758400;
	shl.b64 	%rd4, %rd3, %r32;
	setp.eq.s64	%p23, %rd4, -9223372036854775808;
	// Callseq Start 247
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd48;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd79, [retval0+0];
	
	//{
	}// Callseq End 247
	and.pred  	%p2, %p8, %p23;
	@!%p2 bra 	BB130_19;
	bra.uni 	BB130_18;

BB130_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd79;
	}
	xor.b32  	%r34, %r33, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd79;
	}
	mov.b64 	%fd79, {%r35, %r34};

BB130_19:
	@%p9 bra 	BB130_22;
	bra.uni 	BB130_20;

BB130_22:
	bfe.u32 	%r36, %r3, 20, 11;
	add.s32 	%r37, %r36, -1012;
	shl.b64 	%rd6, %rd3, %r37;
	setp.eq.s64	%p28, %rd6, -9223372036854775808;
	selp.b32	%r38, %r1, 0, %p28;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p29, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p29;
	mov.u32 	%r41, 0;
	mov.b64 	%fd79, {%r41, %r40};
	bra.uni 	BB130_23;

BB130_20:
	setp.gt.s32	%p26, %r1, -1;
	@%p26 bra 	BB130_23;

	cvt.rzi.f64.f64	%fd50, %fd48;
	setp.neu.f64	%p27, %fd50, 0d4010000000000000;
	selp.f64	%fd79, 0dFFF8000000000000, %fd79, %p27;

BB130_23:
	add.f64 	%fd80, %fd3, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd80;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p30, %r43, 2146435072;
	@%p30 bra 	BB130_24;

	setp.gtu.f64	%p31, %fd4, 0d7FF0000000000000;
	@%p31 bra 	BB130_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p32, %r44, 2146435072;
	@%p32 bra 	BB130_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd48;
	}
	setp.eq.s32	%p33, %r45, 0;
	@%p33 bra 	BB130_32;

BB130_28:
	and.b32  	%r46, %r1, 2147483647;
	setp.ne.s32	%p34, %r46, 2146435072;
	@%p34 bra 	BB130_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd3;
	}
	setp.ne.s32	%p35, %r47, 0;
	mov.f64 	%fd80, %fd79;
	@%p35 bra 	BB130_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd80, {%r53, %r52};
	bra.uni 	BB130_33;

BB130_24:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB130_33;

BB130_29:
	mov.f64 	%fd80, %fd79;
	bra.uni 	BB130_33;

BB130_32:
	setp.gt.f64	%p36, %fd4, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p36;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p37, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p37;
	setp.eq.f64	%p38, %fd3, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p38;
	mov.u32 	%r58, 0;
	mov.b64 	%fd80, {%r58, %r57};

BB130_33:
	mul.f64 	%fd52, %fd40, 0dC000000000000000;
	fma.rn.f64 	%fd53, %fd52, %fd41, 0d3FF0000000000000;
	bfe.u32 	%r59, %r3, 20, 11;
	add.s32 	%r60, %r59, -1012;
	shl.b64 	%rd8, %rd3, %r60;
	setp.eq.s64	%p39, %rd8, -9223372036854775808;
	setp.eq.f64	%p40, %fd3, 0d3FF0000000000000;
	selp.f64	%fd54, 0d3FF0000000000000, %fd80, %p40;
	mul.f64 	%fd55, %fd53, 0dC014000000000000;
	mul.f64 	%fd56, %fd53, %fd55;
	selp.f64	%fd57, 0d3FF0000000000000, %fd77, %p40;
	fma.rn.f64 	%fd25, %fd56, %fd54, %fd57;
	add.f64 	%fd58, %fd41, %fd41;
	mul.f64 	%fd59, %fd58, %fd40;
	sub.f64 	%fd61, %fd43, %fd59;
	mul.f64 	%fd62, %fd61, %fd41;
	mul.f64 	%fd63, %fd62, %fd40;
	mul.f64 	%fd26, %fd2, %fd63;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd26;
	}
	abs.f64 	%fd27, %fd26;
	// Callseq Start 248
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd27;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd48;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd82, [retval0+0];
	
	//{
	}// Callseq End 248
	setp.lt.s32	%p41, %r4, 0;
	and.pred  	%p3, %p41, %p39;
	@!%p3 bra 	BB130_35;
	bra.uni 	BB130_34;

BB130_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd82;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd82;
	}
	mov.b64 	%fd82, {%r63, %r62};

BB130_35:
	setp.eq.f64	%p42, %fd26, 0d0000000000000000;
	@%p42 bra 	BB130_38;
	bra.uni 	BB130_36;

BB130_38:
	bfe.u32 	%r64, %r3, 20, 11;
	add.s32 	%r65, %r64, -1012;
	shl.b64 	%rd10, %rd3, %r65;
	setp.eq.s64	%p45, %rd10, -9223372036854775808;
	selp.b32	%r66, %r4, 0, %p45;
	or.b32  	%r67, %r66, 2146435072;
	setp.lt.s32	%p46, %r3, 0;
	selp.b32	%r68, %r67, %r66, %p46;
	mov.u32 	%r69, 0;
	mov.b64 	%fd82, {%r69, %r68};
	bra.uni 	BB130_39;

BB130_36:
	setp.gt.s32	%p43, %r4, -1;
	@%p43 bra 	BB130_39;

	cvt.rzi.f64.f64	%fd66, %fd48;
	setp.neu.f64	%p44, %fd66, 0d4010000000000000;
	selp.f64	%fd82, 0dFFF8000000000000, %fd82, %p44;

BB130_39:
	add.f64 	%fd83, %fd26, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd83;
	}
	and.b32  	%r71, %r70, 2146435072;
	setp.ne.s32	%p47, %r71, 2146435072;
	@%p47 bra 	BB130_40;

	setp.gtu.f64	%p48, %fd27, 0d7FF0000000000000;
	@%p48 bra 	BB130_49;

	and.b32  	%r72, %r3, 2147483647;
	setp.ne.s32	%p49, %r72, 2146435072;
	@%p49 bra 	BB130_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd48;
	}
	setp.eq.s32	%p50, %r73, 0;
	@%p50 bra 	BB130_48;

BB130_44:
	and.b32  	%r74, %r4, 2147483647;
	setp.ne.s32	%p51, %r74, 2146435072;
	@%p51 bra 	BB130_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd26;
	}
	setp.ne.s32	%p52, %r75, 0;
	mov.f64 	%fd83, %fd82;
	@%p52 bra 	BB130_49;

	shr.s32 	%r76, %r3, 31;
	and.b32  	%r77, %r76, -2146435072;
	add.s32 	%r78, %r77, 2146435072;
	or.b32  	%r79, %r78, -2147483648;
	selp.b32	%r80, %r79, %r78, %p3;
	mov.u32 	%r81, 0;
	mov.b64 	%fd83, {%r81, %r80};
	bra.uni 	BB130_49;

BB130_40:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB130_49;

BB130_45:
	mov.f64 	%fd83, %fd82;
	bra.uni 	BB130_49;

BB130_48:
	setp.gt.f64	%p53, %fd27, 0d3FF0000000000000;
	selp.b32	%r82, 2146435072, 0, %p53;
	xor.b32  	%r83, %r82, 2146435072;
	setp.lt.s32	%p54, %r3, 0;
	selp.b32	%r84, %r83, %r82, %p54;
	setp.eq.f64	%p55, %fd26, 0dBFF0000000000000;
	selp.b32	%r85, 1072693248, %r84, %p55;
	mov.u32 	%r86, 0;
	mov.b64 	%fd83, {%r86, %r85};

BB130_49:
	mul.f64 	%fd68, %fd83, 0d408A400000000000;
	setp.eq.f64	%p56, %fd26, 0d3FF0000000000000;
	selp.f64	%fd69, 0d408A400000000000, %fd68, %p56;
	fma.rn.f64 	%fd70, %fd25, 0d407F800000000000, %fd69;
	mul.f64 	%fd71, %fd40, 0d40E9230000000000;
	mul.f64 	%fd72, %fd71, %fd40;
	mul.f64 	%fd73, %fd72, %fd40;
	mul.f64 	%fd74, %fd73, %fd40;
	mul.f64 	%fd84, %fd74, %fd70;

BB130_50:
	st.param.f64	[func_retval0+0], %fd84;
	ret;
}

	// .globl	_Z18C6SmoothBump_tttomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z18C6SmoothBump_tttomddPdiPii(
	.param .b64 _Z18C6SmoothBump_tttomddPdiPii_param_0,
	.param .b64 _Z18C6SmoothBump_tttomddPdiPii_param_1,
	.param .b64 _Z18C6SmoothBump_tttomddPdiPii_param_2,
	.param .b32 _Z18C6SmoothBump_tttomddPdiPii_param_3,
	.param .b64 _Z18C6SmoothBump_tttomddPdiPii_param_4,
	.param .b32 _Z18C6SmoothBump_tttomddPdiPii_param_5
)
{
	.reg .pred 	%p<57>;
	.reg .b32 	%r<87>;
	.reg .f64 	%fd<93>;
	.reg .b64 	%rd<11>;


	ld.param.f64 	%fd40, [_Z18C6SmoothBump_tttomddPdiPii_param_0];
	ld.param.f64 	%fd41, [_Z18C6SmoothBump_tttomddPdiPii_param_1];
	mul.f64 	%fd1, %fd40, %fd41;
	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	setp.gt.f64	%p5, %fd1, 0d3FF0000000000000;
	or.pred  	%p6, %p4, %p5;
	mov.f64 	%fd92, 0d0000000000000000;
	@%p6 bra 	BB131_50;

	mov.f64 	%fd43, 0d3FF0000000000000;
	sub.f64 	%fd44, %fd43, %fd1;
	mul.f64 	%fd2, %fd1, %fd44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd45, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd45;
	}
	bfe.u32 	%r5, %r2, 20, 11;
	add.s32 	%r6, %r5, -1012;
	mov.u64 	%rd2, 4617315517961601024;
	shl.b64 	%rd1, %rd2, %r6;
	setp.eq.s64	%p7, %rd1, -9223372036854775808;
	abs.f64 	%fd3, %fd2;
	// Callseq Start 249
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd45;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd84, [retval0+0];
	
	//{
	}// Callseq End 249
	setp.lt.s32	%p8, %r1, 0;
	and.pred  	%p1, %p8, %p7;
	@!%p1 bra 	BB131_3;
	bra.uni 	BB131_2;

BB131_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd84;
	}
	xor.b32  	%r8, %r7, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd84;
	}
	mov.b64 	%fd84, {%r9, %r8};

BB131_3:
	setp.eq.f64	%p9, %fd2, 0d0000000000000000;
	@%p9 bra 	BB131_6;
	bra.uni 	BB131_4;

BB131_6:
	selp.b32	%r10, %r1, 0, %p7;
	or.b32  	%r11, %r10, 2146435072;
	setp.lt.s32	%p13, %r2, 0;
	selp.b32	%r12, %r11, %r10, %p13;
	mov.u32 	%r13, 0;
	mov.b64 	%fd84, {%r13, %r12};
	bra.uni 	BB131_7;

BB131_4:
	setp.gt.s32	%p10, %r1, -1;
	@%p10 bra 	BB131_7;

	cvt.rzi.f64.f64	%fd47, %fd45;
	setp.neu.f64	%p11, %fd47, 0d4014000000000000;
	selp.f64	%fd84, 0dFFF8000000000000, %fd84, %p11;

BB131_7:
	add.f64 	%fd85, %fd2, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd85;
	}
	and.b32  	%r15, %r14, 2146435072;
	setp.ne.s32	%p14, %r15, 2146435072;
	@%p14 bra 	BB131_8;

	setp.gtu.f64	%p15, %fd3, 0d7FF0000000000000;
	@%p15 bra 	BB131_17;

	and.b32  	%r16, %r2, 2147483647;
	setp.ne.s32	%p16, %r16, 2146435072;
	@%p16 bra 	BB131_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd45;
	}
	setp.eq.s32	%p17, %r17, 0;
	@%p17 bra 	BB131_16;

BB131_12:
	and.b32  	%r18, %r1, 2147483647;
	setp.ne.s32	%p18, %r18, 2146435072;
	@%p18 bra 	BB131_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd2;
	}
	setp.ne.s32	%p19, %r19, 0;
	mov.f64 	%fd85, %fd84;
	@%p19 bra 	BB131_17;

	shr.s32 	%r20, %r2, 31;
	and.b32  	%r21, %r20, -2146435072;
	add.s32 	%r22, %r21, 2146435072;
	or.b32  	%r23, %r22, -2147483648;
	selp.b32	%r24, %r23, %r22, %p1;
	mov.u32 	%r25, 0;
	mov.b64 	%fd85, {%r25, %r24};
	bra.uni 	BB131_17;

BB131_8:
	mov.f64 	%fd85, %fd84;
	bra.uni 	BB131_17;

BB131_13:
	mov.f64 	%fd85, %fd84;
	bra.uni 	BB131_17;

BB131_16:
	setp.gt.f64	%p20, %fd3, 0d3FF0000000000000;
	selp.b32	%r26, 2146435072, 0, %p20;
	xor.b32  	%r27, %r26, 2146435072;
	setp.lt.s32	%p21, %r2, 0;
	selp.b32	%r28, %r27, %r26, %p21;
	setp.eq.f64	%p22, %fd2, 0dBFF0000000000000;
	selp.b32	%r29, 1072693248, %r28, %p22;
	mov.u32 	%r30, 0;
	mov.b64 	%fd85, {%r30, %r29};

BB131_17:
	mov.f64 	%fd49, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd49;
	}
	bfe.u32 	%r31, %r3, 20, 11;
	add.s32 	%r32, %r31, -1012;
	mov.u64 	%rd3, 4616189618054758400;
	shl.b64 	%rd4, %rd3, %r32;
	setp.eq.s64	%p23, %rd4, -9223372036854775808;
	// Callseq Start 250
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd49;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd87, [retval0+0];
	
	//{
	}// Callseq End 250
	and.pred  	%p2, %p8, %p23;
	@!%p2 bra 	BB131_19;
	bra.uni 	BB131_18;

BB131_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd87;
	}
	xor.b32  	%r34, %r33, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd87;
	}
	mov.b64 	%fd87, {%r35, %r34};

BB131_19:
	@%p9 bra 	BB131_22;
	bra.uni 	BB131_20;

BB131_22:
	bfe.u32 	%r36, %r3, 20, 11;
	add.s32 	%r37, %r36, -1012;
	shl.b64 	%rd6, %rd3, %r37;
	setp.eq.s64	%p28, %rd6, -9223372036854775808;
	selp.b32	%r38, %r1, 0, %p28;
	or.b32  	%r39, %r38, 2146435072;
	setp.lt.s32	%p29, %r3, 0;
	selp.b32	%r40, %r39, %r38, %p29;
	mov.u32 	%r41, 0;
	mov.b64 	%fd87, {%r41, %r40};
	bra.uni 	BB131_23;

BB131_20:
	setp.gt.s32	%p26, %r1, -1;
	@%p26 bra 	BB131_23;

	cvt.rzi.f64.f64	%fd51, %fd49;
	setp.neu.f64	%p27, %fd51, 0d4010000000000000;
	selp.f64	%fd87, 0dFFF8000000000000, %fd87, %p27;

BB131_23:
	add.f64 	%fd88, %fd2, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd88;
	}
	and.b32  	%r43, %r42, 2146435072;
	setp.ne.s32	%p30, %r43, 2146435072;
	@%p30 bra 	BB131_24;

	setp.gtu.f64	%p31, %fd3, 0d7FF0000000000000;
	@%p31 bra 	BB131_33;

	and.b32  	%r44, %r3, 2147483647;
	setp.ne.s32	%p32, %r44, 2146435072;
	@%p32 bra 	BB131_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd49;
	}
	setp.eq.s32	%p33, %r45, 0;
	@%p33 bra 	BB131_32;

BB131_28:
	and.b32  	%r46, %r1, 2147483647;
	setp.ne.s32	%p34, %r46, 2146435072;
	@%p34 bra 	BB131_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd2;
	}
	setp.ne.s32	%p35, %r47, 0;
	mov.f64 	%fd88, %fd87;
	@%p35 bra 	BB131_33;

	shr.s32 	%r48, %r3, 31;
	and.b32  	%r49, %r48, -2146435072;
	add.s32 	%r50, %r49, 2146435072;
	or.b32  	%r51, %r50, -2147483648;
	selp.b32	%r52, %r51, %r50, %p2;
	mov.u32 	%r53, 0;
	mov.b64 	%fd88, {%r53, %r52};
	bra.uni 	BB131_33;

BB131_24:
	mov.f64 	%fd88, %fd87;
	bra.uni 	BB131_33;

BB131_29:
	mov.f64 	%fd88, %fd87;
	bra.uni 	BB131_33;

BB131_32:
	setp.gt.f64	%p36, %fd3, 0d3FF0000000000000;
	selp.b32	%r54, 2146435072, 0, %p36;
	xor.b32  	%r55, %r54, 2146435072;
	setp.lt.s32	%p37, %r3, 0;
	selp.b32	%r56, %r55, %r54, %p37;
	setp.eq.f64	%p38, %fd2, 0dBFF0000000000000;
	selp.b32	%r57, 1072693248, %r56, %p38;
	mov.u32 	%r58, 0;
	mov.b64 	%fd88, {%r58, %r57};

BB131_33:
	mul.f64 	%fd53, %fd41, 0dC000000000000000;
	fma.rn.f64 	%fd54, %fd53, %fd40, 0d3FF0000000000000;
	setp.eq.f64	%p39, %fd2, 0d3FF0000000000000;
	selp.f64	%fd55, 0d3FF0000000000000, %fd85, %p39;
	bfe.u32 	%r59, %r3, 20, 11;
	add.s32 	%r60, %r59, -1012;
	shl.b64 	%rd8, %rd3, %r60;
	setp.eq.s64	%p40, %rd8, -9223372036854775808;
	selp.f64	%fd56, 0d3FF0000000000000, %fd88, %p39;
	mul.f64 	%fd57, %fd54, 0d4014000000000000;
	mul.f64 	%fd58, %fd54, %fd57;
	mul.f64 	%fd59, %fd58, %fd56;
	fma.rn.f64 	%fd60, %fd55, 0dC018000000000000, %fd59;
	mul.f64 	%fd61, %fd54, 0d4045000000000000;
	mul.f64 	%fd62, %fd61, %fd60;
	mul.f64 	%fd24, %fd62, 0d4008000000000000;
	add.f64 	%fd63, %fd40, %fd40;
	mul.f64 	%fd64, %fd63, %fd41;
	sub.f64 	%fd66, %fd43, %fd64;
	mul.f64 	%fd67, %fd66, 0d4014000000000000;
	mul.f64 	%fd68, %fd66, %fd67;
	mul.f64 	%fd69, %fd68, %fd56;
	sub.f64 	%fd25, %fd55, %fd69;
	mul.f64 	%fd70, %fd54, %fd41;
	mul.f64 	%fd71, %fd70, %fd40;
	mul.f64 	%fd26, %fd44, %fd71;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd26;
	}
	abs.f64 	%fd27, %fd26;
	// Callseq Start 251
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd27;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd49;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd90, [retval0+0];
	
	//{
	}// Callseq End 251
	setp.lt.s32	%p41, %r4, 0;
	and.pred  	%p3, %p41, %p40;
	@!%p3 bra 	BB131_35;
	bra.uni 	BB131_34;

BB131_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd90;
	}
	xor.b32  	%r62, %r61, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd90;
	}
	mov.b64 	%fd90, {%r63, %r62};

BB131_35:
	setp.eq.f64	%p42, %fd26, 0d0000000000000000;
	@%p42 bra 	BB131_38;
	bra.uni 	BB131_36;

BB131_38:
	bfe.u32 	%r64, %r3, 20, 11;
	add.s32 	%r65, %r64, -1012;
	shl.b64 	%rd10, %rd3, %r65;
	setp.eq.s64	%p45, %rd10, -9223372036854775808;
	selp.b32	%r66, %r4, 0, %p45;
	or.b32  	%r67, %r66, 2146435072;
	setp.lt.s32	%p46, %r3, 0;
	selp.b32	%r68, %r67, %r66, %p46;
	mov.u32 	%r69, 0;
	mov.b64 	%fd90, {%r69, %r68};
	bra.uni 	BB131_39;

BB131_36:
	setp.gt.s32	%p43, %r4, -1;
	@%p43 bra 	BB131_39;

	cvt.rzi.f64.f64	%fd75, %fd49;
	setp.neu.f64	%p44, %fd75, 0d4010000000000000;
	selp.f64	%fd90, 0dFFF8000000000000, %fd90, %p44;

BB131_39:
	add.f64 	%fd91, %fd26, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd91;
	}
	and.b32  	%r71, %r70, 2146435072;
	setp.ne.s32	%p47, %r71, 2146435072;
	@%p47 bra 	BB131_40;

	setp.gtu.f64	%p48, %fd27, 0d7FF0000000000000;
	@%p48 bra 	BB131_49;

	and.b32  	%r72, %r3, 2147483647;
	setp.ne.s32	%p49, %r72, 2146435072;
	@%p49 bra 	BB131_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd49;
	}
	setp.eq.s32	%p50, %r73, 0;
	@%p50 bra 	BB131_48;

BB131_44:
	and.b32  	%r74, %r4, 2147483647;
	setp.ne.s32	%p51, %r74, 2146435072;
	@%p51 bra 	BB131_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd26;
	}
	setp.ne.s32	%p52, %r75, 0;
	mov.f64 	%fd91, %fd90;
	@%p52 bra 	BB131_49;

	shr.s32 	%r76, %r3, 31;
	and.b32  	%r77, %r76, -2146435072;
	add.s32 	%r78, %r77, 2146435072;
	or.b32  	%r79, %r78, -2147483648;
	selp.b32	%r80, %r79, %r78, %p3;
	mov.u32 	%r81, 0;
	mov.b64 	%fd91, {%r81, %r80};
	bra.uni 	BB131_49;

BB131_40:
	mov.f64 	%fd91, %fd90;
	bra.uni 	BB131_49;

BB131_45:
	mov.f64 	%fd91, %fd90;
	bra.uni 	BB131_49;

BB131_48:
	setp.gt.f64	%p53, %fd27, 0d3FF0000000000000;
	selp.b32	%r82, 2146435072, 0, %p53;
	xor.b32  	%r83, %r82, 2146435072;
	setp.lt.s32	%p54, %r3, 0;
	selp.b32	%r84, %r83, %r82, %p54;
	setp.eq.f64	%p55, %fd26, 0dBFF0000000000000;
	selp.b32	%r85, 1072693248, %r84, %p55;
	mov.u32 	%r86, 0;
	mov.b64 	%fd91, {%r86, %r85};

BB131_49:
	mul.f64 	%fd77, %fd91, 0d408A400000000000;
	setp.eq.f64	%p56, %fd26, 0d3FF0000000000000;
	selp.f64	%fd78, 0d408A400000000000, %fd77, %p56;
	fma.rn.f64 	%fd79, %fd25, 0d407F800000000000, %fd78;
	fma.rn.f64 	%fd80, %fd1, %fd79, %fd24;
	mul.f64 	%fd81, %fd40, 0d40E9230000000000;
	mul.f64 	%fd82, %fd81, %fd40;
	mul.f64 	%fd92, %fd82, %fd80;

BB131_50:
	st.param.f64	[func_retval0+0], %fd92;
	ret;
}

	// .globl	_Z19C6SmoothBump_ttomomddPdiPii
.visible .func  (.param .b64 func_retval0) _Z19C6SmoothBump_ttomomddPdiPii(
	.param .b64 _Z19C6SmoothBump_ttomomddPdiPii_param_0,
	.param .b64 _Z19C6SmoothBump_ttomomddPdiPii_param_1,
	.param .b64 _Z19C6SmoothBump_ttomomddPdiPii_param_2,
	.param .b32 _Z19C6SmoothBump_ttomomddPdiPii_param_3,
	.param .b64 _Z19C6SmoothBump_ttomomddPdiPii_param_4,
	.param .b32 _Z19C6SmoothBump_ttomomddPdiPii_param_5
)
{
	.reg .pred 	%p<75>;
	.reg .b32 	%r<114>;
	.reg .f64 	%fd<119>;
	.reg .b64 	%rd<13>;


	ld.param.f64 	%fd53, [_Z19C6SmoothBump_ttomomddPdiPii_param_0];
	ld.param.f64 	%fd54, [_Z19C6SmoothBump_ttomomddPdiPii_param_1];
	mul.f64 	%fd1, %fd53, %fd54;
	setp.lt.f64	%p5, %fd1, 0d0000000000000000;
	setp.gt.f64	%p6, %fd1, 0d3FF0000000000000;
	or.pred  	%p7, %p5, %p6;
	mov.f64 	%fd118, 0d0000000000000000;
	@%p7 bra 	BB132_66;

	mov.f64 	%fd56, 0d3FF0000000000000;
	sub.f64 	%fd2, %fd56, %fd1;
	mul.f64 	%fd3, %fd1, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd3;
	}
	mov.f64 	%fd57, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd57;
	}
	bfe.u32 	%r6, %r2, 20, 11;
	add.s32 	%r7, %r6, -1012;
	mov.u64 	%rd3, 4617315517961601024;
	shl.b64 	%rd1, %rd3, %r7;
	setp.eq.s64	%p8, %rd1, -9223372036854775808;
	abs.f64 	%fd4, %fd3;
	// Callseq Start 252
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd57;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd107, [retval0+0];
	
	//{
	}// Callseq End 252
	setp.lt.s32	%p9, %r1, 0;
	and.pred  	%p1, %p9, %p8;
	@!%p1 bra 	BB132_3;
	bra.uni 	BB132_2;

BB132_2:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd107;
	}
	xor.b32  	%r9, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd107;
	}
	mov.b64 	%fd107, {%r10, %r9};

BB132_3:
	setp.eq.f64	%p10, %fd3, 0d0000000000000000;
	@%p10 bra 	BB132_6;
	bra.uni 	BB132_4;

BB132_6:
	selp.b32	%r11, %r1, 0, %p8;
	or.b32  	%r12, %r11, 2146435072;
	setp.lt.s32	%p14, %r2, 0;
	selp.b32	%r13, %r12, %r11, %p14;
	mov.u32 	%r14, 0;
	mov.b64 	%fd107, {%r14, %r13};
	bra.uni 	BB132_7;

BB132_4:
	setp.gt.s32	%p11, %r1, -1;
	@%p11 bra 	BB132_7;

	cvt.rzi.f64.f64	%fd59, %fd57;
	setp.neu.f64	%p12, %fd59, 0d4014000000000000;
	selp.f64	%fd107, 0dFFF8000000000000, %fd107, %p12;

BB132_7:
	add.f64 	%fd108, %fd3, 0d4014000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd108;
	}
	and.b32  	%r16, %r15, 2146435072;
	setp.ne.s32	%p15, %r16, 2146435072;
	@%p15 bra 	BB132_8;

	setp.gtu.f64	%p16, %fd4, 0d7FF0000000000000;
	@%p16 bra 	BB132_17;

	and.b32  	%r17, %r2, 2147483647;
	setp.ne.s32	%p17, %r17, 2146435072;
	@%p17 bra 	BB132_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd57;
	}
	setp.eq.s32	%p18, %r18, 0;
	@%p18 bra 	BB132_16;

BB132_12:
	and.b32  	%r19, %r1, 2147483647;
	setp.ne.s32	%p19, %r19, 2146435072;
	@%p19 bra 	BB132_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd3;
	}
	setp.ne.s32	%p20, %r20, 0;
	mov.f64 	%fd108, %fd107;
	@%p20 bra 	BB132_17;

	shr.s32 	%r21, %r2, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r23, %r22, 2146435072;
	or.b32  	%r24, %r23, -2147483648;
	selp.b32	%r25, %r24, %r23, %p1;
	mov.u32 	%r26, 0;
	mov.b64 	%fd108, {%r26, %r25};
	bra.uni 	BB132_17;

BB132_8:
	mov.f64 	%fd108, %fd107;
	bra.uni 	BB132_17;

BB132_13:
	mov.f64 	%fd108, %fd107;
	bra.uni 	BB132_17;

BB132_16:
	setp.gt.f64	%p21, %fd4, 0d3FF0000000000000;
	selp.b32	%r27, 2146435072, 0, %p21;
	xor.b32  	%r28, %r27, 2146435072;
	setp.lt.s32	%p22, %r2, 0;
	selp.b32	%r29, %r28, %r27, %p22;
	setp.eq.f64	%p23, %fd3, 0dBFF0000000000000;
	selp.b32	%r30, 1072693248, %r29, %p23;
	mov.u32 	%r31, 0;
	mov.b64 	%fd108, {%r31, %r30};

BB132_17:
	setp.eq.f64	%p24, %fd3, 0d3FF0000000000000;
	selp.f64	%fd15, 0d3FF0000000000000, %fd108, %p24;
	mov.f64 	%fd61, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd61;
	}
	bfe.u32 	%r32, %r3, 20, 11;
	add.s32 	%r33, %r32, -1012;
	mov.u64 	%rd4, 4618441417868443648;
	shl.b64 	%rd2, %rd4, %r33;
	setp.eq.s64	%p25, %rd2, -9223372036854775808;
	// Callseq Start 253
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd110, [retval0+0];
	
	//{
	}// Callseq End 253
	and.pred  	%p2, %p9, %p25;
	@!%p2 bra 	BB132_19;
	bra.uni 	BB132_18;

BB132_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd110;
	}
	xor.b32  	%r35, %r34, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd110;
	}
	mov.b64 	%fd110, {%r36, %r35};

BB132_19:
	@%p10 bra 	BB132_22;
	bra.uni 	BB132_20;

BB132_22:
	selp.b32	%r37, %r1, 0, %p25;
	or.b32  	%r38, %r37, 2146435072;
	setp.lt.s32	%p31, %r3, 0;
	selp.b32	%r39, %r38, %r37, %p31;
	mov.u32 	%r40, 0;
	mov.b64 	%fd110, {%r40, %r39};
	bra.uni 	BB132_23;

BB132_20:
	setp.gt.s32	%p28, %r1, -1;
	@%p28 bra 	BB132_23;

	cvt.rzi.f64.f64	%fd63, %fd61;
	setp.neu.f64	%p29, %fd63, 0d4018000000000000;
	selp.f64	%fd110, 0dFFF8000000000000, %fd110, %p29;

BB132_23:
	add.f64 	%fd111, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd111;
	}
	and.b32  	%r42, %r41, 2146435072;
	setp.ne.s32	%p32, %r42, 2146435072;
	@%p32 bra 	BB132_24;

	setp.gtu.f64	%p33, %fd4, 0d7FF0000000000000;
	@%p33 bra 	BB132_33;

	and.b32  	%r43, %r3, 2147483647;
	setp.ne.s32	%p34, %r43, 2146435072;
	@%p34 bra 	BB132_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r44, %temp}, %fd61;
	}
	setp.eq.s32	%p35, %r44, 0;
	@%p35 bra 	BB132_32;

BB132_28:
	and.b32  	%r45, %r1, 2147483647;
	setp.ne.s32	%p36, %r45, 2146435072;
	@%p36 bra 	BB132_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd3;
	}
	setp.ne.s32	%p37, %r46, 0;
	mov.f64 	%fd111, %fd110;
	@%p37 bra 	BB132_33;

	shr.s32 	%r47, %r3, 31;
	and.b32  	%r48, %r47, -2146435072;
	add.s32 	%r49, %r48, 2146435072;
	or.b32  	%r50, %r49, -2147483648;
	selp.b32	%r51, %r50, %r49, %p2;
	mov.u32 	%r52, 0;
	mov.b64 	%fd111, {%r52, %r51};
	bra.uni 	BB132_33;

BB132_24:
	mov.f64 	%fd111, %fd110;
	bra.uni 	BB132_33;

BB132_29:
	mov.f64 	%fd111, %fd110;
	bra.uni 	BB132_33;

BB132_32:
	setp.gt.f64	%p38, %fd4, 0d3FF0000000000000;
	selp.b32	%r53, 2146435072, 0, %p38;
	xor.b32  	%r54, %r53, 2146435072;
	setp.lt.s32	%p39, %r3, 0;
	selp.b32	%r55, %r54, %r53, %p39;
	setp.eq.f64	%p40, %fd3, 0dBFF0000000000000;
	selp.b32	%r56, 1072693248, %r55, %p40;
	mov.u32 	%r57, 0;
	mov.b64 	%fd111, {%r57, %r56};

BB132_33:
	mov.f64 	%fd65, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd65;
	}
	bfe.u32 	%r58, %r4, 20, 11;
	add.s32 	%r59, %r58, -1012;
	mov.u64 	%rd5, 4616189618054758400;
	shl.b64 	%rd6, %rd5, %r59;
	setp.eq.s64	%p41, %rd6, -9223372036854775808;
	// Callseq Start 254
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd4;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd65;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd113, [retval0+0];
	
	//{
	}// Callseq End 254
	and.pred  	%p3, %p9, %p41;
	@!%p3 bra 	BB132_35;
	bra.uni 	BB132_34;

BB132_34:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r60}, %fd113;
	}
	xor.b32  	%r61, %r60, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r62, %temp}, %fd113;
	}
	mov.b64 	%fd113, {%r62, %r61};

BB132_35:
	@%p10 bra 	BB132_38;
	bra.uni 	BB132_36;

BB132_38:
	bfe.u32 	%r63, %r4, 20, 11;
	add.s32 	%r64, %r63, -1012;
	shl.b64 	%rd8, %rd5, %r64;
	setp.eq.s64	%p46, %rd8, -9223372036854775808;
	selp.b32	%r65, %r1, 0, %p46;
	or.b32  	%r66, %r65, 2146435072;
	setp.lt.s32	%p47, %r4, 0;
	selp.b32	%r67, %r66, %r65, %p47;
	mov.u32 	%r68, 0;
	mov.b64 	%fd113, {%r68, %r67};
	bra.uni 	BB132_39;

BB132_36:
	setp.gt.s32	%p44, %r1, -1;
	@%p44 bra 	BB132_39;

	cvt.rzi.f64.f64	%fd67, %fd65;
	setp.neu.f64	%p45, %fd67, 0d4010000000000000;
	selp.f64	%fd113, 0dFFF8000000000000, %fd113, %p45;

BB132_39:
	add.f64 	%fd114, %fd3, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd114;
	}
	and.b32  	%r70, %r69, 2146435072;
	setp.ne.s32	%p48, %r70, 2146435072;
	@%p48 bra 	BB132_40;

	setp.gtu.f64	%p49, %fd4, 0d7FF0000000000000;
	@%p49 bra 	BB132_49;

	and.b32  	%r71, %r4, 2147483647;
	setp.ne.s32	%p50, %r71, 2146435072;
	@%p50 bra 	BB132_44;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd65;
	}
	setp.eq.s32	%p51, %r72, 0;
	@%p51 bra 	BB132_48;

BB132_44:
	and.b32  	%r73, %r1, 2147483647;
	setp.ne.s32	%p52, %r73, 2146435072;
	@%p52 bra 	BB132_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd3;
	}
	setp.ne.s32	%p53, %r74, 0;
	mov.f64 	%fd114, %fd113;
	@%p53 bra 	BB132_49;

	shr.s32 	%r75, %r4, 31;
	and.b32  	%r76, %r75, -2146435072;
	add.s32 	%r77, %r76, 2146435072;
	or.b32  	%r78, %r77, -2147483648;
	selp.b32	%r79, %r78, %r77, %p3;
	mov.u32 	%r80, 0;
	mov.b64 	%fd114, {%r80, %r79};
	bra.uni 	BB132_49;

BB132_40:
	mov.f64 	%fd114, %fd113;
	bra.uni 	BB132_49;

BB132_45:
	mov.f64 	%fd114, %fd113;
	bra.uni 	BB132_49;

BB132_48:
	setp.gt.f64	%p54, %fd4, 0d3FF0000000000000;
	selp.b32	%r81, 2146435072, 0, %p54;
	xor.b32  	%r82, %r81, 2146435072;
	setp.lt.s32	%p55, %r4, 0;
	selp.b32	%r83, %r82, %r81, %p55;
	setp.eq.f64	%p56, %fd3, 0dBFF0000000000000;
	selp.b32	%r84, 1072693248, %r83, %p56;
	mov.u32 	%r85, 0;
	mov.b64 	%fd114, {%r85, %r84};

BB132_49:
	add.f64 	%fd69, %fd54, %fd54;
	mul.f64 	%fd70, %fd69, %fd53;
	sub.f64 	%fd72, %fd56, %fd70;
	bfe.u32 	%r86, %r4, 20, 11;
	add.s32 	%r87, %r86, -1012;
	shl.b64 	%rd10, %rd5, %r87;
	setp.eq.s64	%p57, %rd10, -9223372036854775808;
	selp.f64	%fd36, 0d3FF0000000000000, %fd114, %p24;
	mul.f64 	%fd73, %fd72, 0d4014000000000000;
	mul.f64 	%fd74, %fd72, %fd73;
	mul.f64 	%fd75, %fd74, %fd36;
	fma.rn.f64 	%fd76, %fd15, 0dC018000000000000, %fd75;
	mul.f64 	%fd77, %fd72, 0d4045000000000000;
	mul.f64 	%fd78, %fd77, %fd76;
	mul.f64 	%fd79, %fd53, 0d4010000000000000;
	mul.f64 	%fd80, %fd79, %fd54;
	mul.f64 	%fd81, %fd80, %fd78;
	mul.f64 	%fd82, %fd72, 0d4018000000000000;
	mul.f64 	%fd83, %fd72, %fd82;
	mul.f64 	%fd84, %fd83, %fd15;
	add.f64 	%fd85, %fd111, %fd111;
	selp.f64	%fd86, 0d4000000000000000, %fd85, %p24;
	sub.f64 	%fd87, %fd84, %fd86;
	mul.f64 	%fd88, %fd87, 0d401C000000000000;
	fma.rn.f64 	%fd37, %fd88, 0d4000000000000000, %fd81;
	mul.f64 	%fd89, %fd72, %fd54;
	mul.f64 	%fd90, %fd89, %fd53;
	mul.f64 	%fd38, %fd2, %fd90;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd38;
	}
	abs.f64 	%fd39, %fd38;
	// Callseq Start 255
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd39;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd65;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd116, [retval0+0];
	
	//{
	}// Callseq End 255
	setp.lt.s32	%p59, %r5, 0;
	and.pred  	%p4, %p59, %p57;
	@!%p4 bra 	BB132_51;
	bra.uni 	BB132_50;

BB132_50:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd116;
	}
	xor.b32  	%r89, %r88, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd116;
	}
	mov.b64 	%fd116, {%r90, %r89};

BB132_51:
	mul.f64 	%fd92, %fd53, 0dC000000000000000;
	fma.rn.f64 	%fd93, %fd92, %fd54, 0d3FF0000000000000;
	setp.eq.f64	%p60, %fd38, 0d0000000000000000;
	mul.f64 	%fd94, %fd93, 0dC014000000000000;
	mul.f64 	%fd95, %fd93, %fd94;
	fma.rn.f64 	%fd43, %fd95, %fd36, %fd15;
	@%p60 bra 	BB132_54;
	bra.uni 	BB132_52;

BB132_54:
	bfe.u32 	%r91, %r4, 20, 11;
	add.s32 	%r92, %r91, -1012;
	shl.b64 	%rd12, %rd5, %r92;
	setp.eq.s64	%p63, %rd12, -9223372036854775808;
	selp.b32	%r93, %r5, 0, %p63;
	or.b32  	%r94, %r93, 2146435072;
	setp.lt.s32	%p64, %r4, 0;
	selp.b32	%r95, %r94, %r93, %p64;
	mov.u32 	%r96, 0;
	mov.b64 	%fd116, {%r96, %r95};
	bra.uni 	BB132_55;

BB132_52:
	setp.gt.s32	%p61, %r5, -1;
	@%p61 bra 	BB132_55;

	cvt.rzi.f64.f64	%fd97, %fd65;
	setp.neu.f64	%p62, %fd97, 0d4010000000000000;
	selp.f64	%fd116, 0dFFF8000000000000, %fd116, %p62;

BB132_55:
	add.f64 	%fd117, %fd38, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd117;
	}
	and.b32  	%r98, %r97, 2146435072;
	setp.ne.s32	%p65, %r98, 2146435072;
	@%p65 bra 	BB132_56;

	setp.gtu.f64	%p66, %fd39, 0d7FF0000000000000;
	@%p66 bra 	BB132_65;

	and.b32  	%r99, %r4, 2147483647;
	setp.ne.s32	%p67, %r99, 2146435072;
	@%p67 bra 	BB132_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd65;
	}
	setp.eq.s32	%p68, %r100, 0;
	@%p68 bra 	BB132_64;

BB132_60:
	and.b32  	%r101, %r5, 2147483647;
	setp.ne.s32	%p69, %r101, 2146435072;
	@%p69 bra 	BB132_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r102, %temp}, %fd38;
	}
	setp.ne.s32	%p70, %r102, 0;
	mov.f64 	%fd117, %fd116;
	@%p70 bra 	BB132_65;

	shr.s32 	%r103, %r4, 31;
	and.b32  	%r104, %r103, -2146435072;
	add.s32 	%r105, %r104, 2146435072;
	or.b32  	%r106, %r105, -2147483648;
	selp.b32	%r107, %r106, %r105, %p4;
	mov.u32 	%r108, 0;
	mov.b64 	%fd117, {%r108, %r107};
	bra.uni 	BB132_65;

BB132_56:
	mov.f64 	%fd117, %fd116;
	bra.uni 	BB132_65;

BB132_61:
	mov.f64 	%fd117, %fd116;
	bra.uni 	BB132_65;

BB132_64:
	setp.gt.f64	%p71, %fd39, 0d3FF0000000000000;
	selp.b32	%r109, 2146435072, 0, %p71;
	xor.b32  	%r110, %r109, 2146435072;
	setp.lt.s32	%p72, %r4, 0;
	selp.b32	%r111, %r110, %r109, %p72;
	setp.eq.f64	%p73, %fd38, 0dBFF0000000000000;
	selp.b32	%r112, 1072693248, %r111, %p73;
	mov.u32 	%r113, 0;
	mov.b64 	%fd117, {%r113, %r112};

BB132_65:
	mul.f64 	%fd99, %fd117, 0d408A400000000000;
	setp.eq.f64	%p74, %fd38, 0d3FF0000000000000;
	selp.f64	%fd100, 0d408A400000000000, %fd99, %p74;
	fma.rn.f64 	%fd101, %fd43, 0d407F800000000000, %fd100;
	mul.f64 	%fd102, %fd53, %fd53;
	mul.f64 	%fd103, %fd102, %fd54;
	mul.f64 	%fd104, %fd103, %fd54;
	fma.rn.f64 	%fd105, %fd104, %fd101, %fd37;
	mul.f64 	%fd118, %fd105, 0d40E9230000000000;

BB132_66:
	st.param.f64	[func_retval0+0], %fd118;
	ret;
}

	// .weak	_ZN3cub11EmptyKernelIvEEvv
.weak .entry _ZN3cub11EmptyKernelIvEEvv(

)
{



	ret;
}

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot134[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<42>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<101>;


	mov.u64 	%SPL, __local_depot134;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd37, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd38, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd38;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	and.b32  	%r40, %r1, -2147483648;
	shr.u32 	%r3, %r1, 20;
	bfe.u32 	%r4, %r1, 20, 11;
	setp.eq.s32	%p1, %r4, 2047;
	@%p1 bra 	BB134_13;

	add.s32 	%r15, %r4, -1024;
	shr.u32 	%r16, %r15, 6;
	mov.u32 	%r17, 15;
	sub.s32 	%r5, %r17, %r16;
	mov.u32 	%r18, 19;
	sub.s32 	%r19, %r18, %r16;
	mov.u32 	%r20, 18;
	min.s32 	%r6, %r20, %r19;
	mov.u64 	%rd94, 0;
	setp.ge.s32	%p2, %r5, %r6;
	mov.u64 	%rd93, %rd1;
	@%p2 bra 	BB134_4;

	bfe.u32 	%r21, %r1, 20, 11;
	add.s32 	%r22, %r21, -1024;
	shr.u32 	%r23, %r22, 6;
	sub.s32 	%r25, %r17, %r23;
	mul.wide.s32 	%rd41, %r25, 8;
	mov.u64 	%rd42, __cudart_i2opi_d;
	add.s64 	%rd89, %rd42, %rd41;
	mov.b64 	 %rd43, %fd4;
	shl.b64 	%rd44, %rd43, 11;
	or.b64  	%rd5, %rd44, -9223372036854775808;
	mov.u64 	%rd94, 0;
	mov.u64 	%rd93, %rd1;
	mov.u64 	%rd91, %rd1;
	mov.u32 	%r39, %r5;

BB134_3:
	.pragma "nounroll";
	ld.const.u64 	%rd47, [%rd89];
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi, clo, chi;
	mov.b64         {alo,ahi}, %rd47;    
	mov.b64         {blo,bhi}, %rd5;    
	mov.b64         {clo,chi}, %rd94;    
	mad.lo.cc.u32   r0, alo, blo, clo;
	madc.hi.cc.u32  r1, alo, blo, chi;
	madc.hi.u32     r2, alo, bhi,   0;
	mad.lo.cc.u32   r1, alo, bhi,  r1;
	madc.hi.cc.u32  r2, ahi, blo,  r2;
	madc.hi.u32     r3, ahi, bhi,   0;
	mad.lo.cc.u32   r1, ahi, blo,  r1;
	madc.lo.cc.u32  r2, ahi, bhi,  r2;
	addc.u32        r3,  r3,   0;     
	mov.b64         %rd45, {r0,r1};      
	mov.b64         %rd94, {r2,r3};      
	}
	// inline asm
	st.local.u64 	[%rd91], %rd45;
	add.s32 	%r39, %r39, 1;
	sub.s32 	%r26, %r39, %r5;
	mul.wide.s32 	%rd50, %r26, 8;
	add.s64 	%rd91, %rd1, %rd50;
	add.s64 	%rd93, %rd93, 8;
	add.s64 	%rd89, %rd89, 8;
	setp.lt.s32	%p3, %r39, %r6;
	@%p3 bra 	BB134_3;

BB134_4:
	st.local.u64 	[%rd93], %rd94;
	ld.local.u64 	%rd95, [%rd1+16];
	ld.local.u64 	%rd96, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB134_6;

	mov.u32 	%r27, 64;
	sub.s32 	%r28, %r27, %r9;
	shl.b64 	%rd51, %rd96, %r9;
	shr.u64 	%rd52, %rd95, %r28;
	or.b64  	%rd96, %rd51, %rd52;
	shl.b64 	%rd53, %rd95, %r9;
	ld.local.u64 	%rd54, [%rd1+8];
	shr.u64 	%rd55, %rd54, %r28;
	or.b64  	%rd95, %rd55, %rd53;

BB134_6:
	shr.u64 	%rd56, %rd96, 62;
	cvt.u32.u64	%r29, %rd56;
	shr.u64 	%rd57, %rd95, 62;
	shl.b64 	%rd58, %rd96, 2;
	or.b64  	%rd98, %rd58, %rd57;
	shl.b64 	%rd97, %rd95, 2;
	shr.u64 	%rd59, %rd96, 61;
	cvt.u32.u64	%r30, %rd59;
	and.b32  	%r31, %r30, 1;
	add.s32 	%r32, %r31, %r29;
	neg.s32 	%r33, %r32;
	setp.eq.s32	%p5, %r40, 0;
	selp.b32	%r34, %r32, %r33, %p5;
	cvta.to.local.u64 	%rd60, %rd37;
	st.local.u32 	[%rd60], %r34;
	setp.eq.s32	%p6, %r31, 0;
	@%p6 bra 	BB134_8;

	mov.u64 	%rd64, 0;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd64;
	mov.b64         {a2,a3}, %rd64;
	mov.b64         {b0,b1}, %rd97;
	mov.b64         {b2,b3}, %rd98;
	sub.cc.u32      r0, a0, b0; 
	subc.cc.u32     r1, a1, b1; 
	subc.cc.u32     r2, a2, b2; 
	subc.u32        r3, a3, b3; 
	mov.b64         %rd97, {r0,r1};
	mov.b64         %rd98, {r2,r3};
	}
	// inline asm
	xor.b32  	%r40, %r40, -2147483648;

BB134_8:
	clz.b64 	%r41, %rd98;
	setp.eq.s32	%p7, %r41, 0;
	@%p7 bra 	BB134_10;

	shl.b64 	%rd67, %rd98, %r41;
	mov.u32 	%r35, 64;
	sub.s32 	%r36, %r35, %r41;
	shr.u64 	%rd68, %rd97, %r36;
	or.b64  	%rd98, %rd68, %rd67;

BB134_10:
	mov.u64 	%rd72, -3958705157555305931;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi;
	mov.b64         {alo,ahi}, %rd98;   
	mov.b64         {blo,bhi}, %rd72;   
	mul.lo.u32      r0, alo, blo;    
	mul.hi.u32      r1, alo, blo;    
	mad.lo.cc.u32   r1, alo, bhi, r1;
	madc.hi.u32     r2, alo, bhi,  0;
	mad.lo.cc.u32   r1, ahi, blo, r1;
	madc.hi.cc.u32  r2, ahi, blo, r2;
	madc.hi.u32     r3, ahi, bhi,  0;
	mad.lo.cc.u32   r2, ahi, bhi, r2;
	addc.u32        r3, r3,  0;      
	mov.b64         %rd69, {r0,r1};     
	mov.b64         %rd100, {r2,r3};     
	}
	// inline asm
	setp.lt.s64	%p8, %rd100, 1;
	@%p8 bra 	BB134_12;

	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd69;
	mov.b64         {a2,a3}, %rd100;
	mov.b64         {b0,b1}, %rd69;
	mov.b64         {b2,b3}, %rd100;
	add.cc.u32      r0, a0, b0; 
	addc.cc.u32     r1, a1, b1; 
	addc.cc.u32     r2, a2, b2; 
	addc.u32        r3, a3, b3; 
	mov.b64         %rd73, {r0,r1};
	mov.b64         %rd100, {r2,r3};
	}
	// inline asm
	add.s32 	%r41, %r41, 1;

BB134_12:
	cvt.u64.u32	%rd79, %r40;
	shl.b64 	%rd80, %rd79, 32;
	mov.u32 	%r37, 1022;
	sub.s32 	%r38, %r37, %r41;
	cvt.u64.u32	%rd81, %r38;
	shl.b64 	%rd82, %rd81, 52;
	add.s64 	%rd83, %rd100, 1;
	shr.u64 	%rd84, %rd83, 10;
	add.s64 	%rd85, %rd84, 1;
	shr.u64 	%rd86, %rd85, 1;
	add.s64 	%rd87, %rd86, %rd82;
	or.b64  	%rd88, %rd87, %rd80;
	mov.b64 	 %fd4, %rd88;

BB134_13:
	st.param.f64	[func_retval0+0], %fd4;
	ret;
}

.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<138>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	ld.param.f64 	%fd13, [__internal_accurate_pow_param_1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd12;
	}
	shr.u32 	%r51, %r50, 20;
	setp.ne.s32	%p1, %r51, 0;
	@%p1 bra 	BB135_2;

	mul.f64 	%fd14, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd14;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd14;
	}
	shr.u32 	%r16, %r50, 20;
	add.s32 	%r51, %r16, -54;

BB135_2:
	add.s32 	%r52, %r51, -1023;
	and.b32  	%r17, %r50, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd135, {%r49, %r18};
	setp.lt.u32	%p2, %r18, 1073127583;
	@%p2 bra 	BB135_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd135;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd135, {%r19, %r21};
	add.s32 	%r52, %r51, -1022;

BB135_4:
	add.f64 	%fd15, %fd135, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd16, %fd15;
	neg.f64 	%fd17, %fd15;
	mov.f64 	%fd18, 0d3FF0000000000000;
	fma.rn.f64 	%fd19, %fd17, %fd16, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd19, %fd19;
	fma.rn.f64 	%fd21, %fd20, %fd16, %fd16;
	add.f64 	%fd22, %fd135, 0dBFF0000000000000;
	mul.f64 	%fd23, %fd22, %fd21;
	fma.rn.f64 	%fd24, %fd22, %fd21, %fd23;
	mul.f64 	%fd25, %fd24, %fd24;
	mov.f64 	%fd26, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd27, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd28, %fd27, %fd25, %fd26;
	mov.f64 	%fd29, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd30, %fd28, %fd25, %fd29;
	mov.f64 	%fd31, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd32, %fd30, %fd25, %fd31;
	mov.f64 	%fd33, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd34, %fd32, %fd25, %fd33;
	mov.f64 	%fd35, 0d3F6249249242B910;
	fma.rn.f64 	%fd36, %fd34, %fd25, %fd35;
	mov.f64 	%fd37, 0d3F89999999999DFB;
	fma.rn.f64 	%fd38, %fd36, %fd25, %fd37;
	sub.f64 	%fd39, %fd22, %fd24;
	add.f64 	%fd40, %fd39, %fd39;
	neg.f64 	%fd41, %fd24;
	fma.rn.f64 	%fd42, %fd41, %fd22, %fd40;
	mul.f64 	%fd43, %fd21, %fd42;
	fma.rn.f64 	%fd44, %fd25, %fd38, 0d3FB5555555555555;
	mov.f64 	%fd45, 0d3FB5555555555555;
	sub.f64 	%fd46, %fd45, %fd44;
	fma.rn.f64 	%fd47, %fd25, %fd38, %fd46;
	add.f64 	%fd48, %fd47, 0d0000000000000000;
	add.f64 	%fd49, %fd48, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd50, %fd44, %fd49;
	sub.f64 	%fd51, %fd44, %fd50;
	add.f64 	%fd52, %fd49, %fd51;
	mul.rn.f64 	%fd53, %fd24, %fd24;
	neg.f64 	%fd54, %fd53;
	fma.rn.f64 	%fd55, %fd24, %fd24, %fd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd43;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd56, {%r22, %r24};
	fma.rn.f64 	%fd57, %fd24, %fd56, %fd55;
	mul.rn.f64 	%fd58, %fd53, %fd24;
	neg.f64 	%fd59, %fd58;
	fma.rn.f64 	%fd60, %fd53, %fd24, %fd59;
	fma.rn.f64 	%fd61, %fd53, %fd43, %fd60;
	fma.rn.f64 	%fd62, %fd57, %fd24, %fd61;
	mul.rn.f64 	%fd63, %fd50, %fd58;
	neg.f64 	%fd64, %fd63;
	fma.rn.f64 	%fd65, %fd50, %fd58, %fd64;
	fma.rn.f64 	%fd66, %fd50, %fd62, %fd65;
	fma.rn.f64 	%fd67, %fd52, %fd58, %fd66;
	add.f64 	%fd68, %fd63, %fd67;
	sub.f64 	%fd69, %fd63, %fd68;
	add.f64 	%fd70, %fd67, %fd69;
	add.f64 	%fd71, %fd24, %fd68;
	sub.f64 	%fd72, %fd24, %fd71;
	add.f64 	%fd73, %fd68, %fd72;
	add.f64 	%fd74, %fd70, %fd73;
	add.f64 	%fd75, %fd43, %fd74;
	add.f64 	%fd76, %fd71, %fd75;
	sub.f64 	%fd77, %fd71, %fd76;
	add.f64 	%fd78, %fd75, %fd77;
	xor.b32  	%r25, %r52, -2147483648;
	mov.u32 	%r26, 1127219200;
	mov.b64 	%fd79, {%r25, %r26};
	mov.u32 	%r27, -2147483648;
	mov.b64 	%fd80, {%r27, %r26};
	sub.f64 	%fd81, %fd79, %fd80;
	mov.f64 	%fd82, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd83, %fd81, %fd82, %fd76;
	neg.f64 	%fd84, %fd81;
	fma.rn.f64 	%fd85, %fd84, %fd82, %fd83;
	sub.f64 	%fd86, %fd85, %fd76;
	sub.f64 	%fd87, %fd78, %fd86;
	mov.f64 	%fd88, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd89, %fd81, %fd88, %fd87;
	add.f64 	%fd90, %fd83, %fd89;
	sub.f64 	%fd91, %fd83, %fd90;
	add.f64 	%fd92, %fd89, %fd91;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd13;
	}
	add.s32 	%r29, %r28, %r28;
	setp.gt.u32	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd13;
	}
	mov.b64 	%fd93, {%r32, %r31};
	mul.rn.f64 	%fd94, %fd90, %fd93;
	neg.f64 	%fd95, %fd94;
	fma.rn.f64 	%fd96, %fd90, %fd93, %fd95;
	fma.rn.f64 	%fd97, %fd92, %fd93, %fd96;
	add.f64 	%fd4, %fd94, %fd97;
	sub.f64 	%fd98, %fd94, %fd4;
	add.f64 	%fd5, %fd97, %fd98;
	mov.f64 	%fd99, 0d4338000000000000;
	mov.f64 	%fd100, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd101, %fd4, %fd100, %fd99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd101;
	}
	mov.f64 	%fd102, 0dC338000000000000;
	add.rn.f64 	%fd103, %fd101, %fd102;
	mov.f64 	%fd104, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd105, %fd103, %fd104, %fd4;
	mov.f64 	%fd106, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd107, %fd103, %fd106, %fd105;
	mov.f64 	%fd108, 0d3E928AF3FCA213EA;
	mov.f64 	%fd109, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd110, %fd109, %fd107, %fd108;
	mov.f64 	%fd111, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd112, %fd110, %fd107, %fd111;
	mov.f64 	%fd113, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd114, %fd112, %fd107, %fd113;
	mov.f64 	%fd115, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd116, %fd114, %fd107, %fd115;
	mov.f64 	%fd117, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd118, %fd116, %fd107, %fd117;
	mov.f64 	%fd119, 0d3F81111111122322;
	fma.rn.f64 	%fd120, %fd118, %fd107, %fd119;
	mov.f64 	%fd121, 0d3FA55555555502A1;
	fma.rn.f64 	%fd122, %fd120, %fd107, %fd121;
	mov.f64 	%fd123, 0d3FC5555555555511;
	fma.rn.f64 	%fd124, %fd122, %fd107, %fd123;
	mov.f64 	%fd125, 0d3FE000000000000B;
	fma.rn.f64 	%fd126, %fd124, %fd107, %fd125;
	fma.rn.f64 	%fd127, %fd126, %fd107, %fd18;
	fma.rn.f64 	%fd128, %fd127, %fd107, %fd18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd128;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd128;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd136, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	 %f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB135_7;

	setp.lt.f64	%p5, %fd4, 0d0000000000000000;
	add.f64 	%fd129, %fd4, 0d7FF0000000000000;
	selp.f64	%fd136, 0d0000000000000000, %fd129, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB135_7;

	mov.f64 	%fd134, 0d4338000000000000;
	mov.f64 	%fd133, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd132, %fd4, %fd133, %fd134;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd132;
	}
	shr.u32 	%r36, %r48, 31;
	add.s32 	%r37, %r48, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r39, %r15;
	mov.b64 	%fd130, {%r14, %r40};
	sub.s32 	%r41, %r48, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd131, {%r44, %r43};
	mul.f64 	%fd136, %fd130, %fd131;

BB135_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd136;
	}
	and.b32  	%r46, %r45, 2147483647;
	setp.ne.s32	%p7, %r46, 2146435072;
	@%p7 bra 	BB135_9;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd136;
	}
	setp.eq.s32	%p8, %r47, 0;
	@%p8 bra 	BB135_10;

BB135_9:
	fma.rn.f64 	%fd136, %fd136, %fd5, %fd136;

BB135_10:
	st.param.f64	[func_retval0+0], %fd136;
	ret;
}


